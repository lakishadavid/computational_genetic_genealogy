{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import urllib3\n",
    "from urllib3.util import Retry\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the environment know where bcftools is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\"):\n",
    "    \"\"\"\n",
    "    Configure logging for both file and console handlers.\n",
    "\n",
    "    Args:\n",
    "        log_filename (str): Path to the log file where logs will be written.\n",
    "        log_file_debug_level (str): Logging level for the file handler.\n",
    "        console_debug_level (str): Logging level for the console handler.\n",
    "    \"\"\"\n",
    "    # Create a root logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)  # Capture all messages at the root level\n",
    "\n",
    "    # Convert level names to numeric levels\n",
    "    file_level = getattr(logging, log_file_debug_level.upper(), logging.INFO)\n",
    "    console_level = getattr(logging, console_debug_level.upper(), logging.INFO)\n",
    "\n",
    "    # File handler: Logs messages at file_level and above to the file\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(file_level)\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "\n",
    "    # Console handler: Logs messages at console_level and above to the console\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(console_level)\n",
    "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "\n",
    "    # Add handlers to the root logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "def clear_logger():\n",
    "    \"\"\"Remove all handlers from the root logger.\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_logger() # Clear the logger before reconfiguring it\n",
    "configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Maps\n",
    "\n",
    "Genetic maps, also known as recombination maps, are essential tools that illustrate the relative positions of genetic markers (such as single nucleotide polymorphisms, or SNPs) along a chromosome. Unlike physical maps that measure distances in base pairs, genetic maps measure distances in centiMorgans (cM), where one centiMorgan represents a 1% probability of recombination between markers during meiosis.\n",
    "\n",
    "## Key Components of Genetic Maps\n",
    "\n",
    "- **Markers:**  \n",
    "  Identifiable DNA sequences used as reference points on the genome.\n",
    "\n",
    "- **Recombination Frequency:**  \n",
    "  The probability of a recombination event occurring between markers, which informs the genetic distances.\n",
    "\n",
    "- **Map Distance:**  \n",
    "  Expressed in centiMorgans (cM), reflecting the likelihood of recombination rather than the physical distance.\n",
    "\n",
    "## BEAGLE's Genetic Map\n",
    "\n",
    "BEAGLE is a widely used software package for phasing, genotype imputation, and identity-by-descent (IBD) analysis. Its performance is closely tied to the use of high-resolution genetic maps. Here are some distinctive features of BEAGLE's genetic map:\n",
    "\n",
    "- **High Marker Density:**  \n",
    "  The genetic maps provided with BEAGLE include a dense array of markers. This density allows for the precise capture of fine-scale recombination events, which in turn improves the accuracy of haplotype phasing and genotype imputation.\n",
    "\n",
    "- **Species and Population Specificity:**  \n",
    "  The maps are often developed from extensive pedigree or population studies. For human genetic studies, they are constructed based on large-scale recombination data, ensuring relevance to the population under study.\n",
    "\n",
    "- **Integration with Statistical Models:**  \n",
    "  BEAGLE utilizes these maps within its statistical algorithms to model recombination events effectively. This integration is crucial for accurately inferring missing genotypes and detecting IBD segments.\n",
    "\n",
    "- **Enhanced Analysis Accuracy:**  \n",
    "  The detailed recombination information in BEAGLE's genetic maps allows for better adjustment for linkage disequilibrium and recombination rates, ultimately leading to more robust downstream genetic analyses.\n",
    "\n",
    "## Benefits of Using BEAGLE's Genetic Map\n",
    "\n",
    "- **Improved Phasing Accuracy:**  \n",
    "  The high-resolution data facilitates precise haplotype reconstruction, reducing errors in phase determination.\n",
    "\n",
    "- **Robust Genotype Imputation:**  \n",
    "  Detailed recombination rate data enhances the accuracy of imputing missing genotypes, ensuring more reliable datasets.\n",
    "\n",
    "- **Streamlined Analysis Workflow:**  \n",
    "  The genetic map is specifically tailored to integrate seamlessly with BEAGLE\u2019s algorithms, thereby optimizing the overall analysis process.\n",
    "\n",
    "## References\n",
    "\n",
    "1. Browning, B. L., & Browning, S. R. (2007). *Rapid and Accurate Haplotype Phasing and Missing-Data Inference for Whole-Genome Association Studies by Use of Localized Haplotype Clustering*. [American Journal of Human Genetics](https://www.cell.com/AJHG/fulltext/S0002-9297(07)63882-8)\n",
    "2. Browning, B. L., Zhou, Y., & Browning, S. R. (2018). *A One-Penny Imputed Genome from Next-Generation Reference Panels*. [American Journal of Human Genetics](https://pubmed.ncbi.nlm.nih.gov/30100085/)\n",
    "3. [BEAGLE Documentation](https://faculty.washington.edu/browning/beagle/beagle.html)\n",
    "4. [NHGRI Glossary: Genetic Map](https://www.genome.gov/genetics-glossary/Genetic-Map)\n",
    "5. Li, Y., Willer, C., Sanna, S., & Abecasis, G. (2009). *Genotype Imputation*. [Annual Review of Genomics and Human Genetics](https://www.annualreviews.org/content/journals/10.1146/annurev.genom.9.081307.164242)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Genetic Maps (Beagle's plink version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define download helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session_with_retries():\n",
    "    \"\"\"Create a requests session with retry strategy\"\"\"\n",
    "    retry_strategy = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=0.5,\n",
    "        status_forcelist=[500, 502, 503, 504]\n",
    "    )\n",
    "    http = urllib3.PoolManager(retries=retry_strategy)\n",
    "    return http\n",
    "\n",
    "session = create_session_with_retries()\n",
    "\n",
    "def download_with_progress(url, output_path):\n",
    "    \"\"\"Download file with progress tracking\"\"\"\n",
    "    response = session.request('GET', url, preload_content=False)\n",
    "\n",
    "    if response.status != 200:\n",
    "        raise Exception(f\"HTTP error occurred: {response.status} {response.reason}\")\n",
    "    \n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 8192\n",
    "    progress_increment = max(1, total_size // 50) if total_size > 0 else block_size\n",
    "    \n",
    "    with open(output_path, 'wb') as f:\n",
    "        downloaded = 0\n",
    "        last_print = 0\n",
    "        while True:\n",
    "            chunk = response.read(block_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "                \n",
    "            f.write(chunk)\n",
    "            downloaded += len(chunk)\n",
    "            if total_size > 0 and downloaded - last_print >= progress_increment:\n",
    "                last_print = downloaded\n",
    "                progress = (downloaded / total_size) * 100\n",
    "                logging.info(f\"Download progress: {progress:.1f}%\")\n",
    "                \n",
    "    response.release_conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the genetic map files from Beagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_beagle(assembly, output_directory):\n",
    "    \"\"\"Downloads and processes Beagle genetic maps\"\"\"\n",
    "    assembly_map_files = {\n",
    "        \"GRCh36\": \"plink.GRCh36.map.zip\",\n",
    "        \"GRCh37\": \"plink.GRCh37.map.zip\",\n",
    "        \"GRCh38\": \"plink.GRCh38.map.zip\"\n",
    "    }\n",
    "\n",
    "    if assembly not in assembly_map_files:\n",
    "        raise ValueError(f\"Unsupported assembly '{assembly}'. Must be one of {list(assembly_map_files.keys())}.\")\n",
    "\n",
    "    file_name = assembly_map_files[assembly]\n",
    "    url = f\"https://bochet.gcc.biostat.washington.edu/beagle/genetic_maps/{file_name}\"\n",
    "    output_path = os.path.join(output_directory, file_name)\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Downloading Beagle map from {url}\")\n",
    "        download_with_progress(url, output_path)\n",
    "        \n",
    "        # Verify zip file integrity\n",
    "        try:\n",
    "            with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "                # Test zip file before extraction\n",
    "                test_result = zip_ref.testzip()\n",
    "                if test_result is not None:\n",
    "                    raise zipfile.BadZipFile(f\"Corrupted file found in ZIP: {test_result}\")\n",
    "                \n",
    "                # Extract files\n",
    "                logging.info(f\"Extracting files to {output_directory}\")\n",
    "                zip_ref.extractall(output_directory)\n",
    "                \n",
    "                # Log extracted files\n",
    "                extracted_files = zip_ref.namelist()\n",
    "                logging.info(f\"Extracted {len(extracted_files)} files: {', '.join(extracted_files)}\")\n",
    "        \n",
    "        except zipfile.BadZipFile as e:\n",
    "            raise Exception(f\"Invalid ZIP file downloaded: {str(e)}\")\n",
    "        \n",
    "        # Clean up zip file\n",
    "        os.remove(output_path)\n",
    "        logging.info(\"ZIP file cleaned up\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing Beagle files: {str(e)}\")\n",
    "        if os.path.exists(output_path):\n",
    "            os.remove(output_path)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Resource\n",
    "\n",
    "Take a look at your `genetic_maps` directory. You should see the `beagle_genetic_maps` directory. Within `beagle_genetic_maps`, you should see your genetic map files, one for each chromosome. The naming convention is `plink.chr{chromosome_number}.GRCh38.map`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VCF Quality Control and Processing Pipeline\n",
    "\n",
    "This script implements a comprehensive quality control (QC) and processing pipeline for merged VCF files, designed specifically for downstream genetic analyses (e.g., genetic genealogy). The pipeline integrates several tools (e.g., PLINK2, bcftools, Beagle) to perform quality control, filtering, and conversion of VCF files into other formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Code Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the Merged VCF file as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select your VCF file**\n",
    "\n",
    "In the next cell, uncomment the file you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vcf_file = os.path.join(results_directory, \"merged_sample_autosomes_unphased.vcf.gz\")\n",
    "# vcf_directory = os.path.join(results_directory, \"real_data_autosomes\")\n",
    "\n",
    "vcf_file = os.path.join(results_directory, \"ped_sim_run2.vcf.gz\")\n",
    "vcf_directory = os.path.join(results_directory, \"ped_sim_run2_autosomes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def validate_merged_vcf(vcf_path):\n",
    "    \"\"\"Validate merged VCF and extract available chromosomes.\"\"\"\n",
    "    cmd_counts = [\"bcftools\", \"plugin\", \"counts\", vcf_path]\n",
    "    result_counts = subprocess.run(cmd_counts, capture_output=True, text=True, check=True)\n",
    "    logging.info(f\"Plugin 'counts' validation output for {vcf_path}:\\n{result_counts.stdout}\")\n",
    "    if result_counts.stderr:\n",
    "        logging.info(f\"Plugin 'counts' validation errors:\\n{result_counts.stderr}\")\n",
    "\n",
    "    num_samples = 0\n",
    "    for line in result_counts.stdout.splitlines():\n",
    "        if line.startswith(\"Number of samples:\"):\n",
    "            parts = line.split(\":\")\n",
    "            if len(parts) == 2:\n",
    "                num_samples = int(parts[1].strip())\n",
    "    if not num_samples:\n",
    "        logging.error(f\"No sample count found in VCF file: {vcf_path}\")\n",
    "\n",
    "    num_snps = 0\n",
    "    for line in result_counts.stdout.splitlines():\n",
    "        if line.startswith(\"Number of SNPs:\"):\n",
    "            parts = line.split(\":\")\n",
    "            if len(parts) == 2:\n",
    "                num_snps = int(parts[1].strip())\n",
    "    if not num_snps:\n",
    "        logging.error(f\"No sample count found in VCF file: {vcf_path}\")\n",
    "\n",
    "\n",
    "    logging.info(\"Extracting list of chromosomes from the VCF header.\")\n",
    "    cmd_chrom_contig = f\"bcftools view -h {vcf_path} | grep '^##contig' | cut -d'=' -f3 | cut -d',' -f1\"\n",
    "    result_chrom_contig = subprocess.run(cmd_chrom_contig, shell=True, capture_output=True, text=True, check=True)\n",
    "    chromosomes_contig = result_chrom_contig.stdout.splitlines()\n",
    "    if not chromosomes_contig:\n",
    "        logging.error(f\"No chromosomes found in VCF file: {vcf_path}\")\n",
    "    else:\n",
    "        logging.debug(f\"Chromosomes found in VCF file header: {', '.join(chromosomes_contig)}\")\n",
    "\n",
    "\n",
    "    logging.info(\"Extracting a list of chromosomes from the CHROM column..\")\n",
    "    cmd_chrom_field = f\"bcftools query -f '%CHROM\\n' {vcf_path} | sort -u\"\n",
    "    result_chrom_field = subprocess.run(cmd_chrom_field, shell=True, capture_output=True, text=True, check=True)\n",
    "    chromosomes_field = result_chrom_field.stdout.splitlines()\n",
    "    if not chromosomes_field:\n",
    "        logging.error(f\"No chromosomes found in VCF file in the CHROM field: {vcf_path}\")\n",
    "    else:\n",
    "        logging.debug(f\"Chromosomes found in VCF file in the CHROM field: {', '.join(chromosomes_field)}\")\n",
    "\n",
    "\n",
    "    if chromosomes_contig != chromosomes_field:\n",
    "        logging.error(\"Mismatch between chromosomes in contig and field headers.\")\n",
    "        logging.error(f\"Contig chromosomes: {chromosomes_contig}\")\n",
    "        logging.error(f\"Field chromosomes: {chromosomes_field}\")\n",
    "\n",
    "\n",
    "    logging.info(\"Extracting sample IDs from the VCF file.\")\n",
    "    cmd_sample_list = [\"bcftools\", \"query\", \"-l\", vcf_path]\n",
    "    result_sample_list = subprocess.run(cmd_sample_list, capture_output=True, text=True, check=True)\n",
    "    sample_ids = result_sample_list.stdout.splitlines()\n",
    "\n",
    "    if not sample_ids:\n",
    "        logging.error(f\"No sample IDs found in VCF file: {vcf_path}\")\n",
    "    else:\n",
    "        logging.debug(f\"Sample IDs found in VCF file: {', '.join(sample_ids)}\")\n",
    "\n",
    "    return num_samples, num_snps, chromosomes_field, sample_ids\n",
    "\n",
    "\n",
    "# VCF created in Lab3 Get Raw DNA Profile\n",
    "num_samples, num_snps, chromosomes, sample_ids = validate_merged_vcf(vcf_file)\n",
    "print(num_samples, num_snps, chromosomes, sample_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The ERROR between the Contig chromosomes and Field chromosomes are okay for now. Try to see why there is an error here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the Supplemental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sex_determination(determined_sex_file, failed_sex):\n",
    "    \"\"\"Parse the sex determination log and create a mapping of user IDs to sexes.\"\"\"\n",
    "    sex_mapping = {}\n",
    "    with open(determined_sex_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:  # Skip empty lines\n",
    "            continue\n",
    "\n",
    "        user_id, sex = line.split(\"\\t\")\n",
    "        sex_mapping[user_id] = \"1\" if sex == \"Male\" else \"2\"\n",
    "\n",
    "    with open(failed_sex, 'r') as p:\n",
    "        lines = p.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        user_id, sex = line.split(\"\\t\")\n",
    "        sex_mapping[user_id] = \"0\" # Unknown sex\n",
    "\n",
    "    # Count occurrences of each sex code\n",
    "    counts = Counter(sex_mapping.values())\n",
    "\n",
    "    # Print results\n",
    "    logging.info(f\"Count of SEX=0 (Unknown): {counts['0']}\")\n",
    "    logging.info(f\"Count of SEX=1 (Male): {counts['1']}\")\n",
    "    logging.info(f\"Count of SEX=2 (Female): {counts['2']}\")\n",
    "\n",
    "    return sex_mapping\n",
    "\n",
    "def write_sex_files(sex_mapping, sample_ids, psam_file_all, psam_file_Y, sex_update_file):\n",
    "    \"\"\"Write both PLINK2-compatible .psam files and sex update file.\"\"\"\n",
    "    \n",
    "    # Reorder sex_mapping based on sample_ids\n",
    "    ordered_sex_mapping = {sample_id: sex_mapping.get(sample_id, \"0\") for sample_id in sample_ids}\n",
    "    \n",
    "    # Write standard .psam file for all chromosomes\n",
    "    with open(psam_file_all, 'w') as f:\n",
    "        f.write(\"#FID\\tIID\\tSEX\\n\")  # Header for .psam file\n",
    "        for user_id, sex_code in ordered_sex_mapping.items():\n",
    "            if sex_code == \"0\":\n",
    "                continue  # Exclude unknown sexes\n",
    "            f.write(f\"{user_id}\\t{user_id}\\t{sex_code}\\n\")\n",
    "    \n",
    "    # Write .psam file for Y chromosome (males only)\n",
    "    with open(psam_file_Y, 'w') as f:\n",
    "        f.write(\"#FID\\tIID\\tSEX\\n\")\n",
    "        for user_id, sex_code in ordered_sex_mapping.items():\n",
    "            if sex_code != \"1\":\n",
    "                continue  # Exclude non-males\n",
    "            f.write(f\"{user_id}\\t{user_id}\\t{sex_code}\\n\")\n",
    "    \n",
    "    # Write sex update file for PLINK2 --update-sex\n",
    "    with open(sex_update_file, 'w') as f:\n",
    "        f.write(\"#IID\\tSEX\\n\")  # PLINK2 format for sex update\n",
    "        for user_id, sex_code in ordered_sex_mapping.items():\n",
    "            if sex_code == \"0\":\n",
    "                continue  # Exclude unknown sexes\n",
    "            f.write(f\"{user_id}\\t{sex_code}\\n\")\n",
    "            \n",
    "\n",
    "determined_sex_file = f\"{data_directory}/class_data/determined_sex.txt\"\n",
    "failed_sex = f\"{data_directory}/class_data/failed_sex.txt\"\n",
    "\n",
    "sex_mapping = parse_sex_determination(determined_sex_file, failed_sex)\n",
    "base_name = os.path.splitext(determined_sex_file)[0]\n",
    "psam_file_all = f\"{base_name}_all.psam\"\n",
    "psam_file_Y = f\"{base_name}_Y.psam\"\n",
    "sex_update_file = f\"{base_name}_update_sex.txt\"\n",
    "write_sex_files(sex_mapping, sample_ids, psam_file_all, psam_file_Y, sex_update_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Base Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$vcf_file\" \"$vcf_directory\"\n",
    "\n",
    "vcf_file=\"$1\"\n",
    "vcf_directory=\"$2\"\n",
    "\n",
    "# Extract the file prefix (removing .vcf.gz extension)\n",
    "output_prefix=\"${vcf_file%.vcf.gz}\"\n",
    "base_name=$(basename \"$output_prefix\")\n",
    "bgzip -d \"$vcf_file\"\n",
    "bgzip \"${output_prefix}.vcf\"\n",
    "\n",
    "unphased_samples_directory=\"${vcf_directory}/unphased_samples\"\n",
    "mkdir -p \"$unphased_samples_directory\"\n",
    "\n",
    "# Define input and output files\n",
    "input_vcf=\"${vcf_file}\"\n",
    "temp_prefix=\"${results_directory}/temp\"\n",
    "bcftools index -t -f \"$input_vcf\"\n",
    "\n",
    "for chromosome in {1..22}; do\n",
    "    echo \"Processing chromosome ${chromosome}...\"\n",
    "    \n",
    "    output_vcf=\"${vcf_directory}/unphased_samples/${base_name}_qcfinished_chr${chromosome}.vcf.gz\"\n",
    "    \n",
    "    # Extended QC pipeline:\n",
    "    # 1. Select autosomal chromosome\n",
    "    # 2. Keep only biallelic SNPs\n",
    "    # -m2 keeps only variants with at least 2 alleles\n",
    "    # -M2 keeps only variants with at most 2 alleles\n",
    "    # could add: -i 'strlen(REF)=1 && strlen(ALT)=1' | \\\n",
    "    # 3. Remove exact duplicate variants\n",
    "    # 4. Filter on MAF and missing data\n",
    "    # 5. Sort variants\n",
    "    bcftools view \"$input_vcf\" \\\n",
    "        --regions \"${chromosome}\" \\\n",
    "        --types snps \\\n",
    "        -m2 -M2 \\\n",
    "        -i 'strlen(REF)=1 && strlen(ALT)=1' | \\\n",
    "    bcftools norm --rm-dup exact | \\\n",
    "    bcftools view \\\n",
    "        -q 0.05:minor \\\n",
    "        -i 'F_MISSING < 0.05' | \\\n",
    "    bcftools sort -Oz -o \"$output_vcf\"\n",
    "    \n",
    "    # Index the final VCF with force flag\n",
    "    bcftools index -f \"$output_vcf\"\n",
    "    \n",
    "    # Report number of variants\n",
    "    echo \"Number of variants in chromosome ${chromosome} after QC:\"\n",
    "    bcftools index -n \"$output_vcf\"\n",
    "    echo\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$vcf_file\" \"$vcf_directory\"\n",
    "\n",
    "vcf_file=\"$1\"\n",
    "vcf_directory=\"$2\"\n",
    "echo \"vcf_file: $vcf_file\"\n",
    "echo \"vcf_directory: $vcf_directory\"\n",
    "\n",
    "# Extract the file prefix (removing .vcf.gz extension)\n",
    "output_prefix=\"${vcf_file%.vcf.gz}\"\n",
    "# Get base name of the VCF file\n",
    "base_name=$(basename \"$output_prefix\")\n",
    "echo \"base_name: ${base_name}\"\n",
    "\n",
    "unphased_directory=\"${vcf_directory}/unphased_samples\"\n",
    "phased_directory=\"${vcf_directory}/phased_samples\"\n",
    "beagle=\"${UTILS_DIRECTORY}/beagle.17Dec24.224.jar\"\n",
    "\n",
    "# Create the phased directory if it does not exist\n",
    "mkdir -p \"$phased_directory\"\n",
    "\n",
    "# Phase chromosomes using Beagle\n",
    "for chr in {1..22}; do\n",
    "    echo \"Processing chromosome ${chr}\"\n",
    "\n",
    "    INPUT_VCF=\"${unphased_directory}/${base_name}_qcfinished_chr${chr}.vcf.gz\"\n",
    "    REF_VCF=\"${REFERENCES_DIRECTORY}/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr${chr}.vcf.gz\"\n",
    "    MAP_FILE=\"${REFERENCES_DIRECTORY}/genetic_maps/beagle_genetic_maps/plink.chr${chr}.GRCh38.map\"\n",
    "    OUTPUT_PREFIX=\"${phased_directory}/${base_name}_phased_chr${chr}_temp\"\n",
    "    PHASED_VCF=\"${OUTPUT_PREFIX}.vcf.gz\"\n",
    "    TEMP_VCF=\"${phased_directory}/temp_chr${chr}.vcf.gz\"\n",
    "    SORTED_VCF=\"${phased_directory}/${base_name}_phased_chr${chr}.vcf.gz\"\n",
    "\n",
    "    # Check if input VCF exists\n",
    "    if [ ! -f \"${INPUT_VCF}\" ]; then\n",
    "        echo \"Input VCF file not found for chromosome ${chr}. Skipping.\"\n",
    "        echo \"${INPUT_VCF}\"\n",
    "        continue\n",
    "    fi\n",
    "\n",
    "    # Run Beagle phasing\n",
    "    if [ -f \"${REF_VCF}\" ]; then\n",
    "        echo \"Running Beagle with reference panel for chromosome ${chr}\"\n",
    "        java -jar ${beagle} \\\n",
    "            gt=\"${INPUT_VCF}\" \\\n",
    "            ref=\"${REF_VCF}\" \\\n",
    "            map=\"${MAP_FILE}\" \\\n",
    "            out=\"${OUTPUT_PREFIX}\" || {\n",
    "                echo \"Beagle failed for chromosome ${chr}. Skipping.\"\n",
    "                continue\n",
    "            }\n",
    "    else\n",
    "        echo \"Running Beagle without reference panel for chromosome ${chr}\"\n",
    "        java -jar ${beagle} \\\n",
    "            gt=\"${INPUT_VCF}\" \\\n",
    "            map=\"${MAP_FILE}\" \\\n",
    "            out=\"${OUTPUT_PREFIX}\" || {\n",
    "                echo \"Beagle failed for chromosome ${chr}. Skipping.\"\n",
    "                continue\n",
    "            }\n",
    "    fi\n",
    "\n",
    "    if [ ! -f \"${PHASED_VCF}\" ]; then\n",
    "        echo \"Phasing failed for chromosome ${chr}. Output file not found. Skipping.\"\n",
    "        continue\n",
    "    fi\n",
    "\n",
    "    # Index the file\n",
    "    tabix -f -p vcf \"${PHASED_VCF}\"\n",
    "    \n",
    "    # Add INFO field definition and sort\n",
    "    echo \"Sorting VCF for chromosome $CHR\"\n",
    "    bcftools annotate --header-lines <(echo '##INFO=<ID=END,Number=1,Type=Integer,Description=\"End position of the variant\">') \"${PHASED_VCF}\" | \\\n",
    "    bcftools sort -Oz -o \"${SORTED_VCF}\" || {\n",
    "        echo \"Sorting failed for chromosome $CHR\"\n",
    "        continue\n",
    "    }\n",
    "\n",
    "    # Index the sorted file\n",
    "    tabix -f -p vcf \"${SORTED_VCF}\"\n",
    "    \n",
    "    # If the sorted vcf and index exists, remove phased vcf and index\n",
    "    if [ -f \"${SORTED_VCF}\" ] && [ -f \"${SORTED_VCF}.tbi\" ]; then\n",
    "        rm -f \"${PHASED_VCF}\"\n",
    "        rm -f \"${PHASED_VCF}.tbi\"\n",
    "        rm -f \"${PHASED_VCF}.log\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's generate some stats on our files to manually inspect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$vcf_file\" \"$vcf_directory\"\n",
    "\n",
    "vcf_file=\"$1\"\n",
    "vcf_directory=\"$2\"\n",
    "echo \"vcf_file: $vcf_file\"\n",
    "echo \"vcf_directory: $vcf_directory\"\n",
    "\n",
    "# Extract the file prefix (removing .vcf.gz extension)\n",
    "output_prefix=\"${vcf_file%.vcf.gz}\"\n",
    "# Get base name of the VCF file\n",
    "base_name=$(basename \"$output_prefix\")\n",
    "echo \"base_name: ${base_name}\"\n",
    "\n",
    "phased_directory=\"${vcf_directory}/phased_samples\"\n",
    "\n",
    "# Generate stats for each chromosome\n",
    "for chr in {1..22}; do\n",
    "    PHASED_VCF=\"${phased_directory}/${base_name}_phased_chr${chr}.vcf.gz\"\n",
    "    echo \"PHASED_VCF: ${PHASED_VCF}\"\n",
    "    if [ -f \"$PHASED_VCF\" ]; then\n",
    "        STATS_OUTPUT=\"${phased_directory}/${base_name}_phased_chr${chr}_stats.vchk\"\n",
    "        bcftools stats -s - \"$PHASED_VCF\" > \"$STATS_OUTPUT\"\n",
    "        echo \"Stats generated for chromosome $chr. See: $STATS_OUTPUT\"\n",
    "    else\n",
    "        echo \"Phased VCF not found for chromosome $chr. Skipping stats generation.\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat the by-chromosome files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$vcf_file\" \"$vcf_directory\"\n",
    "\n",
    "vcf_file=\"$1\"\n",
    "vcf_directory=\"$2\"\n",
    "echo \"vcf_file: $vcf_file\"\n",
    "echo \"vcf_directory: $vcf_directory\"\n",
    "\n",
    "# Extract the file prefix (removing .vcf.gz extension)\n",
    "output_prefix=\"${vcf_file%.vcf.gz}\"\n",
    "# Get base name of the VCF file\n",
    "base_name=$(basename \"$output_prefix\")\n",
    "echo \"base_name: ${base_name}\"\n",
    "\n",
    "phased_directory=\"${vcf_directory}/phased_samples\"\n",
    "\n",
    "merged_vcf=\"${RESULTS_DIRECTORY}/${base_name}_autosomes.vcf.gz\"\n",
    "\n",
    "# List of sorted VCFs\n",
    "vcf_list=()\n",
    "for chr in {1..22}; do\n",
    "    SORTED_VCF=\"${phased_directory}/${base_name}_phased_chr${chr}.vcf.gz\"\n",
    "    if [ -f \"$SORTED_VCF\" ]; then\n",
    "        vcf_list+=(\"$SORTED_VCF\")\n",
    "    else\n",
    "        echo \"Missing sorted VCF for chromosome ${chr}, skipping.\"\n",
    "        echo \"Missing $SORTED_VCF\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "# Merge all VCFs\n",
    "if [ ${#vcf_list[@]} -gt 0 ]; then\n",
    "    echo \"Merging phased VCFs into a single autosomal file...\"\n",
    "    bcftools concat -Oz -o \"${merged_vcf}\" \"${vcf_list[@]}\" || { echo \"Merging failed.\"; exit 1; }\n",
    "\n",
    "    # Index the merged VCF\n",
    "    tabix -f -p vcf \"${merged_vcf}\"\n",
    "    echo \"Merged VCF created at ${merged_vcf}\"\n",
    "else\n",
    "    echo \"No VCFs available for merging.\"\n",
    "fi\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}