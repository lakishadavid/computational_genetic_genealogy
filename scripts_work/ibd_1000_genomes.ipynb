{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a99bf5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lakishadavid/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/__init__.py:10: Warning: Version not available for package utils.bonsaitree.bonsaitree (is it installed?)\n",
      "  warnings.warn(\"Version not available for package %s (is it installed?)\" % __package__,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading genetic data...\n",
      "Loading ID mapping from ../data/class_data/ped_sim_run2.seg_dict.txt\n",
      "Loaded 520 ID mappings\n",
      "Number of unique individuals in seg file: 520\n",
      "Loaded metadata for 520 individuals from FAM file\n",
      "\n",
      "Sample of individuals data:\n",
      "FAM1_g1-b1-s1: {'family_id': 'FAM1', 'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 1}\n",
      "FAM1_g1-b1-i1: {'family_id': 'FAM1', 'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 1}\n",
      "FAM1_g2-b1-s1: {'family_id': 'FAM1', 'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 2}\n",
      "\n",
      "Individuals by generation:\n",
      "Generation 1: 20 individuals\n",
      "Generation 2: 40 individuals\n",
      "Generation 3: 80 individuals\n",
      "Generation 4: 120 individuals\n",
      "Generation 5: 160 individuals\n",
      "Generation 6: 100 individuals\n",
      "Reference population file not found. Creating empty DataFrame.\n",
      "Found 0 reference populations:\n",
      "Total unique samples in IBD data: 520\n",
      "Samples in reference panel: 0\n",
      "Project samples identified: 520\n",
      "Limiting analysis to first 10 samples for demonstration\n",
      "\n",
      "Processing sample 1/10: 1000\n",
      "\n",
      "Running ancestry analysis for sample: 1000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'int64'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1164\u001b[0m\n\u001b[1;32m   1162\u001b[0m fam_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/class_data/ped_sim_run2-everyone.fam\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1163\u001b[0m dict_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/class_data/ped_sim_run2.seg_dict.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1164\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfam_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 1146\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(seg_file, fam_file, dict_file, output_dir, rfmix_dir, sample_list)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     project_samples \u001b[38;5;241m=\u001b[39m project_samples[:\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;66;03m# Run batch analysis\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_ancestry_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfmix_dir\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnalysis pipeline completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 1042\u001b[0m, in \u001b[0;36mbatch_ancestry_analysis\u001b[0;34m(project_samples, segments, sample_df, output_dir, rfmix_dir, chromosome_lengths)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             rfmix_file \u001b[38;5;241m=\u001b[39m potential_file\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# Run analysis for this sample\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_ancestry_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfmix_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchromosome_lengths\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m     all_results[sample_id] \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# Create summary across all samples\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 941\u001b[0m, in \u001b[0;36mrun_ancestry_analysis\u001b[0;34m(sample_id, segments, sample_df, output_dir, rfmix_file, chromosome_lengths)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# Create output directory\u001b[39;00m\n\u001b[1;32m    940\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 941\u001b[0m sample_dir \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    942\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(sample_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# Extract reference populations\u001b[39;00m\n",
      "File \u001b[0;32m<frozen posixpath>:90\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
      "File \u001b[0;32m<frozen genericpath>:164\u001b[0m, in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'int64'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from matplotlib.colors import to_rgba\n",
    "import matplotlib.patches as mpatches\n",
    "import sys\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "# Assuming utils.bonsaitree.bonsaitree.v3 is properly installed\n",
    "try:\n",
    "    from utils.bonsaitree.bonsaitree.v3 import bonsai\n",
    "except ImportError:\n",
    "    print(\"Warning: Unable to import bonsai module. Pedigree reconstruction functions will not work.\")\n",
    "\n",
    "#######################\n",
    "# 1. Data Preparation #\n",
    "#######################\n",
    "def load_genetic_data(seg_file, fam_file, dict_file=None):\n",
    "    \"\"\"\n",
    "    Load and prepare genetic data from .seg, .fam, and optional dict files.\n",
    "    Args:\n",
    "        seg_file: Path to the .seg file\n",
    "        fam_file: Path to the .fam file\n",
    "        dict_file: Path to the ID mapping file (optional)\n",
    "    Returns:\n",
    "        seg_df: DataFrame with segment data\n",
    "        individuals: Dictionary of individual metadata\n",
    "        individual_to_bonsai: Mapping from original IDs to Bonsai IDs\n",
    "    \"\"\"\n",
    "    # Load the ID mapping if provided\n",
    "    individual_to_bonsai = {}\n",
    "    if dict_file and os.path.exists(dict_file):\n",
    "        print(f\"Loading ID mapping from {dict_file}\")\n",
    "        try:\n",
    "            with open(dict_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    if len(parts) == 2:\n",
    "                        individual_id, bonsai_id = parts\n",
    "                        individual_to_bonsai[individual_id] = int(bonsai_id)\n",
    "            print(f\"Loaded {len(individual_to_bonsai)} ID mappings\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading ID mapping: {e}\")\n",
    "\n",
    "    # Read the seg file\n",
    "    seg_df = pd.read_csv(seg_file, sep=\"\\t\", header=None)\n",
    "    if len(seg_df.columns) == 9:\n",
    "        seg_df.columns = [\"sample1\", \"sample2\", \"chrom\", \"phys_start\", \"phys_end\",\n",
    "                        \"ibd_type\", \"gen_start\", \"gen_end\", \"gen_seg_len\"]\n",
    "    else:\n",
    "        print(f\"Warning: Unexpected number of columns in seg file: {len(seg_df.columns)}\")\n",
    "        print(\"Columns found:\", seg_df.columns)\n",
    "        return None, None, None\n",
    "    \n",
    "    # Extract unique individuals from seg file\n",
    "    unique_individuals_from_seg = set(seg_df[\"sample1\"]).union(set(seg_df[\"sample2\"]))\n",
    "    print(f\"Number of unique individuals in seg file: {len(unique_individuals_from_seg)}\")\n",
    "\n",
    "    # Read the fam file to get individual metadata\n",
    "    individuals = {}\n",
    "    try:\n",
    "        with open(fam_file, 'r') as file:\n",
    "            fam_lines = file.readlines()\n",
    "            \n",
    "            # Process each line in the fam file\n",
    "            for line in fam_lines:\n",
    "                fields = line.strip().split()\n",
    "                if len(fields) < 6:\n",
    "                    continue\n",
    "                    \n",
    "                family_id = fields[0]\n",
    "                individual_id = fields[1]\n",
    "                \n",
    "                # Skip individuals not present in the ID mapping if using a mapping\n",
    "                if individual_to_bonsai and individual_id not in individual_to_bonsai:\n",
    "                    continue\n",
    "                    \n",
    "                father_id = fields[2]\n",
    "                mother_id = fields[3]\n",
    "                sex = 'M' if fields[4] == '1' else 'F'\n",
    "                \n",
    "                # Extract generation using regex\n",
    "                match = re.search(r'g(\\d+)-', individual_id)\n",
    "                generation = int(match.group(1)) if match else None\n",
    "                \n",
    "                # Store the individual information\n",
    "                individuals[individual_id] = {\n",
    "                    'family_id': family_id,\n",
    "                    'father_id': father_id,\n",
    "                    'mother_id': mother_id,\n",
    "                    'sex': sex,\n",
    "                    'generation': generation\n",
    "                }\n",
    "                \n",
    "        print(f\"Loaded metadata for {len(individuals)} individuals from FAM file\")\n",
    "        \n",
    "        # Print a sample of the individuals dictionary\n",
    "        sample_keys = list(individuals.keys())[:3]\n",
    "        print(\"\\nSample of individuals data:\")\n",
    "        for key in sample_keys:\n",
    "            print(f\"{key}: {individuals[key]}\")\n",
    "            \n",
    "        # Summary statistics\n",
    "        generations = {}\n",
    "        for ind_id, info in individuals.items():\n",
    "            gen = info.get('generation')\n",
    "            if gen:\n",
    "                generations[gen] = generations.get(gen, 0) + 1\n",
    "                \n",
    "        print(\"\\nIndividuals by generation:\")\n",
    "        for gen, count in sorted(generations.items()):\n",
    "            print(f\"Generation {gen}: {count} individuals\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading FAM file: {e}\")\n",
    "        return None, None, None\n",
    "        \n",
    "    return seg_df, individuals, individual_to_bonsai\n",
    "\n",
    "def create_bioinfo(individuals, individual_to_bonsai):\n",
    "    \"\"\"\n",
    "    Create bioinfo list for Bonsai with ages assigned based on generation.\n",
    "    Args:\n",
    "        individuals: Dictionary of individual metadata\n",
    "        individual_to_bonsai: Mapping of original IDs to Bonsai IDs\n",
    "    Returns:\n",
    "        bioinfo: List of dictionaries with individual metadata for Bonsai\n",
    "    \"\"\"\n",
    "    # Check if we have generation information\n",
    "    has_generation_info = any('generation' in info and info['generation'] is not None\n",
    "                           for info in individuals.values())\n",
    "    \n",
    "    if not has_generation_info:\n",
    "        print(\"Warning: No generation information found in individuals data\")\n",
    "        return []\n",
    "        \n",
    "    # Get generation range\n",
    "    generations = [info['generation'] for info in individuals.values() \n",
    "                 if 'generation' in info and info['generation'] is not None]\n",
    "    \n",
    "    if not generations:\n",
    "        print(\"Warning: No valid generation values found\")\n",
    "        return []\n",
    "        \n",
    "    latest_generation = max(generations)\n",
    "    earliest_generation = min(generations)\n",
    "    print(f\"Generation range: {earliest_generation} to {latest_generation}\")\n",
    "    \n",
    "    # Assign ages based on generation\n",
    "    for individual_id, info in individuals.items():\n",
    "        generation = info.get('generation')\n",
    "        if generation is None:\n",
    "            # Skip individuals without generation info\n",
    "            continue\n",
    "            \n",
    "        if generation == latest_generation:\n",
    "            # Latest generation: ages 18-40\n",
    "            info['age'] = random.randint(18, 40)\n",
    "        else:\n",
    "            # Earlier generations: older based on generation gap\n",
    "            gen_gap = latest_generation - generation\n",
    "            min_age = 25 + (gen_gap * 20)\n",
    "            max_age = 40 + (gen_gap * 20)\n",
    "            info['age'] = random.randint(min_age, max_age)\n",
    "    \n",
    "    # Create bioinfo list for Bonsai\n",
    "    bioinfo = []\n",
    "    for individual_id, info in individuals.items():\n",
    "        if 'generation' in info and info['generation'] is not None:\n",
    "            if individual_id in individual_to_bonsai:\n",
    "                bonsai_id = individual_to_bonsai[individual_id]\n",
    "                age = info.get('age', 30)  # Default age if not calculated\n",
    "                sex = info.get('sex', 'U')  # Default sex if not available\n",
    "                bioinfo.append({'genotype_id': bonsai_id, 'age': age, 'sex': sex})\n",
    "                \n",
    "    return bioinfo\n",
    "\n",
    "def create_ibd_segment_list(seg_df):\n",
    "    \"\"\"Create an unphased IBD segment list for Bonsai from the segment dataframe.\"\"\"\n",
    "    unphased_ibd_seg_list = []\n",
    "    for _, row in seg_df.iterrows():\n",
    "        try:\n",
    "            id1 = int(row['sample1']) \n",
    "            id2 = int(row['sample2'])\n",
    "            chrom = str(row['chrom'])\n",
    "            start_bp = float(row['phys_start'])\n",
    "            end_bp = float(row['phys_end'])\n",
    "            is_full = row['ibd_type'] == 2  # Assuming IBD2 indicates \"full\" sharing\n",
    "            len_cm = float(row['gen_seg_len'])\n",
    "            \n",
    "            unphased_ibd_seg_list.append([id1, id2, chrom, start_bp, end_bp, is_full, len_cm])\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing segment: {e}\")\n",
    "            \n",
    "    return unphased_ibd_seg_list\n",
    "\n",
    "def identify_reference_populations(sample_df):\n",
    "    \"\"\"\n",
    "    Extract reference populations from sample dataframe\n",
    "    \"\"\"\n",
    "    reference_pops = sorted(sample_df['Population'].unique())\n",
    "    print(f\"Found {len(reference_pops)} reference populations:\")\n",
    "    for pop in reference_pops:\n",
    "        count = len(sample_df[sample_df['Population'] == pop])\n",
    "        desc = sample_df[sample_df['Population'] == pop]['Population Description'].iloc[0]\n",
    "        print(f\"  {pop}: {count} individuals - {desc}\")\n",
    "    return reference_pops\n",
    "\n",
    "def identify_project_samples(segments, sample_df):\n",
    "    \"\"\"Identify project samples that aren't in reference panel\"\"\"\n",
    "    # Get unique sample IDs from IBD data\n",
    "    all_samples = pd.unique(segments[['sample1', 'sample2']].values.ravel())\n",
    "    \n",
    "    # Identify project samples (those not in reference panel metadata)\n",
    "    project_samples = set(all_samples) - set(sample_df['Sample'])\n",
    "    \n",
    "    print(f\"Total unique samples in IBD data: {len(all_samples)}\")\n",
    "    print(f\"Samples in reference panel: {len(sample_df['Sample'])}\")\n",
    "    print(f\"Project samples identified: {len(project_samples)}\")\n",
    "    \n",
    "    return list(project_samples)\n",
    "\n",
    "##########################\n",
    "# 2. Community Detection #\n",
    "##########################\n",
    "def detect_communities(ibd_seg_list, bioinfo, resolution=1.0, min_community_size=10):\n",
    "    \"\"\"\n",
    "    Detect communities using Louvain algorithm to divide the dataset.\n",
    "    Args:\n",
    "        ibd_seg_list: List of IBD segments\n",
    "        bioinfo: List of individual metadata\n",
    "        resolution: Resolution parameter for Louvain (higher = smaller communities)\n",
    "        min_community_size: Minimum community size to keep\n",
    "    Returns:\n",
    "        communities: List of detected communities (sets of individual IDs)\n",
    "    \"\"\"\n",
    "    # Create a graph from IBD segments\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes for all individuals in bioinfo\n",
    "    genotype_ids = [info['genotype_id'] for info in bioinfo]\n",
    "    G.add_nodes_from(genotype_ids)\n",
    "    \n",
    "    # Add edges weighted by IBD sharing\n",
    "    edge_weights = defaultdict(float)\n",
    "    for segment in ibd_seg_list:\n",
    "        id1, id2 = segment[0], segment[1]\n",
    "        cm_length = segment[6]  # Length in centiMorgans\n",
    "        edge_weights[(id1, id2)] += cm_length\n",
    "        \n",
    "    # Add all edges to the graph\n",
    "    for (id1, id2), weight in edge_weights.items():\n",
    "        G.add_edge(id1, id2, weight=weight)\n",
    "    \n",
    "    # Find communities using Louvain\n",
    "    try:\n",
    "        communities = list(nx.community.louvain_communities(G, resolution=resolution, weight='weight'))\n",
    "        \n",
    "        # Filter out communities that are too small\n",
    "        communities = [comm for comm in communities if len(comm) >= min_community_size]\n",
    "        \n",
    "        print(f\"Detected {len(communities)} communities\")\n",
    "        for i, community in enumerate(communities):\n",
    "            print(f\"Community {i+1}: {len(community)} members\")\n",
    "            \n",
    "        return communities\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting communities: {e}\")\n",
    "        # If community detection fails, return a single community with all individuals\n",
    "        print(\"Falling back to using all individuals as one community\")\n",
    "        return [set(genotype_ids)]\n",
    "\n",
    "def filter_for_community(community, bioinfo, ibd_seg_list):\n",
    "    \"\"\"Filter bioinfo and IBD segments for a specific community.\"\"\"\n",
    "    # Filter bioinfo\n",
    "    community_bioinfo = [info for info in bioinfo if info['genotype_id'] in community]\n",
    "    \n",
    "    # Filter IBD segments\n",
    "    community_ibd = []\n",
    "    for seg in ibd_seg_list:\n",
    "        id1, id2 = seg[0], seg[1]\n",
    "        if id1 in community and id2 in community:\n",
    "            community_ibd.append(seg)\n",
    "            \n",
    "    return community_bioinfo, community_ibd\n",
    "\n",
    "def visualize_communities(G, communities, output_file=None, figsize=(12, 12)):\n",
    "    \"\"\"Visualize communities in a graph.\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create a colormap for communities\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(communities)))\n",
    "    \n",
    "    # Assign community colors to nodes\n",
    "    node_colors = []\n",
    "    for node in G.nodes():\n",
    "        for i, community in enumerate(communities):\n",
    "            if node in community:\n",
    "                node_colors.append(colors[i])\n",
    "                break\n",
    "        else:\n",
    "            # If node isn't in any community\n",
    "            node_colors.append((0.7, 0.7, 0.7, 0.5))\n",
    "    \n",
    "    # Create color patches for legend\n",
    "    patches = []\n",
    "    for i, color in enumerate(colors):\n",
    "        patches.append(mpatches.Patch(color=color, label=f'Community {i+1}'))\n",
    "    \n",
    "    # Apply layout - try different options depending on graph size\n",
    "    if len(G.nodes()) > 500:\n",
    "        print(\"Using sfdp layout for large graph...\")\n",
    "        try:\n",
    "            pos = nx.nx_agraph.graphviz_layout(G, prog='sfdp')\n",
    "        except:\n",
    "            print(\"Graphviz sfdp layout failed, falling back to spring layout\")\n",
    "            pos = nx.spring_layout(G, k=0.3, iterations=50, seed=42)\n",
    "    else:\n",
    "        try:\n",
    "            # For smaller graphs try neato first\n",
    "            pos = nx.nx_agraph.graphviz_layout(G, prog='neato')\n",
    "        except:\n",
    "            print(\"Graphviz layout failed, falling back to spring layout\")\n",
    "            pos = nx.spring_layout(G, k=0.3, iterations=50, seed=42)\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=50, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, width=0.5, alpha=0.3)\n",
    "    \n",
    "    plt.title(\"IBD Network Communities\", fontsize=16)\n",
    "    plt.legend(handles=patches, loc='upper right')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Network visualization saved to {output_file}\")\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "##########################\n",
    "# 3. IBD-Based Ancestry  #\n",
    "##########################\n",
    "def calculate_time_stratified_ancestry(sample_id, sample_df, segments, reference_populations, total_genome_length=3400):\n",
    "    \"\"\"\n",
    "    Calculate ancestry components across different time periods based on IBD segment length.\n",
    "    \n",
    "    Args:\n",
    "        sample_id: ID of the sample to analyze\n",
    "        sample_df: DataFrame with reference population metadata\n",
    "        segments: DataFrame of IBD segments\n",
    "        reference_populations: List of reference populations to analyze\n",
    "        total_genome_length: Total genetic length of genome in cM (default 3400)\n",
    "        \n",
    "    Returns:\n",
    "        ancestry_by_time: DataFrame with ancestry proportions by population and time period\n",
    "    \"\"\"\n",
    "    print(f\"Calculating time-stratified ancestry for {sample_id}...\")\n",
    "    \n",
    "    # Get IBD segments for this sample\n",
    "    sample_segs = segments[(segments['sample1'] == sample_id) | (segments['sample2'] == sample_id)].copy()\n",
    "    \n",
    "    if len(sample_segs) == 0:\n",
    "        print(f\"Warning: No IBD segments found for {sample_id}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Extract other sample ID\n",
    "    sample_segs['other_id'] = np.where(\n",
    "        sample_segs['sample1'] == sample_id,\n",
    "        sample_segs['sample2'],\n",
    "        sample_segs['sample1']\n",
    "    )\n",
    "    \n",
    "    # Merge with population information\n",
    "    sharing_df = pd.merge(\n",
    "        sample_segs,\n",
    "        sample_df[['Sample', 'Population', 'Population Description']],\n",
    "        left_on='other_id',\n",
    "        right_on='Sample',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Drop rows with no population information\n",
    "    sharing_df = sharing_df.dropna(subset=['Population'])\n",
    "    \n",
    "    if len(sharing_df) == 0:\n",
    "        print(f\"Warning: No matches with reference populations for {sample_id}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Define time periods - more granular, especially for recent periods\n",
    "    time_periods = [\n",
    "        (0, 50, 'Very Recent (0-50 years)'),\n",
    "        (51, 100, 'Recent (51-100 years)'),\n",
    "        (101, 150, 'Recent Historical (101-150 years)'),\n",
    "        (151, 200, 'Historical (151-200 years)'),\n",
    "        (201, 300, 'Early Modern (201-300 years)'),\n",
    "        (301, 500, 'Colonial Era (301-500 years)'),\n",
    "        (501, 1000, 'Medieval (501-1000 years)'),\n",
    "        (1001, 2000, 'Ancient (1001-2000 years)'),\n",
    "        (2001, float('inf'), 'Prehistoric (>2000 years)')\n",
    "    ]\n",
    "    \n",
    "    # Calculate TMRCA (years) based on genetic length\n",
    "    # Using the 50/genetic_length formula for TMRCA in generations\n",
    "    # Then multiply by 25 years per generation\n",
    "    sharing_df['tmrca_years'] = 25 * 50 / sharing_df['gen_seg_len']\n",
    "    \n",
    "    # Assign time periods to each segment\n",
    "    def assign_time_period(years):\n",
    "        for start, end, label in time_periods:\n",
    "            if start <= years < end:\n",
    "                return label\n",
    "        return 'Unknown'\n",
    "        \n",
    "    sharing_df['time_period'] = sharing_df['tmrca_years'].apply(assign_time_period)\n",
    "    \n",
    "    # Initialize results structure - for each population and time period\n",
    "    ancestry_data = {}\n",
    "    for pop in reference_populations:\n",
    "        ancestry_data[pop] = {period[2]: 0 for period in time_periods}\n",
    "    \n",
    "    # Sum IBD sharing by population and time period\n",
    "    for pop in reference_populations:\n",
    "        pop_data = sharing_df[sharing_df['Population'] == pop]\n",
    "        for period_start, period_end, period_name in time_periods:\n",
    "            period_data = pop_data[(pop_data['tmrca_years'] >= period_start) & \n",
    "                                  (pop_data['tmrca_years'] < period_end)]\n",
    "            total_cm = period_data['gen_seg_len'].sum()\n",
    "            ancestry_data[pop][period_name] = total_cm\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    ancestry_df = pd.DataFrame(ancestry_data)\n",
    "    \n",
    "    # Calculate percentages of genome (normalize by total genome length)\n",
    "    ancestry_pct = ancestry_df / total_genome_length * 100\n",
    "    \n",
    "    # Add total row\n",
    "    ancestry_pct.loc['Total'] = ancestry_pct.sum()\n",
    "    \n",
    "    # Add weighted time-based ancestry composition\n",
    "    # Higher weight for more recent ancestry\n",
    "    weights = {\n",
    "        'Very Recent (0-50 years)': 1.0,\n",
    "        'Recent (51-100 years)': 0.9,\n",
    "        'Recent Historical (101-150 years)': 0.8,\n",
    "        'Historical (151-200 years)': 0.7,\n",
    "        'Early Modern (201-300 years)': 0.6,\n",
    "        'Colonial Era (301-500 years)': 0.5,\n",
    "        'Medieval (501-1000 years)': 0.4,\n",
    "        'Ancient (1001-2000 years)': 0.3,\n",
    "        'Prehistoric (>2000 years)': 0.2\n",
    "    }\n",
    "    \n",
    "    # Calculate weighted ancestry\n",
    "    weighted_ancestry = pd.Series(0.0, index=reference_populations)\n",
    "    for period in weights:\n",
    "        if period in ancestry_pct.index:\n",
    "            weighted_ancestry += ancestry_pct.loc[period] * weights[period]\n",
    "    \n",
    "    # Normalize to sum to 100%\n",
    "    if weighted_ancestry.sum() > 0:\n",
    "        weighted_ancestry = weighted_ancestry / weighted_ancestry.sum() * 100\n",
    "    \n",
    "    ancestry_pct.loc['Weighted Total'] = weighted_ancestry\n",
    "    \n",
    "    return ancestry_pct\n",
    "\n",
    "def create_consensus_ancestry_map(sample_id, sample_df, segments, chromosome_lengths, window_size=1000000):\n",
    "    \"\"\"\n",
    "    Create a position-specific ancestry map based on overlapping IBD segments.\n",
    "    \n",
    "    Args:\n",
    "        sample_id: ID of the sample to analyze\n",
    "        sample_df: DataFrame with reference population metadata\n",
    "        segments: DataFrame of IBD segments\n",
    "        chromosome_lengths: Dictionary of chromosome lengths {chrom: length}\n",
    "        window_size: Size of genomic windows in bp\n",
    "        \n",
    "    Returns:\n",
    "        ancestry_map: Dictionary {chrom: {position: {population: probability}}}\n",
    "    \"\"\"\n",
    "    print(f\"Creating consensus ancestry map for {sample_id}...\")\n",
    "    \n",
    "    # Get IBD segments for this sample\n",
    "    sample_segs = segments[(segments['sample1'] == sample_id) | (segments['sample2'] == sample_id)].copy()\n",
    "    \n",
    "    if len(sample_segs) == 0:\n",
    "        print(f\"Warning: No IBD segments found for {sample_id}\")\n",
    "        return {}\n",
    "    \n",
    "    # Extract other sample ID and merge with population information\n",
    "    sample_segs['other_id'] = np.where(\n",
    "        sample_segs['sample1'] == sample_id,\n",
    "        sample_segs['sample2'],\n",
    "        sample_segs['sample1']\n",
    "    )\n",
    "    \n",
    "    sharing_df = pd.merge(\n",
    "        sample_segs,\n",
    "        sample_df[['Sample', 'Population']],\n",
    "        left_on='other_id',\n",
    "        right_on='Sample',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Drop rows with no population information\n",
    "    sharing_df = sharing_df.dropna(subset=['Population'])\n",
    "    \n",
    "    if len(sharing_df) == 0:\n",
    "        print(f\"Warning: No matches with reference populations for {sample_id}\")\n",
    "        return {}\n",
    "    \n",
    "    # Calculate TMRCA in years for weighting\n",
    "    sharing_df['tmrca_years'] = 25 * 50 / sharing_df['gen_seg_len']\n",
    "    \n",
    "    # Weight based on segment length and recency (shorter TMRCA = higher weight)\n",
    "    sharing_df['weight'] = sharing_df['gen_seg_len'] * (1000 / (sharing_df['tmrca_years'] + 100))\n",
    "    \n",
    "    # Get unique populations and chromosomes\n",
    "    populations = sample_df['Population'].unique()\n",
    "    chromosomes = sharing_df['chrom'].unique()\n",
    "    \n",
    "    # Initialize ancestry map\n",
    "    ancestry_map = {}\n",
    "    \n",
    "    # Process each chromosome\n",
    "    for chrom in chromosomes:\n",
    "        chrom_segs = sharing_df[sharing_df['chrom'] == chrom]\n",
    "        \n",
    "        if str(chrom) not in chromosome_lengths:\n",
    "            if chrom not in chromosome_lengths:\n",
    "                print(f\"Warning: No length data for chromosome {chrom}\")\n",
    "                continue\n",
    "        \n",
    "        # Get chromosome length\n",
    "        chrom_length = chromosome_lengths[str(chrom)] if str(chrom) in chromosome_lengths else chromosome_lengths[chrom]\n",
    "            \n",
    "        # Create windows for this chromosome\n",
    "        windows = range(0, chrom_length + window_size, window_size)\n",
    "        \n",
    "        # Initialize ancestry probabilities for this chromosome\n",
    "        chrom_ancestry = {window: {pop: 0.0 for pop in populations} for window in windows}\n",
    "        \n",
    "        # Process each segment to contribute to window probabilities\n",
    "        for _, segment in chrom_segs.iterrows():\n",
    "            start_window = (int(segment['phys_start']) // window_size) * window_size\n",
    "            end_window = (int(segment['phys_end']) // window_size) * window_size\n",
    "            \n",
    "            # Apply segment contribution to each overlapping window\n",
    "            for window in range(start_window, end_window + window_size, window_size):\n",
    "                if window in chrom_ancestry:\n",
    "                    pop = segment['Population']\n",
    "                    if pd.notna(pop):  # Skip if population is unknown\n",
    "                        chrom_ancestry[window][pop] += segment['weight']\n",
    "        \n",
    "        # Normalize probabilities in each window\n",
    "        for window in chrom_ancestry:\n",
    "            total = sum(chrom_ancestry[window].values())\n",
    "            if total > 0:\n",
    "                for pop in chrom_ancestry[window]:\n",
    "                    chrom_ancestry[window][pop] /= total\n",
    "        \n",
    "        ancestry_map[str(chrom)] = chrom_ancestry\n",
    "    \n",
    "    return ancestry_map\n",
    "\n",
    "def visualize_time_stratified_ancestry(sample_id, ancestry_data, output_dir):\n",
    "    \"\"\"\n",
    "    Create visualizations for time-stratified ancestry.\n",
    "    \n",
    "    Args:\n",
    "        sample_id: ID of the sample\n",
    "        ancestry_data: DataFrame with ancestry by time period\n",
    "        output_dir: Directory to save output files\n",
    "    \"\"\"\n",
    "    # Skip if no data\n",
    "    if ancestry_data.empty:\n",
    "        print(f\"No ancestry data to visualize for {sample_id}\")\n",
    "        return\n",
    "    \n",
    "    # Create output directory if needed\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Heatmap of ancestry by time period\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    # Exclude the summary rows\n",
    "    plot_data = ancestry_data.iloc[:-2] if len(ancestry_data) > 2 else ancestry_data\n",
    "    sns.heatmap(plot_data, annot=True, cmap='YlOrRd', fmt='.1f')\n",
    "    plt.title(f\"Time-Stratified Ancestry for {sample_id}\")\n",
    "    plt.ylabel(\"Time Period\")\n",
    "    plt.xlabel(\"Reference Population\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{sample_id}_time_heatmap.png\"), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Stacked bar chart of population proportions over time\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    # Transpose to have populations as rows and time periods as columns\n",
    "    plot_data_t = plot_data.T\n",
    "    # Normalize each column (time period) to sum to 100%\n",
    "    for col in plot_data_t.columns:\n",
    "        if plot_data_t[col].sum() > 0:\n",
    "            plot_data_t[col] = plot_data_t[col] / plot_data_t[col].sum() * 100\n",
    "    \n",
    "    # Plot stacked bars\n",
    "    plot_data_t.plot(kind='bar', stacked=True, colormap='tab20')\n",
    "    plt.title(f\"Ancestry Composition Over Time for {sample_id}\")\n",
    "    plt.xlabel(\"Reference Population\")\n",
    "    plt.ylabel(\"Percentage of Ancestry\")\n",
    "    plt.legend(title=\"Time Period\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{sample_id}_time_stacked.png\"), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Area chart showing ancestry over time\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    # Get time periods as x values (use numeric midpoints of ranges)\n",
    "    time_midpoints = {\n",
    "        'Very Recent (0-50 years)': 25,\n",
    "        'Recent (51-100 years)': 75,\n",
    "        'Recent Historical (101-150 years)': 125,\n",
    "        'Historical (151-200 years)': 175,\n",
    "        'Early Modern (201-300 years)': 250,\n",
    "        'Colonial Era (301-500 years)': 400,\n",
    "        'Medieval (501-1000 years)': 750,\n",
    "        'Ancient (1001-2000 years)': 1500,\n",
    "        'Prehistoric (>2000 years)': 2500\n",
    "    }\n",
    "    \n",
    "    # Prepare data for area chart\n",
    "    area_data = plot_data.copy()\n",
    "    # Add time midpoints as index values\n",
    "    area_data['midpoint'] = area_data.index.map(lambda x: time_midpoints.get(x, 0))\n",
    "    area_data = area_data.sort_values('midpoint')\n",
    "    \n",
    "    # Normalize rows to get percentages\n",
    "    for idx in area_data.index:\n",
    "        if idx != 'midpoint' and area_data.loc[idx].sum() > 0:\n",
    "            row_sum = area_data.loc[idx, [col for col in area_data.columns if col != 'midpoint']].sum()\n",
    "            if row_sum > 0:\n",
    "                area_data.loc[idx, [col for col in area_data.columns if col != 'midpoint']] = \\\n",
    "                    area_data.loc[idx, [col for col in area_data.columns if col != 'midpoint']] / row_sum * 100\n",
    "    \n",
    "    # Plot area chart\n",
    "    x = area_data['midpoint']\n",
    "    y_columns = [col for col in area_data.columns if col != 'midpoint']\n",
    "    plt.stackplot(x, [area_data[col] for col in y_columns], labels=y_columns, alpha=0.8)\n",
    "    \n",
    "    plt.title(f\"Ancestry Composition Through Time for {sample_id}\")\n",
    "    plt.xlabel(\"Years Before Present\")\n",
    "    plt.ylabel(\"Percentage of Ancestry\")\n",
    "    plt.legend(title=\"Population\", loc='upper right')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.xlim(0, 2600)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{sample_id}_time_area.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def visualize_chromosome_painting(sample_id, ancestry_map, output_dir):\n",
    "    \"\"\"\n",
    "    Create chromosome painting visualizations from consensus ancestry map.\n",
    "    \n",
    "    Args:\n",
    "        sample_id: ID of the sample\n",
    "        ancestry_map: Dictionary {chrom: {position: {population: probability}}}\n",
    "        output_dir: Directory to save output files\n",
    "    \"\"\"\n",
    "    if not ancestry_map:\n",
    "        print(f\"No ancestry map data to visualize for {sample_id}\")\n",
    "        return\n",
    "    \n",
    "    # Create output directory if needed\n",
    "    chrom_paint_dir = os.path.join(output_dir, f\"{sample_id}_chromosome_paintings\")\n",
    "    os.makedirs(chrom_paint_dir, exist_ok=True)\n",
    "    \n",
    "    # Create a colormap for populations\n",
    "    populations = []\n",
    "    for chrom in ancestry_map:\n",
    "        for pos in ancestry_map[chrom]:\n",
    "            populations.extend(ancestry_map[chrom][pos].keys())\n",
    "    populations = sorted(set(populations))\n",
    "    \n",
    "    if not populations:\n",
    "        print(f\"No population data in ancestry map for {sample_id}\")\n",
    "        return\n",
    "    \n",
    "    # Create a dictionary mapping populations to colors\n",
    "    pop_colors = {}\n",
    "    cmap = plt.cm.get_cmap('tab20', len(populations))\n",
    "    for i, pop in enumerate(populations):\n",
    "        pop_colors[pop] = cmap(i)\n",
    "    \n",
    "    # Create a summary figure showing all chromosomes\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    chrom_count = len(ancestry_map)\n",
    "    fig, axes = plt.subplots(nrows=min(chrom_count, 6), ncols=max(1, (chrom_count+5)//6), \n",
    "                            figsize=(15, 2*min(chrom_count, 6)), squeeze=False)\n",
    "    \n",
    "    # Flatten axes array for easy iteration\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    for i, chrom in enumerate(sorted(ancestry_map.keys(), key=lambda x: int(x) if x.isdigit() else x)):\n",
    "        if i >= len(axes_flat):\n",
    "            print(f\"Warning: Not enough subplots for all chromosomes\")\n",
    "            break\n",
    "            \n",
    "        ax = axes_flat[i]\n",
    "        chrom_data = ancestry_map[chrom]\n",
    "        \n",
    "        # Sort positions\n",
    "        positions = sorted(chrom_data.keys())\n",
    "        if not positions:\n",
    "            continue\n",
    "            \n",
    "        # Create data arrays for visualization\n",
    "        x_positions = np.array(positions) / 1_000_000  # Convert to Mb\n",
    "        \n",
    "        # For each position, stack colors proportionally\n",
    "        for pos in positions:\n",
    "            pos_data = chrom_data[pos]\n",
    "            bottom = 0\n",
    "            x_pos = pos / 1_000_000  # Convert to Mb\n",
    "            \n",
    "            # Sort populations by contribution (largest at bottom)\n",
    "            sorted_pops = sorted(pos_data.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for pop, prob in sorted_pops:\n",
    "                if prob > 0:\n",
    "                    height = prob\n",
    "                    ax.bar(x_pos, height, bottom=bottom, width=1, color=pop_colors[pop], \n",
    "                          edgecolor='none', align='center', alpha=0.7)\n",
    "                    bottom += height\n",
    "        \n",
    "        ax.set_title(f\"Chr {chrom}\")\n",
    "        ax.set_xlabel(\"Position (Mb)\")\n",
    "        ax.set_ylabel(\"Ancestry Proportion\")\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(i+1, len(axes_flat)):\n",
    "        axes_flat[j].axis('off')\n",
    "    \n",
    "    # Create legend with population colors\n",
    "    legend_elements = [plt.Rectangle((0,0), 1, 1, color=pop_colors[pop], label=pop) for pop in populations]\n",
    "    fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.05), \n",
    "              ncol=min(5, len(populations)))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.savefig(os.path.join(output_dir, f\"{sample_id}_all_chromosomes.png\"), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create individual chromosome paintings with higher resolution\n",
    "    for chrom in sorted(ancestry_map.keys(), key=lambda x: int(x) if x.isdigit() else x):\n",
    "        chrom_data = ancestry_map[chrom]\n",
    "        positions = sorted(chrom_data.keys())\n",
    "        if not positions:\n",
    "            continue\n",
    "            \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # For each position, stack colors proportionally\n",
    "        for pos in positions:\n",
    "            pos_data = chrom_data[pos]\n",
    "            bottom = 0\n",
    "            x_pos = pos / 1_000_000  # Convert to Mb\n",
    "            \n",
    "            # Sort populations by contribution (largest at bottom)\n",
    "            sorted_pops = sorted(pos_data.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for pop, prob in sorted_pops:\n",
    "                if prob > 0:\n",
    "                    height = prob\n",
    "                    plt.bar(x_pos, height, bottom=bottom, width=1, color=pop_colors[pop], \n",
    "                          edgecolor='none', align='center', alpha=0.7)\n",
    "                    bottom += height\n",
    "        \n",
    "        plt.title(f\"Chromosome {chrom} Ancestry Painting for {sample_id}\")\n",
    "        plt.xlabel(\"Position (Mb)\")\n",
    "        plt.ylabel(\"Ancestry Proportion\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # Add population legend\n",
    "        legend_elements = [plt.Rectangle((0,0), 1, 1, color=pop_colors[pop], label=pop) for pop in populations]\n",
    "        plt.legend(handles=legend_elements, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(chrom_paint_dir, f\"chrom_{chrom}_painting.png\"), dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "def compare_with_rfmix(sample_id, ancestry_map, rfmix_file, output_dir, window_size=1000000):\n",
    "    \"\"\"\n",
    "    Compare IBD-based ancestry inference with RFMix results.\n",
    "    \n",
    "    Args:\n",
    "        sample_id: ID of the sample to analyze\n",
    "        ancestry_map: Ancestry map from IBD-based method\n",
    "        rfmix_file: Path to RFMix output file\n",
    "        output_dir: Directory to save comparison results\n",
    "        window_size: Size of genomic windows in bp (should match IBD map)\n",
    "        \n",
    "    Returns:\n",
    "        comparison_df: DataFrame with comparison metrics\n",
    "    \"\"\"\n",
    "    if not os.path.exists(rfmix_file):\n",
    "        print(f\"RFMix file not found: {rfmix_file}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Comparing IBD-based ancestry with RFMix for {sample_id}...\")\n",
    "    \n",
    "    try:\n",
    "        # Load RFMix results\n",
    "        rfmix_df = pd.read_csv(rfmix_file, sep='\\t')\n",
    "        \n",
    "        # Filter for the sample of interest\n",
    "        rfmix_sample = rfmix_df[rfmix_df['sample'] == sample_id]\n",
    "        \n",
    "        if rfmix_sample.empty:\n",
    "            print(f\"Sample {sample_id} not found in RFMix results\")\n",
    "            return None\n",
    "        \n",
    "        # Initialize comparison results\n",
    "        comparison = {\n",
    "            'chrom': [],\n",
    "            'position': [],\n",
    "            'rfmix_ancestry': [],\n",
    "            'ibd_ancestry': [],\n",
    "            'agreement': [],\n",
    "            'ibd_confidence': []\n",
    "        }\n",
    "        \n",
    "        # For each chromosome in both datasets\n",
    "        for chrom in ancestry_map:\n",
    "            if chrom not in rfmix_sample['chrom'].astype(str).unique():\n",
    "                continue\n",
    "                \n",
    "            rfmix_chrom = rfmix_sample[rfmix_sample['chrom'].astype(str) == chrom]\n",
    "            \n",
    "            # Iterate through IBD ancestry windows\n",
    "            for window, pop_probs in ancestry_map[chrom].items():\n",
    "                # Find corresponding RFMix windows\n",
    "                rfmix_windows = rfmix_chrom[\n",
    "                    (rfmix_chrom['start'] >= window) & \n",
    "                    (rfmix_chrom['start'] < window + window_size)\n",
    "                ]\n",
    "                \n",
    "                if rfmix_windows.empty:\n",
    "                    continue\n",
    "                    \n",
    "                # Get most likely ancestry from IBD method\n",
    "                ibd_ancestry = max(pop_probs.items(), key=lambda x: x[1])\n",
    "                ibd_pop = ibd_ancestry[0]\n",
    "                ibd_confidence = ibd_ancestry[1]\n",
    "                \n",
    "                # Get most common RFMix ancestry in this window\n",
    "                rfmix_counts = rfmix_windows['ancestry'].value_counts()\n",
    "                if not rfmix_counts.empty:\n",
    "                    rfmix_pop = rfmix_counts.index[0]\n",
    "                    \n",
    "                    # Check if they agree\n",
    "                    agreement = 1 if rfmix_pop == ibd_pop else 0\n",
    "                    \n",
    "                    # Store comparison\n",
    "                    comparison['chrom'].append(chrom)\n",
    "                    comparison['position'].append(window)\n",
    "                    comparison['rfmix_ancestry'].append(rfmix_pop)\n",
    "                    comparison['ibd_ancestry'].append(ibd_pop)\n",
    "                    comparison['agreement'].append(agreement)\n",
    "                    comparison['ibd_confidence'].append(ibd_confidence)\n",
    "        \n",
    "        # Create comparison DataFrame\n",
    "        comparison_df = pd.DataFrame(comparison)\n",
    "        \n",
    "        # Calculate overall agreement\n",
    "        overall_agreement = comparison_df['agreement'].mean() if not comparison_df.empty else 0\n",
    "        print(f\"Overall agreement with RFMix: {overall_agreement:.2%}\")\n",
    "        \n",
    "        # Save comparison results\n",
    "        if not comparison_df.empty:\n",
    "            comparison_df.to_csv(os.path.join(output_dir, f\"{sample_id}_rfmix_comparison.csv\"), index=False)\n",
    "            \n",
    "            # Create visualization of agreement\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Plot agreement by chromosome as heatmap\n",
    "            agreement_by_chrom = comparison_df.pivot_table(\n",
    "                index='chrom', \n",
    "                columns='ibd_ancestry', \n",
    "                values='agreement',\n",
    "                aggfunc='mean'\n",
    "            )\n",
    "            \n",
    "            sns.heatmap(agreement_by_chrom, annot=True, cmap='YlGnBu', fmt='.2f')\n",
    "            plt.title(f\"Agreement with RFMix by Chromosome and Ancestry ({sample_id})\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, f\"{sample_id}_rfmix_agreement.png\"), dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "        return comparison_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing with RFMix: {e}\")\n",
    "        return None\n",
    "\n",
    "#############################\n",
    "# 4. Main Analysis Function #\n",
    "#############################\n",
    "def run_ancestry_analysis(sample_id, segments, sample_df, output_dir=\"ancestry_results\", \n",
    "                         rfmix_file=None, chromosome_lengths=None):\n",
    "    \"\"\"\n",
    "    Run ancestry analysis for a single sample using IBD segments with a reference panel.\n",
    "    \n",
    "    Args:\n",
    "        sample_id: ID of the sample to analyze\n",
    "        segments: DataFrame of IBD segments\n",
    "        sample_df: DataFrame with reference population metadata\n",
    "        output_dir: Directory to save results\n",
    "        rfmix_file: Path to RFMix results for comparison (optional)\n",
    "        chromosome_lengths: Dictionary with chromosome lengths\n",
    "        \n",
    "    Returns:\n",
    "        results: Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    print(f\"\\nRunning ancestry analysis for sample: {sample_id}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    sample_dir = os.path.join(output_dir, sample_id)\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "    \n",
    "    # Extract reference populations\n",
    "    reference_pops = sorted(sample_df['Population'].unique())\n",
    "    \n",
    "    # Define default chromosome lengths if not provided\n",
    "    if chromosome_lengths is None:\n",
    "        # Example chromosome lengths (GRCh38) in base pairs\n",
    "        chromosome_lengths = {\n",
    "            '1': 248956422, '2': 242193529, '3': 198295559, '4': 190214555, \n",
    "            '5': 181538259, '6': 170805979, '7': 159345973, '8': 145138636, \n",
    "            '9': 138394717, '10': 133797422, '11': 135086622, '12': 133275309, \n",
    "            '13': 114364328, '14': 107043718, '15': 101991189, '16': 90338345, \n",
    "            '17': 83257441, '18': 80373285, '19': 58617616, '20': 64444167, \n",
    "            '21': 46709983, '22': 50818468, 'X': 156040895, 'Y': 57227415\n",
    "        }\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Time-stratified ancestry analysis\n",
    "    print(\"Running time-stratified ancestry analysis...\")\n",
    "    ancestry_by_time = calculate_time_stratified_ancestry(\n",
    "        sample_id, sample_df, segments, reference_pops\n",
    "    )\n",
    "    results['time_stratified'] = ancestry_by_time\n",
    "    \n",
    "    # Save time-stratified results\n",
    "    if not ancestry_by_time.empty:\n",
    "        ancestry_by_time.to_csv(\n",
    "            os.path.join(sample_dir, f\"time_stratified_ancestry.csv\")\n",
    "        )\n",
    "        visualize_time_stratified_ancestry(sample_id, ancestry_by_time, sample_dir)\n",
    "    \n",
    "    # 2. Consensus mapping approach\n",
    "    print(\"Creating consensus ancestry map...\")\n",
    "    ancestry_map = create_consensus_ancestry_map(\n",
    "        sample_id, sample_df, segments, chromosome_lengths\n",
    "    )\n",
    "    results['consensus_map'] = ancestry_map\n",
    "    \n",
    "    # Save consensus map to file\n",
    "    if ancestry_map:\n",
    "        with open(os.path.join(sample_dir, f\"ancestry_map.json\"), 'w') as f:\n",
    "            # Convert ancestry map to serializable format\n",
    "            serializable_map = {}\n",
    "            for chrom, chrom_data in ancestry_map.items():\n",
    "                serializable_map[chrom] = {\n",
    "                    str(pos): {pop: float(prob) for pop, prob in pos_data.items()}\n",
    "                    for pos, pos_data in chrom_data.items()\n",
    "                }\n",
    "            json.dump(serializable_map, f, indent=2)\n",
    "        \n",
    "        # Create chromosome paintings\n",
    "        visualize_chromosome_painting(sample_id, ancestry_map, sample_dir)\n",
    "    \n",
    "    # 3. Compare with RFMix if available\n",
    "    if rfmix_file and os.path.exists(rfmix_file):\n",
    "        print(\"Comparing with RFMix results...\")\n",
    "        comparison = compare_with_rfmix(\n",
    "            sample_id, ancestry_map, rfmix_file, sample_dir\n",
    "        )\n",
    "        results['rfmix_comparison'] = comparison\n",
    "    \n",
    "    print(f\"Analysis complete for {sample_id}\")\n",
    "    return results\n",
    "\n",
    "def batch_ancestry_analysis(project_samples, segments, sample_df, output_dir=\"ancestry_results\", \n",
    "                           rfmix_dir=None, chromosome_lengths=None):\n",
    "    \"\"\"\n",
    "    Run ancestry analysis for multiple samples.\n",
    "    \n",
    "    Args:\n",
    "        project_samples: List of sample IDs to analyze\n",
    "        segments: DataFrame of IBD segments\n",
    "        sample_df: DataFrame with reference population metadata\n",
    "        output_dir: Directory to save results\n",
    "        rfmix_dir: Directory containing RFMix results (optional)\n",
    "        chromosome_lengths: Dictionary with chromosome lengths\n",
    "        \n",
    "    Returns:\n",
    "        all_results: Dictionary with results for all samples\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize results\n",
    "    all_results = {}\n",
    "    \n",
    "    # Process each sample\n",
    "    for i, sample_id in enumerate(project_samples):\n",
    "        print(f\"\\nProcessing sample {i+1}/{len(project_samples)}: {sample_id}\")\n",
    "        \n",
    "        # Define RFMix file path if available\n",
    "        rfmix_file = None\n",
    "        if rfmix_dir:\n",
    "            potential_file = os.path.join(rfmix_dir, f\"{sample_id}_rfmix.txt\")\n",
    "            if os.path.exists(potential_file):\n",
    "                rfmix_file = potential_file\n",
    "        \n",
    "        # Run analysis for this sample\n",
    "        results = run_ancestry_analysis(\n",
    "            sample_id, segments, sample_df, output_dir, rfmix_file, chromosome_lengths\n",
    "        )\n",
    "        \n",
    "        all_results[sample_id] = results\n",
    "    \n",
    "    # Create summary across all samples\n",
    "    print(\"\\nCreating summary across all samples...\")\n",
    "    \n",
    "    # Collect weighted ancestry totals across samples\n",
    "    weighted_totals = {}\n",
    "    for sample_id, results in all_results.items():\n",
    "        if 'time_stratified' in results and not results['time_stratified'].empty:\n",
    "            weighted_totals[sample_id] = results['time_stratified'].loc['Weighted Total']\n",
    "    \n",
    "    if weighted_totals:\n",
    "        weighted_df = pd.DataFrame(weighted_totals).T\n",
    "        \n",
    "        # Save to file\n",
    "        weighted_df.to_csv(os.path.join(output_dir, \"all_samples_weighted_ancestry.csv\"))\n",
    "        \n",
    "        # Create heatmap visualization\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        sns.heatmap(weighted_df, annot=True, cmap='YlOrRd', fmt='.1f')\n",
    "        plt.title(\"Weighted Ancestry Composition Across All Samples\")\n",
    "        plt.xlabel(\"Reference Population\")\n",
    "        plt.ylabel(\"Sample ID\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"all_samples_heatmap.png\"), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Create stacked bar chart\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        weighted_df_pct = weighted_df.copy()\n",
    "        # Normalize rows to 100%\n",
    "        for idx in weighted_df_pct.index:\n",
    "            row_sum = weighted_df_pct.loc[idx].sum()\n",
    "            if row_sum > 0:\n",
    "                weighted_df_pct.loc[idx] = weighted_df_pct.loc[idx] / row_sum * 100\n",
    "                \n",
    "        weighted_df_pct.plot(kind='barh', stacked=True, colormap='tab20')\n",
    "        plt.title(\"Ancestry Composition Across All Samples\")\n",
    "        plt.xlabel(\"Percentage\")\n",
    "        plt.ylabel(\"Sample ID\")\n",
    "        plt.legend(title=\"Population\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"all_samples_stacked.png\"), dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"\\nBatch analysis complete!\")\n",
    "    return all_results\n",
    "\n",
    "############################\n",
    "# 5. Main Entry Point      #\n",
    "############################\n",
    "def main(seg_file, fam_file, dict_file=None, \n",
    "         output_dir=\"ancestry_results\", \n",
    "         rfmix_dir=None,\n",
    "         sample_list=None):\n",
    "    \"\"\"\n",
    "    Main function to run the analysis pipeline.\n",
    "    \n",
    "    Args:\n",
    "        seg_file: Path to the IBD segment file\n",
    "        fam_file: Path to the sample metadata file\n",
    "        dict_file: Path to ID mapping file (optional)\n",
    "        output_dir: Directory to save results\n",
    "        rfmix_dir: Directory containing RFMix results (optional)\n",
    "        sample_list: List of sample IDs to analyze (optional)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"1. Loading genetic data...\")\n",
    "    segments, individuals, individual_to_bonsai = load_genetic_data(seg_file, fam_file, dict_file)\n",
    "    \n",
    "    if segments is None:\n",
    "        print(\"Error loading data. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Load 1000 Genomes population information\n",
    "    reference_file = os.path.join(os.path.dirname(fam_file), \"20140502_complete_sample_summary.txt\")\n",
    "    if os.path.exists(reference_file):\n",
    "        print(f\"Loading reference population information from {reference_file}\")\n",
    "        sample_df = pd.read_csv(reference_file, sep='\\t')\n",
    "    else:\n",
    "        print(\"Reference population file not found. Creating empty DataFrame.\")\n",
    "        sample_df = pd.DataFrame(columns=['Sample', 'Population', 'Population Description'])\n",
    "    \n",
    "    # Identify reference populations\n",
    "    reference_pops = identify_reference_populations(sample_df)\n",
    "    \n",
    "    # Identify project samples (if not provided)\n",
    "    if sample_list is None:\n",
    "        project_samples = identify_project_samples(segments, sample_df)\n",
    "    else:\n",
    "        project_samples = sample_list\n",
    "        print(f\"Using provided list of {len(project_samples)} samples\")\n",
    "    \n",
    "    # Limit to a reasonable number of samples for testing\n",
    "    if len(project_samples) > 10:\n",
    "        print(f\"Limiting analysis to first 10 samples for demonstration\")\n",
    "        project_samples = project_samples[:10]\n",
    "    \n",
    "    # Run batch analysis\n",
    "    results = batch_ancestry_analysis(\n",
    "        project_samples, segments, sample_df, output_dir, rfmix_dir\n",
    "    )\n",
    "    \n",
    "    print(\"\\nAnalysis pipeline completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    if len(sys.argv) > 2:\n",
    "        seg_file = sys.argv[1]\n",
    "        fam_file = sys.argv[2]\n",
    "        dict_file = sys.argv[3] if len(sys.argv) > 3 else None\n",
    "        main(seg_file, fam_file, dict_file)\n",
    "    else:\n",
    "        # Default example files\n",
    "        seg_file = \"../data/class_data/ped_sim_run2.seg\"\n",
    "        fam_file = \"../data/class_data/ped_sim_run2-everyone.fam\"\n",
    "        dict_file = \"../data/class_data/ped_sim_run2.seg_dict.txt\"\n",
    "        main(seg_file, fam_file, dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e92c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ibd_1000_genomes.ipynb to pdf\n",
      "[NbConvertApp] Writing 147577 bytes to notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 109381 bytes to ibd_1000_genomes.pdf\n"
     ]
    }
   ],
   "source": [
    "!poetry run jupyter nbconvert --to pdf ibd_1000_genomes.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
