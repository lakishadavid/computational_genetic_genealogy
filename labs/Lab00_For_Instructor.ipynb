{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 00: Instructor Guide for AWS S3 and Data Management\n",
    "\n",
    "This notebook contains commands and instructions for managing course data in AWS S3 and setting up notebooks for student use through Google Colab or JupyterLite.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- AWS S3 provides scalable cloud storage for course data files\n",
    "- Google Colab offers a free, accessible Jupyter environment requiring S3 data access\n",
    "- JupyterLite provides an in-browser option with bundled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. AWS S3 Commands\n",
    "\n",
    "### Setting up AWS CLI\n",
    "\n",
    "Make sure the AWS CLI is installed and configured with appropriate credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß¨ Google Colab Setup - Run this cell first!\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "def is_colab():\n",
    "    '''Check if running in Google Colab'''\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if is_colab():\n",
    "    print(\"üî¨ Setting up Google Colab environment...\")\n",
    "    \n",
    "    # Install dependencies\n",
    "    print(\"üì¶ Installing packages...\")\n",
    "    !pip install -q pysam biopython scikit-allel networkx pygraphviz seaborn plotly\n",
    "    !apt-get update -qq && apt-get install -qq samtools bcftools tabix graphviz-dev\n",
    "    \n",
    "    # Create directories\n",
    "    !mkdir -p /content/class_data /content/results\n",
    "    \n",
    "    # Download essential class data\n",
    "    print(\"üì• Downloading class data...\")\n",
    "    S3_BASE = \"https://computational-genetic-genealogy.s3.us-east-2.amazonaws.com/class_data/\"\n",
    "    data_files = [\n",
    "        \"pedigree.fam\", \"pedigree.def\", \n",
    "        \"merged_opensnps_autosomes_ped_sim.seg\",\n",
    "        \"merged_opensnps_autosomes_ped_sim-everyone.fam\",\n",
    "        \"ped_sim_run2.seg\", \"ped_sim_run2-everyone.fam\"\n",
    "    ]\n",
    "    \n",
    "    for file in data_files:\n",
    "        !wget -q -O /content/class_data/{file} {S3_BASE}{file}\n",
    "        print(f\"  ‚úÖ {file}\")\n",
    "    \n",
    "    # Define utility functions\n",
    "    def setup_environment():\n",
    "        return \"/content/class_data\", \"/content/results\"\n",
    "    \n",
    "    def save_results(dataframe, filename, description=\"results\"):\n",
    "        os.makedirs(\"/content/results\", exist_ok=True)\n",
    "        full_path = f\"/content/results/{filename}\"\n",
    "        dataframe.to_csv(full_path, index=False)\n",
    "        display(HTML(f'''\n",
    "        <div style=\"padding: 10px; background-color: #e3f2fd; border-left: 4px solid #2196f3; margin: 10px 0;\">\n",
    "            <p><strong>üíæ Results saved!</strong> To download: \n",
    "            <code>from google.colab import files; files.download('{full_path}')</code></p>\n",
    "        </div>\n",
    "        '''))\n",
    "        return full_path\n",
    "    \n",
    "    def save_plot(plt, filename, description=\"plot\"):\n",
    "        os.makedirs(\"/content/results\", exist_ok=True)\n",
    "        full_path = f\"/content/results/{filename}\"\n",
    "        plt.savefig(full_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        display(HTML(f'''\n",
    "        <div style=\"padding: 10px; background-color: #e8f5e8; border-left: 4px solid #4caf50; margin: 10px 0;\">\n",
    "            <p><strong>üìä Plot saved!</strong> To download: \n",
    "            <code>from google.colab import files; files.download('{full_path}')</code></p>\n",
    "        </div>\n",
    "        '''))\n",
    "        return full_path\n",
    "    \n",
    "    print(\"‚úÖ Colab setup complete! Ready to explore genetic genealogy.\")\n",
    "    \n",
    "else:\n",
    "    print(\"üè† Local environment detected\")\n",
    "    def setup_environment():\n",
    "        return \"class_data\", \"results\"\n",
    "    def save_results(df, filename, description=\"\"):\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        path = f\"results/{filename}\"\n",
    "        df.to_csv(path, index=False)\n",
    "        return path\n",
    "    def save_plot(plt, filename, description=\"\"):\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        path = f\"results/{filename}\"\n",
    "        plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        return path\n",
    "\n",
    "# Set up paths and configure visualization\n",
    "DATA_DIR, RESULTS_DIR = setup_environment()\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 1. Upload all files from data/class_data to S3 without any exclusions\n!aws s3 sync data/class_data/ s3://computational-genetic-genealogy/class_data/\n\n# Note: This command uploads all files including large directories\n# The upload may take some time depending on the size of the data\n# If needed for a specific file, you can use:\n!aws s3 cp data/class_data/specific_file.vcf.gz s3://computational-genetic-genealogy/class_data/",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 bucket (if it doesn't exist)\n",
    "!aws s3 mb s3://computational-genetic-genealogy --region us-east-2\n",
    "\n",
    "# Configure bucket for public access (only if needed for course materials)\n",
    "!aws s3api put-public-access-block --bucket computational-genetic-genealogy \\\n",
    "  --public-access-block-configuration \"BlockPublicAcls=false,IgnorePublicAcls=false,BlockPublicPolicy=false,RestrictPublicBuckets=false\"\n",
    "\n",
    "# Set bucket policy for public read access\n",
    "!aws s3api put-bucket-policy --bucket computational-genetic-genealogy --policy '{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "    {\n",
    "      \"Sid\": \"PublicReadGetObject\",\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": \"*\",\n",
    "      \"Action\": \"s3:GetObject\",\n",
    "      \"Resource\": \"arn:aws:s3:::computational-genetic-genealogy/*\"\n",
    "    }\n",
    "  ]\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Data to S3\n",
    "\n",
    "Upload class data to the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Upload all files from data/class_data to S3 (excluding large subdirectories)\n",
    "!aws s3 sync data/class_data/ s3://computational-genetic-genealogy/class_data/ \\\n",
    "  --exclude \"*/phased_samples/*\" \\\n",
    "  --exclude \"*/unphased_samples/*\" \\\n",
    "  --exclude \"*/segments/*\" \\\n",
    "  --exclude \"*opensnps_data_autosomes/segments/*\" \\\n",
    "  --exclude \"*opensnps_data_autosomes/unphased_samples/*\"\n",
    "\n",
    "# 2. Upload specific large files if needed\n",
    "!aws s3 cp data/class_data/specific_large_file.vcf.gz s3://computational-genetic-genealogy/class_data/\n",
    "\n",
    "# 3. Create empty directory placeholders\n",
    "!aws s3api put-object --bucket computational-genetic-genealogy --key class_data/merged_opensnps_data_autosomes/\n",
    "!aws s3api put-object --bucket computational-genetic-genealogy --key class_data/merged_opensnps_data_autosomes/phased_samples/\n",
    "!aws s3api put-object --bucket computational-genetic-genealogy --key class_data/merged_opensnps_data_autosomes/segments/\n",
    "!aws s3api put-object --bucket computational-genetic-genealogy --key class_data/merged_opensnps_data_autosomes/unphased_samples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing S3 Data\n",
    "\n",
    "Commands for managing data in the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all objects in the bucket\n",
    "!aws s3 ls s3://computational-genetic-genealogy/ --recursive | head -20\n",
    "\n",
    "# Count total objects\n",
    "!aws s3 ls s3://computational-genetic-genealogy/ --recursive | wc -l\n",
    "\n",
    "# Check if specific file exists\n",
    "!aws s3api head-object --bucket computational-genetic-genealogy --key class_data/pedigree.fam\n",
    "\n",
    "# Delete a specific file\n",
    "!aws s3 rm s3://computational-genetic-genealogy/class_data/unwanted_file.txt\n",
    "\n",
    "# Delete a directory\n",
    "!aws s3 rm s3://computational-genetic-genealogy/old_data/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing S3 Access\n",
    "\n",
    "Verify that files are accessible via HTTP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test access to a file via curl\n",
    "!curl -I https://computational-genetic-genealogy.s3.us-east-2.amazonaws.com/class_data/pedigree.fam\n",
    "\n",
    "# View content of a small file\n",
    "!curl -s https://computational-genetic-genealogy.s3.us-east-2.amazonaws.com/class_data/pedigree.fam | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Colab Integration\n",
    "\n",
    "To prepare notebooks for Google Colab, add the following code to detect Colab environment and set up data access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to add at the beginning of notebooks for Colab compatibility\n",
    "\n",
    "def is_colab():\n",
    "    \"\"\"Check if the notebook is running in Google Colab\"\"\"\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "# Example usage:\n",
    "if is_colab():\n",
    "    print(\"Running in Google Colab environment\")\n",
    "    \n",
    "    # Option 1: Mount Google Drive (if students want to save data)\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Option 2: Just create directories for this session\n",
    "    !mkdir -p class_data\n",
    "    !mkdir -p results\n",
    "    \n",
    "    # Set environment variables\n",
    "    import os\n",
    "    os.environ['DATA_DIR'] = '/content/class_data'\n",
    "    os.environ['RESULTS_DIR'] = '/content/results'\n",
    "else:\n",
    "    print(\"Running in local environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for Downloading S3 Data in Colab\n",
    "\n",
    "Add this code to notebooks to download required data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to download required data files from S3\n",
    "\n",
    "def download_class_data(files, base_dir=\"class_data\"):\n",
    "    \"\"\"Download required files from S3\n",
    "    \n",
    "    Args:\n",
    "        files: List of filenames or tuples (s3_path, local_name)\n",
    "        base_dir: Local directory to store files\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Create directory if needed\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    # S3 bucket URL\n",
    "    s3_base = \"https://computational-genetic-genealogy.s3.us-east-2.amazonaws.com/class_data/\"\n",
    "    \n",
    "    # Process each file\n",
    "    for file_info in files:\n",
    "        if isinstance(file_info, tuple):\n",
    "            s3_path, local_name = file_info\n",
    "        else:\n",
    "            s3_path = local_name = file_info\n",
    "            \n",
    "        # Ensure subdirectories exist\n",
    "        local_path = os.path.join(base_dir, local_name)\n",
    "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "        \n",
    "        # Download file\n",
    "        !wget -q -O {local_path} {s3_base}{s3_path}\n",
    "        print(f\"Downloaded {s3_path} to {local_path}\")\n",
    "\n",
    "# Example usage\n",
    "if is_colab():\n",
    "    download_class_data([\n",
    "        \"pedigree.fam\",\n",
    "        \"pedigree.def\",\n",
    "        \"merged_opensnps_autosomes_ped_sim.seg\",\n",
    "        # Include subdirectory example\n",
    "        (\"raw_dna_profiles/user12214_file10061_yearofbirth_2001_sex_XY.ancestry.txt\", \n",
    "         \"raw_dna_profiles/user12214.ancestry.txt\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab Embedding\n",
    "\n",
    "Instructions for embedding Colab notebooks in HTML pages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<!-- Example of embedding a Colab notebook in an HTML page -->\n",
    "<iframe\n",
    "  src=\"https://colab.research.google.com/github/lakishadavid/computational_genetic_genealogy/blob/main/labs_v2/Lab01_IBD_and_Genealogy_Intro.ipynb\"\n",
    "  width=\"100%\" height=\"800px\">\n",
    "</iframe>\n",
    "```\n",
    "\n",
    "Key parameters for the iframe URL:\n",
    "- GitHub username: `lakishadavid` \n",
    "- Repository: `computational_genetic_genealogy`\n",
    "- Branch: `main`\n",
    "- Path to notebook: `labs_v2/Lab01_IBD_and_Genealogy_Intro.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. JupyterLite Integration\n",
    "\n",
    "JupyterLite provides a fully client-side, in-browser Jupyter experience. It doesn't require server setup and can include data files directly in the build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the JupyterLite build script\n",
    "!cat scripts_support/build_jupyter.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JupyterLite Embedding\n",
    "\n",
    "Instructions for embedding JupyterLite notebooks in HTML pages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<!-- Example of embedding a JupyterLite notebook in an HTML page -->\n",
    "<iframe\n",
    "  src=\"jupyterlite_app/lab/index.html?path=Lab01_IBD_and_Genealogy_Intro.ipynb\"\n",
    "  width=\"100%\" height=\"800px\">\n",
    "</iframe>\n",
    "```\n",
    "\n",
    "Key parameters:\n",
    "- Base path to JupyterLite app: `jupyterlite_app/lab/index.html`\n",
    "- Notebook path: `Lab01_IBD_and_Genealogy_Intro.ipynb`\n",
    "- Additional options: `kernel=python&toolbar=1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Template Code for Cross-Platform Compatibility\n",
    "\n",
    "Use this template to make notebooks work across environments (local, Colab, JupyterLite):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-environment compatibility code\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Set up environment-specific paths and dependencies\"\"\"\n",
    "    \n",
    "    # Check for Google Colab\n",
    "    in_colab = 'google.colab' in sys.modules\n",
    "    \n",
    "    # Check for JupyterLite\n",
    "    in_jupyterlite = 'pyodide' in sys.modules\n",
    "    \n",
    "    if in_colab:\n",
    "        print(\"Setting up Google Colab environment\")\n",
    "        \n",
    "        # Create directories\n",
    "        !mkdir -p class_data\n",
    "        !mkdir -p results\n",
    "        \n",
    "        # Set paths\n",
    "        data_dir = 'class_data'\n",
    "        results_dir = 'results'\n",
    "        \n",
    "        # Download required data (customize for each notebook)\n",
    "        s3_base = \"https://computational-genetic-genealogy.s3.us-east-2.amazonaws.com/class_data/\"\n",
    "        files_to_download = [\"pedigree.fam\", \"pedigree.def\"]\n",
    "        \n",
    "        for file in files_to_download:\n",
    "            !wget -q -O {data_dir}/{file} {s3_base}{file}\n",
    "            print(f\"Downloaded {file}\")\n",
    "            \n",
    "    elif in_jupyterlite:\n",
    "        print(\"Setting up JupyterLite environment\")\n",
    "        # In JupyterLite, data is pre-loaded in the files/ directory\n",
    "        data_dir = 'class_data'\n",
    "        results_dir = 'results'\n",
    "        \n",
    "    else:\n",
    "        print(\"Setting up local environment\")\n",
    "        # Use environment variables or default paths\n",
    "        data_dir = os.getenv('DATA_DIR', 'data/class_data')\n",
    "        results_dir = os.getenv('RESULTS_DIR', 'results')\n",
    "        \n",
    "        # Ensure results directory exists\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    return data_dir, results_dir\n",
    "\n",
    "# Usage\n",
    "DATA_DIR, RESULTS_DIR = setup_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Notebook Template for S3 Data Access\n",
    "\n",
    "Use this template for creating new lab notebooks with S3 data access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template S3 data access code to include in notebooks\n",
    "\n",
    "def download_s3_data():\n",
    "    \"\"\"Download required data files from S3 for this lab\"\"\"\n",
    "    # Check if running in Google Colab\n",
    "    try:\n",
    "        import google.colab\n",
    "        in_colab = True\n",
    "    except ImportError:\n",
    "        in_colab = False\n",
    "        \n",
    "    if not in_colab:\n",
    "        print(\"Not running in Colab, skipping download\")\n",
    "        return\n",
    "        \n",
    "    # Create directories\n",
    "    !mkdir -p class_data\n",
    "    \n",
    "    # S3 base URL\n",
    "    S3_BASE = \"https://computational-genetic-genealogy.s3.us-east-2.amazonaws.com/class_data/\"\n",
    "    \n",
    "    # Files needed for this specific lab\n",
    "    FILES = [\n",
    "        \"pedigree.fam\",\n",
    "        \"pedigree.def\",\n",
    "        \"merged_opensnps_autosomes_ped_sim.seg\"\n",
    "    ]\n",
    "    \n",
    "    # Download each file\n",
    "    for file in FILES:\n",
    "        !wget -q -O class_data/{file} {S3_BASE}{file}\n",
    "        print(f\"Downloaded {file}\")\n",
    "        \n",
    "    print(\"All required data files downloaded successfully!\")\n",
    "    \n",
    "# Download data when running in Colab\n",
    "download_s3_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}