{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Exploring Population Genomic Data\n",
    "\n",
    "This notebook introduces the fundamental concepts of population genomics through the analysis of data from the 1000 Genomes Project. You'll explore genetic variation across global populations and learn how to visualize and interpret population structure.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we'll import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in JupyterLite (browser) or local environment\n",
    "import sys\n",
    "IN_BROWSER = 'pyodide' in sys.modules\n",
    "\n",
    "# Install required packages if running in browser\n",
    "if IN_BROWSER:\n",
    "    %pip install -q numpy pandas scikit-learn matplotlib seaborn\n",
    "    print(\"Running in JupyterLite browser environment\")\n",
    "else:\n",
    "    print(\"Running in standard Jupyter environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "import random\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Set plot styles\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Configure matplotlib for high-quality plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['savefig.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "In a browser environment, we'll be using a pre-processed subset of the 1000 Genomes Project data that's compatible with JupyterLite. This dataset includes genetic variants (SNPs) from chromosome 22 for 504 individuals across five super-populations."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Exploratory Data Analysis\n\nNow that we have loaded our data, let's explore the patterns of genetic variation across populations. We'll start by calculating some basic summary statistics and then visualize the data using Principal Component Analysis (PCA).",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def calculate_allele_frequencies(genotypes, metadata):\n    \"\"\"Calculate allele frequencies for each population\"\"\"\n    populations = metadata['population'].unique()\n    n_variants = genotypes.shape[1]\n    \n    # Dictionary to store allele frequencies for each population\n    pop_frequencies = {}\n    \n    for pop in populations:\n        # Get indices of samples in this population\n        pop_indices = metadata[metadata['population'] == pop].index\n        \n        # Extract genotypes for this population\n        pop_genotypes = genotypes[pop_indices, :]\n        \n        # Calculate allele frequency (divide by 2 because each genotype has 2 alleles)\n        pop_freq = np.sum(pop_genotypes, axis=0) / (2 * len(pop_indices))\n        \n        # Store in dictionary\n        pop_frequencies[pop] = pop_freq\n    \n    return pop_frequencies\n\n# Calculate allele frequencies for each population\nif genotypes is not None:\n    pop_frequencies = calculate_allele_frequencies(genotypes, metadata)\n    \n    # Create a DataFrame for easier visualization\n    freq_df = pd.DataFrame(pop_frequencies)\n    \n    # Display first few rows\n    print(\"Allele frequencies for first 5 variants:\")\n    display(freq_df.head())\n    \n    # Plot the distribution of allele frequencies for each population\n    plt.figure(figsize=(12, 6))\n    \n    for pop in metadata['population'].unique():\n        sns.kdeplot(pop_frequencies[pop], label=pop)\n    \n    plt.xlabel('Allele Frequency')\n    plt.ylabel('Density')\n    plt.title('Distribution of Allele Frequencies Across Populations')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.show()\n    \n    # Compute and visualize FST (population differentiation)\n    print(\"\\nPairwise FST values (measure of population differentiation):\")\n    \n    # Calculate FST for each pair of populations and each SNP\n    # For simplicity, using Weir & Cockerham's formula for 2 populations\n    def calculate_fst(freq1, freq2):\n        # Simple FST calculation - for educational purposes\n        # In a real analysis, you would use a proper formula like Weir & Cockerham's\n        numerator = (freq1 - freq2)**2\n        denominator = freq1 * (1 - freq1) + freq2 * (1 - freq2)\n        # Avoid division by zero\n        valid_indices = denominator > 0\n        fst = np.zeros_like(numerator)\n        fst[valid_indices] = numerator[valid_indices] / denominator[valid_indices]\n        return np.mean(fst)  # Average across all SNPs\n    \n    # Calculate FST for each pair of populations\n    pops = list(pop_frequencies.keys())\n    fst_matrix = np.zeros((len(pops), len(pops)))\n    \n    for i, pop1 in enumerate(pops):\n        for j, pop2 in enumerate(pops):\n            if i < j:  # Only calculate for unique pairs\n                fst = calculate_fst(pop_frequencies[pop1], pop_frequencies[pop2])\n                fst_matrix[i, j] = fst\n                fst_matrix[j, i] = fst  # Matrix is symmetric\n    \n    # Create a DataFrame and visualize as a heatmap\n    fst_df = pd.DataFrame(fst_matrix, index=pops, columns=pops)\n    display(fst_df)\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(fst_df, annot=True, cmap='YlGnBu', fmt='.4f', \n                linewidths=0.5, cbar_kws={'label': 'FST Value'})\n    plt.title('Pairwise FST Values Between Populations')\n    plt.tight_layout()\n    plt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Principal Component Analysis (PCA)\n\nPCA is a powerful technique for visualizing the genetic structure of populations. It can reveal patterns of genetic relatedness and differentiation that might not be obvious from individual SNPs.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def run_pca(genotypes, metadata, n_components=2):\n    \"\"\"Run PCA on genotype data and return the PCA projections\"\"\"\n    if genotypes is None:\n        return None\n    \n    # Standardize the genotype data (important for PCA)\n    scaler = StandardScaler()\n    genotypes_std = scaler.fit_transform(genotypes)\n    \n    # Apply PCA\n    pca = PCA(n_components=n_components)\n    pca_projections = pca.fit_transform(genotypes_std)\n    \n    # Calculate the percentage of variance explained\n    variance_explained = pca.explained_variance_ratio_ * 100\n    \n    # Return the projections, pca object, and the variance explained\n    return pca_projections, pca, variance_explained\n\n# Run PCA if genotypes data is available\nif genotypes is not None:\n    # Run PCA\n    n_components = 5  # Calculate 5 components\n    pca_projections, pca, variance_explained = run_pca(genotypes, metadata, n_components)\n    \n    # Create a DataFrame with PCA projections and metadata\n    pca_df = pd.DataFrame(pca_projections, columns=[f'PC{i+1}' for i in range(n_components)])\n    pca_df['sample_id'] = metadata['sample_id'].values\n    pca_df['population'] = metadata['population'].values\n    \n    # Print the percentage of variance explained\n    print(\"Percentage of variance explained by each principal component:\")\n    for i, var in enumerate(variance_explained):\n        print(f\"PC{i+1}: {var:.2f}%\")\n    \n    # Plot the PCA results (PC1 vs PC2)\n    plt.figure(figsize=(12, 8))\n    \n    # Define a color palette for the populations\n    palette = {'AFR': '#1f77b4', 'AMR': '#ff7f0e', 'EAS': '#2ca02c', \n               'EUR': '#d62728', 'SAS': '#9467bd'}\n    \n    # Plot each population with a different color\n    for pop in pca_df['population'].unique():\n        subset = pca_df[pca_df['population'] == pop]\n        plt.scatter(subset['PC1'], subset['PC2'], label=pop, alpha=0.7, \n                    edgecolor='w', linewidth=0.5, s=80, color=palette[pop])\n    \n    # Add labels and title\n    plt.xlabel(f'PC1 ({variance_explained[0]:.2f}% variance explained)')\n    plt.ylabel(f'PC2 ({variance_explained[1]:.2f}% variance explained)')\n    plt.title('PCA of Population Genetic Structure')\n    plt.legend(title='Population')\n    plt.grid(True, alpha=0.3)\n    \n    # Add a tight layout and show the plot\n    plt.tight_layout()\n    plt.show()\n    \n    # Plot PC1 vs PC3\n    plt.figure(figsize=(12, 8))\n    for pop in pca_df['population'].unique():\n        subset = pca_df[pca_df['population'] == pop]\n        plt.scatter(subset['PC1'], subset['PC3'], label=pop, alpha=0.7, \n                    edgecolor='w', linewidth=0.5, s=80, color=palette[pop])\n    \n    plt.xlabel(f'PC1 ({variance_explained[0]:.2f}% variance explained)')\n    plt.ylabel(f'PC3 ({variance_explained[2]:.2f}% variance explained)')\n    plt.title('PCA of Population Genetic Structure (PC1 vs PC3)')\n    plt.legend(title='Population')\n    plt.grid(True, alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n    \n    # Create a pairplot for the first 4 PCs\n    plt.figure(figsize=(15, 15))\n    sns.pairplot(pca_df, vars=[f'PC{i+1}' for i in range(4)], \n                 hue='population', palette=palette, plot_kws={'alpha': 0.6, 's': 70, 'edgecolor': 'w', 'linewidth': 0.5})\n    plt.suptitle('Pairwise Relationships Between Principal Components', y=1.02, size=16)\n    plt.tight_layout()\n    plt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Browser Storage Integration\n\nWhen running in JupyterLite, we can save our data to browser storage for use in subsequent labs. This will allow us to continue our analysis across multiple lab sessions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def save_to_browser_storage(data_dict, key_prefix='genetic_genealogy_'):\n    \"\"\"Save data to browser localStorage for use in subsequent notebooks\"\"\"\n    if not IN_BROWSER:\n        print(\"Not running in a browser environment, skipping storage\")\n        return False\n    \n    try:\n        # Convert data to JSON-compatible format\n        from pyodide.ffi import to_js\n        \n        # Create a serializable dictionary for common data types\n        store_dict = {}\n        \n        for key, value in data_dict.items():\n            storage_key = f\"{key_prefix}{key}\"\n            \n            if isinstance(value, np.ndarray):\n                # For numpy arrays, convert to list and store type information\n                data_type = str(value.dtype)\n                shape = list(value.shape)\n                if data_type.startswith('float'):\n                    # Convert to standard Python list\n                    data = value.tolist()\n                    store_dict[storage_key] = {'type': 'ndarray', 'dtype': data_type, \n                                              'shape': shape, 'data': data}\n                elif data_type.startswith('int'):\n                    data = value.tolist()\n                    store_dict[storage_key] = {'type': 'ndarray', 'dtype': data_type, \n                                              'shape': shape, 'data': data}\n                else:\n                    print(f\"Unsupported numpy dtype: {data_type} for key {key}\")\n                    continue\n            \n            elif isinstance(value, pd.DataFrame):\n                # For DataFrames, convert to dict\n                store_dict[storage_key] = {'type': 'dataframe', \n                                          'data': value.to_dict(orient='records'),\n                                          'index': value.index.tolist(),\n                                          'columns': value.columns.tolist()}\n            \n            elif isinstance(value, pd.Series):\n                # For Series, convert to dict\n                store_dict[storage_key] = {'type': 'series', \n                                          'data': value.tolist(),\n                                          'index': value.index.tolist(),\n                                          'name': value.name}\n            \n            elif isinstance(value, (list, dict, str, int, float, bool)) or value is None:\n                # These types are directly JSON serializable\n                store_dict[storage_key] = {'type': type(value).__name__, 'data': value}\n            \n            else:\n                print(f\"Unsupported data type: {type(value)} for key {key}\")\n                continue\n        \n        # Store to localStorage as JSON\n        import json\n        for key, value in store_dict.items():\n            # Convert to JavaScript object\n            js_data = to_js(json.dumps(value))\n            \n            # Use JavaScript to set the item in localStorage\n            from js import localStorage\n            localStorage.setItem(key, js_data)\n        \n        print(f\"Successfully saved {len(store_dict)} items to browser storage\")\n        return True\n    \n    except Exception as e:\n        print(f\"Error saving to browser storage: {str(e)}\")\n        return False\n\n# If in browser environment and we have data, save it for subsequent labs\nif IN_BROWSER and genotypes is not None:\n    # Prepare data to save\n    data_to_save = {\n        'pca_projections': pca_projections if 'pca_projections' in locals() else None,\n        'metadata': metadata,\n        'variant_info': variant_info,\n        'lab_progress': 100  # Mark this lab as completed\n    }\n    \n    # Save to browser storage\n    save_result = save_to_browser_storage(data_to_save)\n    \n    if save_result:\n        print(\"\\nProgress saved successfully! You can now continue to Lab 2.\")\n        \n        # Display a summary of what was saved\n        from IPython.display import HTML\n        display(HTML(\"\"\"\n        <div style=\"background-color: #e2f0d9; padding: 10px; border-radius: 5px; border: 1px solid #a8d08d;\">\n            <h3 style=\"color: #548235;\">Lab 1 Completed</h3>\n            <p>Your data and progress have been saved to browser storage. In the next lab, you'll explore:</p>\n            <ul>\n                <li>Processing raw DNA profiles</li>\n                <li>Applying quality control measures</li>\n                <li>Preparing data for subsequent genetic genealogy analysis</li>\n            </ul>\n            <p>You can return to the course page and proceed to Lab 2.</p>\n        </div>\n        \"\"\"))\n    else:\n        print(\"\\nError saving progress. Please make sure your browser supports localStorage.\")\nelse:\n    print(\"\\nNot saving data (either not in browser environment or no data available).\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Conclusion\n\nIn this lab, you've explored the fundamentals of population genomics using simulated 1000 Genomes Project data. You've learned how to:\n\n1. Load and inspect genetic data\n2. Calculate and visualize allele frequencies across populations\n3. Compute FST values to quantify population differentiation\n4. Apply PCA to visualize population structure\n5. Save your progress for subsequent labs\n\nThese concepts form the foundation for understanding genetic genealogy and interpreting relationships between individuals. In the next lab, you'll learn how to process raw DNA profiles and prepare them for analysis.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data():\n",
    "    \"\"\"Load demo genetic data for JupyterLite\"\"\"\n",
    "    if IN_BROWSER:\n",
    "        # For browser environment, we'll use a small pre-prepared dataset\n",
    "        # This would be fetched from a CDN or embedded in the notebook\n",
    "        \n",
    "        # Simulate sample data for demonstration\n",
    "        # In a real implementation, this would load from a URL or use embedded data\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Create sample metadata\n",
    "        populations = ['AFR', 'AMR', 'EAS', 'EUR', 'SAS']\n",
    "        pop_sizes = {'AFR': 99, 'AMR': 85, 'EAS': 103, 'EUR': 107, 'SAS': 110}\n",
    "        \n",
    "        # Generate sample IDs and population assignments\n",
    "        sample_ids = []\n",
    "        sample_pops = []\n",
    "        \n",
    "        for pop, size in pop_sizes.items():\n",
    "            for i in range(size):\n",
    "                sample_id = f\"HG{i:05d}_{pop}\"\n",
    "                sample_ids.append(sample_id)\n",
    "                sample_pops.append(pop)\n",
    "        \n",
    "        # Create sample metadata DataFrame\n",
    "        metadata = pd.DataFrame({\n",
    "            'sample_id': sample_ids,\n",
    "            'population': sample_pops\n",
    "        })\n",
    "        \n",
    "        # Generate synthetic genetic data (genotype matrix)\n",
    "        # This simulates population structure\n",
    "        n_samples = len(sample_ids)\n",
    "        n_variants = 1000  # Reduced number for browser performance\n",
    "        \n",
    "        # Create population-specific allele frequencies\n",
    "        pop_frequencies = {\n",
    "            'AFR': np.random.beta(a=0.5, b=0.5, size=n_variants),  # More diverse\n",
    "            'EUR': np.random.beta(a=0.3, b=0.7, size=n_variants),\n",
    "            'EAS': np.random.beta(a=0.4, b=0.6, size=n_variants),\n",
    "            'SAS': np.random.beta(a=0.35, b=0.65, size=n_variants),\n",
    "            'AMR': np.random.beta(a=0.3, b=0.5, size=n_variants)   # Admixed\n",
    "        }\n",
    "        \n",
    "        # Generate genotypes based on population frequencies\n",
    "        genotypes = np.zeros((n_samples, n_variants))\n",
    "        \n",
    "        for i, (_, row) in enumerate(metadata.iterrows()):\n",
    "            pop = row['population']\n",
    "            # Generate genotypes as 0, 1, or 2 (counts of alternate allele)\n",
    "            for j in range(n_variants):\n",
    "                p = pop_frequencies[pop][j]\n",
    "                genotypes[i, j] = np.random.binomial(2, p)\n",
    "        \n",
    "        # Create variant info\n",
    "        variant_ids = [f\"rs{i+1000}\" for i in range(n_variants)]\n",
    "        variant_pos = sorted(np.random.choice(range(1, 51000000), n_variants, replace=False))\n",
    "        \n",
    "        variant_info = pd.DataFrame({\n",
    "            'variant_id': variant_ids,\n",
    "            'chrom': 22,\n",
    "            'position': variant_pos,\n",
    "            'ref': np.random.choice(['A', 'C', 'G', 'T'], n_variants),\n",
    "            'alt': np.random.choice(['A', 'C', 'G', 'T'], n_variants)\n",
    "        })\n",
    "        \n",
    "        print(f\"Loaded synthetic data: {n_samples} samples, {n_variants} variants\")\n",
    "        return genotypes, metadata, variant_info\n",
    "    else:\n",
    "        # For non-browser environments, load the real 1000 Genomes data\n",
    "        # This is a simplified version of the data loading - in a real notebook,\n",
    "        # it would use proper libraries like scikit-allel\n",
    "        \n",
    "        # This is just a stub - replace with actual data loading code when running locally\n",
    "        print(\"In a non-browser environment, you would load the actual 1000 Genomes data here.\")\n",
    "        return None, None, None\n",
    "\n",
    "# Load the data\n",
    "genotypes, metadata, variant_info = load_sample_data()\n",
    "\n",
    "# Display basic information about the data\n",
    "if genotypes is not None:\n",
    "    print(f\"\\nSample metadata:\")\n",
    "    display(metadata.head())\n",
    "    \n",
    "    print(f\"\\nVariant information:\")\n",
    "    display(variant_info.head())\n",
    "    \n",
    "    # Show population counts\n",
    "    pop_counts = metadata['population'].value_counts().sort_index()\n",
    "    print(f\"\\nPopulation sample counts:\")\n",
    "    display(pop_counts)\n",
    "    \n",
    "    # Display a small subset of the genotype matrix\n",
    "    print(f\"\\nGenotype matrix (first 5 samples, first 5 variants):\")\n",
    "    genotype_subset = pd.DataFrame(\n",
    "        genotypes[:5, :5], \n",
    "        index=metadata['sample_id'].iloc[:5],\n",
    "        columns=variant_info['variant_id'].iloc[:5]\n",
    "    )\n",
    "    display(genotype_subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}