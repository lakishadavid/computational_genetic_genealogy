{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0: Code Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Code Environments\n",
    "\n",
    "## What is a Code Environment?\n",
    "\n",
    "A **code environment** is the structured setup in which software applications run, including dependencies, libraries, and configurations necessary for execution. Code environments ensure that software behaves consistently across different machines and operating systems, preventing issues related to dependency conflicts and system inconsistencies.\n",
    "\n",
    "### Why Do Code Environments Matter?\n",
    "\n",
    "- **Reproducibility** â€“ Ensures that code runs the same way across different systems, facilitating collaboration and research reproducibility.\n",
    "- **Dependency Management** â€“ Prevents conflicts between different software packages by isolating dependencies.\n",
    "- **System Stability** â€“ Protects the main operating system from unnecessary installations and modifications.\n",
    "- **Scalability** â€“ Makes it easier to scale applications across multiple machines, cloud environments, or containerized deployments.\n",
    "\n",
    "## Virtual Environments with Poetry\n",
    "\n",
    "Our class is using **Poetry**, a modern dependency management tool for Python that simplifies package installation, versioning, and virtual environment creation. Poetry offers an elegant solution by combining dependency management and virtual environment creation into a single workflow.\n",
    "\n",
    "### Why Use Poetry?\n",
    "\n",
    "- **Automated Virtual Environments** â€“ Poetry automatically creates and manages virtual environments for projects.\n",
    "- **Simplified Dependency Management** â€“ Uses a `pyproject.toml` file instead of a `requirements.txt`, making package tracking more structured.\n",
    "- **Reproducibility** â€“ The `poetry.lock` file ensures that everyone working on the project installs the exact same package versions.\n",
    "- **Seamless Package Publishing** â€“ Poetry simplifies the process of building and publishing Python packages.\n",
    "\n",
    "### Key Poetry Commands\n",
    "\n",
    "| Command | Description |\n",
    "|---------|-------------|\n",
    "| `poetry new my_project` | Creates a new Poetry project with a `pyproject.toml` file |\n",
    "| `poetry install` | Installs dependencies and sets up the virtual environment |\n",
    "| `poetry add <package>` | Adds a new package to the project |\n",
    "| `poetry remove <package>` | Removes a package from the project |\n",
    "| `poetry shell` | Activates the project's virtual environment |\n",
    "| `poetry run <command>` | Runs a command inside the virtual environment |\n",
    "| `poetry lock` | Locks the dependencies to exact versions for consistency |\n",
    "\n",
    "## Docker: Containerized Code Environments\n",
    "\n",
    "While Poetry helps manage dependencies within Python projects, **Docker** provides an alternative approach by encapsulating an entire system environment, including the OS, into a container. Unlike virtual environments, which only manage dependencies at the application level, Docker offers a complete solution for deploying applications across different systems.\n",
    "\n",
    "### Key Features of Docker:\n",
    "- **Portability** â€“ Containers run identically on any system with Docker installed.\n",
    "- **Isolation** â€“ Each container runs independently, preventing dependency conflicts.\n",
    "- **Scalability** â€“ Facilitates cloud-based and microservices architectures.\n",
    "\n",
    "### When to Use Poetry vs. Docker:\n",
    "\n",
    "| Feature            | Poetry (Virtual Environment) | Docker (Containerization) |\n",
    "|--------------------|---------------------------|--------------------------|\n",
    "| **Scope**         | Manages Python dependencies within a project | Encapsulates the entire OS and software stack |\n",
    "| **Reproducibility** | Ensures consistent package versions | Provides full OS-level consistency |\n",
    "| **Portability**   | Works across Python projects on the same system | Runs across different machines and cloud platforms |\n",
    "| **Resource Usage** | Lightweight | Slightly heavier due to system overhead |\n",
    "| **Best Use Case** | Managing dependencies for Python projects | Deploying applications in diverse environments |\n",
    "\n",
    "## Docker Environment: Ubuntu 22.04\n",
    "\n",
    "In our Docker setup, we are using **Ubuntu 22.04 (Jammy Jellyfish)** as the base environment. This ensures consistency across different systems and provides a stable, long-term support (LTS) release with security updates and package support until **April 2027**. \n",
    "\n",
    "### Why Use Ubuntu 22.04?\n",
    "\n",
    "- **Long-Term Support (LTS)** â€“ Ubuntu 22.04 is an LTS release, ensuring reliability and security updates for an extended period.\n",
    "- **Stability and Compatibility** â€“ It is widely used in cloud computing, machine learning, and development environments, making it an ideal choice for reproducible research and software deployment.\n",
    "- **Lightweight and Efficient** â€“ The minimal Ubuntu image is optimized for running applications in containers without unnecessary overhead.\n",
    "- **Extensive Package Support** â€“ Ubuntu provides access to a vast software ecosystem, ensuring compatibility with necessary tools and dependencies.\n",
    "\n",
    "By using **Ubuntu 22.04** within Docker, we establish a controlled environment that minimizes discrepancies between development, testing, and production systems, ensuring consistency and reproducibility in our work.\n",
    "\n",
    "## Ensuring You Are Using the Latest Docker Image\n",
    "\n",
    "To maintain consistency and take advantage of the most up-to-date dependencies and security patches, it is important to ensure you are running the latest version of the **Ubuntu 22.04**-based Docker image. This prevents issues caused by outdated packages and ensures alignment with the current development environment.\n",
    "\n",
    "### Pulling the Latest Image\n",
    "\n",
    "Before running a container, always pull the latest version of the image by executing:\n",
    "\n",
    "```\n",
    "docker pull lakishadavid/cgg_image:latest\n",
    "```\n",
    "\n",
    "This command fetches the most recent version of the **cgg_image**, ensuring you are using the most up-to-date environment.\n",
    "\n",
    "### Running the Docker Container\n",
    "\n",
    "Once you have pulled the latest image, start a container interactively with:\n",
    "\n",
    "```\n",
    "docker run -it lakishadavid/cgg_image:latest bash\n",
    "```\n",
    "\n",
    "This command:\n",
    "- **Runs** a new container from the latest image.\n",
    "- **Opens an interactive terminal (`-it`)** to allow direct interaction with the container.\n",
    "- **Launches a Bash shell** so you can execute commands within the container.\n",
    "\n",
    "By following these steps, you ensure that your development environment is always using the most recent and properly configured version of the image.\n",
    "\n",
    "## Exiting the Docker Container\n",
    "\n",
    "Once you have finished working inside the Docker container, you will need to exit properly. There are multiple ways to leave the container depending on whether you want to stop it entirely or keep it running in the background.\n",
    "\n",
    "### Exit and Stop the Container\n",
    "\n",
    "The most common way to exit a Docker container is by using the `exit` command:\n",
    "\n",
    "```\n",
    "exit\n",
    "```\n",
    "\n",
    "This will terminate the container and return you to your local terminal.\n",
    "\n",
    "### When Should You Stop a Container?\n",
    "\n",
    "Stopping a container is necessary when:\n",
    "- You **no longer need** the application or environment running.\n",
    "- You want to **free up system resources** being used by the container.\n",
    "- You need to **apply updates** or modifications before restarting the container.\n",
    "- You want to **preserve changes** made inside the container so they are available the next time you start it.\n",
    "\n",
    "If the container is still running in the background, you can stop it from your terminal using:\n",
    "\n",
    "```\n",
    "docker stop <container_id>\n",
    "```\n",
    "\n",
    "To ensure a clean development workflow, it is good practice to stop containers when they are no longer needed, rather than letting them consume system resources indefinitely.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "A well-structured code environment is essential for ensuring software **stability**, **reproducibility**, and **efficiency**. In our setup:\n",
    "- **Poetry** simplifies dependency and virtual environment management, ensuring consistency across Python projects.\n",
    "- **Docker** provides an isolated, reproducible system environment, making it ideal for deploying applications across different machines.\n",
    "\n",
    "Understanding when to use each tool helps streamline development workflows. **Poetry** is best suited for managing dependencies within a Python project, while **Docker** ensures complete system encapsulation for broader deployment and portability needs. By combining both tools effectively, we create an environment that supports seamless collaboration, minimal dependency conflicts, and efficient software deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responsibility for the Code Environment\n",
    "\n",
    "While I will maintain the **Docker environment**, the focus of this class is on **running and understanding the genomic analysis code itself**. The Docker image provides a controlled and reproducible environment, ensuring that all necessary dependencies are pre-installed and configured correctly. By using Docker, you eliminate potential compatibility issues and can focus on the **analysis and interpretation of genomic data**.\n",
    "\n",
    "### Choosing How to Maintain Your Code Environment\n",
    "\n",
    "Students have two options for managing their code environment:\n",
    "\n",
    "1. **Use the Provided Docker Image**  \n",
    "   - I will maintain and update the Docker image to ensure compatibility and reproducibility.\n",
    "   - If you encounter any issues while using Docker, I will troubleshoot and resolve the problem.\n",
    "   - Using the Docker environment ensures that you are working in the exact same setup as me and others using the image.\n",
    "\n",
    "2. **Maintain Your Own Code Environment**  \n",
    "   - If you choose **not to use Docker**, you are responsible for setting up and maintaining your own code environment.\n",
    "   - You must ensure that all dependencies are correctly installed and compatible with the provided code.\n",
    "   - If issues arise due to your custom environment, I will offer support, but it is ultimately your responsibility to resolve them.\n",
    "\n",
    "### Required Setup for Non-Docker Users\n",
    "\n",
    "If you choose to work **outside of Docker**, you must manually install the required dependencies. The following code blocks have already been completed **within the Docker image**, meaning Docker users **do not need to run them**. However, **non-Docker users must run the following setup commands themselves** to ensure their environment is configured correctly.\n",
    "\n",
    "#### Important Notes:\n",
    "- The provided code blocks assume you are running **Ubuntu 22.04**.\n",
    "- If you are using a different system, you must adapt the installation steps accordingly.\n",
    "- While I can answer general questions about dependencies, my responsibility is to **maintain the code base within the Docker image**. Your responsibility is to effectively use that imageâ€”**either by running it directly or by correctly configuring your own system.**\n",
    "\n",
    "Below are the commands that **non-Docker Ubuntu users must run** to set up their environment properly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the Python Interpreter\n",
    "\n",
    "Your Jupyter Notebook needs to know not only which Python to use, but what set of Python packages to use. Selecting the one described below does that by selecting the Python within the virtual envrionment you created with the `poetry install --no-root` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This first time, go to the VS Code menu and select `View` > `Command Palette` > `Python: Select Interpreter`.\n",
    "2. Select `Enter interpreter path...`\n",
    "3. Select `Find...`\n",
    "4. Note it suggests the `computational_genetic_genealogy/instructions/` directory. Select the `..` at the top of the list to go up one level\n",
    "5. Select `.venv`, `bin`, and `python`.\n",
    "6. Select the button `Select Interpreter`.\n",
    "\n",
    "After this, each time you open this Jupyter Notebook, VS Codes remembers which virtual environment to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Enable Passwordless sudo apt-get for Jupyter Notebook**\n",
    "\n",
    "To run `sudo apt-get` commands in Jupyter Notebook **without being prompted for a password**, follow these steps. (See cell block below to copy and paste code into terminal window.)\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Find Your Username**\n",
    "Before proceeding, you need to determine your Linux username. To do this, run the following in your terminal window:\n",
    "\n",
    "```\n",
    "whoami\n",
    "```\n",
    "\n",
    "This will return your username. **Example Output:**\n",
    "```\n",
    "failingbird\n",
    "```\n",
    "\n",
    "In this example, the username is `failingbird`. The user would see `$HOME` defined as `/home/failingbird`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Add the Rule**\n",
    "Copy and paste the following command into your terminal:\n",
    "\n",
    "```\n",
    "echo \"$(whoami) ALL=(ALL) NOPASSWD: /usr/bin/apt-get, /usr/bin/dpkg, /usr/bin/apt, /bin/rm\" | sudo tee -a /etc/sudoers.d/$(whoami)\n",
    "```\n",
    "\n",
    "This command adds a rule to allow **your user** to execute `sudo apt-get` and `sudo rm` commands without entering a password.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3: Verify the Change**\n",
    "Run the following command to confirm the rule was added successfully:\n",
    "\n",
    "```\n",
    "sudo cat /etc/sudoers.d/$(whoami)\n",
    "```\n",
    "\n",
    "If the output includes:\n",
    "\n",
    "```\n",
    "failingbird ALL=(ALL) NOPASSWD: /usr/bin/apt-get, /usr/bin/dpkg, /usr/bin/apt, /bin/rm\n",
    "```\n",
    "\n",
    "then the setup is correct.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 4: (Optional) Remove the Rule**\n",
    "If you ever need to **undo** this change and restore the default behavior (where a password is required for `sudo apt-get` and `sudo rm`), run:\n",
    "\n",
    "```\n",
    "sudo rm /etc/sudoers.d/$(whoami)\n",
    "```\n",
    "\n",
    "### **Example for Username `failingbird`**\n",
    "```\n",
    "sudo rm /etc/sudoers.d/failingbird\n",
    "```\n",
    "\n",
    "This will remove the rule and require a password for future `sudo apt-get` and `sudo rm` commands.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **You can now run system updates in Jupyter Notebook without entering a password!** ðŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN IN JUPYTER NOTEBOOK. COPY AND PASTE TO TERMINAL WINDOW.\n",
    "\n",
    "# whoami\n",
    "# echo \"$(whoami) ALL=(ALL) NOPASSWD: /usr/bin/apt-add-repository, /usr/bin/apt, /usr/bin/apt-get, /usr/bin/dpkg, /usr/bin/apt, /bin/rm\" | sudo tee -a /etc/sudoers.d/$(whoami)\n",
    "# sudo cat /etc/sudoers.d/$(whoami)\n",
    "# sudo chmod 0440 /etc/sudoers.d/$(whoami)\n",
    "# exec sudo su - $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required System Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://download.docker.com/linux/ubuntu noble InRelease [48.8 kB]\n",
      "Get:2 https://download.docker.com/linux/ubuntu noble/stable amd64 Packages [19.7 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu noble InRelease [256 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu noble/main amd64 Packages [1401 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu noble/main Translation-en [513 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu noble/main amd64 Components [464 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu noble/main amd64 c-n-f Metadata [30.5 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu noble/universe amd64 Packages [15.0 MB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu noble-security InRelease [126 kB]     \u001b[0m\n",
      "Get:12 http://security.ubuntu.com/ubuntu noble-security/main amd64 Packages [619 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu noble/universe Translation-en [5982 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu noble-security/main Translation-en [119 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu noble-security/main amd64 Components [8976 B]3m\n",
      "Get:16 http://security.ubuntu.com/ubuntu noble-security/main amd64 c-n-f Metadata [5892 B]\n",
      "Get:17 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Packages [804 kB]\n",
      "Get:18 http://security.ubuntu.com/ubuntu noble-security/universe Translation-en [172 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Components [51.9 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu noble-security/universe amd64 c-n-f Metadata [13.5 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 Packages [625 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu noble/universe amd64 Components [3871 kB]0m\n",
      "Get:23 http://security.ubuntu.com/ubuntu noble-security/restricted Translation-en [121 kB]\n",
      "Get:24 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 Components [212 B]\n",
      "Get:25 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 c-n-f Metadata [424 B]\n",
      "Get:26 http://security.ubuntu.com/ubuntu noble-security/multiverse amd64 Packages [12.4 kB]\n",
      "Get:27 http://security.ubuntu.com/ubuntu noble-security/multiverse Translation-en [2940 B]\n",
      "Get:28 http://security.ubuntu.com/ubuntu noble-security/multiverse amd64 Components [212 B]\n",
      "Get:29 http://security.ubuntu.com/ubuntu noble-security/multiverse amd64 c-n-f Metadata [356 B]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu noble/universe amd64 c-n-f Metadata [301 kB]3m33m\u001b[33m\u001b[33m\n",
      "Get:31 http://archive.ubuntu.com/ubuntu noble/restricted amd64 Packages [93.9 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu noble/restricted Translation-en [18.7 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu noble/restricted amd64 c-n-f Metadata [416 B]3m\n",
      "Get:34 http://archive.ubuntu.com/ubuntu noble/multiverse amd64 Packages [269 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu noble/multiverse Translation-en [118 kB][0m\u001b[33m\u001b[33m\n",
      "Get:36 http://archive.ubuntu.com/ubuntu noble/multiverse amd64 Components [35.0 kB]\u001b[33m\n",
      "Get:37 http://archive.ubuntu.com/ubuntu noble/multiverse amd64 c-n-f Metadata [8328 B]3m\n",
      "Get:38 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages [867 kB]m\u001b[33m\n",
      "Get:39 http://archive.ubuntu.com/ubuntu noble-updates/main Translation-en [197 kB]m\u001b[33m\u001b[33m\n",
      "Get:40 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 Components [150 kB][33m\n",
      "Get:41 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 c-n-f Metadata [10.4 kB]\n",
      "Get:42 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages [1021 kB]m\n",
      "Get:43 http://archive.ubuntu.com/ubuntu noble-updates/universe Translation-en [255 kB]3m\u001b[33m\n",
      "Get:44 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 Components [363 kB]\n",
      "Get:45 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 c-n-f Metadata [19.9 kB]\n",
      "Get:46 http://archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Packages [655 kB]\n",
      "Get:47 http://archive.ubuntu.com/ubuntu noble-updates/restricted Translation-en [128 kB]\u001b[33m\n",
      "Get:48 http://archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Components [212 B]\n",
      "Get:49 http://archive.ubuntu.com/ubuntu noble-updates/restricted amd64 c-n-f Metadata [424 B]\n",
      "Get:50 http://archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 Packages [23.4 kB]\n",
      "Get:51 http://archive.ubuntu.com/ubuntu noble-updates/multiverse Translation-en [5308 B]\n",
      "Get:52 http://archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 Components [940 B]\n",
      "Get:53 http://archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 c-n-f Metadata [552 B]\n",
      "Get:54 http://archive.ubuntu.com/ubuntu noble-backports/main amd64 Components [208 B]33m\n",
      "Get:55 http://archive.ubuntu.com/ubuntu noble-backports/main amd64 c-n-f Metadata [112 B]\n",
      "Get:56 http://archive.ubuntu.com/ubuntu noble-backports/universe amd64 Packages [14.2 kB]\n",
      "Get:57 http://archive.ubuntu.com/ubuntu noble-backports/universe Translation-en [12.1 kB]\n",
      "Get:58 http://archive.ubuntu.com/ubuntu noble-backports/universe amd64 Components [20.0 kB]\n",
      "Get:59 http://archive.ubuntu.com/ubuntu noble-backports/universe amd64 c-n-f Metadata [1104 B]\n",
      "Get:60 http://archive.ubuntu.com/ubuntu noble-backports/restricted amd64 Components [216 B]\n",
      "Get:61 http://archive.ubuntu.com/ubuntu noble-backports/restricted amd64 c-n-f Metadata [116 B]\n",
      "Get:62 http://archive.ubuntu.com/ubuntu noble-backports/multiverse amd64 Components [212 B]\n",
      "Get:63 http://archive.ubuntu.com/ubuntu noble-backports/multiverse amd64 c-n-f Metadata [116 B]\n",
      "Fetched 35.2 MB in 10s (3546 kB/s)                                             \u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "12 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Adding component(s) 'universe' to all repositories.\n",
      "Hit:1 http://security.ubuntu.com/ubuntu noble-security InRelease\n",
      "Hit:2 https://download.docker.com/linux/ubuntu noble InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu noble InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu noble-updates InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu noble-backports InRelease\n",
      "Reading package lists... Done\n",
      "Adding component(s) 'multiverse' to all repositories.\n",
      "Hit:1 https://download.docker.com/linux/ubuntu noble InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu noble InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu noble-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu noble-backports InRelease\n",
      "Hit:5 http://security.ubuntu.com/ubuntu noble-security InRelease\n",
      "Reading package lists... Done\n",
      "[sudo] password for lakishadavid: \n",
      "sudo: a password is required\n",
      "^C\n",
      "Hit:1 https://download.docker.com/linux/ubuntu noble InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu noble-security InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu noble InRelease\n",
      "Get:4 http://archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu noble-backports InRelease\n",
      "Fetched 126 kB in 4s (33.1 kB/s)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "12 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.10ubuntu1).\n",
      "g++ is already the newest version (4:13.2.0-7ubuntu1).\n",
      "gcc is already the newest version (4:13.2.0-7ubuntu1).\n",
      "make is already the newest version (4.3-4.1build2).\n",
      "python3.12 is already the newest version (3.12.3-1ubuntu0.5).\n",
      "python3.12-dev is already the newest version (3.12.3-1ubuntu0.5).\n",
      "python3.12-venv is already the newest version (3.12.3-1ubuntu0.5).\n",
      "python3-pip is already the newest version (24.0+dfsg-1ubuntu1.1).\n",
      "graphviz is already the newest version (2.42.2-9ubuntu0.1).\n",
      "libfreetype-dev is already the newest version (2.13.2+dfsg-1build3).\n",
      "pkg-config is already the newest version (1.8.1-2build1).\n",
      "libpng-dev is already the newest version (1.6.43-5build1).\n",
      "zlib1g-dev is already the newest version (1:1.3.dfsg-3.1ubuntu2.1).\n",
      "libbz2-dev is already the newest version (1.0.8-5.1build0.1).\n",
      "libharfbuzz-dev is already the newest version (8.3.0-2build2).\n",
      "libcurl4-openssl-dev is already the newest version (8.5.0-2ubuntu10.6).\n",
      "libssl-dev is already the newest version (3.0.13-0ubuntu3.5).\n",
      "libxml2-dev is already the newest version (2.9.14+dfsg-1.3ubuntu3.1).\n",
      "wget is already the newest version (1.21.4-1ubuntu4.1).\n",
      "curl is already the newest version (8.5.0-2ubuntu10.6).\n",
      "git is already the newest version (1:2.43.0-1ubuntu7.2).\n",
      "unzip is already the newest version (6.0-28ubuntu4.1).\n",
      "default-jre is already the newest version (2:1.21-75+exp1).\n",
      "gawk is already the newest version (1:5.2.1-2build3).\n",
      "libboost-all-dev is already the newest version (1.83.0.1ubuntu2).\n",
      "texlive-xetex is already the newest version (2023.20240207-1).\n",
      "texlive-fonts-recommended is already the newest version (2023.20240207-1).\n",
      "texlive-plain-generic is already the newest version (2023.20240207-1).\n",
      "pandoc is already the newest version (3.1.3+ds-2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Update system packages\n",
    "!sudo apt update -y\n",
    "\n",
    "# Revise list of places to search for packages\n",
    "!sudo apt-add-repository -y universe\n",
    "!sudo apt-add-repository -y multiverse\n",
    "!sudo apt-add-repository -y ppa:deadsnakes/ppa \n",
    "!sudo apt update -y\n",
    "\n",
    "# Install system\n",
    "!sudo apt install -y --no-install-recommends \\\n",
    "    build-essential \\\n",
    "    g++ \\\n",
    "    gcc \\\n",
    "    make \\\n",
    "    python3.12 \\\n",
    "    python3.12-dev \\\n",
    "    python3.12-venv \\\n",
    "    python3-pip \\\n",
    "    graphviz \\\n",
    "    libfreetype-dev \\\n",
    "    pkg-config \\\n",
    "    libpng-dev \\\n",
    "    zlib1g-dev \\\n",
    "    libbz2-dev \\\n",
    "    libharfbuzz-dev \\\n",
    "    libcurl4-openssl-dev \\\n",
    "    libssl-dev \\\n",
    "    libxml2-dev \\\n",
    "    wget \\\n",
    "    curl \\\n",
    "    git \\\n",
    "    unzip \\\n",
    "    default-jre \\\n",
    "    gawk \\\n",
    "    libboost-all-dev \\\n",
    "    texlive-xetex \\\n",
    "    texlive-fonts-recommended \\\n",
    "    texlive-plain-generic \\\n",
    "    pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using virtualenv: \u001b[32m/home/lakishadavid/computational_genetic_genealogy/.venv\u001b[39m\n",
      "\u001b[34mInstalling dependencies from lock file\u001b[39m\n",
      "\n",
      "No dependencies to install or update\n",
      "Requirement already satisfied: pip in /home/lakishadavid/computational_genetic_genealogy/.venv/lib/python3.12/site-packages (25.0.1)\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get clean\n",
    "!sudo rm -rf /var/lib/apt/lists/*\n",
    "!poetry env use python3.12\n",
    "!poetry install --no-root\n",
    "!poetry run python3.12 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook assumes you are running this from *computational_genetic_genealogy/instructions. It also assumes that `$HOME` is defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run the Directory Setup Script**\n",
    "\n",
    "Follow these steps to execute the `directory_setup.py` script. (See cell block below to copy and paste code into terminal window.)\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Open Your Terminal Window**\n",
    "- **Linux/macOS**: Open **Terminal**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Navigate to the `computational_genetic_genealogy` Directory**\n",
    "In your terminal, run the following command:\n",
    "\n",
    "```\n",
    "cd ~/computational_genetic_genealogy\n",
    "```\n",
    "\n",
    "If your project is in a different location, replace `~/computational_genetic_genealogy` with the actual path.\n",
    "\n",
    "To confirm you are in the correct directory, run:\n",
    "\n",
    "```\n",
    "pwd\n",
    "```\n",
    "\n",
    "The output should show the full path to `computational_genetic_genealogy`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3: Run the Setup Script**\n",
    "Now, execute the following command:\n",
    "\n",
    "```\n",
    "poetry run python scripts_env/directory_setup.py\n",
    "```\n",
    "\n",
    "This will:\n",
    "- **Run the script to set up required directories.**\n",
    "- **Ensure your environment is properly structured.**\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **You have successfully executed `directory_setup.py`!** ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN IN JUPYTER NOTEBOOK. COPY AND PASTE TO TERMINAL WINDOW.\n",
    "\n",
    "# cd ~/computational_genetic_genealogy\n",
    "# poetry run python scripts_env/directory_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get directory variables\n",
    "\n",
    "Now that you ran `directory_setup.py`, you should see your .env file in your file explorer. Let's make sure the notebook can see the file. Run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_comp_gen_dir():\n",
    "    \"\"\"Find the computational_genetic_genealogy directory by searching up from current directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Search up through parent directories\n",
    "    while current != current.parent:\n",
    "        # Check if target directory exists in current path\n",
    "        target = current / 'computational_genetic_genealogy'\n",
    "        if target.is_dir():\n",
    "            return target\n",
    "        # Move up one directory\n",
    "        current = current.parent\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find computational_genetic_genealogy directory\")\n",
    "\n",
    "def load_env_file():\n",
    "    \"\"\"Find and load the .env file from the computational_genetic_genealogy directory.\"\"\"\n",
    "    try:\n",
    "        # Find the computational_genetic_genealogy directory\n",
    "        comp_gen_dir = find_comp_gen_dir()\n",
    "        \n",
    "        # Look for .env file\n",
    "        env_path = comp_gen_dir / '.env'\n",
    "        if not env_path.exists():\n",
    "            print(f\"Warning: No .env file found in {comp_gen_dir}\")\n",
    "            return None\n",
    "        \n",
    "        # Load the .env file\n",
    "        load_dotenv(env_path, override=True)\n",
    "        print(f\"Loaded environment variables from: {env_path}\")\n",
    "        return env_path\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use the function\n",
    "env_path = load_env_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path above should point to your `.env` file in your `compuational_genetic_genealogy directory`. Please notify the instructor by email with a PDF of the Jupyter Notebook (with output) if this is not the case. The next cell should read the values of your .env for use in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
    "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
    "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
    "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
    "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
    "\n",
    "print(f\"Working Directory: {working_directory}\")\n",
    "print(f\"Data Directory: {data_directory}\")\n",
    "print(f\"References Directory: {references_directory}\")\n",
    "print(f\"Results Directory: {results_directory}\")\n",
    "print(f\"Utils Directory: {utils_directory}\")\n",
    "\n",
    "os.chdir(working_directory)\n",
    "print(f\"The current directory is {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install bcftools, samtools, and tabix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update -y\n",
    "!sudo apt-get install -y --no-install-recommends \\\n",
    "    libbz2-dev \\\n",
    "    liblzma-dev \\\n",
    "    zlib1g-dev \\\n",
    "    libgsl-dev \\\n",
    "    libcurl4-openssl-dev\n",
    "\n",
    "!sudo apt-get install -y bcftools samtools tabix\n",
    "!echo 'export BCFTOOLS_PLUGINS=/usr/lib/x86_64-linux-gnu/bcftools' >> ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bcftools --version\n",
    "!samtools --version\n",
    "!tabix --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if command -v java &> /dev/null; then\n",
    "    echo \"Java is already installed. Version: $(java -version 2>&1 | head -n 1)\"\n",
    "    exit 0\n",
    "fi\n",
    "\n",
    "sudo apt-get install -y default-jdk\n",
    "\n",
    "# Verify installation\n",
    "if command -v java &> /dev/null; then\n",
    "    echo \"Java installation successful. Version: $(java -version 2>&1 | head -n 1)\"\n",
    "else\n",
    "    echo \"Java installation failed. Please check the log at $LOGFILE for details.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Verify Java Home\n",
    "JAVA_HOME=$(readlink -f /usr/bin/java | sed \"s:/bin/java::\")\n",
    "if [ -n \"$JAVA_HOME\" ]; then\n",
    "    echo \"JAVA_HOME detected: $JAVA_HOME\"\n",
    "    if ! grep -q \"export JAVA_HOME=$JAVA_HOME\" \"$HOME/.bashrc\"; then\n",
    "        echo \"Adding JAVA_HOME to .bashrc...\"\n",
    "        echo \"export JAVA_HOME=$JAVA_HOME\" >> \"$HOME/.bashrc\"\n",
    "        echo \"export PATH=\\$JAVA_HOME/bin:\\$PATH\" >> \"$HOME/.bashrc\"\n",
    "        source \"$HOME/.bashrc\"\n",
    "    else\n",
    "        echo \"JAVA_HOME already set in .bashrc.\"\n",
    "    fi\n",
    "else\n",
    "    echo \"Failed to detect JAVA_HOME. Please set it manually if required.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install beagle, bref, and unbref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "BEAGLE_VERSION=\"17Dec24.224\"\n",
    "BEAGLE_JAR=\"beagle.${BEAGLE_VERSION}.jar\"\n",
    "BREF3_JAR=\"bref3.${BEAGLE_VERSION}.jar\"\n",
    "UNBREF3_JAR=\"unbref3.${BEAGLE_VERSION}.jar\"\n",
    "BEAGLE_URL=\"https://faculty.washington.edu/browning/beagle/${BEAGLE_JAR}\"\n",
    "BREF3_URL=\"https://faculty.washington.edu/browning/beagle/${BREF3_JAR}\"\n",
    "UNBREF3_URL=\"https://faculty.washington.edu/browning/beagle/${UNBREF3_JAR}\"\n",
    "\n",
    "# Function to download a file only if it does not exist\n",
    "download_if_missing() {\n",
    "    local file_path=\"${utils_directory}/$1\"\n",
    "    local file_url=\"$2\"\n",
    "\n",
    "    if [ -f \"${file_path}\" ]; then\n",
    "        echo \"âœ… File already exists: ${file_path}. Skipping download.\"\n",
    "    else\n",
    "        echo \"â¬‡ï¸ Downloading $file_url...\"\n",
    "        wget -P \"${utils_directory}\" \"${file_url}\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Check and download each required file\n",
    "download_if_missing \"$UNBREF3_JAR\" \"$UNBREF3_URL\"\n",
    "download_if_missing \"$BREF3_JAR\" \"$BREF3_URL\"\n",
    "download_if_missing \"$BEAGLE_JAR\" \"$BEAGLE_URL\"\n",
    "\n",
    "# Test Beagle installation\n",
    "echo \"ðŸ” Testing Beagle installation...\"\n",
    "java -jar \"${utils_directory}/$BEAGLE_JAR\" 2>&1\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"âŒ Beagle test run failed.\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"âœ… Beagle installed successfully.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install bonsaitree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "bash $PROJECT_WORKING_DIR/scripts_env/install_bonsaitree.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Hap-IBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "# Define variables\n",
    "HAP_IBD_URL=\"https://faculty.washington.edu/browning/hap-ibd.jar\"\n",
    "HAP_IBD_JAR=\"hap-ibd.jar\"\n",
    "\n",
    "# Function to download a file only if it does not exist\n",
    "download_if_missing() {\n",
    "    local file_path=\"$utils_directory/$1\"\n",
    "    local file_url=\"$2\"\n",
    "\n",
    "    if [ -f \"$file_path\" ]; then\n",
    "        echo \"âœ… File already exists: $file_path. Skipping download.\"\n",
    "    else\n",
    "        echo \"â¬‡ï¸ Downloading $file_url...\"\n",
    "        wget -P \"$utils_directory\" \"$file_url\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Check and download each required file\n",
    "download_if_missing \"$HAP_IBD_JAR\" \"$HAP_IBD_URL\"\n",
    "\n",
    "# Test installation\n",
    "echo \"Testing installation...\"\n",
    "java -jar \"$utils_directory/$HAP_IBD_JAR\" 2>&1\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"Test run failed.\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"Installed successfully.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Refined IBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "# Define variables\n",
    "Refined_IBD_URL=\"https://faculty.washington.edu/browning/refined-ibd/refined-ibd.17Jan20.102.jar\"\n",
    "Refined_IBD_JAR=\"refined-ibd.17Jan20.102.jar\"\n",
    "\n",
    "# Function to download a file only if it does not exist\n",
    "download_if_missing() {\n",
    "    local file_path=\"$utils_directory/$1\"\n",
    "    local file_url=\"$2\"\n",
    "\n",
    "    if [ -f \"$file_path\" ]; then\n",
    "        echo \"âœ… File already exists: $file_path. Skipping download.\"\n",
    "    else\n",
    "        echo \"â¬‡ï¸ Downloading $file_url...\"\n",
    "        wget -P \"$utils_directory\" \"$file_url\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Check and download each required file\n",
    "download_if_missing \"$Refined_IBD_JAR\" \"$Refined_IBD_URL\"\n",
    "\n",
    "# Test installation\n",
    "echo \"Testing installation...\"\n",
    "java -jar \"$utils_directory/$Refined_IBD_JAR\" 2>&1\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"Test run failed.\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"Installed successfully.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install IBIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "IBIS_REPO=\"https://github.com/williamslab/ibis.git\"\n",
    "IBIS_DIR=\"$utils_directory/ibis\"\n",
    "\n",
    "# Handle existing IBIS directory\n",
    "if [ -d \"$IBIS_DIR\" ]; then\n",
    "    echo \"ðŸ“‚ IBIS directory already exists at $IBIS_DIR.\"\n",
    "    \n",
    "    # Check if it is a valid Git repo\n",
    "    if [ -d \"$IBIS_DIR/.git\" ]; then\n",
    "        echo \"ðŸ”„ Updating IBIS repository...\"\n",
    "        cd \"$IBIS_DIR\" || { echo \"âŒ Failed to navigate to IBIS directory.\"; exit 1; }\n",
    "        git pull origin master\n",
    "    else\n",
    "        echo \"âš ï¸ Directory exists but is not a Git repository. Consider removing it manually.\"\n",
    "        exit 1  # Stop execution\n",
    "    fi\n",
    "else\n",
    "    # Clone IBIS repository\n",
    "    echo \"â¬‡ï¸ Cloning IBIS repository...\"\n",
    "    git clone --recurse-submodules \"$IBIS_REPO\" \"$IBIS_DIR\" || { echo \"âŒ Git clone failed.\"; exit 1; }\n",
    "    \n",
    "    # Navigate to IBIS directory and build\n",
    "    cd \"$IBIS_DIR\" || { echo \"âŒ Failed to navigate to $IBIS_DIR.\"; exit 1; }\n",
    "    echo \"ðŸ”¨ Building IBIS using make...\"\n",
    "    make || { echo \"âŒ Build failed.\"; exit 1; }\n",
    "fi\n",
    "\n",
    "# Verify IBIS installation\n",
    "if [ -x \"./ibis\" ]; then\n",
    "    echo \"âœ… IBIS installed successfully.\"\n",
    "else\n",
    "    echo \"âŒ IBIS executable not found. Build might have failed.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "sudo apt-get install -y libboost-all-dev make\n",
    "\n",
    "PED_SIM_REPO=\"https://github.com/williamslab/ped-sim.git\"\n",
    "PED_SIM_DIR=\"$utils_directory/ped-sim\"\n",
    "\n",
    "# Handle existing IBIS directory\n",
    "if [ -d \"$PED_SIM_DIR\" ]; then\n",
    "    echo \"ðŸ“‚ Ped-Sim directory already exists at $PED_SIM_DIR.\"\n",
    "    \n",
    "    # Check if it is a valid Git repo\n",
    "    if [ -d \"$PED_SIM_DIR/.git\" ]; then\n",
    "        echo \"ðŸ”„ Updating IBIS repository...\"\n",
    "        cd \"$PED_SIM_DIR\" || { echo \"âŒ Failed to navigate to Ped-Sim directory.\"; exit 1; }\n",
    "        git pull origin master\n",
    "    else\n",
    "        echo \"âš ï¸ Directory exists but is not a Git repository. Consider removing it manually.\"\n",
    "        exit 1  # Stop execution\n",
    "    fi\n",
    "else\n",
    "    # Clone Ped-Sim repository\n",
    "    echo \"â¬‡ï¸ Cloning Ped-Sim repository...\"\n",
    "    git clone --recurse-submodules \"$PED_SIM_REPO\" \"$PED_SIM_DIR\" || { echo \"âŒ Git clone failed.\"; exit 1; }\n",
    "    \n",
    "    # Navigate to Ped-Sim directory and build\n",
    "    cd \"$PED_SIM_DIR\" || { echo \"âŒ Failed to navigate to $PED_SIM_DIR.\"; exit 1; }\n",
    "    echo \"ðŸ”¨ Building Ped-Sim using make...\"\n",
    "    make || { echo \"âŒ Build failed.\"; exit 1; }\n",
    "fi\n",
    "\n",
    "chmod +x ./ped-sim\n",
    "\n",
    "# Verify Ped-Sim installation\n",
    "if [ -x \"./ped-sim\" ]; then\n",
    "    echo \"âœ… Ped-Sim installed successfully.\"\n",
    "else\n",
    "    echo \"âŒ Ped-Sim executable not found. Build might have failed.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "# Define PLINK2 download URL and file\n",
    "plink2_file_url=\"https://s3.amazonaws.com/plink2-assets/alpha6/plink2_linux_x86_64_20241206.zip\"\n",
    "plink2_zip_file=\"$utils_directory/plink2_linux_x86_64_20241206.zip\"\n",
    "plink2_binary=\"$utils_directory/plink2\"\n",
    "\n",
    "# Download and unzip PLINK2 if not already present\n",
    "if [ ! -f \"$plink2_binary\" ]; then\n",
    "    echo\n",
    "    echo \"Downloading PLINK2...\"\n",
    "    echo\n",
    "    wget --progress=bar:force:noscroll \"$plink2_file_url\" -P \"$utils_directory\"\n",
    "    \n",
    "    # Ensure the file is downloaded before unzipping\n",
    "    while [ ! -f \"$plink2_zip_file\" ]; do\n",
    "        sleep 1\n",
    "    done\n",
    "\n",
    "    echo\n",
    "    echo \"Unzipping PLINK2...\"\n",
    "    echo\n",
    "    unzip \"$plink2_zip_file\" -d \"$utils_directory\"\n",
    "\n",
    "    # Remove the zip file after extraction\n",
    "    rm \"$plink2_zip_file\"\n",
    "fi\n",
    "\n",
    "# Check if the PLINK2 binary was installed correctly\n",
    "if [ -f \"$plink2_binary\" ] && [ -x \"$plink2_binary\" ]; then\n",
    "    echo \"PLINK2 installed successfully.\"\n",
    "    \"$plink2_binary\" --version\n",
    "else\n",
    "    echo \"Error: PLINK2 installation failed. Binary not found or not executable.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "# Define RFMix2 installation directory\n",
    "rfmix2_dir=\"$utils_directory/rfmix2\"\n",
    "\n",
    "# Install required tools (if missing)\n",
    "for tool in autoconf make gcc; do\n",
    "    if ! command -v $tool &> /dev/null; then\n",
    "        echo \"$tool not found. Installing...\"\n",
    "        sudo apt-get install -y $tool || {\n",
    "            echo \"Failed to install $tool. Exiting.\"\n",
    "            exit 1\n",
    "        }\n",
    "    else\n",
    "        echo \"$tool is already installed.\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "# Clone RFMix2 repository\n",
    "rfmix_dir=\"$utils_directory/rfmix2\"\n",
    "if [ ! -d \"$rfmix_dir\" ]; then\n",
    "    echo \"Cloning RFMix2 repository...\"\n",
    "    git clone https://github.com/slowkoni/rfmix.git \"$rfmix_dir\" || {\n",
    "        echo \"Failed to clone RFMix2 repository. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # Navigate to RFMix2 directory\n",
    "    if [ -d \"$rfmix_dir\" ]; then\n",
    "        cd \"$rfmix_dir\" || { echo \"Failed to enter $rfmix_dir. Exiting.\"; exit 1; }\n",
    "    else\n",
    "        echo \"Error: RFMix2 directory not found. Exiting.\"\n",
    "        exit 1\n",
    "    fi\n",
    "\n",
    "    # Step-by-step generation of configuration files\n",
    "    echo \"Generating build files the long way...\"\n",
    "\n",
    "    # 1. Create aclocal.m4\n",
    "    echo \"Running aclocal...\"\n",
    "    aclocal || {\n",
    "        echo \"Error running aclocal. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 2. Create config.h.in\n",
    "    echo \"Running autoheader...\"\n",
    "    autoheader || {\n",
    "        echo \"Error running autoheader. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 3. Create configure script\n",
    "    echo \"Running autoconf...\"\n",
    "    autoconf || {\n",
    "        echo \"Error running autoconf. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 4. Create Makefile.in\n",
    "    echo \"Running automake with --add-missing...\"\n",
    "    automake --add-missing || {\n",
    "        echo \"Error running automake. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 5. Configure the build system\n",
    "    echo \"Running ./configure...\"\n",
    "    ./configure || {\n",
    "        echo \"Error running configure. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 6. Compile the program\n",
    "    echo \"Compiling RFMix2...\"\n",
    "    make || {\n",
    "        echo \"Error running make. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "    \n",
    "else\n",
    "    echo \"RFMix2 repository already exists at $rfmix_dir\"\n",
    "fi\n",
    "\n",
    "# Verify RFMix2 build\n",
    "if [ -f \"$rfmix_dir/rfmix\" ]; then\n",
    "    echo \"RFMix2 built successfully and is ready to use.\"\n",
    "else\n",
    "    echo \"Error: RFMix2 binary not found. Build failed.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting a Jupyter Notebook to PDF with Poetry\n",
    "\n",
    "This guide explains how to **export a Jupyter Notebook (`.ipynb`) to a PDF** using Poetryâ€™s virtual environment.\n",
    "\n",
    "## **Running the Conversion in the Terminal**\n",
    "To convert a Jupyter Notebook to PDF, run the following command in the terminal:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf path/to/notebook.ipynb\n",
    "```\n",
    "\n",
    "### **Example:**\n",
    "If your notebook is named `Lab0_Code_Environment.ipynb` and is stored in the `instructions/` directory, run:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb\n",
    "```\n",
    "\n",
    "### **Saving the PDF to a Specific Path**\n",
    "By default, the PDF will be saved in the **same directory as the input notebook**. To save the output in a different location, use the `--output-dir` option:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf path/to/notebook.ipynb --output-dir=path/to/save/\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "To save the PDF in the `results/` directory:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb --output-dir=results/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **What Happens If We Run This Inside a Jupyter Notebook?**\n",
    "If you attempt to run `!poetry run jupyter nbconvert --to pdf ...` inside a Jupyter Notebook cell, you may encounter issues because **Notebook-specific variables (such as inline plots) might not be preserved.**\n",
    "\n",
    "### **Workaround**\n",
    "You can run the conversion within a Jupyter Notebook cell if you don't think that is an issue in the notebook you're using. The commnad to convert the notebook to PDF is (also in cell below)\n",
    "```\n",
    "!poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb\n",
    "```\n",
    "However, **it is recommended to run this in the terminal instead** for better stability.\n",
    "\n",
    "---\n",
    "By following these steps, you can successfully convert Jupyter Notebooks into PDFs while managing dependencies with Poetry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell here in Jupyter Notebook. To get the PDF, go outside of Ubuntu (e.g., Windows), open file explorer, enter `\\\\wsl$` in the navigation bar, select Ubuntu, then navigate to the file starting with `home` and `username`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ðŸš€ Start Your Labs in the Fully Configured Environment!**\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… **Setup Completed! Your Environment is Ready.**\n",
    "Your system has been successfully configured with:\n",
    "\n",
    "- ðŸ“ **Project directory structure set up**\n",
    "- ðŸ“¦ **System packages updated**\n",
    "- ðŸ› ï¸ **`~/.local/bin` added to PATH**\n",
    "- ðŸ”§ **System dependencies installed**\n",
    "- ðŸ— **Poetry installed and configured**\n",
    "- ðŸ **Project dependencies installed**\n",
    "- ðŸ“š **Python kernel installed for Jupyter Notebooks**\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Your environment is fully set up. Get started on your next lab now!** ðŸš€\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
