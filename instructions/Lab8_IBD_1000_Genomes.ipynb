{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from: /home/lakishadavid/computational_genetic_genealogy/.env\n"
     ]
    }
   ],
   "source": [
    "def find_comp_gen_dir():\n",
    "    \"\"\"Find the computational_genetic_genealogy directory by searching up from current directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Search up through parent directories\n",
    "    while current != current.parent:\n",
    "        # Check if target directory exists in current path\n",
    "        target = current / 'computational_genetic_genealogy'\n",
    "        if target.is_dir():\n",
    "            return target\n",
    "        # Move up one directory\n",
    "        current = current.parent\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find computational_genetic_genealogy directory\")\n",
    "\n",
    "def load_env_file():\n",
    "    \"\"\"Find and load the .env file from the computational_genetic_genealogy directory.\"\"\"\n",
    "    try:\n",
    "        # Find the computational_genetic_genealogy directory\n",
    "        comp_gen_dir = find_comp_gen_dir()\n",
    "        \n",
    "        # Look for .env file\n",
    "        env_path = comp_gen_dir / '.env'\n",
    "        if not env_path.exists():\n",
    "            print(f\"Warning: No .env file found in {comp_gen_dir}\")\n",
    "            return None\n",
    "        \n",
    "        # Load the .env file\n",
    "        load_dotenv(env_path, override=True)\n",
    "        print(f\"Loaded environment variables from: {env_path}\")\n",
    "        return env_path\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use the function\n",
    "env_path = load_env_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /home/lakishadavid/computational_genetic_genealogy\n",
      "Data Directory: /home/lakishadavid/computational_genetic_genealogy/data\n",
      "References Directory: /home/lakishadavid/computational_genetic_genealogy/references\n",
      "Results Directory: /home/lakishadavid/computational_genetic_genealogy/results\n",
      "Utils Directory: /home/lakishadavid/computational_genetic_genealogy/utils\n",
      "The current directory is /home/lakishadavid/computational_genetic_genealogy\n"
     ]
    }
   ],
   "source": [
    "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
    "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
    "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
    "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
    "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
    "\n",
    "print(f\"Working Directory: {working_directory}\")\n",
    "print(f\"Data Directory: {data_directory}\")\n",
    "print(f\"References Directory: {references_directory}\")\n",
    "print(f\"Results Directory: {results_directory}\")\n",
    "print(f\"Utils Directory: {utils_directory}\")\n",
    "\n",
    "os.chdir(working_directory)\n",
    "print(f\"The current directory is {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\"):\n",
    "    \"\"\"\n",
    "    Configure logging for both file and console handlers.\n",
    "\n",
    "    Args:\n",
    "        log_filename (str): Path to the log file where logs will be written.\n",
    "        log_file_debug_level (str): Logging level for the file handler.\n",
    "        console_debug_level (str): Logging level for the console handler.\n",
    "    \"\"\"\n",
    "    # Create a root logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)  # Capture all messages at the root level\n",
    "\n",
    "    # Convert level names to numeric levels\n",
    "    file_level = getattr(logging, log_file_debug_level.upper(), logging.INFO)\n",
    "    console_level = getattr(logging, console_debug_level.upper(), logging.INFO)\n",
    "\n",
    "    # File handler: Logs messages at file_level and above to the file\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(file_level)\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "\n",
    "    # Console handler: Logs messages at console_level and above to the console\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(console_level)\n",
    "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "\n",
    "    # Add handlers to the root logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "def clear_logger():\n",
    "    \"\"\"Remove all handlers from the root logger.\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lab 8 log file is located at /home/lakishadavid/computational_genetic_genealogy/results/lab8.log.\n"
     ]
    }
   ],
   "source": [
    "log_filename = os.path.join(results_directory, \"lab8.log\")\n",
    "print(f\"The Lab 8 log file is located at {log_filename}.\")\n",
    "\n",
    "# Ensure the results_directory exists\n",
    "if not os.path.exists(results_directory):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "# Check if the file exists; if not, create it\n",
    "if not os.path.exists(log_filename):\n",
    "    with open(log_filename, 'w') as file:\n",
    "        pass  # The file is now created.\n",
    "    \n",
    "clear_logger() # Clear the logger before reconfiguring it\n",
    "configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chromosome 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing to /tmp/bcftools.doEog7\n",
      "Merging 4 temporary files\n",
      "Cleaning\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3320\n",
      "Skipping chromosome 2: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr2.vcf.gz does not exist.\n",
      "Skipping chromosome 3: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr3.vcf.gz does not exist.\n",
      "Skipping chromosome 4: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr4.vcf.gz does not exist.\n",
      "Skipping chromosome 5: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr5.vcf.gz does not exist.\n",
      "Skipping chromosome 6: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr6.vcf.gz does not exist.\n",
      "Skipping chromosome 7: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr7.vcf.gz does not exist.\n",
      "Skipping chromosome 8: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr8.vcf.gz does not exist.\n",
      "Skipping chromosome 9: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr9.vcf.gz does not exist.\n",
      "Skipping chromosome 10: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr10.vcf.gz does not exist.\n",
      "Skipping chromosome 11: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr11.vcf.gz does not exist.\n",
      "Skipping chromosome 12: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr12.vcf.gz does not exist.\n",
      "Skipping chromosome 13: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr13.vcf.gz does not exist.\n",
      "Skipping chromosome 14: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr14.vcf.gz does not exist.\n",
      "Skipping chromosome 15: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr15.vcf.gz does not exist.\n",
      "Skipping chromosome 16: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr16.vcf.gz does not exist.\n",
      "Skipping chromosome 17: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr17.vcf.gz does not exist.\n",
      "Skipping chromosome 18: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr18.vcf.gz does not exist.\n",
      "Skipping chromosome 19: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr19.vcf.gz does not exist.\n",
      "Processing chromosome 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing to /tmp/bcftools.kbLmJg\n",
      "Merging 2 temporary files\n",
      "Cleaning\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3320\n",
      "Skipping chromosome 21: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr21.vcf.gz does not exist.\n",
      "Skipping chromosome 22: /home/lakishadavid/computational_genetic_genealogy/references/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr22.vcf.gz does not exist.\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$data_directory\" \"$results_directory\" \"$utils_directory\" \"$references_directory\"\n",
    "\n",
    "data_directory=\"$1\"\n",
    "results_directory=\"$2\"\n",
    "utils_directory=\"$3\"\n",
    "references_directory=\"$4\"\n",
    "\n",
    "# Get the 1000 Genomes and merge with sample VCF\n",
    "\n",
    "sample_directory=${results_directory}/onekgenomes_insample\n",
    "mkdir -p \"${sample_directory}\"\n",
    "\n",
    "for chr in {1..22}; do\n",
    "    \n",
    "    onekgenomes_samples=\"${references_directory}/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr${chr}.vcf.gz\"\n",
    "    phased_samples=\"${results_directory}/phased_samples/merged_opensnps_phased_chr${chr}_sorted.vcf.gz\"\n",
    "    output_samples=\"${results_directory}/onekgenomes_insample/sample_with_onekgenomes_chr${chr}_merged.vcf.gz\"\n",
    "    sorted_samples=\"${results_directory}/onekgenomes_insample/sample_with_onekgenomes_chr${chr}.vcf.gz\"\n",
    "    \n",
    "    if [ -f \"${onekgenomes_samples}\" ]; then\n",
    "        echo \"Processing chromosome ${chr}...\"\n",
    "        bcftools merge -O z -o \"${output_samples}\" \"${onekgenomes_samples}\" \"${phased_samples}\"\n",
    " \n",
    "        bcftools index -t \"${output_samples}\"\n",
    "        bcftools sort -Oz -o \"${sorted_samples}\" \"${output_samples}\" || {\n",
    "            echo \"Sorting failed for chromosome $chr\"\n",
    "        }\n",
    "        \n",
    "        if [ -f \"${sorted_samples}\" ]; then\n",
    "            bcftools index -t \"${sorted_samples}\"\n",
    "            rm \"${output_samples}\"\n",
    "            rm \"${output_samples}.tbi\"\n",
    "            num_samples=$(bcftools query -l \"${sorted_samples}\" | wc -l)\n",
    "            echo \"${num_samples}\"\n",
    "        fi\n",
    "        \n",
    "    else\n",
    "        echo \"Skipping chromosome ${chr}: ${onekgenomes_samples} does not exist.\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the hap-IBD Detection Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hap-IBD analysis for chromosome 1...\n",
      "Copyright (C) 2019-2023 Brian L. Browning\n",
      "Enter \"java -jar hap-ibd.jar\" to print a list of command line arguments\n",
      "\n",
      "Program            :  hap-ibd.jar  [ version 1.0, 15Jun23.92f ]\n",
      "Start Time         :  07:21 AM CST on 22 Feb 2025\n",
      "Max Memory         :  1948 MB\n",
      "\n",
      "Parameters\n",
      "  gt               :  /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr1.vcf.gz\n",
      "  map              :  /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr1.GRCh38.map\n",
      "  out              :  /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr1.seg\n",
      "  min-seed         :  2.0\n",
      "  max-gap          :  1000\n",
      "  min-extend       :  1.0\n",
      "  min-output       :  2.0\n",
      "  min-markers      :  100\n",
      "  min-mac          :  2\n",
      "  nthreads         :  4\n",
      "\n",
      "Statistics\n",
      "  samples          :  3320\n",
      "  markers          :  126776\n",
      "  IBD segments     :  2664662\n",
      "  IBD segs/sample  :  802.6\n",
      "  HBD segments     :  1407\n",
      "  HBD segs/sample  :  0.424\n",
      "\n",
      "Wallclock Time:    :  26 seconds\n",
      "End Time           :  07:22 AM CST on 22 Feb 2025\n",
      "hap-IBD analysis completed successfully for chromosome 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr2.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr3.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr4.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr5.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr6.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr7.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr8.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr9.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr10.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr11.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr12.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr13.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr14.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr15.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr16.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr17.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr18.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr19.vcf.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hap-IBD analysis for chromosome 20...\n",
      "Copyright (C) 2019-2023 Brian L. Browning\n",
      "Enter \"java -jar hap-ibd.jar\" to print a list of command line arguments\n",
      "\n",
      "Program            :  hap-ibd.jar  [ version 1.0, 15Jun23.92f ]\n",
      "Start Time         :  07:22 AM CST on 22 Feb 2025\n",
      "Max Memory         :  1948 MB\n",
      "\n",
      "Parameters\n",
      "  gt               :  /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr20.vcf.gz\n",
      "  map              :  /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr20.GRCh38.map\n",
      "  out              :  /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr20.seg\n",
      "  min-seed         :  2.0\n",
      "  max-gap          :  1000\n",
      "  min-extend       :  1.0\n",
      "  min-output       :  2.0\n",
      "  min-markers      :  100\n",
      "  min-mac          :  2\n",
      "  nthreads         :  4\n",
      "\n",
      "Statistics\n",
      "  samples          :  3320\n",
      "  markers          :  37850\n",
      "  IBD segments     :  37681\n",
      "  IBD segs/sample  :  11.3\n",
      "  HBD segments     :  206\n",
      "  HBD segs/sample  :  0.062\n",
      "\n",
      "Wallclock Time:    :  8 seconds\n",
      "End Time           :  07:22 AM CST on 22 Feb 2025\n",
      "hap-IBD analysis completed successfully for chromosome 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr21.vcf.gz\n",
      "File not found: /home/lakishadavid/computational_genetic_genealogy/results/onekgenomes_insample/sample_with_onekgenomes_chr22.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$data_directory\" \"$results_directory\" \"$utils_directory\" \"$references_directory\"\n",
    "\n",
    "data_directory=\"$1\"\n",
    "results_directory=\"$2\"\n",
    "utils_directory=\"$3\"\n",
    "references_directory=\"$4\"\n",
    "\n",
    "# Define the hap-IBD executable path\n",
    "hap_ibd=\"${utils_directory}/hap-ibd.jar\"\n",
    "\n",
    "# Ensure the hap-IBD executable exists\n",
    "if [[ ! -f \"${hap_ibd}\" ]]; then\n",
    "    echo \"Error: Hap-IBD executable not found: ${hap_ibd}\" >&2\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Run hap-IBD analysis in loop by chromosome\n",
    "for chr in {1..22}; do\n",
    "    phased_samples=\"${results_directory}/onekgenomes_insample/sample_with_onekgenomes_chr${chr}.vcf.gz\"\n",
    "    \n",
    "    if [[ -f \"${phased_samples}\" ]]; then\n",
    "        echo \"Running hap-IBD analysis for chromosome ${chr}...\"\n",
    "\n",
    "        java -jar \"${hap_ibd}\" gt=\"${phased_samples}\" \\\n",
    "            map=\"${references_directory}/genetic_maps/beagle_genetic_maps/plink.chr${chr}.GRCh38.map\" \\\n",
    "            out=\"${results_directory}/sample_with_onekgenomes_hapibd_chr${chr}.seg\" \\\n",
    "            nthreads=4\n",
    "            \n",
    "        if [[ $? -eq 0 ]]; then\n",
    "            echo \"hap-IBD analysis completed successfully for chromosome ${chr}.\"\n",
    "        else\n",
    "            echo \"Error running hap-IBD analysis for chromosome ${chr}.\" >&2\n",
    "            exit 1\n",
    "        fi\n",
    "    else\n",
    "        echo \"File not found: ${phased_samples}\" >&2\n",
    "        continue\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chromosome 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: File for chromosome 2 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr2.seg.ibd.gz\n",
      "Warning: File for chromosome 3 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr3.seg.ibd.gz\n",
      "Warning: File for chromosome 4 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr4.seg.ibd.gz\n",
      "Warning: File for chromosome 5 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr5.seg.ibd.gz\n",
      "Warning: File for chromosome 6 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr6.seg.ibd.gz\n",
      "Warning: File for chromosome 7 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr7.seg.ibd.gz\n",
      "Warning: File for chromosome 8 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr8.seg.ibd.gz\n",
      "Warning: File for chromosome 9 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr9.seg.ibd.gz\n",
      "Warning: File for chromosome 10 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr10.seg.ibd.gz\n",
      "Warning: File for chromosome 11 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr11.seg.ibd.gz\n",
      "Warning: File for chromosome 12 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr12.seg.ibd.gz\n",
      "Warning: File for chromosome 13 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr13.seg.ibd.gz\n",
      "Warning: File for chromosome 14 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr14.seg.ibd.gz\n",
      "Warning: File for chromosome 15 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr15.seg.ibd.gz\n",
      "Warning: File for chromosome 16 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr16.seg.ibd.gz\n",
      "Warning: File for chromosome 17 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr17.seg.ibd.gz\n",
      "Warning: File for chromosome 18 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr18.seg.ibd.gz\n",
      "Warning: File for chromosome 19 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr19.seg.ibd.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chromosome 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: File for chromosome 21 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr21.seg.ibd.gz\n",
      "Warning: File for chromosome 22 not found during concatenation: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_hapibd_chr22.seg.ibd.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed temporary file for chromosome 1\n",
      "Removed temporary file for chromosome 20\n",
      "Processing complete. Merged file created at: /home/lakishadavid/computational_genetic_genealogy/results/sample_with_onekgenomes_autosomes_hapibd.seg\n",
      "Note: HBD and log files still remain\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$data_directory\" \"$results_directory\" \"$utils_directory\" \"$references_directory\"\n",
    "\n",
    "data_directory=\"$1\"\n",
    "results_directory=\"$2\"\n",
    "utils_directory=\"$3\"\n",
    "references_directory=\"$4\"\n",
    "\n",
    "# Create or empty the merged output file\n",
    "output_file=\"${results_directory}/sample_with_onekgenomes_autosomes_hapibd.seg\"\n",
    ": > \"${output_file}\"\n",
    "\n",
    "# Merge chromosome files\n",
    "for chr in {1..22}; do\n",
    "    input_file=\"${results_directory}/sample_with_onekgenomes_hapibd_chr${chr}.seg.ibd.gz\"\n",
    "    \n",
    "    if [[ -f \"${input_file}\" ]]; then\n",
    "        echo \"Processing chromosome ${chr}...\"\n",
    "        zcat \"${input_file}\" >> \"${output_file}\"\n",
    "    else\n",
    "        echo \"Warning: File for chromosome ${chr} not found during concatenation: ${input_file}\" >&2\n",
    "    fi\n",
    "done\n",
    "\n",
    "# Remove temporary files\n",
    "for chr in {1..22}; do\n",
    "    temp_file=\"${results_directory}/sample_with_onekgenomes_hapibd_chr${chr}.seg.ibd.gz\"\n",
    "    if [[ -f \"${temp_file}\" ]]; then\n",
    "        rm -f \"${temp_file}\"\n",
    "        echo \"Removed temporary file for chromosome ${chr}\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"Processing complete. Merged file created at: ${output_file}\"\n",
    "echo \"Note: HBD and log files still remain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore The Segments Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2702343 entries, 0 to 2702342\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   id1                object \n",
      " 1   sample1_haplotype  int64  \n",
      " 2   id2                object \n",
      " 3   sample2_haplotype  int64  \n",
      " 4   chrom              int64  \n",
      " 5   phys_start_pos     int64  \n",
      " 6   phys_end_pos       int64  \n",
      " 7   genetic_length     float64\n",
      "dtypes: float64(1), int64(5), object(2)\n",
      "memory usage: 164.9+ MB\n"
     ]
    }
   ],
   "source": [
    "segments = os.path.join(results_directory, \"sample_with_onekgenomes_autosomes_hapibd.seg\")\n",
    "\n",
    "segments_temp = pd.read_csv(segments, sep=\"\\t\", header=None)\n",
    "segments_temp.columns = [\n",
    "    \"id1\", \"sample1_haplotype\", \"id2\", \"sample2_haplotype\",\n",
    "    \"chrom\", \"phys_start_pos\", \"phys_end_pos\", \n",
    "    \"genetic_length\"\n",
    "    ]\n",
    "segments = segments_temp.sort_values(\n",
    "    by=[\"chrom\", \"phys_start_pos\", \"phys_end_pos\"],\n",
    "    ascending=[True, True, True]\n",
    ")\n",
    "segments = segments.reset_index(drop=True)\n",
    "output_file = os.path.join(results_directory, \"merged_opensnps_autosomes_hapibd.csv\")\n",
    "segments.to_csv(output_file, sep=\"\\t\", index=False, header=False)\n",
    "segments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>sample1_haplotype</th>\n",
       "      <th>id2</th>\n",
       "      <th>sample2_haplotype</th>\n",
       "      <th>chrom</th>\n",
       "      <th>phys_start_pos</th>\n",
       "      <th>phys_end_pos</th>\n",
       "      <th>genetic_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG02343</td>\n",
       "      <td>1</td>\n",
       "      <td>HG02561</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>115746</td>\n",
       "      <td>945562</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG02343</td>\n",
       "      <td>1</td>\n",
       "      <td>HG03455</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>115746</td>\n",
       "      <td>945562</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG02343</td>\n",
       "      <td>1</td>\n",
       "      <td>HG03456</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>115746</td>\n",
       "      <td>945562</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG02343</td>\n",
       "      <td>1</td>\n",
       "      <td>HG03578</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>115746</td>\n",
       "      <td>945562</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG02561</td>\n",
       "      <td>2</td>\n",
       "      <td>HG03499</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>115746</td>\n",
       "      <td>945562</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id1  sample1_haplotype      id2  sample2_haplotype  chrom  \\\n",
       "0  HG02343                  1  HG02561                  2      1   \n",
       "1  HG02343                  1  HG03455                  1      1   \n",
       "2  HG02343                  1  HG03456                  2      1   \n",
       "3  HG02343                  1  HG03578                  2      1   \n",
       "4  HG02561                  2  HG03499                  2      1   \n",
       "\n",
       "   phys_start_pos  phys_end_pos  genetic_length  \n",
       "0          115746        945562            2.24  \n",
       "1          115746        945562            2.24  \n",
       "2          115746        945562            2.24  \n",
       "3          115746        945562            2.24  \n",
       "4          115746        945562            2.24  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.head() # You can enter a number greater than 5 to view more rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sample', 'Family ID', 'Population', 'Population Description', 'Gender',\n",
      "       'Relationship', 'Unexpected Parent/Child ', 'Non Paternity', 'Siblings',\n",
      "       'Grandparents', 'Avuncular', 'Half Siblings', 'Unknown Second Order',\n",
      "       'Third Order', 'Other Comments', 'In Low Coverage Pilot',\n",
      "       'LC Pilot Platforms', 'LC Pilot Centers', 'In High Coverage Pilot',\n",
      "       'HC Pilot Platforms', 'HC Pilot Centers', 'In Exon Targetted Pilot',\n",
      "       'ET Pilot Platforms', 'ET Pilot Centers', 'Has Sequence in Phase1',\n",
      "       'Phase1 LC Platform', 'Phase1 LC Centers', 'Phase1 E Platform',\n",
      "       'Phase1 E Centers', 'In Phase1 Integrated Variant Set',\n",
      "       'Has Phase1 chrY SNPS', 'Has phase1 chrY Deletions',\n",
      "       'Has phase1 chrMT SNPs', 'Main project LC Centers',\n",
      "       'Main project LC platform', 'Total LC Sequence',\n",
      "       'LC Non Duplicated Aligned Coverage', 'Main Project E Centers',\n",
      "       'Main Project  E Platform', 'Total Exome Sequence',\n",
      "       '% Targets Covered to 20x or greater', 'VerifyBam E Omni Free',\n",
      "       'VerifyBam E Affy Free', 'VerifyBam E Omni Chip',\n",
      "       'VerifyBam E Affy Chip', 'VerifyBam LC Omni Free',\n",
      "       'VerifyBam LC Affy Free', 'VerifyBam LC Omni Chip',\n",
      "       'VerifyBam LC Affy Chip', 'LC Indel Ratio', 'E Indel Ration',\n",
      "       'LC Passed QC', 'E Passed QC', 'In Final Phase Variant Calling',\n",
      "       'Has Omni Genotypes', 'Has Axiom Genotypes', 'Has Affy 6.0 Genotypes',\n",
      "       'Has Exome/LOF Genotypes', 'EBV Coverage', 'DNA Source from Coriell',\n",
      "       'Has Sequence from Blood in Index'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the sample and population files into Pandas DataFrames\n",
    "sample_file_name = os.path.join(references_directory, \"20140502_complete_sample_summary.txt\")\n",
    "try:\n",
    "    sample_df = pd.read_csv(sample_file_name, sep='\\t')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "\n",
    "print(sample_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique samples in IBD data: 3320\n",
      "Samples in 1000 Genomes: 3690\n",
      "Project samples identified: 119\n"
     ]
    }
   ],
   "source": [
    "def identify_project_samples(segments, sample_df):\n",
    "    \"\"\"Identify project samples that aren't in 1000 Genomes\"\"\"\n",
    "    # Get unique sample IDs from IBD data\n",
    "    all_samples = pd.unique(segments[['id1', 'id2']].values.ravel())\n",
    "    \n",
    "    # Identify project samples (those not in 1000 Genomes metadata)\n",
    "    project_samples = set(all_samples) - set(sample_df['Sample'])\n",
    "    \n",
    "    print(f\"Total unique samples in IBD data: {len(all_samples)}\")\n",
    "    print(f\"Samples in 1000 Genomes: {len(sample_df['Sample'])}\")\n",
    "    print(f\"Project samples identified: {len(project_samples)}\")\n",
    "    \n",
    "    return list(project_samples)\n",
    "\n",
    "project_samples = identify_project_samples(segments, sample_df)\n",
    "\n",
    "# print(\"\\nProject sample IDs:\")\n",
    "# print(project_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>Population</th>\n",
       "      <th>Population Description</th>\n",
       "      <th>n_segments</th>\n",
       "      <th>total_length_cM</th>\n",
       "      <th>mean_length_cM</th>\n",
       "      <th>std_length_cM</th>\n",
       "      <th>mean_tmrca_gen</th>\n",
       "      <th>min_tmrca_gen</th>\n",
       "      <th>max_tmrca_gen</th>\n",
       "      <th>mean_tmrca_years</th>\n",
       "      <th>min_tmrca_years</th>\n",
       "      <th>max_tmrca_years</th>\n",
       "      <th>n_individuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user1001</td>\n",
       "      <td>ACB</td>\n",
       "      <td>African Caribbean in Barbados</td>\n",
       "      <td>71</td>\n",
       "      <td>372.470000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>9.640000</td>\n",
       "      <td>8.960000</td>\n",
       "      <td>22.140000</td>\n",
       "      <td>241.030000</td>\n",
       "      <td>223.890000</td>\n",
       "      <td>553.590000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user1001</td>\n",
       "      <td>ASW</td>\n",
       "      <td>African Ancestry in Southwest US</td>\n",
       "      <td>50</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>10.380000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>22.610000</td>\n",
       "      <td>259.580000</td>\n",
       "      <td>225.100000</td>\n",
       "      <td>565.360000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user1001</td>\n",
       "      <td>BEB</td>\n",
       "      <td>Bengali in Bangladesh</td>\n",
       "      <td>120</td>\n",
       "      <td>546.430000</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>12.410000</td>\n",
       "      <td>8.320000</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>310.200000</td>\n",
       "      <td>207.950000</td>\n",
       "      <td>557.540000</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user1001</td>\n",
       "      <td>CDX</td>\n",
       "      <td>Chinese Dai in Xishuangbanna, China</td>\n",
       "      <td>98</td>\n",
       "      <td>506.790000</td>\n",
       "      <td>5.170000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>10.030000</td>\n",
       "      <td>8.540000</td>\n",
       "      <td>21.540000</td>\n",
       "      <td>250.830000</td>\n",
       "      <td>213.530000</td>\n",
       "      <td>538.560000</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user1001</td>\n",
       "      <td>CEU</td>\n",
       "      <td>Utah residents with Northern and Western Europ...</td>\n",
       "      <td>308</td>\n",
       "      <td>1466.990000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>11.460000</td>\n",
       "      <td>6.610000</td>\n",
       "      <td>24.740000</td>\n",
       "      <td>286.420000</td>\n",
       "      <td>165.300000</td>\n",
       "      <td>618.510000</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id Population                             Population Description  \\\n",
       "0  user1001        ACB                      African Caribbean in Barbados   \n",
       "1  user1001        ASW                   African Ancestry in Southwest US   \n",
       "2  user1001        BEB                              Bengali in Bangladesh   \n",
       "3  user1001        CDX                Chinese Dai in Xishuangbanna, China   \n",
       "4  user1001        CEU  Utah residents with Northern and Western Europ...   \n",
       "\n",
       "   n_segments  total_length_cM  mean_length_cM  std_length_cM  mean_tmrca_gen  \\\n",
       "0          71       372.470000        5.250000       0.390000        9.640000   \n",
       "1          50       254.000000        5.080000       0.830000       10.380000   \n",
       "2         120       546.430000        4.550000       1.300000       12.410000   \n",
       "3          98       506.790000        5.170000       0.730000       10.030000   \n",
       "4         308      1466.990000        4.760000       1.090000       11.460000   \n",
       "\n",
       "   min_tmrca_gen  max_tmrca_gen  mean_tmrca_years  min_tmrca_years  \\\n",
       "0       8.960000      22.140000        241.030000       223.890000   \n",
       "1       9.000000      22.610000        259.580000       225.100000   \n",
       "2       8.320000      22.300000        310.200000       207.950000   \n",
       "3       8.540000      21.540000        250.830000       213.530000   \n",
       "4       6.610000      24.740000        286.420000       165.300000   \n",
       "\n",
       "   max_tmrca_years  n_individuals  \n",
       "0       553.590000             40  \n",
       "1       565.360000             25  \n",
       "2       557.540000             67  \n",
       "3       538.560000             52  \n",
       "4       618.510000            135  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_tmrca(genetic_length, constant=50):\n",
    "    \"\"\"Calculate TMRCA in generations based on genetic length in cM\"\"\"\n",
    "    return constant/genetic_length\n",
    "\n",
    "def calculate_sharing_stats(sample_id, sample_df):\n",
    "    \"\"\"Calculate IBD sharing statistics with TMRCA estimates\"\"\"\n",
    "    # Get all segments where this sample is either id1 or id2\n",
    "    sample_segments = segments[(segments['id1'] == sample_id) | (segments['id2'] == sample_id)].copy()\n",
    "    \n",
    "    # Calculate TMRCA for each segment\n",
    "    sample_segments['tmrca_generations'] = sample_segments['genetic_length'].apply(calculate_tmrca)\n",
    "    sample_segments['tmrca_years'] = sample_segments['tmrca_generations'] * 25  # assuming 25 years per generation\n",
    "    \n",
    "    # For each segment, get the other sample ID\n",
    "    sample_segments['other_id'] = np.where(\n",
    "        sample_segments['id1'] == sample_id,\n",
    "        sample_segments['id2'],\n",
    "        sample_segments['id1']\n",
    "    )\n",
    "    \n",
    "    # Merge with population information\n",
    "    sharing_df = pd.merge(\n",
    "        sample_segments,\n",
    "        sample_df[['Sample', 'Population', 'Population Description']],\n",
    "        left_on='other_id',\n",
    "        right_on='Sample',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Calculate statistics by population\n",
    "    stats_df = sharing_df.groupby(['Population', 'Population Description']).agg({\n",
    "        'genetic_length': ['count', 'sum', 'mean', 'std'],\n",
    "        'tmrca_generations': ['mean', 'min', 'max'],\n",
    "        'tmrca_years': ['mean', 'min', 'max'],\n",
    "        'other_id': 'nunique'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    stats_df.columns = ['n_segments', 'total_length_cM', 'mean_length_cM', 'std_length_cM',\n",
    "                       'mean_tmrca_gen', 'min_tmrca_gen', 'max_tmrca_gen',\n",
    "                       'mean_tmrca_years', 'min_tmrca_years', 'max_tmrca_years',\n",
    "                       'n_individuals']\n",
    "    \n",
    "    # Reset index to make Population and Population Description regular columns\n",
    "    stats_df = stats_df.reset_index()\n",
    "    \n",
    "    # Add sample ID column\n",
    "    stats_df['sample_id'] = sample_id\n",
    "    \n",
    "    # Reorder columns\n",
    "    cols = ['sample_id', 'Population', 'Population Description', \n",
    "            'n_segments', 'total_length_cM', 'mean_length_cM', 'std_length_cM',\n",
    "            'mean_tmrca_gen', 'min_tmrca_gen', 'max_tmrca_gen',\n",
    "            'mean_tmrca_years', 'min_tmrca_years', 'max_tmrca_years',\n",
    "            'n_individuals']\n",
    "    stats_df = stats_df[cols]\n",
    "    \n",
    "    return stats_df\n",
    "\n",
    "stats_df = calculate_sharing_stats('user1001', sample_df)\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sharing_heatmap(project_samples, sample_df):\n",
    "    \"\"\"Create a heatmap of IBD sharing and TMRCA between project samples and populations\"\"\"\n",
    "    # Initialize results matrices with float dtype\n",
    "    populations = sample_df['Population'].unique()\n",
    "    sharing_matrix = pd.DataFrame(0.0, index=project_samples, columns=populations, dtype=float)\n",
    "    tmrca_matrix = pd.DataFrame(0.0, index=project_samples, columns=populations, dtype=float)\n",
    "    \n",
    "    # Calculate sharing for each sample-population pair\n",
    "    for sample in project_samples:\n",
    "        pop_stats = calculate_sharing_stats(sample, sample_df)\n",
    "        for _, row in pop_stats.iterrows():\n",
    "            if pd.notna(row['Population']):\n",
    "                sharing_matrix.loc[sample, row['Population']] = float(row['total_length_cM'])\n",
    "                tmrca_matrix.loc[sample, row['Population']] = float(row['mean_tmrca_years'])\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, len(project_samples)))\n",
    "    \n",
    "    # Plot 1: Total IBD sharing\n",
    "    sns.heatmap(sharing_matrix, cmap='YlOrRd', annot=True, fmt='.1f', ax=ax1)\n",
    "    ax1.set_title('Total IBD sharing (cM) with 1000 Genomes populations')\n",
    "    ax1.set_xlabel('1000 Genomes Population')\n",
    "    ax1.set_ylabel('Project Samples')\n",
    "    \n",
    "    # Plot 2: Mean TMRCA\n",
    "    sns.heatmap(tmrca_matrix, cmap='viridis', annot=True, fmt='.0f', ax=ax2)\n",
    "    ax2.set_title('Mean TMRCA (years) with 1000 Genomes populations')\n",
    "    ax2.set_xlabel('1000 Genomes Population')\n",
    "    ax2.set_ylabel('Project Samples')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return sharing_matrix, tmrca_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_segment_distribution(project_samples, sample_df):\n",
    "    \"\"\"Analyze the distribution of IBD segment lengths and TMRCA\"\"\"\n",
    "    # Create figure with multiple subplots\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 12))\n",
    "    \n",
    "    # Get project segments\n",
    "    project_segments = segments[\n",
    "        (segments['id1'].isin(project_samples)) | \n",
    "        (segments['id2'].isin(project_samples))\n",
    "    ].copy()\n",
    "    \n",
    "    # Calculate TMRCA for segments\n",
    "    project_segments['tmrca_generations'] = project_segments['genetic_length'].apply(lambda x: 50/x)\n",
    "    project_segments['tmrca_years'] = project_segments['tmrca_generations'] * 25\n",
    "    \n",
    "    # Add population information\n",
    "    project_segments['other_id'] = np.where(\n",
    "        project_segments['id1'].isin(project_samples),\n",
    "        project_segments['id2'],\n",
    "        project_segments['id1']\n",
    "    )\n",
    "    \n",
    "    merged_segments = pd.merge(\n",
    "        project_segments,\n",
    "        sample_df[['Sample', 'Population', 'Population Description']],\n",
    "        left_on='other_id',\n",
    "        right_on='Sample',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Plot 1: Segment length distribution\n",
    "    sns.histplot(data=merged_segments, x='genetic_length', bins=50, ax=ax1)\n",
    "    ax1.set_title('Distribution of IBD segment lengths')\n",
    "    ax1.set_xlabel('Segment length (cM)')\n",
    "    \n",
    "    # Plot 2: TMRCA distribution\n",
    "    sns.histplot(data=merged_segments, x='tmrca_years', bins=50, ax=ax2)\n",
    "    ax2.set_title('Distribution of TMRCA')\n",
    "    ax2.set_xlabel('TMRCA (years)')\n",
    "    \n",
    "    # Plot 3: Box plot of segment lengths by population\n",
    "    sns.boxplot(data=merged_segments, x='Population', y='genetic_length', ax=ax3)\n",
    "    ax3.set_title('IBD segment lengths by population')\n",
    "    ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # Plot 4: Box plot of TMRCA by population\n",
    "    sns.boxplot(data=merged_segments, x='Population', y='tmrca_years', ax=ax4)\n",
    "    ax4.set_title('TMRCA by population')\n",
    "    ax4.set_xticklabels(ax4.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, merged_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_population_sharing(project_samples, sample_df):\n",
    "    \"\"\"Create a summary of IBD sharing and TMRCA with each population\"\"\"\n",
    "    all_stats = []\n",
    "    \n",
    "    for sample in project_samples:\n",
    "        pop_stats = calculate_sharing_stats(sample, sample_df)\n",
    "        all_stats.append(pop_stats)\n",
    "    \n",
    "    # Combine all statistics\n",
    "    summary_df = pd.concat(all_stats, ignore_index=True)\n",
    "    \n",
    "    # Create pivot table for easy viewing\n",
    "    summary_pivot = pd.pivot_table(\n",
    "        summary_df, \n",
    "        values=['total_length_cM', 'n_segments', 'mean_tmrca_years', 'min_tmrca_years', 'max_tmrca_years'],\n",
    "        index='sample_id',\n",
    "        columns='Population',\n",
    "        aggfunc='first'\n",
    "    )\n",
    "    \n",
    "    return summary_df, summary_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique samples in IBD data: 3320\n",
      "Samples in 1000 Genomes: 3690\n",
      "Project samples identified: 119\n"
     ]
    }
   ],
   "source": [
    "# First identify your project samples\n",
    "project_samples = identify_project_samples(segments, sample_df)\n",
    "\n",
    "# Create all visualizations and get summaries\n",
    "# 1. Create heatmaps\n",
    "sharing_matrix, tmrca_matrix = create_sharing_heatmap(project_samples, sample_df)\n",
    "\n",
    "# 2. Analyze segment distributions and get merged segment data\n",
    "distribution_fig, merged_segments = analyze_segment_distribution(project_samples, sample_df)\n",
    "\n",
    "# 3. Get summary statistics\n",
    "summary_df, summary_pivot = summarize_population_sharing(project_samples, sample_df)\n",
    "\n",
    "# View the results\n",
    "print(\"Summary of sharing statistics:\")\n",
    "print(summary_df.head())\n",
    "\n",
    "print(\"\\nPivot table view:\")\n",
    "print(summary_pivot.head())\n",
    "\n",
    "# If you want to save any of the results:\n",
    "# sharing_matrix.to_csv('sharing_matrix.csv')\n",
    "# summary_df.to_csv('detailed_summary.csv')\n",
    "# summary_pivot.to_csv('pivot_summary.csv')\n",
    "\n",
    "# The figures will display automatically in Jupyter notebook\n",
    "# If you want to save them:\n",
    "# distribution_fig.savefig('segment_distribution.png', bbox_inches='tight', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
