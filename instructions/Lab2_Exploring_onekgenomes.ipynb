{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyrnlNJ2hiso"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZmLfSJqg2uR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from decouple import config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nduw3nmhg5kV"
      },
      "outputs": [],
      "source": [
        "working_directory = config('PROJECT_WORKING_DIR', default=None)\n",
        "data_directory = config('PROJECT_DATA_DIR', default=None)\n",
        "references_directory = config('PROJECT_REFERENCES_DIR', default=None)\n",
        "results_directory = config('PROJECT_RESULTS_DIR', default=None)\n",
        "utils_directory = config('PROJECT_UTILS_DIR', default=None)\n",
        "\n",
        "print(f\"Working Directory: {working_directory}\")\n",
        "print(f\"Data Directory: {data_directory}\")\n",
        "print(f\"References Directory: {references_directory}\")\n",
        "print(f\"Results Directory: {results_directory}\")\n",
        "print(f\"Utils Directory: {utils_directory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkJZC1Dzg8ZQ"
      },
      "outputs": [],
      "source": [
        "if primary_directory.startswith('/content'):\n",
        "\n",
        "  from google.colab import drive\n",
        "\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L65GYfvahCmi"
      },
      "outputs": [],
      "source": [
        "# Define directories\n",
        "if primary_directory.startswith('/content'):\n",
        "    use_directory = \"/content/use\"\n",
        "else:\n",
        "    use_directory = os.path.join(primary_directory, \"use\")\n",
        "\n",
        "results_directory = os.path.join(primary_directory, \"results\")\n",
        "references_directory = os.path.join(primary_directory, \"references\")\n",
        "data_directory = os.path.join(primary_directory, \"data\")\n",
        "\n",
        "# Directories to check\n",
        "directories = [use_directory, results_directory, references_directory, data_directory]\n",
        "\n",
        "# Check if the directories exist and print a message\n",
        "for directory in directories:\n",
        "    if os.path.exists(directory):\n",
        "        print(f\"Directory exists: {directory}\")\n",
        "    else:\n",
        "        os.makedirs(directory)\n",
        "        print(f\"Directory created: {directory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "816gBy1shVYD"
      },
      "outputs": [],
      "source": [
        "# Function to check if a package is installed\n",
        "def check_install_package(package_name, pip_name=None):\n",
        "    package_spec = importlib.util.find_spec(package_name)\n",
        "    if package_spec is None:\n",
        "        print(f\"{package_name} not found. Installing...\")\n",
        "        !pip install {pip_name if pip_name else package_name}\n",
        "    else:\n",
        "        print(f\"{package_name} is already installed.\")\n",
        "\n",
        "check_install_package('pandas', 'pandas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p73BhhWAiTU4"
      },
      "source": [
        "## Install bcftools +"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PGahysbiWfz"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$primary_directory\" \"$use_directory\"\n",
        "\n",
        "primary_directory=$1\n",
        "use_directory=$2\n",
        "\n",
        "# Install dependencies\n",
        "sudo apt-get update\n",
        "sudo apt-get install -y tabix\n",
        "sudo apt-get install -y bcftools\n",
        "\n",
        "cd $use_directory\n",
        "git clone --recurse-submodules https://github.com/samtools/htslib.git\n",
        "git clone https://github.com/samtools/bcftools.git\n",
        "\n",
        "cd ${use_directory}/bcftools\n",
        "make\n",
        "export BCFTOOLS_PLUGINS=${use_directory}/bcftools/plugins\n",
        "\n",
        "cd $primary_directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq5kJINf__z6"
      },
      "source": [
        "## Introduction to the IGSR 30x GRCh38 Data Collection\n",
        "The International Genome Sample Resource (IGSR) provides a data collection for the 30x GRCh38 human genome assembly. This resource is invaluable for researchers and scientists who are working on genomics, as it offers high-quality, publicly available data sets. The 30x coverage ensures a high level of accuracy and reliability for genomic studies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlCMi4XbbUvA"
      },
      "source": [
        "## Upload the metadata\n",
        "\n",
        "Upload your onethousandgenomes_metadata.zip file and place it in your references directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vskf-pZFbDYw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_file_path = os.path.join(references_directory, \"onethousandgenomes_metadata.zip\")\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zipf:\n",
        "    zipf.extractall(references_directory)\n",
        "\n",
        "# Delete the zip file\n",
        "os.remove(zip_file_path)\n",
        "\n",
        "print(\"Zip file extracted and deleted successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMsomId3__z6"
      },
      "source": [
        "**Although you already have the metadata, the instructions for where to find the metadata from the source is provided below for your reference. You do not have to use those instructions. If you ran the code above, you can skip to File Verification.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XgdCYKK__z6"
      },
      "source": [
        "## How to Download Populations File and Sample File\n",
        "\n",
        "Normally, you would find options to download various data files, including the populations file and the sample file, on the IGSR data portal. Here's a general outline of how you could download these files and save them to your references_directory:\n",
        "\n",
        "Navigate to the Data Download Section: Go to the IGSR data portal at https://www.internationalgenome.org/data-portal/data-collection/30x-grch38. Locate the buttons that says \"Download the list\" in the sample section and the population section.\n",
        "\n",
        "Download Files: Click on the download links for the populations file and the sample file. Note the directory where these files are saved and the filenames.\n",
        "\n",
        "Move Files to references_directory: Move these downloaded files to your reference directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXv4RUAY__z6"
      },
      "source": [
        "## File Verification\n",
        "\n",
        "Before proceeding with the data subsetting, let's ensure that the sample and population files you intend to use are available in the `references_directory`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAo4xAEo__z6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "sample_file_name = os.path.join(references_directory, \"samples_igsr_1000genomes_grch38.tsv\")\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(sample_file_name):\n",
        "    print(f\"Sample file exists: {sample_file_name}\")\n",
        "else:\n",
        "    print(f\"File does not exist: {sample_file_name}\")\n",
        "\n",
        "\n",
        "population_file_name = os.path.join(references_directory, \"populations_igsr_1000genomes_grch38.tsv\")\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(population_file_name):\n",
        "    print(f\"Population file exists: {population_file_name}\")\n",
        "else:\n",
        "    print(f\"File does not exist: {population_file_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AchZ8oe5__z6"
      },
      "source": [
        "## Exploring the Sample and Population Files\n",
        "\n",
        "Before diving into the analysis, it's a good idea to explore the sample and population files to get a sense of what the data looks like. We'll use Pandas to open these files and display the first few rows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yICBWXb__z7"
      },
      "outputs": [],
      "source": [
        "# Import the Pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# Load the sample and population files into Pandas DataFrames\n",
        "try:\n",
        "    sample_df = pd.read_csv(sample_file_name, sep='\\t')\n",
        "    population_df = pd.read_csv(population_file_name, sep='\\t')\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"File not found: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmqwDU84dgRY"
      },
      "source": [
        "## Data Files Overview\n",
        "\n",
        "Before diving into the analysis, it's crucial to understand the data files we'll be working with.\n",
        "\n",
        "---\n",
        "\n",
        "### Populations File\n",
        "\n",
        "#### Description\n",
        "The populations file contains information about the various populations that are part of the genomic study. This file is essential for understanding the diversity of the samples and for performing population-specific analyses.\n",
        "\n",
        "#### Typical Columns\n",
        "- **Population ID**: Unique identifier for each population.\n",
        "- **Population Name**: Name of the population.\n",
        "- **Region**: Geographical region where the population is located.\n",
        "- **Number of Samples**: Number of samples collected from this population.\n",
        "- **Other Metadata**: Additional information such as ethnicity, age range, etc.\n",
        "\n",
        "#### Use Cases\n",
        "- Filtering genomic data based on specific populations.\n",
        "- Performing population-specific genetic variation analyses.\n",
        "- Understanding the distribution of samples across different populations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06zxlXswdJtT"
      },
      "outputs": [],
      "source": [
        "print(\"First few rows of the population file:\")\n",
        "display(population_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJc1QeykdXOj"
      },
      "source": [
        "### Sample File\n",
        "\n",
        "#### Description\n",
        "The sample file contains detailed information about each individual sample that is part of the study. This file is essential for tracking the source of each genomic sequence and for associating it with specific traits or conditions.\n",
        "\n",
        "#### Typical Columns\n",
        "- **Sample ID**: Unique identifier for each sample.\n",
        "- **Population ID**: The population to which the sample belongs.\n",
        "- **Gender**: Gender of the individual from whom the sample was taken.\n",
        "- **Age**: Age of the individual.\n",
        "- **Health Status**: Information about the health condition of the individual, if applicable.\n",
        "- **Other Metadata**: Additional information such as the date of sample collection, sequencing technology used, etc.\n",
        "\n",
        "#### Use Cases\n",
        "- Filtering genomic data based on specific samples or traits.\n",
        "- Performing individual-level analyses.\n",
        "- Associating genomic variations with specific traits or conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUdfsXI9dD0y"
      },
      "outputs": [],
      "source": [
        "print(\"First few rows of the sample file:\")\n",
        "display(sample_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCpN1YGD__z7"
      },
      "source": [
        "You can preview the dataframe by viewing the first rows using .head() or the last rows using .tail, default 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIzvmwwzHDdi"
      },
      "source": [
        "# Exploratory Data Analysis with Pandas\n",
        "\n",
        "## Introduction\n",
        "Before diving into more complex analyses, it's essential to understand the structure and characteristics of your data. Pandas is a powerful Python library that provides fast, flexible, and expressive data structures designed to make working with \"relational\" or \"labeled\" data both easy and intuitive. Let's explore some basic Pandas functionalities to better understand our sample and population files.\n",
        "\n",
        "Remember that we loaded the sample and population files earlier and created Pandas Dataframes called sample_df and population_df.\n",
        "\n",
        "### Basic Information\n",
        "You can get a quick overview of the DataFrame using .info()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg8pLrPxHDdi"
      },
      "outputs": [],
      "source": [
        "# Get basic information about the sample DataFrame\n",
        "sample_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv17QCtJHDdj"
      },
      "source": [
        "You can preview the dataframe by viewing the first rows using .head() or the last rows using .tail, default 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlRSjav4HDdj"
      },
      "outputs": [],
      "source": [
        "sample_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14t_v3hzHDdj"
      },
      "outputs": [],
      "source": [
        "sample_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiZDwGI-HDdj"
      },
      "outputs": [],
      "source": [
        "sample_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqX1SAeQHDdj"
      },
      "outputs": [],
      "source": [
        "sample_df.tail(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3hy7wC-HDdj"
      },
      "source": [
        "### Summary Statistics\n",
        "The .describe() method provides summary statistics of the DataFrame, useful for getting a sense of the distribution of each attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu2C7jTeHDdk"
      },
      "outputs": [],
      "source": [
        "# Get summary statistics for the sample DataFrame\n",
        "sample_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL2lFQQ9HDdk"
      },
      "source": [
        "### Count Values\n",
        "To count the number of occurrences of each unique value in a column, you can use .value_counts()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6cYY4upHDdk"
      },
      "outputs": [],
      "source": [
        "# Count the number of individuals per population\n",
        "sample_df['Population name'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUKj5BFHHDdk"
      },
      "source": [
        "### Filtering Data\n",
        "You can filter rows based on certain conditions. For example, let's filter the sample DataFrame to only include individuals from a specific population."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T77MImOkHDdk"
      },
      "outputs": [],
      "source": [
        "# Filter to include only individuals from the 'YRI' population\n",
        "yri_population = sample_df[sample_df['Population code'] == 'YRI']\n",
        "yri_population.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-YkLg5VHDdk"
      },
      "outputs": [],
      "source": [
        "type(yri_population)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR4QoEXmHDdl"
      },
      "outputs": [],
      "source": [
        "yri_population.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vUklUylHDdl"
      },
      "outputs": [],
      "source": [
        "yri_population.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ8O8y3nHDdl"
      },
      "outputs": [],
      "source": [
        "# Search for individuals with specific attributes\n",
        "specific_entries = sample_df[(sample_df['Population code'] == 'YRI') & (sample_df['Sex'] == 'female')]\n",
        "specific_entries.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVmb9U6eHDdl"
      },
      "outputs": [],
      "source": [
        "specific_entries.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1tY8OvgHDdl"
      },
      "outputs": [],
      "source": [
        "specific_entries.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6U_Jp14HDdl"
      },
      "source": [
        "### Multiple Conditions\n",
        "You can include multiple conditions in your query. For example, let's find all females in either the 'YRI' or 'CEU' populations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pZCL17AHDdl"
      },
      "outputs": [],
      "source": [
        "# Search for females in either 'YRI' or 'CEU' populations\n",
        "multiple_conditions = sample_df[(sample_df['Population code'].isin(['YRI', 'CEU'])) & (sample_df['Sex'] == 'female')]\n",
        "multiple_conditions.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ELgy7yaHDdm"
      },
      "outputs": [],
      "source": [
        "target_population = 'YRI'\n",
        "target_sex = 'female'\n",
        "\n",
        "# Search using variables\n",
        "variable_filter = sample_df[(sample_df['Population code'] == target_population) & (sample_df['Sex'] == target_sex)]\n",
        "variable_filter.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgK5aLb5HDd0"
      },
      "source": [
        "### Searching for Entries in a List\n",
        "If you have a list of values to search for, you can use the isin() method within .query()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4rBLgw9HDd0"
      },
      "outputs": [],
      "source": [
        "# List of target populations\n",
        "target_populations = ['YRI', 'CEU']\n",
        "\n",
        "# Search for individuals in target populations\n",
        "list_filter = sample_df[sample_df['Population code'].isin(target_populations)]\n",
        "list_filter.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2caBwXQHDd0"
      },
      "source": [
        "### Using String Methods\n",
        "You can also use string methods to search for specific patterns in string columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lvDU06_HDd1"
      },
      "outputs": [],
      "source": [
        "# Search for individuals whose sample IDs start with 'NA'\n",
        "string_filter = sample_df[sample_df['Sample name'].str.startswith('NA')]\n",
        "print(len(string_filter))\n",
        "string_filter.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOPrafdkHDd1"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "Before we move on, let's specifically look at:\n",
        "\n",
        "1. The total number of samples in the dataset.\n",
        "2. The distribution of samples by sex.\n",
        "3. The distribution of samples by population.\n",
        "4. The distribution of samples by superpopulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNfqn7iMHDd1"
      },
      "outputs": [],
      "source": [
        "# Check if the sample DataFrame is loaded\n",
        "if 'sample_df' in locals():\n",
        "\n",
        "    # Total number of samples\n",
        "    total_samples = len(sample_df)\n",
        "    print(f\"Total number of samples: {total_samples}\")\n",
        "\n",
        "    # Distribution by Sex\n",
        "    print(\"\\nDistribution of samples by Sex:\")\n",
        "    display(sample_df['Sex'].value_counts())\n",
        "\n",
        "    # Distribution by Superpopulation\n",
        "    print(\"\\nDistribution of samples by Superpopulation:\")\n",
        "    display(sample_df['Superpopulation name'].value_counts())\n",
        "\n",
        "else:\n",
        "    print(\"The sample DataFrame is not loaded. Please make sure to load the sample file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgnzw5q___z7"
      },
      "source": [
        "## Downloading 1000 Genomes Data\n",
        "\n",
        "Up to this point, we have explored the sample and population metadata files to understand the structure of our data. However, we have not yet downloaded the actual genetic data from the 1000 Genomes Project.\n",
        "\n",
        "(Optional: Check out the page where we will download the files: https://www.internationalgenome.org/data-portal/data-collection/30x-grch38. Look in the description text for \"Phased VCFs\". This will take you to the ftp page where we get our links for our code. You can also manually download the files from here.)\n",
        "\n",
        "In the next step, we will download the VCF (Variant Call Format) files for chromosome 21.\n",
        "\n",
        "Note: The script will also check if the directory for storing the 1000 Genomes reference panel exists. If not, it will create one for you.\n",
        "\n",
        "Let's proceed to download the data for chromosome 21."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDRQykj0__z7"
      },
      "source": [
        "#### Download 1000 Genomes Chromosome 21, if you haven't done so already.\n",
        "file size: 407 M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj6jISFF__z7"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$primary_directory\" \"$references_directory\" \"$results_directory\"\n",
        "\n",
        "# Receive directory variables from Python\n",
        "primary_dir=$1\n",
        "ref_dir=$2\n",
        "results_dir=$3\n",
        "\n",
        "# Define the directory for the 1000 Genomes reference panel\n",
        "onekg_reference_panel_dir=\"${ref_dir}/onekg_reference_panel\"\n",
        "\n",
        "# Check if the onekg_reference_panel directory exists; if not, create it\n",
        "if [ ! -d \"${onekg_reference_panel_dir}\" ]; then\n",
        "    echo \"Creating onekg_reference_panel directory...\"\n",
        "    mkdir -p \"${onekg_reference_panel_dir}\"\n",
        "fi\n",
        "\n",
        "echo\n",
        "\n",
        "# Download the VCF file for chromosome 21 from the 1000 Genomes FTP site\n",
        "echo \"Downloading chromosome 21...\"\n",
        "wget https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20220422_3202_phased_SNV_INDEL_SV/1kGP_high_coverage_Illumina.chr21.filtered.SNV_INDEL_SV_phased_panel.vcf.gz \\\n",
        "    -P ${onekg_reference_panel_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YLZmdzT__z7"
      },
      "source": [
        "#### **Optional**: Run the folloiwng cell to download 1000 Genomes for all chromosomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ3bjNTa__z7"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$primary_directory\" \"$references_directory\" \"$results_directory\"\n",
        "\n",
        "# Receive directory variables from Python\n",
        "primary_dir=$1\n",
        "ref_dir=$2\n",
        "results_dir=$3\n",
        "\n",
        "# Define the directory for the 1000 Genomes reference panel\n",
        "onekg_reference_panel_dir=\"${ref_dir}/onekg_reference_panel\"\n",
        "\n",
        "# Check if the onekg_reference_panel directory exists; if not, create it\n",
        "if [ ! -d \"${onekg_reference_panel_dir}\" ]; then\n",
        "    echo \"Creating onekg_reference_panel directory...\"\n",
        "    mkdir -p \"${onekg_reference_panel_dir}\"\n",
        "fi\n",
        "\n",
        "echo\n",
        "\n",
        "# Loop through each chromosome to download data\n",
        "for chromosome in {1..22}\n",
        "do\n",
        "    # Download the VCF file for each chromosome from the 1000 Genomes FTP site\n",
        "    echo \"Downloading chromosome ${chromosome}...\"\n",
        "    wget https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20220422_3202_phased_SNV_INDEL_SV/1kGP_high_coverage_Illumina.chr${chromosome}.filtered.SNV_INDEL_SV_phased_panel.vcf.gz \\\n",
        "        -P ${onekg_reference_panel_dir}\n",
        "\n",
        "    # Index the downloaded VCF file\n",
        "    echo \"Indexing chromosome ${chromosome}...\"\n",
        "    tabix -p vcf \"${onekg_reference_panel_dir}/1kGP_high_coverage_Illumina.chr${chromosome}.filtered.SNV_INDEL_SV_phased_panel.vcf.gz\"\n",
        "\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcilolfTgp9a"
      },
      "source": [
        "## Subsetting our data\n",
        "\n",
        "### Why Is It Necessary?\n",
        "\n",
        "As we dive deeper into genetic data analysis, it's important to manage computational resources effectively. Whole-genome VCF files from projects like the 1000 Genomes can be extremely large, often containing data for thousands of individuals across millions of genetic variants. Loading such extensive data into memory can be computationally intensive and may even cause the kernel to crash, as we've experienced.\n",
        "\n",
        "### Advantages of Subsetting\n",
        "\n",
        "1. **Reduced Computational Load**: By focusing on a subset of 500 individuals, we significantly reduce the computational resources needed for the analysis.\n",
        "\n",
        "2. **Faster Execution**: Smaller datasets mean that code will execute more quickly, allowing us to focus on the analysis rather than waiting for code to run.\n",
        "\n",
        "3. **Feasibility**: Not all personal computers will have the resources to handle large genomic datasets. Subsetting makes the tutorial more accessible.\n",
        "\n",
        "4. **Focused Analysis**: With fewer individuals, it's easier to explore the data in depth, which is particularly useful for educational purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQw_qNqEhNw7"
      },
      "outputs": [],
      "source": [
        "population_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xS7LryJgx5H"
      },
      "source": [
        "## Subsetting based on population"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njClncR-gxVl"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$primary_directory\" \"$references_directory\" \"$results_directory\"\n",
        "\n",
        "# Receive directory variables from Python\n",
        "primary_directory=$1\n",
        "references_directory=$2\n",
        "results_directory=$3\n",
        "\n",
        "# Define the directory for the 1000 Genomes reference panel\n",
        "onekg_reference_panel_dir=${references_directory}/onekg_reference_panel\n",
        "\n",
        "# Define the path to the metadata file\n",
        "onekg_metadata_file=${references_directory}/samples_igsr_1000genomes_grch38.tsv\n",
        "\n",
        "# Define the populations to subset\n",
        "populations=(\"ASW\" \"ACB\")\n",
        "\n",
        "# Loop for specificed chromosome(s)\n",
        "for chromosome in 21; do\n",
        "    # Define the input VCF file path\n",
        "    input_vcf=${onekg_reference_panel_dir}/1kGP_high_coverage_Illumina.chr${chromosome}.filtered.SNV_INDEL_SV_phased_panel.vcf.gz\n",
        "\n",
        "    # Define the output VCF file path\n",
        "    output_vcf=${onekg_reference_panel_dir}/1kGP_high_coverage_Illumina.chr${chromosome}.filtered.SNV_INDEL_SV_phased_panel.${populations[*]}.vcf.gz\n",
        "\n",
        "    # Create a temporary file to store the sample names\n",
        "    sample_file=${onekg_reference_panel_dir}/samples_${populations[*]}.txt\n",
        "\n",
        "    # Extract sample names for the specified populations from the metadata file\n",
        "    grep -E \"$(IFS='|'; echo \"${populations[*]}\")\" \"${onekg_metadata_file}\" | cut -f 1 > \"${sample_file}\"\n",
        "\n",
        "    # Subset the VCF file for the specified populations\n",
        "    bcftools view -S \"${sample_file}\" -Oz -o \"${output_vcf}\" \"${input_vcf}\"\n",
        "\n",
        "    # Index the subsetted VCF file\n",
        "    tabix -p vcf \"${output_vcf}\"\n",
        "\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl8hT8IF9HfZ"
      },
      "source": [
        "### **Optional:** Subset on selected populations for autosomal chromosomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVCfjveX9GPQ"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$primary_directory\" \"$references_directory\" \"$results_directory\"\n",
        "\n",
        "# Receive directory variables from Python\n",
        "primary_directory=$1\n",
        "references_directory=$2\n",
        "results_directory=$3\n",
        "\n",
        "# Define the directory for the 1000 Genomes reference panel\n",
        "onekg_reference_panel_dir=${references_directory}/onekg_reference_panel\n",
        "\n",
        "# Define the path to the metadata file\n",
        "onekg_metadata_file=${references_directory}/samples_igsr_1000genomes_grch38.tsv\n",
        "\n",
        "# Define the populations to subset\n",
        "populations=(\"ASW\" \"ACB\")\n",
        "\n",
        "# Loop through each chromosome\n",
        "for chromosome in {1..22}; do\n",
        "    # Define the input VCF file path\n",
        "    input_vcf=${onekg_reference_panel_dir}/1kGP_high_coverage_Illumina.chr${chromosome}.filtered.SNV_INDEL_SV_phased_panel.vcf.gz\n",
        "    echo $input_vcf\n",
        "\n",
        "    # Define the output VCF file path\n",
        "    output_vcf=${onekg_reference_panel_dir}/1kGP_high_coverage_Illumina.chr${chromosome}.filtered.SNV_INDEL_SV_phased_panel.${populations[*]}.vcf.gz\n",
        "    echo $output_vcf\n",
        "\n",
        "    # Create a temporary file to store the sample names\n",
        "    sample_file=${onekg_reference_panel_dir}/samples_${populations[*]}.txt\n",
        "    echo $sample_file\n",
        "\n",
        "    # Extract sample names for the specified populations from the metadata file\n",
        "    grep -E \"$(IFS='|'; echo \"${populations[*]}\")\" \"${onekg_metadata_file}\" | cut -f 1 > \"${sample_file}\"\n",
        "\n",
        "    # Subset the VCF file for the specified populations\n",
        "    bcftools view -S \"${sample_file}\" -Oz -o \"${output_vcf}\" \"${input_vcf}\"\n",
        "\n",
        "    # Index the subsetted VCF file\n",
        "    tabix -p vcf \"${output_vcf}\"\n",
        "\n",
        "    # Remove the temporary sample file\n",
        "    rm \"${sample_file}\"\n",
        "done\n",
        "\n",
        "# Note for instructor: fix so that it creates one single sample file, then subsets autosomes on that single sample file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbQnSktB__z7"
      },
      "source": [
        "## Subsetting to 500 Individuals\n",
        "\n",
        "### Random Selection\n",
        "\n",
        "In the next cell, we will use `bcftools` to subset our VCF file to include only these 500 randomly selected individuals. This will make subsequent analyses more manageable and less resource-intensive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzHjIeRnH7PO"
      },
      "outputs": [],
      "source": [
        "# Instructor: add a cell to count the samples within the populations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdB1yhxZlEdT"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$references_directory\"\n",
        "# Receive directory variables from Python\n",
        "references_directory=$1\n",
        "\n",
        "# Define the directory for the 1000 Genomes reference panel\n",
        "onekg_reference_panel_dir=\"${references_directory}/onekg_reference_panel\"\n",
        "\n",
        "# Define the populations\n",
        "populations=(\"ASW\" \"ACB\")\n",
        "\n",
        "# Loop for specificed chromosome(s)\n",
        "for chromosome in 21; do\n",
        "    # Define the input VCF file path\n",
        "    input_vcf=\"${onekg_reference_panel_dir}/1kGP_high_coverage_Illumina.chr${chromosome}.filtered.SNV_INDEL_SV_phased_panel.${populations[*]}.vcf.gz\"\n",
        "\n",
        "    # Extract sample names from the subsetted VCF file\n",
        "    bcftools query -l \"${input_vcf}\" > \"${onekg_reference_panel_dir}/sample_ids_chr${chromosome}_${populations[*]}.txt\"\n",
        "\n",
        "    # Randomly select 500 sample names\n",
        "    shuf -n 500 \"${onekg_reference_panel_dir}/sample_ids_chr${chromosome}_${populations[*]}.txt\" > \"${onekg_reference_panel_dir}/random_500_sample_ids_chr${chromosome}_${populations[*]}.txt\"\n",
        "\n",
        "    # Subset the VCF file based on the random 500 sample IDs\n",
        "    bcftools view -S \"${onekg_reference_panel_dir}/random_500_sample_ids_chr${chromosome}_${populations[*]}.txt\" -Oz -o \"${onekg_reference_panel_dir}/subset_500_chr${chromosome}_${populations[*]}.vcf.gz\" \"${input_vcf}\"\n",
        "\n",
        "    # Index the subsetted VCF file\n",
        "    tabix -p vcf \"${onekg_reference_panel_dir}/subset_500_chr${chromosome}_${populations[*]}.vcf.gz\"\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQgDONOF9iWU"
      },
      "source": [
        "### **Optional:** Subset on samples for autosomal chromosomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrPpU8Nk9g-M"
      },
      "outputs": [],
      "source": [
        "%%bash -s \"$references_directory\"\n",
        "# Receive directory variables from Python\n",
        "references_directory=$1\n",
        "\n",
        "# Define the directory for the 1000 Genomes reference panel\n",
        "onekg_reference_panel_dir=\"${references_directory}/onekg_reference_panel\"\n",
        "\n",
        "# Define the populations\n",
        "populations=(\"ASW\" \"ACB\")\n",
        "\n",
        "# Loop through each chromosome\n",
        "for chromosome in {1..22}; do\n",
        "    # Define the input VCF file path\n",
        "    input_vcf=\"${onekg_reference_panel_dir}/1kGP_high_coverage_Illumina.chr${chromosome}.filtered.SNV_INDEL_SV_phased_panel.${populations[*]}.vcf.gz\"\n",
        "\n",
        "    # Extract sample names from the subsetted VCF file\n",
        "    bcftools query -l \"${input_vcf}\" > \"${onekg_reference_panel_dir}/sample_ids_chr${chromosome}_${populations[*]}.txt\"\n",
        "\n",
        "    # Randomly select 500 sample names\n",
        "    shuf -n 500 \"${onekg_reference_panel_dir}/sample_ids_chr${chromosome}_${populations[*]}.txt\" > \"${onekg_reference_panel_dir}/random_500_sample_ids_chr${chromosome}_${populations[*]}.txt\"\n",
        "\n",
        "    # Subset the VCF file based on the random 500 sample IDs\n",
        "    bcftools view -S \"${onekg_reference_panel_dir}/random_500_sample_ids_chr${chromosome}_${populations[*]}.txt\" -Oz -o \"${onekg_reference_panel_dir}/subset_500_chr${chromosome}_${populations[*]}.vcf.gz\" \"${input_vcf}\"\n",
        "\n",
        "    # Index the subsetted VCF file\n",
        "    tabix -p vcf \"${onekg_reference_panel_dir}/subset_500_chr${chromosome}_${populations[*]}.vcf.gz\"\n",
        "done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "herLAvc-__0B"
      },
      "source": [
        "## Exploring the VCF Files\n",
        "\n",
        "Now that we have downloaded the VCF files and selected a subset of 500 indiviuals, it's time to explore the VCF files. VCF (Variant Call Format) files contain information about genetic variants found in the samples.\n",
        "\n",
        "In this section, we will:\n",
        "1. Load a VCF file for a specific chromosome.\n",
        "2. Explore the structure of the VCF file.\n",
        "3. Examine some basic statistics.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSYuHvw1__0B"
      },
      "source": [
        "### Installing Required Packages\n",
        "\n",
        "In data analysis and scientific computing, we often rely on specialized packages to perform specific tasks. These packages are collections of functions and methods that allow us to perform operations without having to write code from scratch.\n",
        "\n",
        "Before we can use these packages, we need to install them. This is usually a one-time operation. Below, we will install the `scikit-allel` package, which provides tools for bioinformatics and genomics, particularly in the domain of high-throughput sequencing.\n",
        "\n",
        "Let's proceed to install the package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV_3k-Hm__0B"
      },
      "outputs": [],
      "source": [
        "# https://scikit-allel.readthedocs.io/en/stable/\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install build-essential\n",
        "!pip install scikit-allel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5WZZtdp__0B"
      },
      "source": [
        "### Loading a VCF File\n",
        "\n",
        "We will start by loading a VCF file for a specific chromosome. For demonstration purposes, let's focus on chromosome 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HuhM_-8__0B"
      },
      "outputs": [],
      "source": [
        "import allel  # Importing the scikit-allel package\n",
        "# https://scikit-allel.readthedocs.io/en/stable/index.html\n",
        "\n",
        "print(\"Ignore the 'UserWarning: invalid INFO header' warning.\\n\")\n",
        "\n",
        "# Define the path to the subsetted VCF file\n",
        "# NOTE for instructor: change to use one populations variable across Jupyter Notebook.\n",
        "vcf_path_chromosome_21_subset = os.path.join(references_directory, \"onekg_reference_panel\", \"subset_500_chr21_ASW ACB.vcf.gz\")\n",
        "\n",
        "# Check if the subsetted VCF file exists\n",
        "if os.path.exists(vcf_path_chromosome_21_subset):\n",
        "    # Load the subsetted VCF file\n",
        "    callset = allel.read_vcf(vcf_path_chromosome_21_subset)\n",
        "\n",
        "    # Display the keys to understand the structure\n",
        "    print(\"\\n\\nKeys in the VCF file:\", list(callset.keys()))\n",
        "else:\n",
        "    print(f\"The subsetted VCF file does not exist at {vcf_path_chromosome_21_subset}. Please make sure the file is in the correct location.\")\n",
        "\n",
        "# NOTE: add instructions for if it crash here.\n",
        "\n",
        "print(\"Notice the output are the keys in the VCF file. We will use the second key, 'calldata/GT', 'variants/ALT', and 'variants/REF'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG-1LVYF__0C"
      },
      "source": [
        "## Understanding Allele Frequencies and SNPs\n",
        "\n",
        "Before we proceed to subset our data, it's essential to understand some key genetic concepts: Allele Frequencies and Single Nucleotide Polymorphisms (SNPs).\n",
        "\n",
        "### Allele Frequencies\n",
        "\n",
        "Allele frequencies describe how often a particular variant (allele) of a gene appears within a given population. It is usually expressed as a proportion or percentage. Understanding allele frequencies is crucial for studying genetic diversity and for identifying alleles that may be associated with specific traits or diseases.\n",
        "\n",
        "### Single Nucleotide Polymorphisms (SNPs)\n",
        "\n",
        "SNPs are variations at a single position in a DNA sequence among individuals. They are the most common type of genetic variation and serve as markers for locating genes associated with diseases or specific traits.\n",
        "\n",
        "### What Makes a SNP a SNP?\n",
        "A Single Nucleotide Polymorphism occurs when a single nucleotide (A, T, C, or G) in the genome sequence is altered. For a variation to be considered a SNP, it must occur in at least 1% of the population. This distinguishes SNPs from random mutations, which are rare and may occur in any individual. SNPs can be synonymous (do not change the protein sequence) or non-synonymous (change the protein sequence), and they can occur in coding or non-coding regions of the genome.\n",
        "\n",
        "### Assumptions in SNP Analysis\n",
        "In SNP analysis, it is generally assumed that the nucleotide sequences between the SNPs are conserved, or identical, across the individuals being studied. This assumption allows us to focus on the SNPs as markers of genetic variation without having to analyze the entire genome.\n",
        "\n",
        "This is a reasonable assumption because:\n",
        "\n",
        "Most of the human genome is highly conserved.\n",
        "SNPs are the most common form of genetic variation, making them effective markers for genetic diversity.\n",
        "By focusing on SNPs, we can efficiently study genetic variation and its implications for traits, diseases, and population history.\n",
        "\n",
        "### Relatedness and Shared SNPs\n",
        "\n",
        "#### What Does It Mean If Two Individuals Share the Same SNP?\n",
        "\n",
        "Sharing a single SNP between two individuals doesn't necessarily imply a close genetic relationship, as SNPs can be quite common in populations. However, sharing the same SNPs over a specific length of DNA sequence can be a strong indicator of relatedness. **The length of the DNA sequence where the SNPs are shared is crucial.** A longer stretch of shared SNPs increases the likelihood that the two individuals are closely related. This is often measured in centimorgans (cM), a unit that describes the genetic distance between positions on a chromosome.\n",
        "\n",
        "#### Implications for Relatedness\n",
        "\n",
        "1. **Close Relatives**: Close relatives like siblings or parent-child pairs will share long stretches of SNPs.\n",
        "  \n",
        "2. **Distant Relatives**: More distant relatives like cousins may share shorter stretches but still longer than what would be expected by random chance.\n",
        "\n",
        "3. **Very Distantly Related Individuals**: In individuals who share a distant common ancestry, any shared SNPs are likely to be short, often less than 1 centimorgan (cM). These short stretches are scattered randomly across the genome. While they are not indicative of a close or recent familial relationship, they do reflect shared ancestors from a distant past.\n",
        "\n",
        "By analyzing the length and distribution of shared SNPs, researchers can infer the degree of relatedness between individuals, which is valuable in studies including Migration Patterns, Adaptation Studies, Archaeogenetics, Forensic Anthropology, and Evolutionary Anthropology.\n",
        "\n",
        "### Identifying SNPs\n",
        "\n",
        "1. **Total SNPs**: The total number of SNPs identified in the dataset gives us an overview of the genetic variation present.\n",
        "  \n",
        "2. **SNPs by Superpopulation**: Breaking down the SNPs by superpopulation allows us to understand how genetic variations are distributed among different groups. This is crucial for studies that aim to understand the genetic basis of population-specific traits or susceptibilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hcv4HBGU__0C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# callset variable was created in the previous code cell.\n",
        "gt = allel.GenotypeArray(callset['calldata/GT'])\n",
        "\n",
        "# Get the reference and alternate alleles from the VCF file.\n",
        "ref_alleles = callset['variants/REF']\n",
        "alt_alleles = callset['variants/ALT'][:, 0] #  to extract the first alternate allele for each variant.\n",
        "# This slice operation is taking all rows (:) and the first column (0) of the alt_alleles array\n",
        "\n",
        "# Create a boolean mask for biallelic variants\n",
        "is_biallelic = np.array([len(set(allele) - {'', '.'}) == 1 for allele in alt_alleles])\n",
        "\n",
        "# Create a boolean mask for valid SNPs\n",
        "valid_bases = {'A', 'T', 'C', 'G'}\n",
        "is_valid_snp = np.array([ref in valid_bases and alt in valid_bases for ref, alt in zip(ref_alleles, alt_alleles)])\n",
        "\n",
        "# Combine the two masks\n",
        "final_mask = is_biallelic & is_valid_snp\n",
        "\n",
        "# Apply the mask to the genotype array\n",
        "gt_filtered = gt.compress(final_mask, axis=0)\n",
        "\n",
        "print(f\"Total number of samples: {gt_filtered.n_samples}\")\n",
        "print(f\"Total number of variants: {gt.shape[0]:,}\")\n",
        "print(f\"Total number of biallelic variants: {gt_filtered.n_variants:,}\")\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KL440cV__0C"
      },
      "source": [
        "### Calculate allele counts\n",
        "\n",
        "We use our gt variable that we created to calculate the allele counts using the count_alleles() method.\n",
        "This gives us the number of occurrences of each allele for each variant.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu_jOyKY__0C"
      },
      "outputs": [],
      "source": [
        "ac = gt_filtered.count_alleles()\n",
        "\n",
        "max_allele_count = ac.max(axis=1)\n",
        "total_allele_count = ac.sum(axis=1)\n",
        "\n",
        "does_vary = (total_allele_count - max_allele_count) > 0\n",
        "# does_vary = (ac.sum(axis=1) - ac.max(axis=1)) > 0\n",
        "\n",
        "print(\"\\nVariability Analysis:\")\n",
        "print(\"If a genetic variant has the same allele in all individuals, it's non-variable.\")\n",
        "print(\"The following shows whether there's variability among the first few variants:\")\n",
        "print(\"\\n\")\n",
        "print(\"Allele Count:\")\n",
        "print(\"count_for_first_allele\\tcount_for_second_allele\")\n",
        "print(\"reference_allele_count\\talt_allele_count\")\n",
        "print(ac[:5]) # the first 5 variants\n",
        "print(f\"\\nTotal number of genetic variants that vary among the {gt_filtered.n_samples} individuals ({gt_filtered.n_samples * 2} haplotypes): {np.count_nonzero(does_vary):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOWsh0J9__0C"
      },
      "source": [
        "985: This is the count of the first allele for the first genetic variant. It means that this particular allele appears 985 times across all the haplotypes or individuals you've sampled.\n",
        "\n",
        "15: This is the count of the second allele for the same variant. It means that this second allele appears 15 times across your sampled haplotypes or individuals.\n",
        "\n",
        "So, for this first genetic variant, you have two alleles with the counts of 985 and 15, respectively. This indicates that in your sample, the first allele is much more common than the second allele for this specific variant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFZXL2db__0C"
      },
      "source": [
        "**What is ac?**\n",
        "\n",
        "`ac` is an Allele Counts Array, where each row represents a variant (like a SNP or an indel), and each column represents an allele.\n",
        "\n",
        "For bi-allelic SNPs, you'll typically have two columns: one for each allele (e.g., A and T).\n",
        "\n",
        "Here's a simplified example of what ac might look like for 3 variants:\n",
        "\n",
        "```\n",
        "20  30  # Variant 1: 20 counts of allele 1, 30 counts of allele 2\n",
        "40  10  # Variant 2: 40 counts of allele 1, 10 counts of allele 2\n",
        "25  25  # Variant 3: 25 counts of allele 1, 25 counts of allele 2\n",
        "```\n",
        "**What does axis=1 mean?**\n",
        "\n",
        "In NumPy (and many other Python libraries), an array can have multiple dimensions. The axis parameter specifies which dimension you want to perform the operation along.\n",
        "\n",
        "`axis=0` means that the operation will be performed vertically (down the rows for each column).\n",
        "`axis=1` means that the operation will be performed horizontally (across the columns for each row).\n",
        "\n",
        "For our example ac array:\n",
        "\n",
        "The sum for Variant 1 would be `20 + 30 = 50`\n",
        "\n",
        "The sum for Variant 2 would be `40 + 10 = 50`\n",
        "\n",
        "The sum for Variant 3 would be `25 + 25 = 50`\n",
        "\n",
        "So, ac.sum(axis=1) would return `[50, 50, 50]` in this example.\n",
        "\n",
        "**Why is this useful?**\n",
        "\n",
        "Summing the allele counts for each variant gives you the total number of alleles observed for that variant. This is useful for various types of genetic analyses, including identifying SNPs, calculating allele frequencies, and more.\n",
        "\n",
        "`ac.max(axis=1)`\n",
        "\n",
        "This finds the maximum allele count for each variant. Essentially, it identifies the most common allele for each variant.\n",
        "\n",
        "`(ac.sum(axis=1) - ac.max(axis=1)) > 0`\n",
        "\n",
        "This expression calculates the difference between the total number of alleles and the count of the most common allele for each variant. The idea is to find out how many of the \"other\" alleles are present.\n",
        "\n",
        "For example, if a variant has allele counts `[20, 30]`, the sum would be `50`, and the max would be `30`. The difference `50 - 30` would be `20`, representing the count of the less common allele.\n",
        "\n",
        "If the value of `ac.max(axis=1)` is the same as `ac.sum(axis=1)`, it means that all observed alleles for that particular variant are the same. In other words, there is only one type of allele present for that variant.\n",
        "\n",
        "For example, let's say a variant has allele counts `[50, 0]`. The sum would be `50`, and the max would also be `50`. The difference `50 - 50` would be `0`, and `(ac.sum(axis=1) - ac.max(axis=1)) > 0` would evaluate to `False` for this variant, indicating that it is not a SNP.\n",
        "\n",
        "So, when the sum and the max are the same, the variant is not considered a Single Nucleotide Polymorphism (SNP) because there is no variation; all observed alleles are the same.\n",
        "\n",
        "If the count of the less common allele is greater than zero, that means there is more than one type of allele present for that variant, making it a Single Nucleotide Polymorphism (SNP).\n",
        "\n",
        "`np.count_nonzero(is_snp)`\n",
        "Finally, this counts the number of `True` values in the `is_snp` array, giving you the total number of SNPs identified.\n",
        "\n",
        "Putting it all together\n",
        "The line `is_snp = (ac.sum(axis=1) - ac.max(axis=1)) > 0` is a way to identify SNPs by checking if there is more than one type of allele present for each variant. Then, np.count_nonzero(is_snp) counts how many SNPs have been identified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_NwJ0QY__0C"
      },
      "source": [
        "## Minor Allele Frequency\n",
        "What is Minor Allele Frequency?\n",
        "\n",
        "In a given population, for a particular genetic variant (or SNP), the allele that occurs less frequently is termed the \"minor allele.\" The frequency of this minor allele in the population is known as the Minor Allele Frequency (MAF). It is calculated as the count of the minor allele divided by the total number of alleles examined.\n",
        "\n",
        "**Why is MAF Important?**\n",
        "\n",
        "Statistical Power: Variants with extremely low MAF are often excluded because they may lack the statistical power to detect association with a trait or disease.\n",
        "\n",
        "Quality Control: Filtering by MAF is a common quality control step to remove potential errors in variant calling.\n",
        "\n",
        "Biological Relevance: Variants with higher MAF are more likely to be biologically relevant and less likely to be random mutations.\n",
        "\n",
        "Calculating MAF with scikit-allel\n",
        "In scikit-allel, you can calculate the MAF as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIammNKd__0C"
      },
      "outputs": [],
      "source": [
        "print(f\"Of the {gt_filtered.shape[0]:,} variants in chromosome 21, we determine that {np.count_nonzero(does_vary):,} vary, but are not necessarly SNPs.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQmt1cbK__0C"
      },
      "outputs": [],
      "source": [
        "# Calculate Minor Allele Frequency (MAF)\n",
        "\n",
        "# max_allele_count = ac.max(axis=1)\n",
        "# total_allele_count = ac.sum(axis=1)\n",
        "\n",
        "minor_allele_count = total_allele_count - max_allele_count\n",
        "\n",
        "maf = (total_allele_count - max_allele_count) / total_allele_count\n",
        "\n",
        "\n",
        "# Here, gt.compress(maf > 0.05, axis=0) will keep only the rows (variants) in the genotype array where the MAF is greater than 5%.\n",
        "# A set of SNPs with a MAF greater than 5%\n",
        "gt_maf_filtered_5 = gt_filtered.compress(maf > 0.05, axis=0)\n",
        "print(f\"Total number of common SNPs accross the whole dataset: {gt_maf_filtered_5.shape[0]:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXeGTP1u__0D"
      },
      "source": [
        "### Summary\n",
        "Filtering by MAF is a crucial step in many genetic analyses. It helps in focusing on variants that are likely to be meaningful, thereby increasing the robustness and reliability of your results."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5YLZmdzT__z7",
        "Pl8hT8IF9HfZ",
        "AQgDONOF9iWU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
