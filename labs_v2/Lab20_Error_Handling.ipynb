{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 20: Error Handling and Data Validation\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab, we'll explore the error handling and data validation techniques used in Bonsai v3 to ensure robust performance even with imperfect input data. Effective error handling is critical for genetic genealogy applications, where data quality can vary significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import inspect\n",
    "import importlib\n",
    "import copy\n",
    "import random\n",
    "import logging\n",
    "import traceback\n",
    "import json\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Tuple, Set, Optional, Union, Any, Callable\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Cross-compatibility setup\n",
    "from scripts_support.lab_cross_compatibility import setup_environment, is_jupyterlite, save_results, save_plot\n",
    "\n",
    "# Set up environment-specific paths\n",
    "DATA_DIR, RESULTS_DIR = setup_environment()\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Setup Bonsai module paths\nif not is_jupyterlite():\n    # In local environment, add the utils directory to system path\n    utils_dir = os.getenv('PROJECT_UTILS_DIR', os.path.join(os.path.dirname(DATA_DIR), 'utils'))\n    bonsaitree_dir = os.path.join(utils_dir, 'bonsaitree')\n    \n    # Add to path if it exists and isn't already there\n    if os.path.exists(bonsaitree_dir) and bonsaitree_dir not in sys.path:\n        sys.path.append(bonsaitree_dir)\n        print(f\"Added {bonsaitree_dir} to sys.path\")\nelse:\n    # In JupyterLite, use a simplified approach\n    print(\"⚠️ Running in JupyterLite: Some Bonsai functionality may be limited.\")\n    print(\"This notebook is primarily designed for local execution where the Bonsai codebase is available.\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Helper functions for exploring modules\ndef display_module_classes(module_name):\n    \"\"\"Display classes and their docstrings from a module\"\"\"\n    try:\n        # Import the module\n        module = importlib.import_module(module_name)\n        \n        # Find all classes\n        classes = inspect.getmembers(module, inspect.isclass)\n        \n        # Filter classes defined in this module (not imported)\n        classes = [(name, cls) for name, cls in classes if cls.__module__ == module_name]\n        \n        # Print info for each class\n        for name, cls in classes:\n            print(f\"\\n## {name}\")\n            \n            # Get docstring\n            doc = inspect.getdoc(cls)\n            if doc:\n                print(f\"Docstring: {doc}\")\n            else:\n                print(\"No docstring available\")\n            \n            # Get methods\n            methods = inspect.getmembers(cls, inspect.isfunction)\n            if methods:\n                print(\"\\nMethods:\")\n                for method_name, method in methods:\n                    if not method_name.startswith('_'):  # Skip private methods\n                        print(f\"- {method_name}\")\n    except ImportError as e:\n        print(f\"Error importing module {module_name}: {e}\")\n    except Exception as e:\n        print(f\"Error processing module {module_name}: {e}\")\n\ndef display_module_functions(module_name):\n    \"\"\"Display functions and their docstrings from a module\"\"\"\n    try:\n        # Import the module\n        module = importlib.import_module(module_name)\n        \n        # Find all functions\n        functions = inspect.getmembers(module, inspect.isfunction)\n        \n        # Filter functions defined in this module (not imported)\n        functions = [(name, func) for name, func in functions if func.__module__ == module_name]\n        \n        # Print info for each function\n        for name, func in functions:\n            if name.startswith('_'):  # Skip private functions\n                continue\n                \n            print(f\"\\n## {name}\")\n            \n            # Get signature\n            sig = inspect.signature(func)\n            print(f\"Signature: {name}{sig}\")\n            \n            # Get docstring\n            doc = inspect.getdoc(func)\n            if doc:\n                print(f\"Docstring: {doc}\")\n            else:\n                print(\"No docstring available\")\n    except ImportError as e:\n        print(f\"Error importing module {module_name}: {e}\")\n    except Exception as e:\n        print(f\"Error processing module {module_name}: {e}\")\n\ndef view_source(obj):\n    \"\"\"Display the source code of an object (function or class)\"\"\"\n    try:\n        source = inspect.getsource(obj)\n        display(Markdown(f\"```python\\n{source}\\n```\"))\n    except Exception as e:\n        print(f\"Error retrieving source: {e}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Check Bonsai Installation\n\nLet's verify that the Bonsai v3 module is available for import:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "try:\n    from utils.bonsaitree.bonsaitree import v3\n    print(\"✅ Successfully imported Bonsai v3 module\")\nexcept ImportError as e:\n    print(f\"❌ Failed to import Bonsai v3 module: {e}\")\n    print(\"This lab requires access to the Bonsai v3 codebase.\")\n    print(\"Make sure you've properly set up your environment with the Bonsai repository.\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Lab 20: Error Handling and Data Validation in Bonsai v3\n\nIn computational genetic genealogy, we often work with data that is imperfect, incomplete, or inconsistent. Effective error handling and data validation are critical for building robust applications that can gracefully handle these challenges. In this lab, we'll explore the error handling and data validation mechanisms used in Bonsai v3.\n\nWe'll focus on several key aspects:\n\n1. **Custom Exception Hierarchy**: Understanding Bonsai's exception classes and how they help with targeted error handling\n2. **Input Validation**: Techniques for validating data before processing\n3. **Defensive Programming**: Strategies to anticipate and handle potential errors\n4. **Graceful Degradation**: Continuing operation despite partial failures\n5. **Logging and Debugging**: Tools for tracking and diagnosing issues\n\nLet's implement simplified versions of these mechanisms to better understand how they work in Bonsai v3.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Part 1: Custom Exception Hierarchy\n\nBonsai v3 uses a custom exception hierarchy to provide specific error types that make it easier to handle different categories of errors appropriately. Let's look at how this works:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Check if Bonsai exceptions are available for import\nif not is_jupyterlite():\n    try:\n        from utils.bonsaitree.bonsaitree.v3.exceptions import BonsaiException\n        \n        # Display the source code if available\n        print(\"Source code for BonsaiException base class:\")\n        view_source(BonsaiException)\n    except (ImportError, AttributeError) as e:\n        print(f\"Could not import exception classes: {e}\")\n        print(\"We'll implement our own versions for this lab.\")\nelse:\n    print(\"Cannot display source code in JupyterLite environment.\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 1.1 Implementing a Custom Exception Hierarchy\n\nLet's implement a simplified version of Bonsai's exception hierarchy:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class BonsaiException(Exception):\n    \"\"\"\n    Base exception class for all Bonsai-specific exceptions.\n    \n    This provides a common ancestor for all Bonsai exceptions, making it\n    easier to catch any Bonsai-related error with a single except clause.\n    \n    Attributes:\n        message: Human-readable error message\n        details: Optional dictionary with additional error details\n    \"\"\"\n    def __init__(self, message, details=None):\n        self.message = message\n        self.details = details or {}\n        super().__init__(self.message)\n    \n    def __str__(self):\n        if self.details:\n            details_str = \", \".join(f\"{k}={v}\" for k, v in self.details.items())\n            return f\"{self.message} ({details_str})\"\n        return self.message\n    \n    def to_dict(self):\n        \"\"\"Convert the exception to a dictionary representation.\"\"\"\n        return {\n            \"error_type\": self.__class__.__name__,\n            \"message\": self.message,\n            \"details\": self.details\n        }\n\n# Input-related exceptions\nclass InputError(BonsaiException):\n    \"\"\"Base class for input-related errors.\"\"\"\n    pass\n\nclass ValidationError(InputError):\n    \"\"\"Raised when input data fails validation.\"\"\"\n    pass\n\nclass DataFormatError(InputError):\n    \"\"\"Raised when input data has incorrect format.\"\"\"\n    pass\n\nclass MissingDataError(InputError):\n    \"\"\"Raised when required data is missing.\"\"\"\n    pass\n\n# Processing-related exceptions\nclass ProcessingError(BonsaiException):\n    \"\"\"Base class for processing-related errors.\"\"\"\n    pass\n\nclass CalculationError(ProcessingError):\n    \"\"\"Raised when a calculation fails.\"\"\"\n    pass\n\nclass IncompatibleDataError(ProcessingError):\n    \"\"\"Raised when data sources are incompatible.\"\"\"\n    pass\n\nclass AlgorithmError(ProcessingError):\n    \"\"\"Raised when an algorithm fails to produce a result.\"\"\"\n    pass\n\n# Configuration-related exceptions\nclass ConfigurationError(BonsaiException):\n    \"\"\"Raised when there's an issue with the configuration.\"\"\"\n    pass\n\n# Resource-related exceptions\nclass ResourceError(BonsaiException):\n    \"\"\"Base class for resource-related errors.\"\"\"\n    pass\n\nclass MemoryError(ResourceError):\n    \"\"\"Raised when an operation would exceed available memory.\"\"\"\n    pass\n\nclass TimeoutError(ResourceError):\n    \"\"\"Raised when an operation takes too long.\"\"\"\n    pass\n\n# Create a visual representation of the exception hierarchy\ndef visualize_exception_hierarchy():\n    \"\"\"Visualize the exception hierarchy using networkx.\"\"\"\n    # Create a directed graph\n    G = nx.DiGraph()\n    \n    # Get all classes defined in this notebook\n    all_classes = {name: cls for name, cls in globals().items() if isinstance(cls, type)}\n    \n    # Add exception classes to the graph\n    exception_classes = {name: cls for name, cls in all_classes.items() \n                         if issubclass(cls, Exception) and cls != Exception}\n    \n    # Add nodes and edges\n    for name, cls in exception_classes.items():\n        G.add_node(name)\n        # Get base classes (excluding object and Exception)\n        bases = [base.__name__ for base in cls.__bases__ \n                 if base.__name__ in exception_classes or base.__name__ == \"Exception\"]\n        for base in bases:\n            G.add_edge(base, name)\n    \n    # Create positions for the graph\n    pos = nx.nx_agraph.graphviz_layout(G, prog=\"dot\") if hasattr(nx, 'nx_agraph') else nx.spring_layout(G)\n    \n    # Create figure\n    plt.figure(figsize=(12, 8))\n    \n    # Define node colors based on type\n    node_colors = []\n    for node in G.nodes():\n        if node == \"Exception\" or node == \"BonsaiException\":\n            node_colors.append(\"#6495ED\")  # Base classes - blue\n        elif \"Input\" in node:\n            node_colors.append(\"#FF6347\")  # Input errors - red\n        elif \"Processing\" in node or \"Algorithm\" in node or \"Calculation\" in node:\n            node_colors.append(\"#32CD32\")  # Processing errors - green\n        elif \"Configuration\" in node:\n            node_colors.append(\"#FFD700\")  # Configuration errors - yellow\n        elif \"Resource\" in node or \"Memory\" in node or \"Timeout\" in node:\n            node_colors.append(\"#9370DB\")  # Resource errors - purple\n        else:\n            node_colors.append(\"#A9A9A9\")  # Others - gray\n    \n    # Draw the graph\n    nx.draw_networkx(G, pos, with_labels=True, node_color=node_colors, \n                    node_size=3000, alpha=0.8, arrows=True, \n                    arrowsize=20, arrowstyle='->', width=2)\n    \n    plt.title(\"Bonsai Exception Hierarchy\")\n    plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n# Visualize the exception hierarchy\nvisualize_exception_hierarchy()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 1.2 Using the Exception Hierarchy\n\nNow that we have our exception hierarchy, let's see how it can be used in practice:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def process_ibd_segments(segments, min_cm=7.0, min_snps=500):\n    \"\"\"\n    Process IBD segments with input validation and error handling.\n    \n    Args:\n        segments: List of IBD segments, each as (start_pos, end_pos, cM, snps)\n        min_cm: Minimum centiMorgan threshold\n        min_snps: Minimum SNP threshold\n        \n    Returns:\n        List of filtered and processed segments\n    \n    Raises:\n        ValidationError: If segments don't meet validation criteria\n        MissingDataError: If required fields are missing\n        DataFormatError: If data format is incorrect\n    \"\"\"\n    # Input validation\n    if segments is None:\n        raise MissingDataError(\"IBD segments data is missing\")\n    \n    if not isinstance(segments, list):\n        raise DataFormatError(\n            \"IBD segments must be provided as a list\",\n            details={\"actual_type\": type(segments).__name__}\n        )\n    \n    if len(segments) == 0:\n        # No segments is a valid case, just return empty list\n        return []\n    \n    # Verify segment format\n    valid_segments = []\n    invalid_segments = []\n    \n    for i, segment in enumerate(segments):\n        try:\n            # Check if segment has the expected format\n            if not isinstance(segment, tuple) or len(segment) != 4:\n                raise DataFormatError(\n                    f\"Segment {i} has incorrect format\",\n                    details={\"segment\": segment, \"expected_format\": \"(start_pos, end_pos, cM, snps)\"}\n                )\n            \n            start_pos, end_pos, cm, snps = segment\n            \n            # Validate values\n            if not isinstance(start_pos, (int, float)) or start_pos < 0:\n                raise ValidationError(\n                    f\"Segment {i} has invalid start position\",\n                    details={\"start_pos\": start_pos}\n                )\n            \n            if not isinstance(end_pos, (int, float)) or end_pos <= start_pos:\n                raise ValidationError(\n                    f\"Segment {i} has invalid end position\",\n                    details={\"end_pos\": end_pos, \"start_pos\": start_pos}\n                )\n            \n            if not isinstance(cm, (int, float)) or cm < 0:\n                raise ValidationError(\n                    f\"Segment {i} has invalid centiMorgan value\",\n                    details={\"cM\": cm}\n                )\n            \n            if not isinstance(snps, (int, float)) or snps < 0:\n                raise ValidationError(\n                    f\"Segment {i} has invalid SNP count\",\n                    details={\"snps\": snps}\n                )\n            \n            # Apply thresholds\n            if cm < min_cm:\n                continue  # Skip segments below cM threshold\n            \n            if snps < min_snps:\n                continue  # Skip segments below SNP threshold\n            \n            # If we reach here, the segment is valid\n            valid_segments.append(segment)\n            \n        except BonsaiException as e:\n            # Store invalid segment and continue processing\n            invalid_segments.append((i, segment, str(e)))\n    \n    # If all segments were invalid, raise an error\n    if len(valid_segments) == 0 and len(invalid_segments) > 0:\n        raise ValidationError(\n            f\"All {len(invalid_segments)} segments failed validation\",\n            details={\"invalid_segments\": invalid_segments}\n        )\n    \n    return valid_segments\n\n# Let's test the function with different inputs\ndef test_process_ibd_segments():\n    # Valid input\n    valid_segments = [\n        (1000000, 5000000, 10.5, 1200),\n        (10000000, 15000000, 8.2, 900),\n        (20000000, 25000000, 6.5, 600),  # Below cM threshold, should be filtered out\n        (30000000, 35000000, 12.0, 400)   # Below SNP threshold, should be filtered out\n    ]\n    \n    # Different error cases\n    missing_data = None\n    wrong_type = \"not a list\"\n    empty_list = []\n    invalid_segment = [\n        (1000000, 5000000, 10.5, 1200),\n        \"invalid\",\n        (20000000, 25000000, 6.5, 600)\n    ]\n    invalid_values = [\n        (1000000, 5000000, 10.5, 1200),\n        (15000000, 10000000, 8.2, 900),  # end_pos < start_pos\n        (20000000, 25000000, -6.5, 600)  # negative cM\n    ]\n    all_invalid = [\n        (15000000, 10000000, 8.2, 900),  # end_pos < start_pos\n        (20000000, 25000000, -6.5, 600),  # negative cM\n        (\"invalid\", \"positions\", \"values\", \"here\")  # wrong types\n    ]\n    \n    # Test cases\n    test_cases = [\n        (\"Valid segments\", valid_segments, None),\n        (\"Missing data\", missing_data, MissingDataError),\n        (\"Wrong type\", wrong_type, DataFormatError),\n        (\"Empty list\", empty_list, None),\n        (\"Invalid segment\", invalid_segment, DataFormatError),\n        (\"Invalid values\", invalid_values, DataFormatError),\n        (\"All invalid\", all_invalid, ValidationError)\n    ]\n    \n    # Run the tests\n    results = []\n    for name, input_data, expected_error in test_cases:\n        try:\n            result = process_ibd_segments(input_data)\n            results.append({\n                \"test_name\": name,\n                \"status\": \"Pass\" if expected_error is None else \"Fail (expected error not raised)\",\n                \"result\": f\"{len(result)} valid segments\"\n            })\n        except Exception as e:\n            if expected_error and isinstance(e, expected_error):\n                results.append({\n                    \"test_name\": name,\n                    \"status\": \"Pass (expected error raised)\",\n                    \"result\": str(e)\n                })\n            else:\n                results.append({\n                    \"test_name\": name,\n                    \"status\": f\"Fail (unexpected error: {type(e).__name__})\",\n                    \"result\": str(e)\n                })\n    \n    # Display results as a table\n    print(\"Test Results:\")\n    print(\"-\" * 100)\n    print(f\"{'Test Name':<20} | {'Status':<35} | {'Result':<40}\")\n    print(\"-\" * 100)\n    \n    for result in results:\n        print(f\"{result['test_name']:<20} | {result['status']:<35} | {result['result']:<40}\")\n\n# Run the test function\ntest_process_ibd_segments()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 1.3 Benefits of Targeted Error Handling\n\nThe custom exception hierarchy allows for more targeted error handling, letting us catch and respond to specific types of errors. Let's see how this works in practice:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def ibd_analysis_pipeline(segments_data, iid1, iid2, min_cm=7.0, min_snps=500):\n    \"\"\"\n    A simplified IBD analysis pipeline with targeted error handling.\n    \n    Args:\n        segments_data: List of IBD segments\n        iid1: ID of the first individual\n        iid2: ID of the second individual\n        min_cm: Minimum centiMorgan threshold\n        min_snps: Minimum SNP threshold\n        \n    Returns:\n        Dict with analysis results\n    \"\"\"\n    try:\n        # Process and validate the segments\n        valid_segments = process_ibd_segments(segments_data, min_cm, min_snps)\n        \n        # Calculate statistics and relationship\n        total_cm = sum(segment[2] for segment in valid_segments)\n        longest_segment = max(valid_segments, key=lambda x: x[2])[2] if valid_segments else 0\n        total_snps = sum(segment[3] for segment in valid_segments)\n        \n        # Simplified relationship inference\n        relationship = \"unknown\"\n        confidence = 0.0\n        \n        if total_cm > 3000:\n            relationship = \"parent-child\"\n            confidence = 0.95\n        elif total_cm > 2000:\n            relationship = \"full-sibling\"\n            confidence = 0.9\n        elif total_cm > 1000:\n            relationship = \"half-sibling/grandparent\"\n            confidence = 0.85\n        elif total_cm > 500:\n            relationship = \"1st cousin\"\n            confidence = 0.8\n        elif total_cm > 250:\n            relationship = \"2nd cousin\"\n            confidence = 0.7\n        elif total_cm > 100:\n            relationship = \"3rd cousin\"\n            confidence = 0.6\n        elif total_cm > 50:\n            relationship = \"4th cousin\"\n            confidence = 0.5\n        elif total_cm > 20:\n            relationship = \"distant relative\"\n            confidence = 0.4\n        else:\n            relationship = \"very distant/unrelated\"\n            confidence = 0.3\n        \n        # Return the results\n        return {\n            \"iid1\": iid1,\n            \"iid2\": iid2,\n            \"segments_count\": len(valid_segments),\n            \"total_cm\": total_cm,\n            \"longest_segment_cm\": longest_segment,\n            \"total_snps\": total_snps,\n            \"inferred_relationship\": relationship,\n            \"confidence\": confidence,\n            \"status\": \"success\"\n        }\n    \n    except ValidationError as e:\n        # Handle validation errors (can often be fixed by adjusting parameters)\n        print(f\"Validation error: {str(e)}\")\n        return {\n            \"iid1\": iid1,\n            \"iid2\": iid2,\n            \"error\": str(e),\n            \"error_type\": \"validation\",\n            \"status\": \"error\",\n            \"suggested_action\": \"Check input data format and values\"\n        }\n    \n    except MissingDataError as e:\n        # Handle missing data errors\n        print(f\"Missing data error: {str(e)}\")\n        return {\n            \"iid1\": iid1,\n            \"iid2\": iid2,\n            \"error\": str(e),\n            \"error_type\": \"missing_data\",\n            \"status\": \"error\",\n            \"suggested_action\": \"Ensure all required data is provided\"\n        }\n    \n    except DataFormatError as e:\n        # Handle data format errors\n        print(f\"Data format error: {str(e)}\")\n        return {\n            \"iid1\": iid1,\n            \"iid2\": iid2,\n            \"error\": str(e),\n            \"error_type\": \"data_format\",\n            \"status\": \"error\",\n            \"suggested_action\": \"Fix the format of the input data\"\n        }\n    \n    except BonsaiException as e:\n        # Handle any other Bonsai-specific exceptions\n        print(f\"Bonsai error: {str(e)}\")\n        return {\n            \"iid1\": iid1,\n            \"iid2\": iid2,\n            \"error\": str(e),\n            \"error_type\": \"bonsai_error\",\n            \"status\": \"error\",\n            \"suggested_action\": \"Check the error message for details\"\n        }\n    \n    except Exception as e:\n        # Handle any other unexpected exceptions\n        print(f\"Unexpected error: {str(e)}\")\n        return {\n            \"iid1\": iid1,\n            \"iid2\": iid2,\n            \"error\": str(e),\n            \"error_type\": \"unexpected\",\n            \"status\": \"error\",\n            \"suggested_action\": \"Contact support with the error details\"\n        }\n\n# Let's test the pipeline with different error scenarios\ndef test_ibd_analysis_pipeline():\n    # Test cases\n    test_cases = [\n        {\n            \"name\": \"Valid Data\",\n            \"segments\": [\n                (1000000, 5000000, 10.5, 1200),\n                (10000000, 15000000, 8.2, 900),\n                (20000000, 25000000, 15.5, 1800)\n            ],\n            \"iid1\": \"sample1\",\n            \"iid2\": \"sample2\"\n        },\n        {\n            \"name\": \"Missing Data\",\n            \"segments\": None,\n            \"iid1\": \"sample1\",\n            \"iid2\": \"sample2\"\n        },\n        {\n            \"name\": \"Wrong Data Format\",\n            \"segments\": \"not a list\",\n            \"iid1\": \"sample1\",\n            \"iid2\": \"sample2\"\n        },\n        {\n            \"name\": \"Invalid Segments\",\n            \"segments\": [\n                (1000000, 5000000, 10.5, 1200),\n                (10000000, 5000000, 8.2, 900),  # end < start\n                (20000000, 25000000, -5.5, 1800)  # negative cM\n            ],\n            \"iid1\": \"sample1\",\n            \"iid2\": \"sample2\"\n        },\n        {\n            \"name\": \"Empty Segments\",\n            \"segments\": [],\n            \"iid1\": \"sample1\",\n            \"iid2\": \"sample2\"\n        },\n        {\n            \"name\": \"Parent-Child Relationship\",\n            \"segments\": [\n                (1000000, 5000000, 1000.5, 12000),\n                (10000000, 15000000, 800.2, 9000),\n                (20000000, 25000000, 1500.5, 18000)\n            ],\n            \"iid1\": \"parent\",\n            \"iid2\": \"child\"\n        }\n    ]\n    \n    # Run the tests\n    results = []\n    for test_case in test_cases:\n        print(f\"\\nRunning test: {test_case['name']}\")\n        result = ibd_analysis_pipeline(\n            test_case[\"segments\"], \n            test_case[\"iid1\"], \n            test_case[\"iid2\"]\n        )\n        print(f\"Result status: {result['status']}\")\n        \n        # Store result for later comparison\n        results.append({\n            \"test_name\": test_case[\"name\"],\n            \"status\": result[\"status\"],\n            \"result\": result\n        })\n    \n    # Create a visualization of the test results\n    plt.figure(figsize=(12, 6))\n    \n    # Count successes vs different error types\n    counts = {\"success\": 0}\n    for result in results:\n        if result[\"status\"] == \"success\":\n            counts[\"success\"] += 1\n        else:\n            error_type = result[\"result\"][\"error_type\"]\n            counts[error_type] = counts.get(error_type, 0) + 1\n    \n    # Create bar chart\n    categories = list(counts.keys())\n    values = list(counts.values())\n    colors = ['#66b3ff' if cat == 'success' else '#ff9999' for cat in categories]\n    \n    plt.bar(categories, values, color=colors)\n    plt.title('IBD Analysis Pipeline Test Results')\n    plt.xlabel('Result Type')\n    plt.ylabel('Count')\n    plt.grid(axis='y', linestyle='--', alpha=0.7)\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\n    \n    # Display full results table\n    print(\"\\nDetailed Test Results:\")\n    print(\"-\" * 100)\n    for result in results:\n        print(f\"Test: {result['test_name']}\")\n        print(f\"Status: {result['status']}\")\n        \n        r = result[\"result\"]\n        if result[\"status\"] == \"success\":\n            print(f\"Segments: {r['segments_count']}\")\n            print(f\"Total cM: {r['total_cm']:.2f}\")\n            print(f\"Relationship: {r['inferred_relationship']} (confidence: {r['confidence']:.2f})\")\n        else:\n            print(f\"Error type: {r['error_type']}\")\n            print(f\"Error message: {r['error']}\")\n            print(f\"Suggested action: {r['suggested_action']}\")\n        \n        print(\"-\" * 100)\n\n# Run the test function\ntest_ibd_analysis_pipeline()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Part 2: Input Validation\n\nInput validation is a critical part of error handling, helping to catch issues early before they propagate through the system. Let's explore the input validation techniques used in Bonsai v3.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 2.1 Using Data Classes for Validation\n\nOne technique used in Bonsai v3 is to define data classes with built-in validation. Let's implement a simple example:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "@dataclass\nclass IBDSegment:\n    \"\"\"\n    A data class representing an IBD segment with built-in validation.\n    \n    Attributes:\n        start_pos: Start position (in base pairs)\n        end_pos: End position (in base pairs)\n        cm: Length in centiMorgans\n        snps: Number of SNPs in the segment\n        chromosome: Chromosome number (1-22, X, Y)\n    \"\"\"\n    start_pos: int\n    end_pos: int\n    cm: float\n    snps: int\n    chromosome: str = \"1\"  # Default to chromosome 1\n    \n    def __post_init__(self):\n        \"\"\"Validate the segment after initialization.\"\"\"\n        # Check types\n        if not isinstance(self.start_pos, int):\n            raise ValidationError(\n                \"start_pos must be an integer\",\n                details={\"start_pos\": self.start_pos}\n            )\n        \n        if not isinstance(self.end_pos, int):\n            raise ValidationError(\n                \"end_pos must be an integer\",\n                details={\"end_pos\": self.end_pos}\n            )\n        \n        if not isinstance(self.cm, (int, float)):\n            raise ValidationError(\n                \"cm must be a number\",\n                details={\"cm\": self.cm}\n            )\n        \n        if not isinstance(self.snps, int):\n            raise ValidationError(\n                \"snps must be an integer\",\n                details={\"snps\": self.snps}\n            )\n        \n        # Check values\n        if self.start_pos < 0:\n            raise ValidationError(\n                \"start_pos must be non-negative\",\n                details={\"start_pos\": self.start_pos}\n            )\n        \n        if self.end_pos <= self.start_pos:\n            raise ValidationError(\n                \"end_pos must be greater than start_pos\",\n                details={\"start_pos\": self.start_pos, \"end_pos\": self.end_pos}\n            )\n        \n        if self.cm < 0:\n            raise ValidationError(\n                \"cm must be non-negative\",\n                details={\"cm\": self.cm}\n            )\n        \n        if self.snps < 0:\n            raise ValidationError(\n                \"snps must be non-negative\",\n                details={\"snps\": self.snps}\n            )\n        \n        # Validate chromosome\n        valid_chromosomes = [str(i) for i in range(1, 23)] + [\"X\", \"Y\"]\n        if self.chromosome not in valid_chromosomes:\n            raise ValidationError(\n                \"chromosome must be 1-22, X, or Y\",\n                details={\"chromosome\": self.chromosome}\n            )\n    \n    @property\n    def length_bp(self):\n        \"\"\"Get the length of the segment in base pairs.\"\"\"\n        return self.end_pos - self.start_pos\n    \n    @property\n    def density(self):\n        \"\"\"Get the SNP density (SNPs per centiMorgan).\"\"\"\n        return self.snps / self.cm if self.cm > 0 else 0\n    \n    def overlaps(self, other):\n        \"\"\"Check if this segment overlaps with another segment.\"\"\"\n        if self.chromosome != other.chromosome:\n            return False\n        return self.start_pos < other.end_pos and self.end_pos > other.start_pos\n\n# Test the data class with valid and invalid data\ndef test_ibd_segment_class():\n    # Valid data\n    valid_segments = [\n        {\"start_pos\": 1000000, \"end_pos\": 5000000, \"cm\": 10.5, \"snps\": 1200, \"chromosome\": \"1\"},\n        {\"start_pos\": 10000000, \"end_pos\": 15000000, \"cm\": 8.2, \"snps\": 900, \"chromosome\": \"X\"}\n    ]\n    \n    # Invalid data\n    invalid_segments = [\n        {\"start_pos\": -1000, \"end_pos\": 5000000, \"cm\": 10.5, \"snps\": 1200, \"chromosome\": \"1\"},  # negative start\n        {\"start_pos\": 15000000, \"end_pos\": 10000000, \"cm\": 8.2, \"snps\": 900, \"chromosome\": \"X\"},  # end < start\n        {\"start_pos\": 1000000, \"end_pos\": 5000000, \"cm\": -10.5, \"snps\": 1200, \"chromosome\": \"1\"},  # negative cM\n        {\"start_pos\": 1000000, \"end_pos\": 5000000, \"cm\": 10.5, \"snps\": -1200, \"chromosome\": \"1\"},  # negative SNPs\n        {\"start_pos\": 1000000, \"end_pos\": 5000000, \"cm\": 10.5, \"snps\": 1200, \"chromosome\": \"Z\"}  # invalid chromosome\n    ]\n    \n    # Test valid segments\n    print(\"Testing valid segments:\")\n    valid_objects = []\n    for i, segment_data in enumerate(valid_segments):\n        try:\n            segment = IBDSegment(**segment_data)\n            valid_objects.append(segment)\n            print(f\"✅ Segment {i+1} is valid: {segment}\")\n            print(f\"   Length: {segment.length_bp} bp, Density: {segment.density:.2f} SNPs/cM\")\n        except Exception as e:\n            print(f\"❌ Segment {i+1} failed unexpectedly: {e}\")\n    \n    # Test overlapping segments\n    if len(valid_objects) >= 2:\n        overlaps = valid_objects[0].overlaps(valid_objects[1])\n        print(f\"\\nSegments overlap: {overlaps}\")\n    \n    # Test invalid segments\n    print(\"\\nTesting invalid segments:\")\n    for i, segment_data in enumerate(invalid_segments):\n        try:\n            segment = IBDSegment(**segment_data)\n            print(f\"❌ Segment {i+1} should have failed but didn't: {segment}\")\n        except ValidationError as e:\n            print(f\"✅ Segment {i+1} failed as expected: {e}\")\n        except Exception as e:\n            print(f\"⚠️ Segment {i+1} failed with unexpected error: {e}\")\n\n# Run the tests\ntest_ibd_segment_class()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 2.2 Validator Functions\n\nAnother approach is to use separate validator functions that can be applied to different types of data. This allows for more flexibility and reuse:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class Validator:\n    \"\"\"A collection of validation functions for genetic data.\"\"\"\n    \n    @staticmethod\n    def validate_chromosome(chrom):\n        \"\"\"\n        Validate a chromosome identifier.\n        \n        Args:\n            chrom: Chromosome identifier to validate\n            \n        Returns:\n            The validated chromosome identifier\n            \n        Raises:\n            ValidationError: If the chromosome is invalid\n        \"\"\"\n        valid_chromosomes = [str(i) for i in range(1, 23)] + [\"X\", \"Y\"]\n        \n        if not isinstance(chrom, str):\n            raise ValidationError(\n                \"Chromosome must be a string\",\n                details={\"chromosome\": chrom, \"type\": type(chrom).__name__}\n            )\n        \n        # Normalize the chromosome format (remove \"chr\" prefix if present)\n        normalized = chrom.replace(\"chr\", \"\").upper()\n        \n        if normalized not in valid_chromosomes:\n            raise ValidationError(\n                \"Chromosome must be 1-22, X, or Y\",\n                details={\"chromosome\": chrom, \"normalized\": normalized}\n            )\n        \n        return normalized\n    \n    @staticmethod\n    def validate_position(pos, allow_zero=True):\n        \"\"\"\n        Validate a genomic position.\n        \n        Args:\n            pos: Position to validate\n            allow_zero: Whether to allow position 0\n            \n        Returns:\n            The validated position\n            \n        Raises:\n            ValidationError: If the position is invalid\n        \"\"\"\n        if not isinstance(pos, (int, float)):\n            raise ValidationError(\n                \"Position must be a number\",\n                details={\"position\": pos, \"type\": type(pos).__name__}\n            )\n        \n        if not allow_zero and pos == 0:\n            raise ValidationError(\n                \"Position cannot be zero\",\n                details={\"position\": pos}\n            )\n        \n        if pos < 0:\n            raise ValidationError(\n                \"Position must be non-negative\",\n                details={\"position\": pos}\n            )\n        \n        # Convert to integer\n        return int(pos)\n    \n    @staticmethod\n    def validate_centimorgans(cm):\n        \"\"\"\n        Validate a centiMorgan value.\n        \n        Args:\n            cm: centiMorgan value to validate\n            \n        Returns:\n            The validated centiMorgan value\n            \n        Raises:\n            ValidationError: If the centiMorgan value is invalid\n        \"\"\"\n        if not isinstance(cm, (int, float)):\n            raise ValidationError(\n                \"centiMorgan value must be a number\",\n                details={\"cm\": cm, \"type\": type(cm).__name__}\n            )\n        \n        if cm < 0:\n            raise ValidationError(\n                \"centiMorgan value must be non-negative\",\n                details={\"cm\": cm}\n            )\n        \n        return float(cm)\n    \n    @staticmethod\n    def validate_snp_count(snps):\n        \"\"\"\n        Validate a SNP count.\n        \n        Args:\n            snps: SNP count to validate\n            \n        Returns:\n            The validated SNP count\n            \n        Raises:\n            ValidationError: If the SNP count is invalid\n        \"\"\"\n        if not isinstance(snps, (int, float)):\n            raise ValidationError(\n                \"SNP count must be a number\",\n                details={\"snps\": snps, \"type\": type(snps).__name__}\n            )\n        \n        if snps < 0:\n            raise ValidationError(\n                \"SNP count must be non-negative\",\n                details={\"snps\": snps}\n            )\n        \n        # Convert to integer\n        return int(snps)\n    \n    @staticmethod\n    def validate_individual_id(iid):\n        \"\"\"\n        Validate an individual identifier.\n        \n        Args:\n            iid: Individual identifier to validate\n            \n        Returns:\n            The validated individual identifier\n            \n        Raises:\n            ValidationError: If the individual identifier is invalid\n        \"\"\"\n        if not isinstance(iid, str):\n            raise ValidationError(\n                \"Individual ID must be a string\",\n                details={\"iid\": iid, \"type\": type(iid).__name__}\n            )\n        \n        if len(iid) == 0:\n            raise ValidationError(\n                \"Individual ID cannot be empty\",\n                details={\"iid\": iid}\n            )\n        \n        # No other restrictions on individual IDs\n        return iid\n    \n    @staticmethod\n    def validate_ibd_segment(segment_dict):\n        \"\"\"\n        Validate an IBD segment dictionary.\n        \n        Args:\n            segment_dict: Dictionary with IBD segment data\n            \n        Returns:\n            Validated and normalized segment dictionary\n            \n        Raises:\n            ValidationError: If the segment is invalid\n            MissingDataError: If required fields are missing\n        \"\"\"\n        if not isinstance(segment_dict, dict):\n            raise ValidationError(\n                \"Segment must be a dictionary\",\n                details={\"segment\": segment_dict, \"type\": type(segment_dict).__name__}\n            )\n        \n        # Check for required fields\n        required_fields = [\"start_pos\", \"end_pos\", \"cm\", \"snps\"]\n        for field in required_fields:\n            if field not in segment_dict:\n                raise MissingDataError(\n                    f\"Missing required field: {field}\",\n                    details={\"segment\": segment_dict}\n                )\n        \n        # Validate and normalize each field\n        normalized = {}\n        \n        # Optional chromosome field (default to \"1\")\n        chrom = segment_dict.get(\"chromosome\", \"1\")\n        normalized[\"chromosome\"] = Validator.validate_chromosome(chrom)\n        \n        # Required fields\n        normalized[\"start_pos\"] = Validator.validate_position(segment_dict[\"start_pos\"])\n        normalized[\"end_pos\"] = Validator.validate_position(segment_dict[\"end_pos\"])\n        normalized[\"cm\"] = Validator.validate_centimorgans(segment_dict[\"cm\"])\n        normalized[\"snps\"] = Validator.validate_snp_count(segment_dict[\"snps\"])\n        \n        # Additional validation for segment integrity\n        if normalized[\"end_pos\"] <= normalized[\"start_pos\"]:\n            raise ValidationError(\n                \"End position must be greater than start position\",\n                details={\n                    \"start_pos\": normalized[\"start_pos\"],\n                    \"end_pos\": normalized[\"end_pos\"]\n                }\n            )\n        \n        return normalized\n\n# Test the validator functions\ndef test_validators():\n    # Test chromosome validation\n    print(\"Testing chromosome validation:\")\n    chrom_tests = [\"1\", \"22\", \"X\", \"chrY\", \"chr5\", \"Z\", 10]\n    for chrom in chrom_tests:\n        try:\n            result = Validator.validate_chromosome(chrom)\n            print(f\"✅ Chromosome '{chrom}' is valid: {result}\")\n        except ValidationError as e:\n            print(f\"❌ Chromosome '{chrom}' is invalid: {e}\")\n    \n    # Test position validation\n    print(\"\\nTesting position validation:\")\n    pos_tests = [10000, 0, -1, \"not a number\"]\n    for pos in pos_tests:\n        try:\n            result = Validator.validate_position(pos)\n            print(f\"✅ Position {pos} is valid: {result}\")\n        except ValidationError as e:\n            print(f\"❌ Position {pos} is invalid: {e}\")\n    \n    # Test centiMorgan validation\n    print(\"\\nTesting centiMorgan validation:\")\n    cm_tests = [10.5, 0, -5.2, \"not a number\"]\n    for cm in cm_tests:\n        try:\n            result = Validator.validate_centimorgans(cm)\n            print(f\"✅ cM {cm} is valid: {result}\")\n        except ValidationError as e:\n            print(f\"❌ cM {cm} is invalid: {e}\")\n    \n    # Test segment validation\n    print(\"\\nTesting segment validation:\")\n    segment_tests = [\n        {\n            \"start_pos\": 1000000,\n            \"end_pos\": 5000000,\n            \"cm\": 10.5,\n            \"snps\": 1200,\n            \"chromosome\": \"1\"\n        },\n        {\n            \"start_pos\": 10000000,\n            \"end_pos\": 5000000,  # end < start\n            \"cm\": 8.2,\n            \"snps\": 900,\n            \"chromosome\": \"X\"\n        },\n        {\n            \"start_pos\": 1000000,\n            \"end_pos\": 5000000,\n            \"snps\": 1200,  # missing cm\n            \"chromosome\": \"1\"\n        },\n        \"not a dictionary\"\n    ]\n    \n    for i, segment in enumerate(segment_tests):\n        try:\n            result = Validator.validate_ibd_segment(segment)\n            print(f\"✅ Segment {i+1} is valid: {result}\")\n        except (ValidationError, MissingDataError) as e:\n            print(f\"❌ Segment {i+1} is invalid: {e}\")\n        except Exception as e:\n            print(f\"⚠️ Segment {i+1} raised unexpected error: {e}\")\n\n# Run the tests\ntest_validators()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Part 3: Defensive Programming\n\nDefensive programming is all about anticipating potential problems and handling them gracefully. Let's explore some defensive programming techniques used in Bonsai v3.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 3.1 Checking Preconditions and Postconditions\n\nOne key technique in defensive programming is to check preconditions (conditions that must be true before a function runs) and postconditions (conditions that should be true after a function runs):",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def get_common_ancestors(id1, id2, up_dict):\n    \"\"\"\n    Find common ancestors of two individuals in a pedigree.\n    \n    This function demonstrates defensive programming with\n    precondition and postcondition checks.\n    \n    Args:\n        id1: ID of the first individual\n        id2: ID of the second individual\n        up_dict: Dictionary mapping individual IDs to their parents\n        \n    Returns:\n        Set of common ancestor IDs\n        \n    Raises:\n        ValidationError: If input validation fails\n        MissingDataError: If required data is missing\n    \"\"\"\n    # Precondition checks\n    if up_dict is None:\n        raise MissingDataError(\"Pedigree data is missing (up_dict is None)\")\n    \n    if not isinstance(up_dict, dict):\n        raise ValidationError(\n            \"Pedigree data must be a dictionary\",\n            details={\"actual_type\": type(up_dict).__name__}\n        )\n    \n    # Validate individual IDs\n    for id_val, label in [(id1, \"id1\"), (id2, \"id2\")]:\n        if id_val is None:\n            raise MissingDataError(f\"Individual ID is missing ({label} is None)\")\n        \n        if not id_val in up_dict:\n            raise ValidationError(\n                f\"Individual not found in pedigree\",\n                details={\"id\": id_val, \"label\": label}\n            )\n    \n    # Defensive check for cycles in the pedigree\n    def check_for_cycles(iid, visited=None, path=None):\n        \"\"\"Check if there are cycles in the ancestry path.\"\"\"\n        if visited is None:\n            visited = set()\n        if path is None:\n            path = []\n        \n        if iid in path:\n            # Found a cycle\n            cycle_path = path[path.index(iid):] + [iid]\n            raise ValidationError(\n                \"Cycle detected in pedigree\",\n                details={\"cycle\": \"->\".join(str(i) for i in cycle_path)}\n            )\n        \n        if iid in visited:\n            # Already checked this individual\n            return\n        \n        visited.add(iid)\n        new_path = path + [iid]\n        \n        # Check all parents\n        for parent_id in up_dict.get(iid, {}):\n            check_for_cycles(parent_id, visited, new_path)\n    \n    # Check for cycles starting from both individuals\n    try:\n        check_for_cycles(id1)\n        check_for_cycles(id2)\n    except ValidationError as e:\n        # Attach additional context to the error\n        e.details[\"error_context\"] = \"Cycle check during get_common_ancestors\"\n        raise\n    \n    # The actual function implementation\n    ancestors1 = get_all_ancestors(id1, up_dict)\n    ancestors2 = get_all_ancestors(id2, up_dict)\n    \n    # Find the common ancestors\n    common_ancestors = ancestors1.intersection(ancestors2)\n    \n    # Postcondition checks\n    if id1 in ancestors2:\n        # id1 is an ancestor of id2\n        assert id1 in common_ancestors, \"id1 should be in common ancestors if it's an ancestor of id2\"\n    \n    if id2 in ancestors1:\n        # id2 is an ancestor of id1\n        assert id2 in common_ancestors, \"id2 should be in common ancestors if it's an ancestor of id1\"\n    \n    return common_ancestors\n\ndef get_all_ancestors(id_val, up_dict):\n    \"\"\"\n    Get all ancestors of an individual in a pedigree.\n    \n    Args:\n        id_val: ID of the individual\n        up_dict: Dictionary mapping individual IDs to their parents\n        \n    Returns:\n        Set of ancestor IDs\n    \"\"\"\n    ancestors = set()\n    to_process = [id_val]\n    \n    while to_process:\n        current = to_process.pop()\n        \n        for parent in up_dict.get(current, {}):\n            if parent not in ancestors:\n                ancestors.add(parent)\n                to_process.append(parent)\n    \n    return ancestors\n\n# Create a test pedigree\ndef create_test_pedigree(include_cycle=False):\n    \"\"\"\n    Create a test pedigree for demonstrating defensive programming.\n    \n    Args:\n        include_cycle: Whether to include a cycle in the pedigree\n        \n    Returns:\n        Dictionary representing the pedigree\n    \"\"\"\n    # Create a basic pedigree\n    #\n    #      1       2\n    #      |       |\n    #      +---3---+\n    #          |\n    #      +---4---+\n    #      |       |\n    #      5       6\n    #\n    pedigree = {\n        1: {},  # No parents (founder)\n        2: {},  # No parents (founder)\n        3: {1: 1, 2: 1},  # Child of 1 and 2\n        4: {3: 1},  # Child of 3\n        5: {4: 1},  # Child of 4\n        6: {4: 1},  # Child of 4\n    }\n    \n    if include_cycle:\n        # Add a cycle: 1 -> 3 -> 4 -> 1\n        pedigree[1] = {4: 1}\n    \n    return pedigree\n\n# Test the function with different inputs\ndef test_get_common_ancestors():\n    # Create test pedigrees\n    regular_pedigree = create_test_pedigree(include_cycle=False)\n    cyclic_pedigree = create_test_pedigree(include_cycle=True)\n    \n    # Test cases\n    test_cases = [\n        {\n            \"name\": \"Valid case - distant relatives\",\n            \"id1\": 5,\n            \"id2\": 6,\n            \"pedigree\": regular_pedigree,\n            \"expected_success\": True,\n            \"expected_ancestors\": {1, 2, 3, 4}\n        },\n        {\n            \"name\": \"Valid case - direct ancestor\",\n            \"id1\": 1,\n            \"id2\": 5,\n            \"pedigree\": regular_pedigree,\n            \"expected_success\": True,\n            \"expected_ancestors\": {1}\n        },\n        {\n            \"name\": \"Missing individual\",\n            \"id1\": 5,\n            \"id2\": 7,  # not in pedigree\n            \"pedigree\": regular_pedigree,\n            \"expected_success\": False,\n            \"expected_error\": ValidationError\n        },\n        {\n            \"name\": \"Cyclic pedigree\",\n            \"id1\": 5,\n            \"id2\": 6,\n            \"pedigree\": cyclic_pedigree,\n            \"expected_success\": False,\n            \"expected_error\": ValidationError\n        },\n        {\n            \"name\": \"Missing pedigree\",\n            \"id1\": 5,\n            \"id2\": 6,\n            \"pedigree\": None,\n            \"expected_success\": False,\n            \"expected_error\": MissingDataError\n        }\n    ]\n    \n    # Run the tests\n    results = []\n    for test_case in test_cases:\n        print(f\"\\nRunning test: {test_case['name']}\")\n        try:\n            common = get_common_ancestors(\n                test_case[\"id1\"], \n                test_case[\"id2\"], \n                test_case[\"pedigree\"]\n            )\n            \n            success = test_case[\"expected_success\"]\n            if success:\n                expected_ancestors = test_case[\"expected_ancestors\"]\n                match = common == expected_ancestors\n                if match:\n                    print(f\"✅ Test passed: Found expected common ancestors: {common}\")\n                else:\n                    print(f\"❌ Test failed: Expected {expected_ancestors}, got {common}\")\n                \n                results.append({\n                    \"test\": test_case[\"name\"],\n                    \"status\": \"Pass\" if match else \"Fail\",\n                    \"message\": f\"Expected {expected_ancestors}, got {common}\" if not match else \"\"\n                })\n            else:\n                print(f\"❌ Test failed: Expected error but got success\")\n                results.append({\n                    \"test\": test_case[\"name\"],\n                    \"status\": \"Fail\",\n                    \"message\": \"Expected error but got success\"\n                })\n        \n        except Exception as e:\n            if not test_case[\"expected_success\"]:\n                expected_error = test_case[\"expected_error\"]\n                if isinstance(e, expected_error):\n                    print(f\"✅ Test passed: Got expected error: {e}\")\n                    results.append({\n                        \"test\": test_case[\"name\"],\n                        \"status\": \"Pass\",\n                        \"message\": f\"Got expected error: {type(e).__name__}\"\n                    })\n                else:\n                    print(f\"❌ Test failed: Expected {expected_error.__name__}, got {type(e).__name__}\")\n                    results.append({\n                        \"test\": test_case[\"name\"],\n                        \"status\": \"Fail\",\n                        \"message\": f\"Expected {expected_error.__name__}, got {type(e).__name__}\"\n                    })\n            else:\n                print(f\"❌ Test failed: Unexpected error: {e}\")\n                results.append({\n                    \"test\": test_case[\"name\"],\n                    \"status\": \"Fail\",\n                    \"message\": f\"Unexpected error: {type(e).__name__}: {str(e)}\"\n                })\n    \n    # Display summary\n    print(\"\\nTest Summary:\")\n    print(\"-\" * 100)\n    for result in results:\n        status_emoji = \"✅\" if result[\"status\"] == \"Pass\" else \"❌\"\n        print(f\"{status_emoji} {result['test']}: {result['status']}\")\n        if result[\"message\"]:\n            print(f\"   {result['message']}\")\n    \n    # Count passes and failures\n    passes = sum(1 for r in results if r[\"status\"] == \"Pass\")\n    failures = sum(1 for r in results if r[\"status\"] == \"Fail\")\n    \n    print(\"-\" * 100)\n    print(f\"Total: {len(results)} tests, {passes} passed, {failures} failed\")\n    \n    # Visualize results\n    plt.figure(figsize=(8, 5))\n    plt.bar([\"Passed\", \"Failed\"], [passes, failures], color=[\"#66b3ff\", \"#ff9999\"])\n    plt.title(\"Test Results\")\n    plt.ylabel(\"Count\")\n    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n    \n    # Add text labels\n    for i, v in enumerate([passes, failures]):\n        plt.text(i, v + 0.1, str(v), ha=\"center\")\n    \n    plt.tight_layout()\n    plt.show()\n\n# Run the tests\ntest_get_common_ancestors()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 3.2 Implementing Fallback Mechanisms\n\nAnother important aspect of defensive programming is implementing fallback mechanisms when things go wrong:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class IBDSegmentStore:\n    \"\"\"\n    A store for IBD segments with fallback mechanisms.\n    \n    This class demonstrates defensive programming with\n    fallback mechanisms and logging.\n    \"\"\"\n    def __init__(self, segments=None, logger=None):\n        \"\"\"\n        Initialize the IBD segment store.\n        \n        Args:\n            segments: Initial segments to add\n            logger: Logger instance\n        \"\"\"\n        self.segments = []\n        self.logger = logger or self._get_default_logger()\n        \n        self.config = {\n            \"min_cm\": 7.0,\n            \"min_snps\": 500,\n            \"max_segments\": 10000,\n            \"allow_overlapping\": True\n        }\n        \n        # Try to add initial segments if provided\n        if segments:\n            try:\n                for segment in segments:\n                    self.add_segment(segment)\n            except Exception as e:\n                self.logger.warning(f\"Failed to add some initial segments: {e}\")\n    \n    def _get_default_logger(self):\n        \"\"\"Create a default logger if none is provided.\"\"\"\n        logger = logging.getLogger(\"IBDSegmentStore\")\n        logger.setLevel(logging.INFO)\n        \n        # Add console handler if not already present\n        if not logger.handlers:\n            handler = logging.StreamHandler()\n            formatter = logging.Formatter(\n                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n            )\n            handler.setFormatter(formatter)\n            logger.addHandler(handler)\n        \n        return logger\n    \n    def add_segment(self, segment_data):\n        \"\"\"\n        Add a segment to the store with validation.\n        \n        Args:\n            segment_data: Segment data (tuple or dictionary)\n            \n        Returns:\n            True if the segment was added, False otherwise\n            \n        Raises:\n            ValidationError: If the segment is invalid\n        \"\"\"\n        try:\n            # Handle different input formats with fallbacks\n            if isinstance(segment_data, tuple) and len(segment_data) >= 4:\n                # Tuple format: (start_pos, end_pos, cm, snps, [chromosome])\n                start_pos, end_pos, cm, snps = segment_data[:4]\n                chromosome = segment_data[4] if len(segment_data) > 4 else \"1\"\n                \n                segment_dict = {\n                    \"start_pos\": start_pos,\n                    \"end_pos\": end_pos,\n                    \"cm\": cm,\n                    \"snps\": snps,\n                    \"chromosome\": chromosome\n                }\n            elif isinstance(segment_data, dict):\n                # Dictionary format\n                segment_dict = segment_data.copy()\n            else:\n                raise ValidationError(\n                    \"Segment must be a tuple or dictionary\",\n                    details={\"segment\": segment_data, \"type\": type(segment_data).__name__}\n                )\n            \n            # Validate the segment\n            validated = Validator.validate_ibd_segment(segment_dict)\n            \n            # Check against configuration thresholds\n            if validated[\"cm\"] < self.config[\"min_cm\"]:\n                self.logger.debug(\n                    f\"Segment rejected: cM ({validated['cm']}) below threshold \"\n                    f\"({self.config['min_cm']})\"\n                )\n                return False\n            \n            if validated[\"snps\"] < self.config[\"min_snps\"]:\n                self.logger.debug(\n                    f\"Segment rejected: SNPs ({validated['snps']}) below threshold \"\n                    f\"({self.config['min_snps']})\"\n                )\n                return False\n            \n            # Check for maximum segments limit\n            if len(self.segments) >= self.config[\"max_segments\"]:\n                self.logger.warning(\n                    f\"Segment store is full ({self.config['max_segments']} segments limit)\"\n                )\n                # Fallback: Remove the shortest segment if this one is longer\n                if any(s[\"cm\"] < validated[\"cm\"] for s in self.segments):\n                    shortest = min(self.segments, key=lambda s: s[\"cm\"])\n                    self.segments.remove(shortest)\n                    self.logger.info(\n                        f\"Removed shortest segment ({shortest['cm']} cM) to make room \"\n                        f\"for new segment ({validated['cm']} cM)\"\n                    )\n                else:\n                    # New segment is not longer than any existing segment\n                    return False\n            \n            # Check for overlapping segments\n            if not self.config[\"allow_overlapping\"]:\n                # Create IBDSegment objects for easier comparison\n                new_segment = IBDSegment(**validated)\n                \n                for existing in self.segments:\n                    existing_obj = IBDSegment(**existing)\n                    \n                    if new_segment.chromosome == existing_obj.chromosome and new_segment.overlaps(existing_obj):\n                        self.logger.debug(\n                            f\"Segment rejected: Overlaps with existing segment on \"\n                            f\"chromosome {new_segment.chromosome}\"\n                        )\n                        return False\n            \n            # Add the segment\n            self.segments.append(validated)\n            self.logger.debug(\n                f\"Added segment: chr{validated['chromosome']}:{validated['start_pos']}-\"\n                f\"{validated['end_pos']} ({validated['cm']} cM, {validated['snps']} SNPs)\"\n            )\n            return True\n            \n        except (ValidationError, MissingDataError) as e:\n            # Log and re-raise validation errors\n            self.logger.warning(f\"Validation error: {e}\")\n            raise\n        except Exception as e:\n            # Log unexpected errors but don't raise\n            self.logger.error(f\"Unexpected error adding segment: {e}\")\n            return False\n    \n    def get_segments(self, chromosome=None, min_cm=None, min_snps=None):\n        \"\"\"\n        Get segments with optional filtering.\n        \n        Args:\n            chromosome: Optional chromosome filter\n            min_cm: Optional minimum centiMorgan filter\n            min_snps: Optional minimum SNP filter\n            \n        Returns:\n            List of matching segments\n        \"\"\"\n        # Start with all segments\n        result = self.segments\n        \n        # Apply filters if provided\n        if chromosome is not None:\n            try:\n                chrom = Validator.validate_chromosome(chromosome)\n                result = [s for s in result if s[\"chromosome\"] == chrom]\n            except ValidationError as e:\n                # Fallback: Log the error but return empty list\n                self.logger.warning(f\"Invalid chromosome filter: {e}\")\n                return []\n        \n        if min_cm is not None:\n            try:\n                cm_threshold = Validator.validate_centimorgans(min_cm)\n                result = [s for s in result if s[\"cm\"] >= cm_threshold]\n            except ValidationError as e:\n                # Fallback: Use the configured threshold instead\n                self.logger.warning(\n                    f\"Invalid min_cm filter ({min_cm}), using default: {self.config['min_cm']}\"\n                )\n                result = [s for s in result if s[\"cm\"] >= self.config[\"min_cm\"]]\n        \n        if min_snps is not None:\n            try:\n                snp_threshold = Validator.validate_snp_count(min_snps)\n                result = [s for s in result if s[\"snps\"] >= snp_threshold]\n            except ValidationError as e:\n                # Fallback: Use the configured threshold instead\n                self.logger.warning(\n                    f\"Invalid min_snps filter ({min_snps}), using default: {self.config['min_snps']}\"\n                )\n                result = [s for s in result if s[\"snps\"] >= self.config[\"min_snps\"]]\n        \n        return result\n    \n    def get_total_cm(self, chromosome=None):\n        \"\"\"\n        Get the total centiMorgans for all segments.\n        \n        Args:\n            chromosome: Optional chromosome filter\n            \n        Returns:\n            Total centiMorgans\n        \"\"\"\n        segments = self.get_segments(chromosome=chromosome)\n        return sum(segment[\"cm\"] for segment in segments)\n    \n    def get_segment_count(self, chromosome=None):\n        \"\"\"\n        Get the number of segments.\n        \n        Args:\n            chromosome: Optional chromosome filter\n            \n        Returns:\n            Number of segments\n        \"\"\"\n        segments = self.get_segments(chromosome=chromosome)\n        return len(segments)\n    \n    def get_statistics(self):\n        \"\"\"\n        Get statistics about the segments.\n        \n        Returns:\n            Dictionary with statistics\n        \"\"\"\n        if not self.segments:\n            return {\n                \"segment_count\": 0,\n                \"total_cm\": 0,\n                \"avg_cm\": 0,\n                \"max_cm\": 0,\n                \"chromosomes\": []\n            }\n        \n        total_cm = sum(segment[\"cm\"] for segment in self.segments)\n        max_cm = max(segment[\"cm\"] for segment in self.segments) if self.segments else 0\n        chromosomes = sorted(set(segment[\"chromosome\"] for segment in self.segments))\n        \n        return {\n            \"segment_count\": len(self.segments),\n            \"total_cm\": total_cm,\n            \"avg_cm\": total_cm / len(self.segments) if self.segments else 0,\n            \"max_cm\": max_cm,\n            \"chromosomes\": chromosomes\n        }\n\n# Test the IBD Segment Store\ndef test_ibd_segment_store():\n    # Create a custom logger for testing\n    test_logger = logging.getLogger(\"TestIBDSegmentStore\")\n    test_logger.setLevel(logging.DEBUG)\n    \n    # Add a handler that captures log messages\n    log_messages = []\n    \n    class ListHandler(logging.Handler):\n        def emit(self, record):\n            log_messages.append(self.format(record))\n    \n    handler = ListHandler()\n    formatter = logging.Formatter('%(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n    test_logger.addHandler(handler)\n    \n    # Test with various scenarios\n    print(\"Creating segment store with mixed valid and invalid segments\")\n    store = IBDSegmentStore([\n        (1000000, 5000000, 10.5, 1200, \"1\"),  # Valid\n        (10000000, 15000000, 8.2, 900, \"X\"),  # Valid\n        (20000000, 15000000, 8.2, 900, \"2\"),  # Invalid (end < start)\n        (30000000, 35000000, 5.5, 600, \"3\"),  # Valid but below default cM threshold\n        (40000000, 45000000, 12.0, 400, \"4\"),  # Valid but below default SNP threshold\n        \"not a segment\"  # Invalid type\n    ], logger=test_logger)\n    \n    # Check what was added\n    print(f\"\\nStore contains {store.get_segment_count()} segments\")\n    for i, segment in enumerate(store.segments):\n        print(f\"Segment {i+1}: chr{segment['chromosome']}:{segment['start_pos']}-{segment['end_pos']} \"\n              f\"({segment['cm']} cM, {segment['snps']} SNPs)\")\n    \n    # Try adding more segments with various fallback situations\n    print(\"\\nTesting fallback mechanisms:\")\n    \n    # Add a segment with invalid chromosome but valid otherwise\n    try:\n        result = store.add_segment((50000000, 55000000, 15.0, 1500, \"Z\"))\n        print(f\"Added segment with invalid chromosome: {result}\")\n    except Exception as e:\n        print(f\"Error adding segment with invalid chromosome: {e}\")\n    \n    # Modify configuration to disallow overlapping segments\n    store.config[\"allow_overlapping\"] = False\n    \n    # Try to add an overlapping segment\n    overlap_result = store.add_segment((1000000, 3000000, 8.0, 800, \"1\"))\n    print(f\"Added overlapping segment: {overlap_result}\")\n    \n    # Try filtering with invalid parameters\n    print(\"\\nTesting filtering with invalid parameters:\")\n    segments_invalid_chrom = store.get_segments(chromosome=\"Z\")\n    print(f\"Segments with invalid chromosome: {len(segments_invalid_chrom)}\")\n    \n    segments_invalid_cm = store.get_segments(min_cm=\"not a number\")\n    print(f\"Segments with invalid min_cm: {len(segments_invalid_cm)}\")\n    \n    # Get statistics\n    stats = store.get_statistics()\n    print(\"\\nSegment Statistics:\")\n    for key, value in stats.items():\n        print(f\"{key}: {value}\")\n    \n    # Test maximum segment limit\n    print(\"\\nTesting maximum segment limit:\")\n    \n    # Create a store with a small maximum\n    small_store = IBDSegmentStore(logger=test_logger)\n    small_store.config[\"max_segments\"] = 3\n    \n    # Add segments to trigger the limit\n    for i in range(5):\n        cm_value = 10.0 + i  # Increasing cM values\n        result = small_store.add_segment((i * 10000000, (i + 1) * 10000000, cm_value, 1000, \"1\"))\n        print(f\"Added segment {i+1} (cM: {cm_value}): {result}\")\n    \n    # Check what's in the store\n    print(f\"\\nSmall store contains {small_store.get_segment_count()} segments\")\n    for i, segment in enumerate(small_store.segments):\n        print(f\"Segment {i+1}: ({segment['cm']} cM)\")\n    \n    # Visualize statistics\n    plt.figure(figsize=(10, 6))\n    \n    # Bar chart of segments by chromosome\n    chrom_counts = {}\n    for segment in store.segments:\n        chrom = segment[\"chromosome\"]\n        chrom_counts[chrom] = chrom_counts.get(chrom, 0) + 1\n    \n    # Sort chromosomes naturally (1, 2, ..., 22, X, Y)\n    def chrom_sort_key(chrom):\n        try:\n            return int(chrom)\n        except ValueError:\n            return 99 if chrom == \"X\" else 100  # X before Y\n    \n    sorted_chroms = sorted(chrom_counts.keys(), key=chrom_sort_key)\n    counts = [chrom_counts[chrom] for chrom in sorted_chroms]\n    \n    plt.bar(sorted_chroms, counts, color=\"#66b3ff\")\n    plt.title(\"IBD Segments by Chromosome\")\n    plt.xlabel(\"Chromosome\")\n    plt.ylabel(\"Number of Segments\")\n    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Print some of the log messages\n    print(\"\\nSelected log messages:\")\n    for msg in log_messages[:10]:  # Show just the first few messages\n        print(msg)\n\n# Run the tests\ntest_ibd_segment_store()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Part 4: Graceful Degradation\n\nGraceful degradation is all about continuing to function (potentially with reduced capability) even when parts of the system fail. Let's look at how this works in Bonsai v3:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class RelationshipAnalyzer:\n    \"\"\"\n    A class that analyzes genetic relationships with graceful degradation.\n    \n    This demonstrates how to implement graceful degradation when components fail.\n    \"\"\"\n    def __init__(self):\n        \"\"\"Initialize the relationship analyzer.\"\"\"\n        self.logger = logging.getLogger(\"RelationshipAnalyzer\")\n        self.logger.setLevel(logging.INFO)\n        \n        # Add console handler if not already present\n        if not self.logger.handlers:\n            handler = logging.StreamHandler()\n            formatter = logging.Formatter('%(levelname)s - %(message)s')\n            handler.setFormatter(formatter)\n            self.logger.addHandler(handler)\n        \n        # Initialize all analyzers\n        self._init_analyzers()\n    \n    def _init_analyzers(self):\n        \"\"\"Initialize the individual analyzers.\"\"\"\n        # In a real system, these might be separate components that could fail\n        self.analyzers = {\n            \"ibd\": self._create_ibd_analyzer(),\n            \"age\": self._create_age_analyzer(),\n            \"sex\": self._create_sex_analyzer(),\n            \"ethnicity\": self._create_ethnicity_analyzer()\n        }\n        \n        # Track which analyzers are working\n        self.available_analyzers = set(self.analyzers.keys())\n        \n        self.logger.info(f\"Initialized {len(self.available_analyzers)} analyzers\")\n    \n    def _create_ibd_analyzer(self):\n        \"\"\"Create the IBD analyzer component.\"\"\"\n        # This would initialize the IBD analysis component\n        # For demonstration, we'll just return a function\n        \n        def analyze_ibd(data):\n            \"\"\"Analyze IBD data to infer relationships.\"\"\"\n            if not data.get(\"segments\"):\n                raise MissingDataError(\"IBD segments are missing\")\n            \n            segments = data[\"segments\"]\n            total_cm = sum(segment.get(\"cm\", 0) for segment in segments)\n            \n            # Simple relationship inference based on total cM\n            if total_cm > 3000:\n                return {\"relationship\": \"parent-child\", \"confidence\": 0.95}\n            elif total_cm > 2000:\n                return {\"relationship\": \"full-sibling\", \"confidence\": 0.9}\n            elif total_cm > 1000:\n                return {\"relationship\": \"half-sibling/grandparent\", \"confidence\": 0.8}\n            elif total_cm > 500:\n                return {\"relationship\": \"1st cousin\", \"confidence\": 0.7}\n            elif total_cm > 250:\n                return {\"relationship\": \"2nd cousin\", \"confidence\": 0.6}\n            elif total_cm > 100:\n                return {\"relationship\": \"3rd cousin\", \"confidence\": 0.5}\n            elif total_cm > 50:\n                return {\"relationship\": \"4th cousin\", \"confidence\": 0.4}\n            elif total_cm > 20:\n                return {\"relationship\": \"distant relative\", \"confidence\": 0.3}\n            else:\n                return {\"relationship\": \"unrelated\", \"confidence\": 0.2}\n        \n        return analyze_ibd\n    \n    def _create_age_analyzer(self):\n        \"\"\"Create the age analyzer component.\"\"\"\n        def analyze_age(data):\n            \"\"\"Analyze age data to constrain relationships.\"\"\"\n            if not data.get(\"ages\"):\n                raise MissingDataError(\"Age data is missing\")\n            \n            ages = data[\"ages\"]\n            if len(ages) < 2:\n                raise ValidationError(\"Need at least two ages for comparison\")\n            \n            age1, age2 = ages[:2]\n            age_diff = abs(age1 - age2)\n            \n            # Age-based relationship constraints\n            if age_diff < 10:\n                return {\n                    \"possible\": [\"sibling\", \"cousin\", \"unrelated\"],\n                    \"unlikely\": [\"parent-child\", \"grandparent\"],\n                    \"confidence\": 0.7\n                }\n            elif 10 <= age_diff < 20:\n                return {\n                    \"possible\": [\"half-sibling\", \"cousin\", \"unrelated\", \"parent-child\"],\n                    \"unlikely\": [],\n                    \"confidence\": 0.6\n                }\n            elif 20 <= age_diff < 40:\n                return {\n                    \"possible\": [\"parent-child\", \"aunt/uncle\", \"unrelated\"],\n                    \"unlikely\": [\"sibling\", \"cousin\"],\n                    \"confidence\": 0.7\n                }\n            else:  # age_diff >= 40\n                return {\n                    \"possible\": [\"grandparent\", \"unrelated\"],\n                    \"unlikely\": [\"sibling\", \"cousin\"],\n                    \"confidence\": 0.8\n                }\n        \n        return analyze_age\n    \n    def _create_sex_analyzer(self):\n        \"\"\"Create the sex analyzer component.\"\"\"\n        def analyze_sex(data):\n            \"\"\"Analyze sex data to constrain relationships.\"\"\"\n            if not data.get(\"sexes\"):\n                raise MissingDataError(\"Sex data is missing\")\n            \n            sexes = data[\"sexes\"]\n            if len(sexes) < 2:\n                raise ValidationError(\"Need at least two sexes for comparison\")\n            \n            sex1, sex2 = sexes[:2]\n            \n            # In a real system, this would be more sophisticated\n            if sex1 == sex2:\n                return {\n                    \"possible\": [\"sibling\", \"cousin\", \"grandparent\", \"unrelated\"],\n                    \"impossible\": [\"mother-son\", \"father-daughter\"],\n                    \"confidence\": 0.9\n                }\n            else:\n                return {\n                    \"possible\": [\"all\"],\n                    \"impossible\": [],\n                    \"confidence\": 0.5\n                }\n        \n        return analyze_sex\n    \n    def _create_ethnicity_analyzer(self):\n        \"\"\"Create the ethnicity analyzer component.\"\"\"\n        def analyze_ethnicity(data):\n            \"\"\"Analyze ethnicity data to constrain relationships.\"\"\"\n            if not data.get(\"ethnicities\"):\n                raise MissingDataError(\"Ethnicity data is missing\")\n            \n            ethnicities = data[\"ethnicities\"]\n            if len(ethnicities) < 2:\n                raise ValidationError(\"Need at least two ethnicity profiles for comparison\")\n            \n            # Simplified ethnicity comparison\n            # In a real system, this would compare detailed admixture proportions\n            ethn1, ethn2 = ethnicities[:2]\n            \n            # Calculate a similarity score (0-1)\n            common_regions = set(ethn1.keys()).intersection(set(ethn2.keys()))\n            if not common_regions:\n                similarity = 0.0\n            else:\n                differences = sum(abs(ethn1.get(region, 0) - ethn2.get(region, 0)) \n                                 for region in common_regions)\n                similarity = max(0, 1 - differences / len(common_regions))\n            \n            # Interpret the similarity\n            if similarity > 0.8:\n                return {\n                    \"assessment\": \"very similar ancestry\",\n                    \"related_probability\": 0.8,\n                    \"confidence\": 0.7\n                }\n            elif similarity > 0.6:\n                return {\n                    \"assessment\": \"similar ancestry\",\n                    \"related_probability\": 0.6,\n                    \"confidence\": 0.6\n                }\n            elif similarity > 0.4:\n                return {\n                    \"assessment\": \"somewhat similar ancestry\",\n                    \"related_probability\": 0.4,\n                    \"confidence\": 0.5\n                }\n            else:\n                return {\n                    \"assessment\": \"different ancestry\",\n                    \"related_probability\": 0.2,\n                    \"confidence\": 0.6\n                }\n        \n        return analyze_ethnicity\n    \n    def analyze(self, data):\n        \"\"\"\n        Analyze genetic data to infer relationships with graceful degradation.\n        \n        Args:\n            data: Dictionary with genetic data\n            \n        Returns:\n            Dictionary with analysis results\n        \"\"\"\n        if not data:\n            raise MissingDataError(\"No data provided for analysis\")\n        \n        # Track all analysis results and errors\n        results = {}\n        errors = {}\n        \n        # Try each analyzer and gracefully handle failures\n        for name, analyzer in self.analyzers.items():\n            if name not in self.available_analyzers:\n                self.logger.debug(f\"Skipping unavailable analyzer: {name}\")\n                continue\n            \n            try:\n                self.logger.debug(f\"Running {name} analyzer\")\n                results[name] = analyzer(data)\n            except MissingDataError as e:\n                self.logger.info(f\"{name} analyzer skipped: {e}\")\n                errors[name] = {\"error\": \"missing_data\", \"message\": str(e)}\n            except ValidationError as e:\n                self.logger.info(f\"{name} analyzer failed validation: {e}\")\n                errors[name] = {\"error\": \"validation\", \"message\": str(e)}\n            except Exception as e:\n                self.logger.warning(f\"{name} analyzer failed unexpectedly: {e}\")\n                errors[name] = {\"error\": \"unexpected\", \"message\": str(e)}\n                \n                # Mark this analyzer as unavailable for future calls\n                self.available_analyzers.remove(name)\n        \n        # If all analyzers failed, raise an error\n        if not results and errors:\n            raise ProcessingError(\n                \"All analyzers failed\",\n                details={\"errors\": errors}\n            )\n        \n        # Try to combine results for a final assessment\n        final_assessment = self._combine_results(results, errors)\n        \n        # Return the complete analysis\n        return {\n            \"individual_results\": results,\n            \"errors\": errors,\n            \"final_assessment\": final_assessment,\n            \"available_analyzers\": list(self.available_analyzers),\n            \"status\": \"partial\" if errors else \"complete\"\n        }\n    \n    def _combine_results(self, results, errors):\n        \"\"\"\n        Combine individual analyzer results into a final assessment.\n        \n        Args:\n            results: Dictionary with individual analyzer results\n            errors: Dictionary with analyzer errors\n            \n        Returns:\n            Dictionary with combined assessment\n        \"\"\"\n        # If no results available, return minimal information\n        if not results:\n            return {\n                \"relationship\": \"unknown\",\n                \"confidence\": 0.0,\n                \"reason\": \"No analyzers succeeded\"\n            }\n        \n        # Start with the IBD results if available, as they're most reliable\n        if \"ibd\" in results:\n            assessment = results[\"ibd\"].copy()\n            assessment[\"primary_evidence\"] = \"ibd\"\n            confidence = assessment.get(\"confidence\", 0.5)\n        else:\n            # Without IBD, we have lower confidence\n            assessment = {\n                \"relationship\": \"unknown\",\n                \"confidence\": 0.1,\n                \"primary_evidence\": \"none\"\n            }\n            confidence = 0.1\n        \n        # Apply constraints from other analyzers\n        if \"age\" in results:\n            age_result = results[\"age\"]\n            relationship = assessment.get(\"relationship\", \"unknown\")\n            \n            # If current relationship is in the \"unlikely\" list, reduce confidence\n            if relationship in age_result.get(\"unlikely\", []):\n                assessment[\"confidence\"] = max(0.1, confidence - 0.2)\n                assessment[\"notes\"] = assessment.get(\"notes\", []) + [\n                    f\"Age difference makes {relationship} relationship unlikely\"\n                ]\n            \n            # If current relationship is not in the \"possible\" list, reduce confidence\n            possible = age_result.get(\"possible\", [])\n            if possible != [\"all\"] and relationship not in possible and relationship != \"unknown\":\n                assessment[\"confidence\"] = max(0.1, confidence - 0.3)\n                assessment[\"notes\"] = assessment.get(\"notes\", []) + [\n                    f\"Age difference is not typical for {relationship} relationship\"\n                ]\n        \n        if \"sex\" in results:\n            sex_result = results[\"sex\"]\n            relationship = assessment.get(\"relationship\", \"unknown\")\n            \n            # If current relationship is in the \"impossible\" list, reduce confidence substantially\n            if relationship in sex_result.get(\"impossible\", []):\n                assessment[\"confidence\"] = 0.1\n                assessment[\"notes\"] = assessment.get(\"notes\", []) + [\n                    f\"Sex combination makes {relationship} relationship impossible\"\n                ]\n                assessment[\"relationship\"] = \"unknown\"\n        \n        if \"ethnicity\" in results:\n            ethnicity_result = results[\"ethnicity\"]\n            \n            # Use ethnicity similarity to adjust confidence\n            related_prob = ethnicity_result.get(\"related_probability\", 0.5)\n            \n            # Only adjust slightly based on ethnicity\n            adjustment = (related_prob - 0.5) * 0.1  # Small adjustment\n            new_confidence = min(1.0, max(0.1, assessment.get(\"confidence\", 0.5) + adjustment))\n            assessment[\"confidence\"] = new_confidence\n            \n            assessment[\"notes\"] = assessment.get(\"notes\", []) + [\n                f\"Ethnicity assessment: {ethnicity_result.get('assessment', 'unknown')}\"\n            ]\n        \n        # Note which analyzers were missing\n        if errors:\n            assessment[\"missing_evidence\"] = list(errors.keys())\n        \n        return assessment\n\n# Test the RelationshipAnalyzer with graceful degradation\ndef test_relationship_analyzer():\n    # Create the analyzer\n    analyzer = RelationshipAnalyzer()\n    \n    # Test cases\n    test_cases = [\n        {\n            \"name\": \"Complete data\",\n            \"data\": {\n                \"segments\": [\n                    {\"start_pos\": 1000000, \"end_pos\": 5000000, \"cm\": 10.5, \"chromosome\": \"1\"},\n                    {\"start_pos\": 10000000, \"end_pos\": 15000000, \"cm\": 15.2, \"chromosome\": \"2\"},\n                    {\"start_pos\": 20000000, \"end_pos\": 25000000, \"cm\": 8.7, \"chromosome\": \"3\"}\n                ],\n                \"ages\": [30, 60],\n                \"sexes\": [\"XX\", \"XY\"],\n                \"ethnicities\": {\n                    \"person1\": {\"European\": 0.8, \"East Asian\": 0.1, \"African\": 0.1},\n                    \"person2\": {\"European\": 0.7, \"East Asian\": 0.2, \"African\": 0.1}\n                }\n            }\n        },\n        {\n            \"name\": \"Missing IBD data\",\n            \"data\": {\n                \"ages\": [25, 55],\n                \"sexes\": [\"XX\", \"XX\"],\n                \"ethnicities\": {\n                    \"person1\": {\"European\": 0.9, \"African\": 0.1},\n                    \"person2\": {\"European\": 0.5, \"African\": 0.5}\n                }\n            }\n        },\n        {\n            \"name\": \"Only IBD data\",\n            \"data\": {\n                \"segments\": [\n                    {\"start_pos\": 1000000, \"end_pos\": 5000000, \"cm\": 100.5, \"chromosome\": \"1\"},\n                    {\"start_pos\": 10000000, \"end_pos\": 15000000, \"cm\": 150.2, \"chromosome\": \"2\"},\n                    {\"start_pos\": 20000000, \"end_pos\": 25000000, \"cm\": 80.7, \"chromosome\": \"3\"}\n                ]\n            }\n        },\n        {\n            \"name\": \"Invalid age data\",\n            \"data\": {\n                \"segments\": [\n                    {\"start_pos\": 1000000, \"end_pos\": 5000000, \"cm\": 20.5, \"chromosome\": \"1\"}\n                ],\n                \"ages\": [30],  # Only one age\n                \"sexes\": [\"XX\", \"XY\"],\n                \"ethnicities\": {\n                    \"person1\": {\"European\": 0.8, \"East Asian\": 0.1, \"African\": 0.1},\n                    \"person2\": {\"European\": 0.2, \"East Asian\": 0.7, \"African\": 0.1}\n                }\n            }\n        },\n        {\n            \"name\": \"Empty data\",\n            \"data\": {}\n        }\n    ]\n    \n    # Run the tests\n    results = []\n    for test_case in test_cases:\n        print(f\"\\nRunning test: {test_case['name']}\")\n        try:\n            result = analyzer.analyze(test_case[\"data\"])\n            print(f\"Analysis completed with status: {result['status']}\")\n            \n            # Show the final assessment\n            assessment = result[\"final_assessment\"]\n            print(f\"Relationship: {assessment.get('relationship', 'unknown')} \"\n                  f\"(confidence: {assessment.get('confidence', 0):.2f})\")\n            \n            if \"notes\" in assessment:\n                print(\"Notes:\")\n                for note in assessment[\"notes\"]:\n                    print(f\"- {note}\")\n            \n            # Show errors\n            if result[\"errors\"]:\n                print(\"Errors:\")\n                for analyzer_name, error in result[\"errors\"].items():\n                    print(f\"- {analyzer_name}: {error['message']}\")\n            \n            results.append({\n                \"test\": test_case[\"name\"],\n                \"status\": \"success\",\n                \"result\": result\n            })\n            \n        except Exception as e:\n            print(f\"Analysis failed: {e}\")\n            results.append({\n                \"test\": test_case[\"name\"],\n                \"status\": \"failure\",\n                \"error\": str(e)\n            })\n    \n    # Create a visualization of analyzer availability\n    plt.figure(figsize=(10, 5))\n    \n    # Show which analyzers were available for each test\n    analyzer_names = [\"ibd\", \"age\", \"sex\", \"ethnicity\"]\n    test_names = [r[\"test\"] for r in results if r[\"status\"] == \"success\"]\n    \n    # Create a matrix of availability\n    availability_matrix = []\n    for test_name in test_names:\n        test_result = next(r for r in results if r[\"test\"] == test_name)\n        avail = test_result[\"result\"][\"available_analyzers\"]\n        row = [1 if name in avail else 0 for name in analyzer_names]\n        availability_matrix.append(row)\n    \n    # Create a heatmap\n    if availability_matrix:\n        fig, ax = plt.subplots(figsize=(10, 5))\n        sns.heatmap(availability_matrix, annot=True, cmap=\"YlGnBu\", \n                    xticklabels=analyzer_names, yticklabels=test_names,\n                    cbar=False, linewidths=1, linecolor='white')\n        plt.title(\"Analyzer Availability by Test Case\")\n        plt.tight_layout()\n        plt.show()\n    \n    # Return the results for further analysis\n    return results\n\n# Run the tests\ntest_relationship_analyzer()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Part 5: Logging and Debugging\n\nEffective logging and debugging are essential for diagnosing and resolving issues in production. Let's look at how Bonsai v3 handles this:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class BonsaiLogger:\n    \"\"\"\n    A specialized logger for Bonsai operations.\n    \n    This demonstrates best practices for logging in genetic genealogy applications.\n    \"\"\"\n    # Log levels\n    DEBUG = logging.DEBUG\n    INFO = logging.INFO\n    WARNING = logging.WARNING\n    ERROR = logging.ERROR\n    CRITICAL = logging.CRITICAL\n    \n    def __init__(self, name, level=logging.INFO, log_file=None, console=True):\n        \"\"\"\n        Initialize the logger.\n        \n        Args:\n            name: Logger name (usually the module name)\n            level: Logging level\n            log_file: Optional path to log file\n            console: Whether to log to console\n        \"\"\"\n        self.logger = logging.getLogger(name)\n        self.logger.setLevel(level)\n        \n        # Clear existing handlers to avoid duplicates\n        self.logger.handlers = []\n        \n        # Create formatters\n        console_fmt = logging.Formatter(\n            '%(levelname)s - %(name)s - %(message)s'\n        )\n        \n        file_fmt = logging.Formatter(\n            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n        )\n        \n        # Add console handler if requested\n        if console:\n            console_handler = logging.StreamHandler()\n            console_handler.setFormatter(console_fmt)\n            self.logger.addHandler(console_handler)\n        \n        # Add file handler if requested\n        if log_file:\n            try:\n                file_handler = logging.FileHandler(log_file)\n                file_handler.setFormatter(file_fmt)\n                self.logger.addHandler(file_handler)\n            except (IOError, PermissionError) as e:\n                # Fallback: Log to console if file logging fails\n                self.logger.warning(f\"Failed to create log file {log_file}: {e}\")\n                self.logger.warning(\"Falling back to console logging only\")\n        \n        # Capture the start time for performance tracking\n        self.start_time = time.time()\n        self.last_checkpoint = self.start_time\n        \n        # Event and error counters\n        self.counters = {\n            \"warnings\": 0,\n            \"errors\": 0,\n            \"validations\": 0,\n            \"calculations\": 0\n        }\n    \n    def debug(self, message, **kwargs):\n        \"\"\"Log a debug message with optional structured data.\"\"\"\n        self._log(logging.DEBUG, message, **kwargs)\n    \n    def info(self, message, **kwargs):\n        \"\"\"Log an info message with optional structured data.\"\"\"\n        self._log(logging.INFO, message, **kwargs)\n    \n    def warning(self, message, **kwargs):\n        \"\"\"Log a warning message with optional structured data.\"\"\"\n        self.counters[\"warnings\"] += 1\n        self._log(logging.WARNING, message, **kwargs)\n    \n    def error(self, message, **kwargs):\n        \"\"\"Log an error message with optional structured data.\"\"\"\n        self.counters[\"errors\"] += 1\n        self._log(logging.ERROR, message, **kwargs)\n    \n    def critical(self, message, **kwargs):\n        \"\"\"Log a critical message with optional structured data.\"\"\"\n        self.counters[\"errors\"] += 1\n        self._log(logging.CRITICAL, message, **kwargs)\n    \n    def _log(self, level, message, **kwargs):\n        \"\"\"Internal method to format and log messages with structured data.\"\"\"\n        # Add timestamp and structured data if provided\n        if kwargs:\n            # Format structured data for readability\n            data_str = \", \".join(f\"{k}={self._format_value(v)}\" for k, v in kwargs.items())\n            full_message = f\"{message} [{data_str}]\"\n        else:\n            full_message = message\n        \n        # Log the message\n        self.logger.log(level, full_message)\n    \n    def _format_value(self, value):\n        \"\"\"Format a value for structured logging.\"\"\"\n        if isinstance(value, (int, float, bool, str)):\n            return str(value)\n        elif isinstance(value, (list, tuple)) and len(value) <= 3:\n            return str(value)\n        elif isinstance(value, (list, tuple)):\n            return f\"[{len(value)} items]\"\n        elif isinstance(value, dict) and len(value) <= 3:\n            return str(value)\n        elif isinstance(value, dict):\n            return f\"{{{len(value)} items}}\"\n        else:\n            return f\"{type(value).__name__}\"\n    \n    def checkpoint(self, name):\n        \"\"\"\n        Log a performance checkpoint.\n        \n        Args:\n            name: Checkpoint name\n            \n        Returns:\n            Elapsed time since the last checkpoint\n        \"\"\"\n        now = time.time()\n        elapsed = now - self.last_checkpoint\n        total_elapsed = now - self.start_time\n        \n        self.info(\n            f\"Checkpoint: {name}\",\n            elapsed_seconds=f\"{elapsed:.3f}\",\n            total_elapsed=f\"{total_elapsed:.3f}\"\n        )\n        \n        self.last_checkpoint = now\n        return elapsed\n    \n    def log_exception(self, e, context=None):\n        \"\"\"\n        Log an exception with context.\n        \n        Args:\n            e: The exception\n            context: Optional context dictionary\n        \"\"\"\n        tb = traceback.format_exc()\n        context_dict = context or {}\n        \n        # Extract exception details\n        exc_type = type(e).__name__\n        exc_message = str(e)\n        \n        # Make a clean traceback for logging\n        tb_lines = tb.split('\\n')\n        if len(tb_lines) > 10:\n            # Truncate if too long\n            tb_summary = '\\n'.join(tb_lines[:3] + [\"...\"] + tb_lines[-5:])\n        else:\n            tb_summary = tb\n        \n        # Log the exception\n        self.error(\n            f\"Exception: {exc_type}: {exc_message}\",\n            exception_type=exc_type,\n            **context_dict\n        )\n        \n        # Log the traceback at debug level\n        self.debug(f\"Traceback:\\n{tb_summary}\")\n    \n    def log_validation(self, success, entity_type, details=None):\n        \"\"\"\n        Log a validation event.\n        \n        Args:\n            success: Whether validation succeeded\n            entity_type: Type of entity being validated\n            details: Optional validation details\n        \"\"\"\n        self.counters[\"validations\"] += 1\n        details_dict = details or {}\n        \n        if success:\n            self.debug(\n                f\"Validation succeeded: {entity_type}\",\n                **details_dict\n            )\n        else:\n            self.warning(\n                f\"Validation failed: {entity_type}\",\n                **details_dict\n            )\n    \n    def log_calculation(self, calc_type, details=None, result=None):\n        \"\"\"\n        Log a calculation event.\n        \n        Args:\n            calc_type: Type of calculation\n            details: Optional calculation details\n            result: Optional calculation result\n        \"\"\"\n        self.counters[\"calculations\"] += 1\n        details_dict = details or {}\n        \n        # Log differently depending on result\n        if result is None:\n            self.debug(\n                f\"Starting calculation: {calc_type}\",\n                **details_dict\n            )\n        else:\n            # Include condensed result in the log\n            result_dict = {\"result\": self._format_value(result)}\n            self.debug(\n                f\"Completed calculation: {calc_type}\",\n                **{**details_dict, **result_dict}\n            )\n    \n    def get_summary(self):\n        \"\"\"\n        Get a summary of logging activity.\n        \n        Returns:\n            Dict with summary information\n        \"\"\"\n        return {\n            \"total_time\": time.time() - self.start_time,\n            \"counters\": self.counters.copy()\n        }\n\n# Example usage of the logger in a pedigree reconstruction task\ndef demo_logging():\n    # Create a logger\n    log_file = os.path.join(RESULTS_DIR, \"bonsai_demo.log\")\n    logger = BonsaiLogger(\"BonsaiDemo\", level=logging.DEBUG, log_file=log_file)\n    \n    logger.info(\"Starting pedigree reconstruction demo\")\n    \n    try:\n        # Simulate a multi-step process with logging\n        logger.checkpoint(\"Initialization\")\n        \n        # Step 1: Load data\n        logger.info(\"Loading IBD data\")\n        try:\n            # Simulate a data loading step\n            time.sleep(0.2)  # Simulate work\n            segments = [\n                {\"start_pos\": 1000000, \"end_pos\": 5000000, \"cm\": 10.5, \"chromosome\": \"1\"},\n                {\"start_pos\": 10000000, \"end_pos\": 15000000, \"cm\": 8.2, \"chromosome\": \"X\"},\n                {\"start_pos\": 20000000, \"end_pos\": 15000000, \"cm\": 8.2, \"chromosome\": \"2\"}  # Invalid\n            ]\n            logger.info(\"Loaded IBD segments\", count=len(segments))\n        except Exception as e:\n            logger.log_exception(e, context={\"step\": \"data_loading\"})\n            # Simulate fallback data\n            segments = []\n            logger.warning(\"Using empty segment list as fallback\")\n        \n        # Step 2: Validate data\n        logger.checkpoint(\"Data validation\")\n        valid_segments = []\n        \n        for i, segment in enumerate(segments):\n            try:\n                if \"chromosome\" not in segment:\n                    raise ValidationError(\"Missing chromosome\", details={\"segment_index\": i})\n                \n                if segment.get(\"start_pos\", 0) >= segment.get(\"end_pos\", 0):\n                    raise ValidationError(\n                        \"Invalid positions\", \n                        details={\n                            \"segment_index\": i,\n                            \"start\": segment.get(\"start_pos\"),\n                            \"end\": segment.get(\"end_pos\")\n                        }\n                    )\n                \n                # Log successful validation\n                logger.log_validation(True, \"segment\", {\n                    \"index\": i,\n                    \"chromosome\": segment.get(\"chromosome\"),\n                    \"cm\": segment.get(\"cm\")\n                })\n                \n                valid_segments.append(segment)\n                \n            except ValidationError as e:\n                # Log failed validation\n                logger.log_validation(False, \"segment\", {\n                    \"index\": i,\n                    \"error\": str(e),\n                    **e.details\n                })\n        \n        logger.info(\"Validated segments\", valid=len(valid_segments), invalid=len(segments)-len(valid_segments))\n        \n        # Step 3: Perform calculations\n        logger.checkpoint(\"Relationship inference\")\n        \n        # Simulate a calculation that might fail\n        try:\n            logger.log_calculation(\"total_cm\", {\"segments\": len(valid_segments)})\n            total_cm = sum(segment.get(\"cm\", 0) for segment in valid_segments)\n            logger.log_calculation(\"total_cm\", {\"segments\": len(valid_segments)}, total_cm)\n            \n            # Deliberately cause an error\n            if random.random() < 0.3:  # 30% chance of error\n                missing_value = None\n                result = total_cm / len(missing_value)  # Will raise TypeError\n            \n            relationship = \"unknown\"\n            if total_cm > 3000:\n                relationship = \"parent-child\"\n            elif total_cm > 2000:\n                relationship = \"full-sibling\"\n            elif total_cm > 1000:\n                relationship = \"half-sibling/grandparent\"\n            elif total_cm > 500:\n                relationship = \"1st cousin\"\n            \n            logger.info(\"Inferred relationship\", relationship=relationship, total_cm=total_cm)\n            \n        except Exception as e:\n            logger.log_exception(e, context={\"step\": \"relationship_inference\", \"valid_segments\": len(valid_segments)})\n            logger.warning(\"Failed to infer relationship, using fallback\")\n            relationship = \"unknown\"\n        \n        # Step 4: Generate report\n        logger.checkpoint(\"Report generation\")\n        \n        report = {\n            \"relationship\": relationship,\n            \"segments\": len(valid_segments),\n            \"total_cm\": total_cm if 'total_cm' in locals() else None,\n            \"status\": \"success\" if relationship != \"unknown\" else \"partial\"\n        }\n        \n        logger.info(\"Generated report\", status=report[\"status\"])\n        \n        # Wrap up\n        summary = logger.get_summary()\n        logger.info(\n            \"Processing complete\",\n            total_time=f\"{summary['total_time']:.3f}s\",\n            warnings=summary['counters']['warnings'],\n            errors=summary['counters']['errors']\n        )\n        \n        return report, summary\n        \n    except Exception as e:\n        # Catch-all for unexpected errors\n        logger.log_exception(e, context={\"phase\": \"overall_process\"})\n        logger.critical(\"Processing failed with unhandled exception\")\n        \n        # Even if we fail, return a summary\n        summary = logger.get_summary()\n        logger.info(\n            \"Processing failed\",\n            total_time=f\"{summary['total_time']:.3f}s\",\n            warnings=summary['counters']['warnings'],\n            errors=summary['counters']['errors']\n        )\n        \n        return {\"status\": \"failed\", \"error\": str(e)}, summary\n\n# Run the logging demo\nreport, summary = demo_logging()\n\n# Display the results\nprint(\"\\nReport:\")\nfor key, value in report.items():\n    print(f\"{key}: {value}\")\n\nprint(\"\\nLogging Summary:\")\nprint(f\"Total time: {summary['total_time']:.3f} seconds\")\nprint(\"Event counts:\")\nfor event, count in summary['counters'].items():\n    print(f\"- {event}: {count}\")\n\n# Display a visualization of the event counts\nplt.figure(figsize=(10, 5))\nevents = list(summary['counters'].keys())\ncounts = list(summary['counters'].values())\n\n# Define colors based on event type\ncolors = []\nfor event in events:\n    if event == \"errors\":\n        colors.append(\"#ff9999\")  # Red\n    elif event == \"warnings\":\n        colors.append(\"#ffcc99\")  # Orange\n    else:\n        colors.append(\"#66b3ff\")  # Blue\n\n# Create the bar chart\nplt.bar(events, counts, color=colors)\nplt.title(\"Event Counts During Processing\")\nplt.ylabel(\"Count\")\nplt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n\n# Add count labels on top of bars\nfor i, v in enumerate(counts):\n    plt.text(i, v + 0.1, str(v), ha=\"center\")\n\nplt.tight_layout()\nplt.show()\n\n# If we created a log file, show its content\nif os.path.exists(os.path.join(RESULTS_DIR, \"bonsai_demo.log\")):\n    with open(os.path.join(RESULTS_DIR, \"bonsai_demo.log\"), \"r\") as f:\n        log_content = f.readlines()\n    \n    print(\"\\nLog File Content (first 10 lines):\")\n    for line in log_content[:10]:\n        print(line.strip())",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n\nIn this lab, we explored the error handling and data validation techniques used in Bonsai v3 to ensure robust and reliable operation, even when faced with imperfect data or unexpected situations:\n\n1. **Custom Exception Hierarchy**: We implemented a specialized exception hierarchy that allows for more targeted error handling and clearer error messages.\n\n2. **Input Validation**: We demonstrated the importance of thorough input validation, using both data classes with built-in validation and separate validator functions.\n\n3. **Defensive Programming**: We showed how to use precondition and postcondition checks to catch problems early and ensure the correctness of our functions.\n\n4. **Graceful Degradation**: We implemented a system that continues to function (at potentially reduced capability) even when parts of it fail, focusing on maximizing the value of available data.\n\n5. **Logging and Debugging**: We built a comprehensive logging system that provides visibility into the operation of complex genetic genealogy applications, making it easier to diagnose and resolve issues.\n\nThese techniques are critical for building reliable genetic genealogy applications that can handle the complexities and uncertainties of real-world genetic data. By implementing robust error handling and validation, Bonsai v3 is able to provide more reliable results and a better user experience.\n\nIn the next lab, we'll explore pedigree rendering and visualization techniques used in Bonsai v3 to help users interpret and understand the results of pedigree reconstruction.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}