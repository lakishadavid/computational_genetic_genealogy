{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 29: End-to-End Pedigree Reconstruction Implementation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook guides you through developing a complete pedigree reconstruction pipeline using Bonsai v3. You'll learn how to integrate all components from data preparation through pedigree visualization, creating a comprehensive solution that handles real-world data challenges while producing interpretable, confidence-scored results.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Design and implement an end-to-end pedigree reconstruction pipeline\n",
    "- Integrate Bonsai's core components into a cohesive workflow\n",
    "- Apply appropriate preprocessing and filtering techniques for input data\n",
    "- Handle real-world genetic data challenges like missing data and complex relationships\n",
    "- Evaluate and interpret confidence metrics for reconstructed pedigrees\n",
    "- Generate meaningful visualizations and outputs for different use cases\n",
    "\n",
    "**Prerequisites:**\n",
    "- Completion of Lab 9: Pedigree Data Structures\n",
    "- Completion of Lab 16: Merging Pedigrees\n",
    "- Completion of Lab 21: Pedigree Rendering\n",
    "- Completion of Lab 28: Integration with Other Genealogical Tools\n",
    "\n",
    "**Estimated completion time:** 90-120 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import inspect\n",
    "import importlib\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Cross-compatibility setup\n",
    "from scripts_support.lab_cross_compatibility import setup_environment, is_jupyterlite, save_results, save_plot\n",
    "\n",
    "# Set up environment-specific paths\n",
    "DATA_DIR, RESULTS_DIR = setup_environment()\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette(\"colorblind\")  # Improve accessibility with colorblind-friendly palette\n",
    "\n",
    "# Configure plot defaults for better readability\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (10, 6),\n",
    "    'font.size': 12,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup Bonsai module paths\n",
    "if not is_jupyterlite():\n",
    "    # In local environment, add the utils directory to system path\n",
    "    utils_dir = os.getenv('PROJECT_UTILS_DIR', os.path.join(os.path.dirname(DATA_DIR), 'utils'))\n",
    "    bonsaitree_dir = os.path.join(utils_dir, 'bonsaitree')\n",
    "    \n",
    "    # Add to path if it exists and isn't already there\n",
    "    if os.path.exists(bonsaitree_dir) and bonsaitree_dir not in sys.path:\n",
    "        sys.path.append(bonsaitree_dir)\n",
    "        print(f\"Added {bonsaitree_dir} to sys.path\")\n",
    "else:\n",
    "    # In JupyterLite, use a simplified approach\n",
    "    print(\"\u26a0\ufe0f Running in JupyterLite: Some Bonsai functionality may be limited.\")\n",
    "    print(\"This notebook is primarily designed for local execution where the Bonsai codebase is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Helper functions for exploring modules\n",
    "def display_module_classes(module_name):\n",
    "    \"\"\"Display classes and their docstrings from a module\"\"\"\n",
    "    try:\n",
    "        # Import the module\n",
    "        module = importlib.import_module(module_name)\n",
    "        \n",
    "        # Find all classes\n",
    "        classes = inspect.getmembers(module, inspect.isclass)\n",
    "        \n",
    "        # Filter classes defined in this module (not imported)\n",
    "        classes = [(name, cls) for name, cls in classes if cls.__module__ == module_name]\n",
    "        \n",
    "        if not classes:\n",
    "            print(f\"No classes found in module {module_name}\")\n",
    "            return\n",
    "            \n",
    "        # Print info for each class\n",
    "        for name, cls in classes:\n",
    "            display(Markdown(f\"### Class: {name}\"))\n",
    "            \n",
    "            # Get docstring\n",
    "            doc = inspect.getdoc(cls)\n",
    "            if doc:\n",
    "                display(Markdown(f\"**Documentation:**\\\n{doc}\"))\n",
    "            else:\n",
    "                display(Markdown(\"*No documentation available*\"))\n",
    "            \n",
    "            # Get methods\n",
    "            methods = inspect.getmembers(cls, inspect.isfunction)\n",
    "            public_methods = [(method_name, method) for method_name, method in methods \n",
    "                             if not method_name.startswith('_')]\n",
    "            \n",
    "            if public_methods:\n",
    "                display(Markdown(\"**Public Methods:**\"))\n",
    "                for method_name, method in public_methods:\n",
    "                    sig = inspect.signature(method)\n",
    "                    display(Markdown(f\"- `{method_name}{sig}`\"))\n",
    "            else:\n",
    "                display(Markdown(\"*No public methods*\"))\n",
    "            \n",
    "            display(Markdown(\"---\"))\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing module {module_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing module {module_name}: {e}\")\n",
    "\n",
    "def display_module_functions(module_name):\n",
    "    \"\"\"Display functions and their docstrings from a module\"\"\"\n",
    "    try:\n",
    "        # Import the module\n",
    "        module = importlib.import_module(module_name)\n",
    "        \n",
    "        # Find all functions\n",
    "        functions = inspect.getmembers(module, inspect.isfunction)\n",
    "        \n",
    "        # Filter functions defined in this module (not imported)\n",
    "        functions = [(name, func) for name, func in functions if func.__module__ == module_name]\n",
    "        \n",
    "        if not functions:\n",
    "            print(f\"No functions found in module {module_name}\")\n",
    "            return\n",
    "            \n",
    "        # Filter public functions\n",
    "        public_functions = [(name, func) for name, func in functions if not name.startswith('_')]\n",
    "        \n",
    "        if not public_functions:\n",
    "            print(f\"No public functions found in module {module_name}\")\n",
    "            return\n",
    "            \n",
    "        # Print info for each function\n",
    "        for name, func in public_functions:                \n",
    "            display(Markdown(f\"### Function: {name}\"))\n",
    "            \n",
    "            # Get signature\n",
    "            sig = inspect.signature(func)\n",
    "            display(Markdown(f\"**Signature:** `{name}{sig}`\"))\n",
    "            \n",
    "            # Get docstring\n",
    "            doc = inspect.getdoc(func)\n",
    "            if doc:\n",
    "                display(Markdown(f\"**Documentation:**\\\n{doc}\"))\n",
    "            else:\n",
    "                display(Markdown(\"*No documentation available*\"))\n",
    "                \n",
    "            display(Markdown(\"---\"))\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing module {module_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing module {module_name}: {e}\")\n",
    "\n",
    "def view_function_source(module_name, function_name):\n",
    "    \"\"\"Display the source code of a function\"\"\"\n",
    "    try:\n",
    "        # Import the module\n",
    "        module = importlib.import_module(module_name)\n",
    "        \n",
    "        # Get the function\n",
    "        func = getattr(module, function_name)\n",
    "        \n",
    "        # Get the source code\n",
    "        source = inspect.getsource(func)\n",
    "        \n",
    "        # Print the source code with syntax highlighting\n",
    "        display(Markdown(f\"### Source code for `{function_name}`\\\n```python\\\n{source}\\\n```\"))\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing module {module_name}: {e}\")\n",
    "    except AttributeError:\n",
    "        print(f\"Function {function_name} not found in module {module_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing function {function_name}: {e}\")\n",
    "\n",
    "def view_class_source(module_name, class_name):\n",
    "    \"\"\"Display the source code of a class\"\"\"\n",
    "    try:\n",
    "        # Import the module\n",
    "        module = importlib.import_module(module_name)\n",
    "        \n",
    "        # Get the class\n",
    "        cls = getattr(module, class_name)\n",
    "        \n",
    "        # Get the source code\n",
    "        source = inspect.getsource(cls)\n",
    "        \n",
    "        # Print the source code with syntax highlighting\n",
    "        display(Markdown(f\"### Source code for class `{class_name}`\\\n```python\\\n{source}\\\n```\"))\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing module {module_name}: {e}\")\n",
    "    except AttributeError:\n",
    "        print(f\"Class {class_name} not found in module {module_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing class {class_name}: {e}\")\n",
    "\n",
    "def explore_module(module_name):\n",
    "    \"\"\"Display a comprehensive overview of a module with classes and functions\"\"\"\n",
    "    try:\n",
    "        # Import the module\n",
    "        module = importlib.import_module(module_name)\n",
    "        \n",
    "        # Module docstring\n",
    "        doc = inspect.getdoc(module)\n",
    "        display(Markdown(f\"# Module: {module_name}\"))\n",
    "        \n",
    "        if doc:\n",
    "            display(Markdown(f\"**Module Documentation:**\\\n{doc}\"))\n",
    "        else:\n",
    "            display(Markdown(\"*No module documentation available*\"))\n",
    "            \n",
    "        display(Markdown(\"---\"))\n",
    "        \n",
    "        # Display classes\n",
    "        display(Markdown(\"## Classes\"))\n",
    "        display_module_classes(module_name)\n",
    "        \n",
    "        # Display functions\n",
    "        display(Markdown(\"## Functions\"))\n",
    "        display_module_functions(module_name)\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing module {module_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exploring module {module_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Bonsai Installation\n",
    "\n",
    "Let's verify that the Bonsai v3 module is available for import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "try:\n",
    "    from bonsaitree import v3\n",
    "    print(\"\u2705 Successfully imported Bonsai v3 module\")\n",
    "    \n",
    "    # Print Bonsai version information if available\n",
    "    if hasattr(v3, \"__version__\"):\n",
    "        print(f\"Bonsai v3 version: {v3.__version__}\")\n",
    "    \n",
    "    # List key submodules\n",
    "    print(\"\\\nAvailable Bonsai submodules:\")\n",
    "    for module_name in dir(v3):\n",
    "        if not module_name.startswith(\"_\") and not module_name.startswith(\"__\"):\n",
    "            print(f\"- {module_name}\")\n",
    "except ImportError as e:\n",
    "    print(f\"\u274c Failed to import Bonsai v3 module: {e}\")\n",
    "    print(\"This lab requires access to the Bonsai v3 codebase.\")\n",
    "    print(\"Make sure you've properly set up your environment with the Bonsai repository.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In previous labs, we've explored individual components of the Bonsai v3 system, from IBD processing to relationship inference and pedigree rendering. In this lab, we'll bring all these components together to build a complete end-to-end pipeline for pedigree reconstruction from genetic data.\n",
    "\n",
    "A comprehensive pedigree reconstruction system needs to handle multiple stages:\n",
    "\n",
    "1. **Input Data Processing**: Loading and validating genetic data, IBD segments, and demographic information\n",
    "2. **Data Preparation**: Filtering, merging, and normalizing data for consistency\n",
    "3. **Relationship Inference**: Estimating relationships between pairs of individuals\n",
    "4. **Pedigree Construction**: Building and optimizing pedigree structures\n",
    "5. **Confidence Evaluation**: Assessing the reliability of reconstructed relationships\n",
    "6. **Result Visualization**: Rendering pedigrees in an interpretable format\n",
    "7. **Output Generation**: Producing structured data for further analysis\n",
    "\n",
    "By integrating these components into a cohesive pipeline, we can create a powerful tool for genetic genealogy research, ancestry analysis, and family discovery applications."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Part 1: Pipeline Design and Architecture\\\n\\\n### Theory and Background\\\n\\\nDesigning an effective pedigree reconstruction pipeline requires careful consideration of both the algorithm flow and data structures. A well-architected pipeline should:\\\n\\\n1. **Be Modular**: Components should be cleanly separated with well-defined interfaces\\\n2. **Handle Errors Gracefully**: Robust error handling and validation at each stage\\\n3. **Support Configuration**: Allow parameters to be customized for different scenarios\\\n4. **Scale Appropriately**: Efficiently process datasets of varying sizes\\\n5. **Provide Feedback**: Offer visibility into progress and intermediate results\\\n\\\nIn Bonsai v3, the pedigree reconstruction process follows a progression from raw IBD segments to complete pedigrees:\\\n\\\n```\\\nIBD Segments \u2192 Pairwise Relationships \u2192 Small Pedigree Clusters \u2192 Merged Pedigree\\\n```\\\n\\\nThis workflow leverages multiple Bonsai components in sequence, with each component handling a specific aspect of the reconstruction process. Let's examine how these components can be integrated into a cohesive pipeline.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Implementation in Bonsai v3\\\n\\\nLet's look at how Bonsai v3 implements key pipeline components through its module structure. We'll examine the most important interfaces for building an end-to-end pipeline.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Explore the bonsai.py module, which provides the main pipeline functionality\\\ntry:\\\n    explore_module(\\\\\"bonsaitree.v3.bonsai\\\\\")\\\nexcept Exception as e:\\\n    print(f\\\\\"Error exploring bonsai module: {e}\\\\\")\\\n    print(\\\\\"Will continue with a theoretical discussion of the pipeline architecture.\\\\\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Look for the run_bonsai.py script which demonstrates end-to-end usage\\\ntry:\\\n    # Assuming the script is in the scripts_work directory\\\n    script_path = \\\\\"/home/lakishadavid/computational_genetic_genealogy/scripts_work/run_bonsai.py\\\\\"\\\n    \\\n    # Use subprocess to check if the file exists and show its contents\\\n    import subprocess\\\n    result = subprocess.run([\\\\\"ls\\\\\", \\\\\"-l\\\\\", script_path], capture_output=True, text=True)\\\n    \\\n    if result.returncode == 0:\\\n        print(f\\\\\"Found run_bonsai.py script for end-to-end workflow example at:\\\\\\\n{script_path}\\\\\")\\\n        \\\n        # Show the first few lines to get an overview\\\n        head_result = subprocess.run([\\\\\"head\\\\\", \\\\\"-n\\\\\", \\\\\"20\\\\\", script_path], capture_output=True, text=True)\\\n        print(\\\\\"\\\\\\\nPreview of run_bonsai.py:\\\\\")\\\n        print(head_result.stdout)\\\n    else:\\\n        print(\\\\\"Could not find run_bonsai.py script. Using theoretical discussion instead.\\\\\")\\\n        \\\nexcept Exception as e:\\\n    print(f\\\\\"Error checking for run_bonsai.py: {e}\\\\\")\\\n    print(\\\\\"Will proceed with theoretical workflow example.\\\\\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Bonsai Pipeline Architecture\\\n\\\nBased on the module exploration and documentation, we can outline the architecture of a complete Bonsai pedigree reconstruction pipeline:\\\n\\\n1. **IBD Data Processing**:\\\n   - Loading IBD segments from various formats\\\n   - Filtering segments by length, quality, etc.\\\n   - Converting to Bonsai's internal format\\\n\\\n2. **Demographic Data Integration**:\\\n   - Loading age and sex information\\\n   - Incorporating prior relationship knowledge if available\\\n   - Setting up demographic constraints\\\n\\\n3. **Pairwise Relationship Inference**:\\\n   - Computing IBD statistics between pairs\\\n   - Calculating likelihood scores for different relationship types\\\n   - Ranking relationship hypotheses\\\n\\\n4. **Community Detection**:\\\n   - Clustering individuals into related groups\\\n   - Identifying independent pedigree components\\\n   - Prioritizing clusters for reconstruction\\\n\\\n5. **Pedigree Construction**:\\\n   - Building small pedigree structures\\\n   - Optimizing placement of individuals\\\n   - Merging pedigree fragments\\\n\\\n6. **Confidence Assessment**:\\\n   - Calculating confidence scores for relationships\\\n   - Identifying ambiguous relationships\\\n   - Generating alternative pedigree hypotheses\\\n\\\n7. **Visualization and Output**:\\\n   - Rendering pedigrees with Graphviz\\\n   - Exporting results in various formats\\\n   - Generating summary statistics and reports",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a visualization of the pipeline architecture\\\nimport matplotlib.pyplot as plt\\\nimport matplotlib.patches as mpatches\\\nfrom matplotlib.path import Path\\\nimport numpy as np\\\n\\\n# Define the pipeline components with their dependencies and Bonsai modules\\\npipeline_stages = [\\\n    {\\\\\"name\\\\\": \\\\\"IBD Data Processing\\\\\", \\\\\"module\\\\\": \\\\\"ibd.py\\\\\", \\\\\"position\\\\\": 1},\\\n    {\\\\\"name\\\\\": \\\\\"Demographic Data\\\\\", \\\\\"module\\\\\": \\\\\"demographics.py\\\\\", \\\\\"position\\\\\": 2},\\\n    {\\\\\"name\\\\\": \\\\\"Relationship Inference\\\\\", \\\\\"module\\\\\": \\\\\"likelihoods.py, druid.py\\\\\", \\\\\"position\\\\\": 3},\\\n    {\\\\\"name\\\\\": \\\\\"Community Detection\\\\\", \\\\\"module\\\\\": \\\\\"clusters.py\\\\\", \\\\\"position\\\\\": 4},\\\n    {\\\\\"name\\\\\": \\\\\"Pedigree Construction\\\\\", \\\\\"module\\\\\": \\\\\"bonsai.py, pedigrees.py\\\\\", \\\\\"position\\\\\": 5},\\\n    {\\\\\"name\\\\\": \\\\\"Confidence Assessment\\\\\", \\\\\"module\\\\\": \\\\\"confidence.py\\\\\", \\\\\"position\\\\\": 6},\\\n    {\\\\\"name\\\\\": \\\\\"Visualization & Output\\\\\", \\\\\"module\\\\\": \\\\\"rendering.py\\\\\", \\\\\"position\\\\\": 7}\\\n]\\\n\\\n# Create the figure and axis\\\nfig, ax = plt.subplots(figsize=(12, 8))\\\nax.set_xlim(0, 10)\\\nax.set_ylim(0, 10)\\\n\\\n# Remove axis ticks and labels\\\nax.set_xticks([])\\\nax.set_yticks([])\\\nax.set_frame_on(False)\\\n\\\n# Define colors and styles\\\nbox_props = {\\\n    \\\\\"facecolor\\\\\": \\\\\"#3498db\\\\\",  # Blue\\\n    \\\\\"edgecolor\\\\\": \\\\\"#2c3e50\\\\\",  # Dark blue\\\n    \\\\\"alpha\\\\\": 0.7,\\\n    \\\\\"boxstyle\\\\\": \\\\\"round,pad=0.5\\\\\"\\\n}\\\n\\\nmodule_props = {\\\n    \\\\\"facecolor\\\\\": \\\\\"#ecf0f1\\\\\",  # Light gray\\\n    \\\\\"edgecolor\\\\\": \\\\\"#bdc3c7\\\\\",  # Darker gray\\\n    \\\\\"alpha\\\\\": 0.9,\\\n    \\\\\"boxstyle\\\\\": \\\\\"round,pad=0.3\\\\\"\\\n}\\\n\\\n# Calculate positions for the pipeline stages\\\ndef calculate_positions(stages):\\\n    positions = []\\\n    max_position = max(stage[\\\\\"position\\\\\"] for stage in stages)\\\n    spacing = 8.0 / (max_position + 1)  # Horizontal spacing\\\n    \\\n    for stage in stages:\\\n        x = stage[\\\\\"position\\\\\"] * spacing + 1.0\\\n        \\\n        # Zigzag pattern for visual interest\\\n        if stage[\\\\\"position\\\\\"] % 2 == 0:\\\n            y = 6.5\\\n        else:\\\n            y = 3.5\\\n            \\\n        positions.append((x, y))\\\n    \\\n    return positions\\\n\\\n# Get positions for each stage\\\npositions = calculate_positions(pipeline_stages)\\\n\\\n# Draw boxes and module info for each stage\\\nfor i, (stage, pos) in enumerate(zip(pipeline_stages, positions)):\\\n    x, y = pos\\\n    \\\n    # Draw the main stage box\\\n    text_box = mpatches.FancyBboxPatch(\\\n        (x - 1.2, y - 0.6), 2.4, 1.2, \\\n        **box_props\\\n    )\\\n    ax.add_patch(text_box)\\\n    \\\n    # Add the stage name\\\n    ax.text(x, y, stage[\\\\\"name\\\\\"], ha='center', va='center', color='white', \\\n            fontsize=12, fontweight='bold')\\\n    \\\n    # Add the module information below\\\n    ax.text(x, y - 0.8, f\\\\\"Module: {stage['module']}\\\\\", ha='center', va='center', \\\n            fontsize=9, bbox=module_props)\\\n    \\\n    # Add stage number above\\\n    ax.text(x, y + 0.8, f\\\\\"Stage {stage['position']}\\\\\", ha='center', va='center', \\\n            fontsize=10, fontweight='bold')\\\n\\\n# Draw arrows connecting the stages\\\narrow_props = dict(arrowstyle=\\\\\"->\\\\\", connectionstyle=\\\\\"arc3,rad=0.1\\\\\", \\\n                  color=\\\\\"#34495e\\\\\", lw=2, alpha=0.7)\\\n\\\nfor i in range(len(positions) - 1):\\\n    start = positions[i]\\\n    end = positions[i + 1]\\\n    \\\n    # Calculate start and end points for the arrow\\\n    if i % 2 == 0:  # Every other connection goes down\\\n        start_point = (start[0] + 0.8, start[1] - 0.2)\\\n        end_point = (end[0] - 0.8, end[1] - 0.2)\\\n    else:  # The others go up\\\n        start_point = (start[0] + 0.8, start[1] + 0.2)\\\n        end_point = (end[0] - 0.8, end[1] + 0.2)\\\n    \\\n    arrow = mpatches.FancyArrowPatch(start_point, end_point, **arrow_props)\\\n    ax.add_patch(arrow)\\\n\\\n# Add data flow indicators\\\ndata_types = [\\\n    (\\\\\"IBD Segments\\\\\", 1.5, 2.5),\\\n    (\\\\\"Age & Sex Data\\\\\", 2.5, 2.5),\\\n    (\\\\\"Pairwise Likelihoods\\\\\", 4.2, 2.5),\\\n    (\\\\\"Related Clusters\\\\\", 5.8, 2.5),\\\n    (\\\\\"Pedigree Structures\\\\\", 7.5, 2.5),\\\n    (\\\\\"Confidence Scores\\\\\", 8.5, 5.5),\\\n    (\\\\\"Visualized Pedigrees\\\\\", 9.0, 3.5)\\\n]\\\n\\\nfor text, x, y in data_types:\\\n    ax.text(x, y, text, ha='center', va='center', fontsize=8,\\\n            bbox=dict(facecolor='#f39c12', alpha=0.7, boxstyle=\\\\\"round,pad=0.3\\\\\"))\\\n\\\n# Add title\\\nax.set_title(\\\\\"Bonsai v3 End-to-End Pedigree Reconstruction Pipeline\\\\\", fontsize=14, pad=20)\\\n\\\n# Show the plot\\\nplt.tight_layout()\\\nplt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 1: Designing a Pipeline Class Structure\\\n\\\nIn this exercise, you'll design a class structure for a modular pedigree reconstruction pipeline using Bonsai v3 components.\\\n\\\n**Task:** Complete the skeleton of a `BonsaiPipeline` class that implements an end-to-end workflow with well-defined component interfaces.\\\n\\\n**Hint:** Focus on how data flows between pipeline stages and how configuration options are handled.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import Dict, List, Optional, Set, Tuple, Union, Any\\\nimport os\\\nimport logging\\\nimport time\\\n\\\nclass BonsaiPipeline:\\\n    \\\\\"\\\\\"\\\\\"End-to-end pedigree reconstruction pipeline using Bonsai v3.\\\\\"\\\\\"\\\\\"\\\n    \\\n    def __init__(self, config: Dict[str, Any] = None):\\\n        \\\\\"\\\\\"\\\\\"Initialize the pipeline with configuration options.\\\n        \\\n        Args:\\\n            config: Dictionary of configuration options, including:\\\n                - input_dir: Directory containing input data\\\n                - output_dir: Directory for output files\\\n                - min_segment_cm: Minimum IBD segment length in cM\\\n                - use_age_info: Whether to use age information in relationship inference\\\n                - clustering_method: Method for community detection\\\n                - confidence_threshold: Minimum confidence score for reported relationships\\\n                - max_pedigree_size: Maximum size of pedigrees to reconstruct\\\n        \\\\\"\\\\\"\\\\\"\\\n        self.config = config or {}\\\n        \\\n        # Set default configuration values\\\n        self.config.setdefault('input_dir', './input')\\\n        self.config.setdefault('output_dir', './output')\\\n        self.config.setdefault('min_segment_cm', 7.0)\\\n        self.config.setdefault('use_age_info', True)\\\n        self.config.setdefault('clustering_method', 'louvain')\\\n        self.config.setdefault('confidence_threshold', 0.8)\\\n        self.config.setdefault('max_pedigree_size', 100)\\\n        \\\n        # Create output directory if it doesn't exist\\\n        os.makedirs(self.config['output_dir'], exist_ok=True)\\\n        \\\n        # Initialize pipeline state\\\n        self.ibd_segments = []\\\n        self.demographic_data = {}\\\n        self.pairwise_relationships = {}\\\n        self.clusters = []\\\n        self.pedigrees = {}\\\n        self.confidence_scores = {}\\\n        \\\n        # Set up logging\\\n        self._setup_logging()\\\n        \\\n        self.logger.info(f\\\\\"Initialized BonsaiPipeline with configuration: {self.config}\\\\\")\\\n    \\\n    def _setup_logging(self):\\\n        \\\\\"\\\\\"\\\\\"Set up logging configuration.\\\\\"\\\\\"\\\\\"\\\n        # Create a logger\\\n        self.logger = logging.getLogger(\\\\\"BonsaiPipeline\\\\\")\\\n        self.logger.setLevel(logging.INFO)\\\n        \\\n        # Create a file handler\\\n        log_file = os.path.join(self.config['output_dir'], 'pipeline.log')\\\n        file_handler = logging.FileHandler(log_file, mode='w')\\\n        \\\n        # Create a console handler\\\n        console_handler = logging.StreamHandler()\\\n        \\\n        # Create a formatter and add it to the handlers\\\n        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\\\n        file_handler.setFormatter(formatter)\\\n        console_handler.setFormatter(formatter)\\\n        \\\n        # Add handlers to the logger\\\n        self.logger.addHandler(file_handler)\\\n        self.logger.addHandler(console_handler)\\\n    \\\n    def load_ibd_data(self, ibd_file: str, format: str = 'bonsai'):\\\n        \\\\\"\\\\\"\\\\\"Load IBD segment data from a file.\\\n        \\\n        Args:\\\n            ibd_file: Path to the IBD segment file\\\n            format: Format of the IBD segment file ('bonsai', 'ibis', 'hapibd', etc.)\\\n        \\\\\"\\\\\"\\\\\"\\\n        self.logger.info(f\\\\\"Loading IBD data from {ibd_file} in {format} format\\\\\")\\\n        \\\n        # TODO: Implement IBD data loading based on format\\\n        # You would use different loaders based on the format parameter\\\n        if format == 'bonsai':\\\n            # Direct loading of Bonsai format\\\n            # self.ibd_segments = load_bonsai_ibd_segments(ibd_file)\\\n            pass\\\n        elif format == 'ibis':\\\n            # Convert IBIS format to Bonsai format\\\n            # self.ibd_segments = convert_ibis_to_bonsai(ibd_file)\\\n            pass\\\n        elif format == 'hapibd':\\\n            # Convert hap-IBD format to Bonsai format\\\n            # self.ibd_segments = convert_hapibd_to_bonsai(ibd_file)\\\n            pass\\\n        else:\\\n            self.logger.error(f\\\\\"Unsupported IBD format: {format}\\\\\")\\\n            raise ValueError(f\\\\\"Unsupported IBD format: {format}\\\\\")\\\n        \\\n        # Apply filtering based on configuration\\\n        self._filter_ibd_segments()\\\n        \\\n        self.logger.info(f\\\\\"Loaded {len(self.ibd_segments)} IBD segments\\\\\")\\\n    \\\n    def _filter_ibd_segments(self):\\\n        \\\\\"\\\\\"\\\\\"Filter IBD segments based on configuration criteria.\\\\\"\\\\\"\\\\\"\\\n        if not self.ibd_segments:\\\n            return\\\n        \\\n        min_segment_cm = self.config['min_segment_cm']\\\n        self.logger.info(f\\\\\"Filtering segments by minimum length: {min_segment_cm} cM\\\\\")\\\n        \\\n        # Apply length filter\\\n        original_count = len(self.ibd_segments)\\\n        self.ibd_segments = [seg for seg in self.ibd_segments if seg[7] >= min_segment_cm]\\\n        \\\n        self.logger.info(f\\\\\"Filtered {original_count - len(self.ibd_segments)} segments below {min_segment_cm} cM\\\\\")\\\n    \\\n    def load_demographic_data(self, demographic_file: str):\\\n        \\\\\"\\\\\"\\\\\"Load demographic data (age, sex, etc.) from a file.\\\n        \\\n        Args:\\\n            demographic_file: Path to the demographic data file\\\n        \\\\\"\\\\\"\\\\\"\\\n        self.logger.info(f\\\\\"Loading demographic data from {demographic_file}\\\\\")\\\n        \\\n        # TODO: Implement demographic data loading\\\n        # This would typically read from a CSV file with columns like ID, Age, Sex, etc.\\\n        # Example:\\\n        # import pandas as pd\\\n        # df = pd.read_csv(demographic_file)\\\n        # self.demographic_data = {row['ID']: {'age': row['Age'], 'sex': row['Sex']} for _, row in df.iterrows()}\\\n        \\\n        self.logger.info(f\\\\\"Loaded demographic data for {len(self.demographic_data)} individuals\\\\\")\\\n    \\\n    def infer_pairwise_relationships(self):\\\n        \\\\\"\\\\\"\\\\\"Infer pairwise relationships between individuals based on IBD data.\\\\\"\\\\\"\\\\\"\\\n        self.logger.info(\\\\\"Inferring pairwise relationships\\\\\")\\\n        \\\n        # TODO: Implement relationship inference using Bonsai functions\\\n        # This would use functions from the likelihoods module to calculate\\\n        # log-likelihoods for different relationship hypotheses\\\n        # Example:\\\n        # from bonsaitree.v3 import likelihoods\\\n        # self.pairwise_relationships = calculate_all_pairwise_likelihoods(self.ibd_segments, self.demographic_data)\\\n        \\\n        self.logger.info(f\\\\\"Inferred relationships for {len(self.pairwise_relationships)} pairs\\\\\")\\\n    \\\n    def detect_communities(self):\\\n        \\\\\"\\\\\"\\\\\"Detect communities of related individuals.\\\\\"\\\\\"\\\\\"\\\n        self.logger.info(\\\\\"Detecting communities of related individuals\\\\\")\\\n        \\\n        # TODO: Implement community detection\\\n        # This would use network analysis to group individuals into related clusters\\\n        # Example:\\\n        # import networkx as nx\\\n        # G = create_relationship_graph(self.pairwise_relationships)\\\n        # self.clusters = detect_communities(G, method=self.config['clustering_method'])\\\n        \\\n        self.logger.info(f\\\\\"Detected {len(self.clusters)} communities\\\\\")\\\n    \\\n    def reconstruct_pedigrees(self):\\\n        \\\\\"\\\\\"\\\\\"Reconstruct pedigrees for each community.\\\\\"\\\\\"\\\\\"\\\n        self.logger.info(\\\\\"Reconstructing pedigrees\\\\\")\\\n        \\\n        # TODO: Implement pedigree reconstruction\\\n        # For each cluster, use Bonsai's pedigree reconstruction algorithms\\\n        # Example:\\\n        # from bonsaitree.v3 import bonsai\\\n        # for i, cluster in enumerate(self.clusters):\\\n        #     self.pedigrees[i] = bonsai.build_pedigree(\\\n        #         genotyped_ids=cluster,\\\n        #         ibd_segments=self.ibd_segments,\\\n        #         demographic_data=self.demographic_data\\\n        #     )\\\n        \\\n        self.logger.info(f\\\\\"Reconstructed {len(self.pedigrees)} pedigrees\\\\\")\\\n    \\\n    def assess_confidence(self):\\\n        \\\\\"\\\\\"\\\\\"Assess confidence in reconstructed relationships.\\\\\"\\\\\"\\\\\"\\\n        self.logger.info(\\\\\"Assessing confidence in reconstructed relationships\\\\\")\\\n        \\\n        # TODO: Implement confidence assessment\\\n        # Calculate confidence scores for each relationship in the pedigrees\\\n        # Example:\\\n        # from bonsaitree.v3 import confidence\\\n        # for ped_id, pedigree in self.pedigrees.items():\\\n        #     self.confidence_scores[ped_id] = calculate_confidence_scores(pedigree, self.ibd_segments)\\\n        \\\n        self.logger.info(\\\\\"Completed confidence assessment\\\\\")\\\n    \\\n    def visualize_results(self):\\\n        \\\\\"\\\\\"\\\\\"Visualize the reconstructed pedigrees.\\\\\"\\\\\"\\\\\"\\\n        self.logger.info(\\\\\"Visualizing pedigrees\\\\\")\\\n        \\\n        # TODO: Implement pedigree visualization\\\n        # Render pedigrees using Graphviz or NetworkX\\\n        # Example:\\\n        # from bonsaitree.v3 import rendering\\\n        # for ped_id, pedigree in self.pedigrees.items():\\\n        #     output_file = os.path.join(self.config['output_dir'], f\\\\\"pedigree_{ped_id}.png\\\\\")\\\n        #     rendering.render_pedigree(pedigree, output_file, confidence_scores=self.confidence_scores.get(ped_id))\\\n        \\\n        self.logger.info(\\\\\"Completed pedigree visualization\\\\\")\\\n    \\\n    def generate_reports(self):\\\n        \\\\\"\\\\\"\\\\\"Generate summary reports and detailed relationship information.\\\\\"\\\\\"\\\\\"\\\n        self.logger.info(\\\\\"Generating reports\\\\\")\\\n        \\\n        # TODO: Implement report generation\\\n        # Create summary statistics and detailed relationship reports\\\n        # Example:\\\n        # summary_file = os.path.join(self.config['output_dir'], \\\\\"summary.csv\\\\\")\\\n        # detailed_file = os.path.join(self.config['output_dir'], \\\\\"detailed_relationships.csv\\\\\")\\\n        # write_summary_report(self.pedigrees, self.confidence_scores, summary_file)\\\n        # write_detailed_report(self.pedigrees, self.confidence_scores, detailed_file)\\\n        \\\n        self.logger.info(\\\\\"Completed report generation\\\\\")\\\n    \\\n    def run_pipeline(self, ibd_file: str, demographic_file: Optional[str] = None):\\\n        \\\\\"\\\\\"\\\\\"Run the complete pipeline from data loading to visualization.\\\n        \\\n        Args:\\\n            ibd_file: Path to the IBD segment file\\\n            demographic_file: Path to the demographic data file (optional)\\\n        \\\\\"\\\\\"\\\\\"\\\n        self.logger.info(\\\\\"Starting pipeline execution\\\\\")\\\n        start_time = time.time()\\\n        \\\n        # Step 1: Load IBD data\\\n        self.load_ibd_data(ibd_file)\\\n        \\\n        # Step 2: Load demographic data if provided\\\n        if demographic_file:\\\n            self.load_demographic_data(demographic_file)\\\n        \\\n        # Step 3: Infer pairwise relationships\\\n        self.infer_pairwise_relationships()\\\n        \\\n        # Step 4: Detect communities\\\n        self.detect_communities()\\\n        \\\n        # Step 5: Reconstruct pedigrees\\\n        self.reconstruct_pedigrees()\\\n        \\\n        # Step 6: Assess confidence\\\n        self.assess_confidence()\\\n        \\\n        # Step 7: Visualize results\\\n        self.visualize_results()\\\n        \\\n        # Step 8: Generate reports\\\n        self.generate_reports()\\\n        \\\n        elapsed_time = time.time() - start_time\\\n        self.logger.info(f\\\\\"Pipeline completed in {elapsed_time:.2f} seconds\\\\\")\\\n        \\\n        return {\\\n            \\\\\"pedigrees\\\\\": self.pedigrees,\\\n            \\\\\"confidence_scores\\\\\": self.confidence_scores,\\\n            \\\\\"execution_time\\\\\": elapsed_time\\\n        }\\\n\\\n# Example usage\\\nif __name__ == \\\\\"__main__\\\\\":\\\n    # Create a pipeline with custom configuration\\\n    pipeline = BonsaiPipeline({\\\n        'input_dir': './data',\\\n        'output_dir': './results',\\\n        'min_segment_cm': 7.0,\\\n        'use_age_info': True,\\\n        'clustering_method': 'louvain',\\\n        'confidence_threshold': 0.8,\\\n        'max_pedigree_size': 100\\\n    })\\\n    \\\n    # Run the pipeline\\\n    results = pipeline.run_pipeline(\\\n        ibd_file='./data/ibd_segments.csv',\\\n        demographic_file='./data/demographics.csv'\\\n    )\\\n    \\\n    print(f\\\\\"Reconstructed {len(results['pedigrees'])} pedigrees\\\\\")\\\n    print(f\\\\\"Pipeline execution time: {results['execution_time']:.2f} seconds\\\\\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Part 2: IBD Processing and Relationship Inference\\\n\\\n### Theory and Background\\\n\\\nIBD (Identity-By-Descent) segments form the foundational data for genetic pedigree reconstruction. These segments represent regions of the genome that two individuals have inherited from a common ancestor. Properly processing and analyzing IBD segments is critical for accurate relationship inference.\\\n\\\nIn an end-to-end pipeline, the IBD processing stage typically involves:\\\n\\\n1. **Format Standardization**: Converting tool-specific IBD formats to a common representation\\\n2. **Quality Filtering**: Removing low-quality or unreliable segments\\\n3. **Segment Merging**: Combining adjacent or overlapping segments when appropriate\\\n4. **IBD Statistics Calculation**: Computing summary statistics like total IBD sharing\\\n\\\nOnce IBD segments are processed, the next step is pairwise relationship inference, which:\\\n\\\n1. **Computes Likelihoods**: Calculates how likely different relationship types are given the observed IBD\\\n2. **Incorporates Demographic Data**: Uses age and sex information to refine predictions\\\n3. **Ranks Hypotheses**: Orders possible relationships by their likelihood\\\n4. **Provides Confidence Scores**: Quantifies certainty in the inferred relationships",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Implementation in Bonsai v3\\\n\\\nLet's examine how Bonsai v3 implements IBD processing and pairwise relationship inference. We'll look at key functions that our pipeline can leverage for these stages.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Explore the IBD module which handles segment processing\\\ntry:\\\n    explore_module(\\\\\"bonsaitree.v3.ibd\\\\\")\\\nexcept Exception as e:\\\n    print(f\\\\\"Error exploring IBD module: {e}\\\\\")\\\n    print(\\\\\"Will continue with a theoretical discussion of IBD processing.\\\\\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Explore the likelihoods module which handles relationship inference\\\ntry:\\\n    explore_module(\\\\\"bonsaitree.v3.likelihoods\\\\\")\\\nexcept Exception as e:\\\n    print(f\\\\\"Error exploring likelihoods module: {e}\\\\\")\\\n    print(\\\\\"Will continue with a theoretical discussion of relationship inference.\\\\\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Implementing IBD Processing\\\n\\\nNow let's implement the IBD processing components for our pipeline. This includes loading IBD segments from various formats, filtering, and merging.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def load_ibd_segments(file_path, format='bonsai'):\\\n    \\\\\"\\\\\"\\\\\"Load IBD segments from a file in the specified format.\\\n    \\\n    Args:\\\n        file_path: Path to the IBD segment file\\\n        format: Format of the file ('bonsai', 'ibis', 'hapibd', etc.)\\\n        \\\n    Returns:\\\n        List of IBD segments in Bonsai format:\\\n        [id1, id2, hap1, hap2, chromosome, start_pos, end_pos, length_cM]\\\n    \\\\\"\\\\\"\\\\\"\\\n    print(f\\\\\"Loading IBD segments from {file_path} in {format} format\\\\\")\\\n    \\\n    # We'll simulate loading data for demonstration purposes\\\n    # In a real implementation, this would read from a file\\\n    \\\n    # Create some sample IBD segments \\\n    import random\\\n    sample_ids = [f\\\\\"sample_{i:03d}\\\\\" for i in range(1, 21)]\\\n    segments = []\\\n    \\\n    # Generate random segments between samples\\\n    for _ in range(100):\\\n        id1, id2 = random.sample(sample_ids, 2)\\\n        \\\n        # Phased or unphased based on format\\\n        if format in ['hapibd', 'refinedibd']:\\\n            hap1, hap2 = random.randint(0, 1), random.randint(0, 1)\\\n        else:\\\n            hap1, hap2 = -1, -1\\\n            \\\n        chrom = random.randint(1, 22)\\\n        start_pos = random.randint(1000000, 200000000)\\\n        end_pos = start_pos + random.randint(1000000, 20000000)\\\n        \\\n        # Generate segment length in cM (typically 1-20 cM)\\\n        length_cm = random.uniform(1.0, 30.0)\\\n        \\\n        segment = [id1, id2, hap1, hap2, chrom, start_pos, end_pos, length_cm]\\\n        segments.append(segment)\\\n    \\\n    print(f\\\\\"Loaded {len(segments)} IBD segments\\\\\")\\\n    return segments\\\n\\\ndef filter_ibd_segments(segments, min_length=7.0, min_snps=None, max_gap=None):\\\n    \\\\\"\\\\\"\\\\\"Filter IBD segments based on quality criteria.\\\n    \\\n    Args:\\\n        segments: List of IBD segments in Bonsai format\\\n        min_length: Minimum segment length in cM\\\n        min_snps: Minimum number of SNPs in a segment (optional)\\\n        max_gap: Maximum gap between adjacent segments to be considered separate (optional)\\\n        \\\n    Returns:\\\n        Filtered list of IBD segments\\\n    \\\\\"\\\\\"\\\\\"\\\n    print(f\\\\\"Filtering IBD segments: min_length={min_length} cM\\\\\")\\\n    \\\n    # Apply length filter\\\n    filtered_segments = [seg for seg in segments if seg[7] >= min_length]\\\n    \\\n    print(f\\\\\"Filtered out {len(segments) - len(filtered_segments)} segments below length threshold\\\\\")\\\n    return filtered_segments\\\n\\\ndef merge_adjacent_segments(segments, max_gap=2.0, phase_sensitive=True):\\\n    \\\\\"\\\\\"\\\\\"Merge adjacent or overlapping IBD segments between the same pair of individuals.\\\n    \\\n    Args:\\\n        segments: List of IBD segments in Bonsai format\\\n        max_gap: Maximum gap in cM between segments to be merged\\\n        phase_sensitive: If True, only merge segments on the same haplotypes\\\n        \\\n    Returns:\\\n        List of merged IBD segments\\\n    \\\\\"\\\\\"\\\\\"\\\n    print(f\\\\\"Merging adjacent segments: max_gap={max_gap} cM, phase_sensitive={phase_sensitive}\\\\\")\\\n    \\\n    # Group segments by individual pair, chromosome, and haplotypes if phase_sensitive\\\n    segment_groups = {}\\\n    \\\n    for segment in segments:\\\n        id1, id2, hap1, hap2, chrom, start, end, length = segment\\\n        \\\n        # Ensure consistent ordering of IDs\\\n        if id1 > id2:\\\n            id1, id2 = id2, id1\\\n            hap1, hap2 = hap2, hap1\\\n        \\\n        # Create a key that includes haplotype information if phase_sensitive\\\n        if phase_sensitive and hap1 >= 0 and hap2 >= 0:\\\n            key = (id1, id2, chrom, hap1, hap2)\\\n        else:\\\n            key = (id1, id2, chrom)\\\n        \\\n        if key not in segment_groups:\\\n            segment_groups[key] = []\\\n        \\\n        segment_groups[key].append(segment)\\\n    \\\n    # Process each group to merge adjacent segments\\\n    merged_segments = []\\\n    \\\n    for key, group in segment_groups.items():\\\n        # Sort segments by start position\\\n        sorted_segments = sorted(group, key=lambda x: x[5])\\\n        \\\n        # Initialize with the first segment\\\n        if not sorted_segments:\\\n            continue\\\n        \\\n        current = list(sorted_segments[0])  # Make a copy that we can modify\\\n        \\\n        for segment in sorted_segments[1:]:\\\n            # Check if this segment is adjacent to the current one\\\n            if segment[5] <= current[6] + max_gap:  # start <= current_end + max_gap\\\n                # Merge by extending the end position and length\\\n                if segment[6] > current[6]:  # if new_end > current_end\\\n                    overlap = max(0, current[6] - segment[5])  # Calculate overlap\\\n                    current[6] = segment[6]  # Update end position\\\n                    current[7] = current[7] + segment[7] - overlap  # Update length accounting for overlap\\\n            else:\\\n                # Not adjacent, so add the current segment and start a new one\\\n                merged_segments.append(tuple(current))  # Convert to tuple for immutability\\\n                current = list(segment)  # Start a new current segment\\\n        \\\n        # Add the last segment in the group\\\n        merged_segments.append(tuple(current))\\\n    \\\n    print(f\\\\\"Merged {len(segments) - len(merged_segments)} segments\\\\\")\\\n    return merged_segments\\\n\\\ndef calculate_ibd_statistics(segments):\\\n    \\\\\"\\\\\"\\\\\"Calculate summary statistics for IBD segments.\\\n    \\\n    Args:\\\n        segments: List of IBD segments in Bonsai format\\\n        \\\n    Returns:\\\n        Dictionary mapping pairs of individuals to their IBD statistics\\\n    \\\\\"\\\\\"\\\\\"\\\n    print(\\\\\"Calculating IBD statistics for all pairs\\\\\")\\\n    \\\n    # Initialize statistics dictionary\\\n    pair_stats = {}\\\n    \\\n    for segment in segments:\\\n        id1, id2, hap1, hap2, chrom, start, end, length = segment\\\n        \\\n        # Ensure consistent ordering of IDs\\\n        if id1 > id2:\\\n            id1, id2 = id2, id1\\\n        \\\n        pair = (id1, id2)\\\n        \\\n        # Initialize stats for this pair if needed\\\n        if pair not in pair_stats:\\\n            pair_stats[pair] = {\\\n                'total_ibd': 0.0,\\\n                'segment_count': 0,\\\n                'max_segment': 0.0,\\\n                'chromosomes': set()\\\n            }\\\n        \\\n        # Update statistics\\\n        pair_stats[pair]['total_ibd'] += length\\\n        pair_stats[pair]['segment_count'] += 1\\\n        pair_stats[pair]['max_segment'] = max(pair_stats[pair]['max_segment'], length)\\\n        pair_stats[pair]['chromosomes'].add(chrom)\\\n    \\\n    print(f\\\\\"Calculated statistics for {len(pair_stats)} pairs\\\\\")\\\n    return pair_stats\\\n\\\n# Demonstrate the IBD processing pipeline\\\ndef demonstrate_ibd_processing():\\\n    # 1. Load IBD segments\\\n    segments = load_ibd_segments('simulated_data.csv', format='ibis')\\\n    \\\n    # 2. Filter segments\\\n    filtered_segments = filter_ibd_segments(segments, min_length=7.0)\\\n    \\\n    # 3. Merge adjacent segments\\\n    merged_segments = merge_adjacent_segments(filtered_segments, max_gap=2.0, phase_sensitive=False)\\\n    \\\n    # 4. Calculate IBD statistics\\\n    pair_stats = calculate_ibd_statistics(merged_segments)\\\n    \\\n    # Display summary of results\\\n    print(\\\\\"\\\\\\\nSummary of IBD Processing:\\\\\")\\\n    print(f\\\\\"  Original segments: {len(segments)}\\\\\")\\\n    print(f\\\\\"  After filtering: {len(filtered_segments)}\\\\\")\\\n    print(f\\\\\"  After merging: {len(merged_segments)}\\\\\")\\\n    print(f\\\\\"  Number of related pairs: {len(pair_stats)}\\\\\")\\\n    \\\n    # Calculate distribution of total IBD\\\n    if pair_stats:\\\n        total_ibd_values = [stats['total_ibd'] for stats in pair_stats.values()]\\\n        total_ibd_values.sort()\\\n        \\\n        print(\\\\\"\\\\\\\nDistribution of Total IBD (cM):\\\\\")\\\n        print(f\\\\\"  Minimum: {min(total_ibd_values):.2f} cM\\\\\")\\\n        print(f\\\\\"  Maximum: {max(total_ibd_values):.2f} cM\\\\\")\\\n        print(f\\\\\"  Median: {total_ibd_values[len(total_ibd_values)//2]:.2f} cM\\\\\")\\\n        print(f\\\\\"  Mean: {sum(total_ibd_values)/len(total_ibd_values):.2f} cM\\\\\")\\\n        \\\n        # Plot distribution of total IBD\\\n        plt.figure(figsize=(10, 6))\\\n        plt.hist(total_ibd_values, bins=20, alpha=0.7, color='steelblue')\\\n        plt.xlabel('Total IBD (cM)')\\\n        plt.ylabel('Number of Pairs')\\\n        plt.title('Distribution of Total IBD Sharing Between Pairs')\\\n        plt.grid(alpha=0.3)\\\n        plt.show()\\\n        \\\n        # Return for further analysis\\\n        return segments, filtered_segments, merged_segments, pair_stats\\\n    \\\n    return segments, filtered_segments, merged_segments, pair_stats\\\n\\\n# Run the demonstration\\\nibd_segments, filtered_segments, merged_segments, pair_stats = demonstrate_ibd_processing()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Implementing Relationship Inference\\\n\\\nNow let's implement the relationship inference component of our pipeline. This involves calculating likelihoods for different relationship hypotheses based on the processed IBD data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def load_demographic_data(file_path):\n    \"\"\"Load demographic data (age, sex, etc.) from a file.\n    \n    Args:\n        file_path: Path to the demographic data file\n        \n    Returns:\n        Dictionary mapping individual IDs to demographic information\n    \"\"\"\n    print(f\"Loading demographic data from {file_path}\")\n    \n    # We'll simulate loading data for demonstration purposes\n    # In a real implementation, this would read from a CSV file\n    \n    # Create some sample demographic data\n    import random\n    \n    # Get list of all individuals from the IBD segments\n    all_individuals = set()\n    for segment in merged_segments:\n        all_individuals.add(segment[0])\n        all_individuals.add(segment[1])\n    \n    demographic_data = {}\n    for individual in all_individuals:\n        demographic_data[individual] = {\n            'age': random.randint(18, 80),\n            'sex': random.choice(['M', 'F']),\n            'birth_year': random.randint(1940, 2002),\n            'population': random.choice(['EUR', 'AFR', 'EAS', 'SAS', 'AMR'])\n        }\n    \n    print(f\"Loaded demographic data for {len(demographic_data)} individuals\")\n    return demographic_data\n\ndef estimate_degree_by_ibd(total_ibd):\n    \"\"\"Estimate the relationship degree based on total IBD sharing.\n    \n    Args:\n        total_ibd: Total IBD sharing in cM\n        \n    Returns:\n        estimated_degree: Estimated relationship degree\n        relationship_type: Most likely relationship type\n        confidence: Confidence in the estimate (high, medium, low)\n    \"\"\"\n    # Define thresholds for different degrees\n    # These are simplified thresholds based on average sharing\n    thresholds = [\n        (2800, 0, \"Self\"),                  # > 2800 cM: Self\n        (2250, 0.5, \"Identical twin\"),      # > 2250 cM: Identical twin\n        (1450, 1, \"Parent-child\"),          # > 1450 cM: Parent-child\n        (1300, 1, \"Full sibling\"),          # > 1300 cM: Full sibling\n        (650, 2, \"Half sibling/Grandparent\"),  # > 650 cM: Half sibling/Grandparent/Avuncular\n        (325, 3, \"First cousin\"),           # > 325 cM: First cousin\n        (160, 4, \"First cousin once removed\"),  # > 160 cM: First cousin once removed\n        (80, 5, \"Second cousin\"),            # > 80 cM: Second cousin\n        (40, 6, \"Second cousin once removed\"),  # > 40 cM: Second cousin once removed\n        (20, 7, \"Third cousin\"),             # > 20 cM: Third cousin\n        (0, 8, \"Distant relation\")           # Any IBD: Distant relation\n    ]\n    \n    # Find the appropriate threshold\n    for threshold, degree, relationship in thresholds:\n        if total_ibd >= threshold:\n            # Calculate confidence based on distance from threshold boundaries\n            if degree < len(thresholds) - 1:\n                next_threshold = thresholds[degree + 1][0]\n                if total_ibd > (threshold + next_threshold) / 2:\n                    confidence = \"high\"\n                elif total_ibd > threshold * 0.8:\n                    confidence = \"medium\"\n                else:\n                    confidence = \"low\"\n            else:\n                confidence = \"medium\"\n                \n            return degree, relationship, confidence\n    \n    # If we get here, there's no IBD sharing\n    return None, \"Unrelated\", \"high\"\n\ndef refine_with_demographic_data(pair, degree, relationship, demographic_data):\n    \"\"\"Refine relationship estimate using demographic data.\n    \n    Args:\n        pair: Tuple of (id1, id2)\n        degree: Estimated relationship degree\n        relationship: Estimated relationship type\n        demographic_data: Dictionary of demographic information\n        \n    Returns:\n        refined_relationship: Refined relationship type\n        rationale: Explanation for the refinement\n    \"\"\"\n    id1, id2 = pair\n    \n    # Make sure we have demographic data for both individuals\n    if id1 not in demographic_data or id2 not in demographic_data:\n        return relationship, \"No demographic data available\"\n    \n    demo1 = demographic_data[id1]\n    demo2 = demographic_data[id2]\n    \n    # Calculate age difference\n    age_diff = abs(demo1['age'] - demo2['age'])\n    \n    # Apply demographic constraints to refine relationship type\n    if degree == 1:\n        # Parent-child vs full sibling\n        if age_diff > 15:  # Assume parent-child relationship if age difference > 15\n            if demo1['age'] > demo2['age']:\n                return \"Parent-child (1\u21922)\", f\"Age difference of {age_diff} years suggests parent-child\"\n            else:\n                return \"Parent-child (2\u21921)\", f\"Age difference of {age_diff} years suggests parent-child\"\n        else:\n            return \"Full sibling\", f\"Age difference of {age_diff} years suggests siblings\"\n    \n    elif degree == 2:\n        # Half sibling vs grandparent vs avuncular\n        if age_diff > 40:  # Large age difference suggests grandparent\n            if demo1['age'] > demo2['age']:\n                return \"Grandparent (1\u21922)\", f\"Age difference of {age_diff} years suggests grandparent\"\n            else:\n                return \"Grandparent (2\u21921)\", f\"Age difference of {age_diff} years suggests grandparent\"\n        elif age_diff > 15:  # Moderate age difference suggests avuncular\n            return \"Avuncular\", f\"Age difference of {age_diff} years suggests avuncular\"\n        else:  # Small age difference suggests half sibling\n            return \"Half sibling\", f\"Age difference of {age_diff} years suggests half siblings\"\n    \n    # For more distant relationships, we keep the estimate based on IBD\n    return relationship, \"Based on IBD sharing alone\"\n\ndef infer_pairwise_relationships(ibd_stats, demographic_data=None):\n    \"\"\"Infer pairwise relationships based on IBD statistics and demographic data.\n    \n    Args:\n        ibd_stats: Dictionary mapping pairs to IBD statistics\n        demographic_data: Dictionary of demographic information (optional)\n        \n    Returns:\n        Dictionary mapping pairs to inferred relationships\n    \"\"\"\n    print(\"Inferring pairwise relationships\")\n    \n    # Initialize relationships dictionary\n    relationships = {}\n    \n    for pair, stats in ibd_stats.items():\n        # Estimate degree based on total IBD\n        total_ibd = stats['total_ibd']\n        degree, relationship, confidence = estimate_degree_by_ibd(total_ibd)\n        \n        # Skip unrelated pairs (no degree)\n        if degree is None:\n            continue\n        \n        # Refine with demographic data if available\n        if demographic_data:\n            refined_relationship, rationale = refine_with_demographic_data(\n                pair, degree, relationship, demographic_data)\n        else:\n            refined_relationship = relationship\n            rationale = \"Based on IBD sharing alone\"\n        \n        # Store the inferred relationship\n        relationships[pair] = {\n            'degree': degree,\n            'relationship': refined_relationship,\n            'confidence': confidence,\n            'total_ibd': total_ibd,\n            'segment_count': stats['segment_count'],\n            'max_segment': stats['max_segment'],\n            'chromosome_count': len(stats['chromosomes']),\n            'rationale': rationale\n        }\n    \n    print(f\"Inferred {len(relationships)} relationships\")\n    return relationships\n\n# Demonstrate relationship inference\ndef demonstrate_relationship_inference():\n    # Load demographic data\n    demographic_data = load_demographic_data('simulated_demographics.csv')\n    \n    # Infer relationships using IBD statistics and demographic data\n    relationships = infer_pairwise_relationships(pair_stats, demographic_data)\n    \n    # Analyze the distribution of relationship degrees\n    degree_counts = {}\n    for rel_info in relationships.values():\n        degree = rel_info['degree']\n        degree_counts[degree] = degree_counts.get(degree, 0) + 1\n    \n    # Display summary of relationship inference\n    print(\"\\\nSummary of Relationship Inference:\")\n    print(f\"  Total pairs analyzed: {len(pair_stats)}\")\n    print(f\"  Relationships inferred: {len(relationships)}\")\n    \n    print(\"\\\nRelationship Degree Distribution:\")\n    for degree in sorted(degree_counts.keys()):\n        print(f\"  Degree {degree}: {degree_counts[degree]} pairs\")\n    \n    # Create a visualization of relationship degrees\n    degrees = sorted(degree_counts.keys())\n    counts = [degree_counts[d] for d in degrees]\n    \n    plt.figure(figsize=(10, 6))\n    bars = plt.bar(degrees, counts, color='steelblue', alpha=0.7)\n    \n    # Add count labels above bars\n    for bar in bars:\n        height = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n                f'{int(height)}', ha='center', va='bottom')\n    \n    plt.xlabel('Relationship Degree')\n    plt.ylabel('Number of Pairs')\n    plt.title('Distribution of Inferred Relationship Degrees')\n    plt.xticks(degrees)\n    plt.grid(axis='y', alpha=0.3)\n    plt.tight_layout()\n    plt.show()\n    \n    # Display examples of each relationship type\n    print(\"\\\nExamples of Inferred Relationships:\")\n    examples = {}\n    for pair, rel_info in relationships.items():\n        relationship = rel_info['relationship']\n        # Only show one example of each relationship type\n        if relationship not in examples:\n            examples[relationship] = (pair, rel_info)\n    \n    for relationship, (pair, rel_info) in examples.items():\n        print(f\"  {pair[0]} and {pair[1]}: {relationship} (Degree {rel_info['degree']}, {rel_info['confidence']} confidence)\")\n        print(f\"    Total IBD: {rel_info['total_ibd']:.2f} cM in {rel_info['segment_count']} segments\")\n        print(f\"    Rationale: {rel_info['rationale']}\")\n        print()\n    \n    return demographic_data, relationships\n\n# Run the demonstration\ndemographic_data, pairwise_relationships = demonstrate_relationship_inference()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Part 3: Pedigree Construction and Community Detection\n\n### Theory and Background\n\nAfter inferring pairwise relationships, the next step in a pedigree reconstruction pipeline is to organize individuals into coherent family structures. This process involves two key components:\n\n1. **Community Detection**: Identifying clusters of related individuals\n2. **Pedigree Construction**: Assembling individuals into biologically valid pedigree structures\n\n#### Community Detection\n\nFor large datasets with many individuals, it's often beneficial to first partition the data into smaller clusters of related individuals. This serves several purposes:\n\n- Reduces computational complexity by breaking the problem into manageable subproblems\n- Ensures that reconstructed pedigrees represent truly related individuals\n- Allows parallelization of the pedigree reconstruction process\n- Makes the final output more interpretable\n\nCommunity detection algorithms from network science are well-suited for this task. We can represent individuals as nodes in a graph, with edges representing inferred relationships. The strength of each edge can be based on the degree of relationship or IBD sharing amount.\n\nPopular community detection algorithms include:\n- **Louvain Method**: Maximizes modularity through iterative node reassignment and community merging\n- **Label Propagation**: Spreads community labels based on neighborhood majority\n- **Spectral Clustering**: Uses eigenvalues of the graph Laplacian matrix to identify communities\n- **Hierarchical Clustering**: Builds a dendrogram of relationships and cuts at an appropriate level\n\n#### Pedigree Construction\n\nOnce we have identified communities of related individuals, we can reconstruct pedigrees within each community. This process involves:\n\n1. **Identifying Key Relationships**: Parent-child and sibling relationships form the core structure\n2. **Placing Ungenotyped Ancestors**: Adding ancestors not in the dataset to connect individuals\n3. **Resolving Ambiguities**: Handling cases where multiple pedigree configurations are possible\n4. **Optimizing the Structure**: Finding the pedigree that best explains the observed IBD sharing\n\nBonsai v3 employs several algorithms for pedigree construction:\n- **Bottom-up Construction**: Starting with close relationships and building upward\n- **Template Matching**: Identifying common family structures\n- **Constrained Optimization**: Finding the best pedigree given pairwise constraints\n- **Incremental Building**: Adding individuals one by one to an existing structure",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Implementation of Community Detection\n\nLet's implement community detection to identify clusters of related individuals based on our pairwise relationship data. We'll use the NetworkX library for graph analysis and community detection algorithms.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def build_relationship_graph(relationships):\n    \"\"\"Build a relationship graph from pairwise relationship data.\n    \n    Args:\n        relationships: Dictionary mapping pairs to relationship information\n        \n    Returns:\n        NetworkX Graph object representing the relationship network\n    \"\"\"\n    import networkx as nx\n    \n    # Create a new undirected graph\n    G = nx.Graph()\n    \n    # Add edges with relationship attributes\n    for pair, rel_info in relationships.items():\n        id1, id2 = pair\n        \n        # Add nodes if they don't exist\n        if id1 not in G:\n            G.add_node(id1)\n        if id2 not in G:\n            G.add_node(id2)\n        \n        # Add edge with relationship attributes\n        # Weight is inversely proportional to degree (closer relationships have higher weight)\n        degree = rel_info['degree']\n        weight = 1.0 / (degree + 0.1)  # Add 0.1 to avoid division by zero\n        \n        G.add_edge(id1, id2, \n                  degree=degree,\n                  relationship=rel_info['relationship'],\n                  confidence=rel_info['confidence'],\n                  total_ibd=rel_info['total_ibd'],\n                  weight=weight)  # Weight for community detection\n    \n    print(f\"Created relationship graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n    return G\n\ndef detect_communities(G, method='louvain', resolution=1.0, min_degree=7):\n    \"\"\"Detect communities of related individuals in the relationship graph.\n    \n    Args:\n        G: NetworkX Graph object representing the relationship network\n        method: Community detection algorithm to use ('louvain', 'label_propagation', 'hierarchical')\n        resolution: Resolution parameter for Louvain method (higher values create more communities)\n        min_degree: Maximum relationship degree to include (e.g., 3 = include up to first cousins)\n        \n    Returns:\n        List of communities, where each community is a set of individual IDs\n    \"\"\"\n    import networkx as nx\n    \n    # Create a filtered graph with only relationships up to min_degree\n    filtered_G = nx.Graph()\n    \n    for u, v, data in G.edges(data=True):\n        if data['degree'] <= min_degree:\n            filtered_G.add_edge(u, v, **data)\n    \n    print(f\"Filtered graph has {filtered_G.number_of_nodes()} nodes and {filtered_G.number_of_edges()} edges\")\n    \n    # Detect communities using the specified method\n    if method == 'louvain':\n        try:\n            # Try to use the community module if available\n            from community import best_partition\n            \n            # Get the partition\n            partition = best_partition(filtered_G, weight='weight', resolution=resolution)\n            \n            # Convert the partition to a list of communities\n            communities = {}\n            for node, community_id in partition.items():\n                if community_id not in communities:\n                    communities[community_id] = set()\n                communities[community_id].add(node)\n            \n            communities_list = list(communities.values())\n            \n        except ImportError:\n            print(\"Warning: python-louvain module not available, using networkx_community instead\")\n            import networkx.algorithms.community as nx_comm\n            \n            # Use Louvain method from NetworkX\n            communities_list = list(nx_comm.louvain_communities(filtered_G, weight='weight', resolution=resolution))\n    \n    elif method == 'label_propagation':\n        import networkx.algorithms.community as nx_comm\n        communities_list = list(nx_comm.label_propagation_communities(filtered_G))\n    \n    elif method == 'hierarchical':\n        import networkx.algorithms.community as nx_comm\n        communities_list = list(nx_comm.asyn_fluidc(filtered_G, k=10, max_iter=100))\n    \n    else:\n        raise ValueError(f\"Unknown community detection method: {method}\")\n    \n    # Sort communities by size (largest first)\n    communities_list.sort(key=len, reverse=True)\n    \n    print(f\"Detected {len(communities_list)} communities\")\n    \n    # Print information about each community\n    for i, community in enumerate(communities_list):\n        print(f\"  Community {i+1}: {len(community)} members\")\n    \n    return communities_list\n\n# Demonstrate community detection using the pairwise relationships\ndef demonstrate_community_detection():\n    # Build the relationship graph\n    G = build_relationship_graph(pairwise_relationships)\n    \n    # Detect communities\n    communities = detect_communities(G, method='louvain', min_degree=5)\n    \n    # Visualize the relationship graph with community colors\n    plt.figure(figsize=(12, 10))\n    pos = nx.spring_layout(G, seed=42)  # Layout algorithm\n    \n    # Create a mapping from nodes to community index\n    community_map = {}\n    for i, community in enumerate(communities):\n        for node in community:\n            community_map[node] = i\n    \n    # Create a color map based on community membership\n    colors = plt.cm.tab20(range(min(20, len(communities))))\n    node_colors = [colors[community_map.get(node, 0) % len(colors)] for node in G.nodes()]\n    \n    # Draw nodes (sized by degree centrality)\n    node_size = dict(nx.degree_centrality(G))\n    node_sizes = [300 * node_size.get(node, 0.1) + 50 for node in G.nodes()]\n    \n    # Draw the network\n    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8)\n    \n    # Draw edges with varying width based on relationship closeness\n    edge_weights = [G[u][v]['weight'] * 3 for u, v in G.edges()]\n    nx.draw_networkx_edges(G, pos, width=edge_weights, alpha=0.3, edge_color='gray')\n    \n    # Draw labels for larger communities\n    nx.draw_networkx_labels(G, pos, font_size=8, font_color='black', alpha=0.7)\n    \n    plt.title(\"Relationship Network with Detected Communities\")\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n    \n    # Print details about the largest communities\n    print(\"\\\nLargest Communities and Their Key Relationships:\")\n    for i, community in enumerate(communities[:5]):  # Show top 5 communities\n        if len(community) <= 2:  # Skip very small communities\n            continue\n            \n        print(f\"\\\nCommunity {i+1}: {len(community)} members\")\n        print(\"  Members: \" + \", \".join(list(community)[:10]) + \n              (\"...\" if len(community) > 10 else \"\"))\n        \n        # Find all relationships within this community\n        community_relationships = {}\n        for pair, rel_info in pairwise_relationships.items():\n            id1, id2 = pair\n            if id1 in community and id2 in community:\n                community_relationships[pair] = rel_info\n        \n        # Sort by relationship degree (closest first)\n        sorted_rels = sorted(community_relationships.items(), key=lambda x: x[1]['degree'])\n        \n        # Print the closest relationships in this community\n        print(\"  Key relationships:\")\n        for pair, rel_info in sorted_rels[:5]:  # Show top 5 relationships\n            print(f\"    {pair[0]} and {pair[1]}: {rel_info['relationship']} \" + \n                  f\"(Degree {rel_info['degree']}, Total IBD: {rel_info['total_ibd']:.2f} cM)\")\n    \n    return G, communities\n\n# Run the demonstration\nrelationship_graph, detected_communities = demonstrate_community_detection()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Implementation of Pedigree Construction\n\nNow that we've identified communities of related individuals, let's implement pedigree construction algorithms to build family trees within each community.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class Pedigree:\n    \"\"\"A class representing a pedigree (family tree) structure.\"\"\"\n    \n    def __init__(self, name=\"Untitled Pedigree\"):\n        \"\"\"Initialize an empty pedigree.\n        \n        Args:\n            name: Name of the pedigree\n        \"\"\"\n        self.name = name\n        self.individuals = {}  # id -> individual data\n        self.relationships = {}  # (id1, id2) -> relationship\n        self.parents = {}  # id -> (mother_id, father_id)\n        self.children = {}  # id -> set of child_ids\n        self.confidence_scores = {}  # (id1, id2) -> confidence score\n        \n    def add_individual(self, individual_id, **attributes):\n        \"\"\"Add an individual to the pedigree.\n        \n        Args:\n            individual_id: Unique identifier for the individual\n            **attributes: Additional attributes (e.g., age, sex, birth_year)\n        \"\"\"\n        self.individuals[individual_id] = attributes\n        self.children[individual_id] = set()\n        \n    def add_relationship(self, id1, id2, relationship_type, confidence=None):\n        \"\"\"Add a relationship between two individuals.\n        \n        Args:\n            id1: ID of the first individual\n            id2: ID of the second individual\n            relationship_type: Type of relationship\n            confidence: Confidence score for this relationship\n        \"\"\"\n        # Ensure the individuals exist in the pedigree\n        if id1 not in self.individuals:\n            raise ValueError(f\"Individual {id1} does not exist in the pedigree\")\n        if id2 not in self.individuals:\n            raise ValueError(f\"Individual {id2} does not exist in the pedigree\")\n            \n        # Store the relationship\n        self.relationships[(id1, id2)] = relationship_type\n        \n        # Store the confidence score if provided\n        if confidence is not None:\n            self.confidence_scores[(id1, id2)] = confidence\n            \n    def set_parent_child(self, parent_id, child_id):\n        \"\"\"Set a parent-child relationship.\n        \n        Args:\n            parent_id: ID of the parent\n            child_id: ID of the child\n        \"\"\"\n        # Ensure the individuals exist\n        if parent_id not in self.individuals:\n            raise ValueError(f\"Parent {parent_id} does not exist in the pedigree\")\n        if child_id not in self.individuals:\n            raise ValueError(f\"Child {child_id} does not exist in the pedigree\")\n            \n        # Get the parent's sex\n        parent_sex = self.individuals.get(parent_id, {}).get('sex', None)\n        \n        # Get the current parents of the child\n        mother_id, father_id = self.parents.get(child_id, (None, None))\n        \n        # Update the parent information based on sex\n        if parent_sex == 'F':\n            mother_id = parent_id\n        elif parent_sex == 'M':\n            father_id = parent_id\n        else:\n            # If sex is unknown, use an available parent slot\n            if mother_id is None:\n                mother_id = parent_id\n            else:\n                father_id = parent_id\n                \n        # Update the parents dictionary\n        self.parents[child_id] = (mother_id, father_id)\n        \n        # Update the children set for the parent\n        self.children[parent_id].add(child_id)\n        \n        # Add the relationship\n        self.add_relationship(parent_id, child_id, 'parent-child', confidence=1.0)\n            \n    def add_ungenotyped_individual(self, individual_id, sex=None, **attributes):\n        \"\"\"Add an ungenotyped individual (ancestor/connector) to the pedigree.\n        \n        Args:\n            individual_id: Unique identifier for the individual\n            sex: Sex of the individual ('M' or 'F')\n            **attributes: Additional attributes\n        \"\"\"\n        # Create a unique ID for the ungenotyped individual if not provided\n        if individual_id is None or individual_id in self.individuals:\n            individual_id = f\"ungenotyped_{len(self.individuals) + 1}\"\n            \n        # Set attributes\n        attributes['genotyped'] = False\n        if sex:\n            attributes['sex'] = sex\n            \n        # Add to the pedigree\n        self.add_individual(individual_id, **attributes)\n        return individual_id\n    \n    def get_siblings(self, individual_id):\n        \"\"\"Get the siblings of an individual.\n        \n        Args:\n            individual_id: ID of the individual\n            \n        Returns:\n            Set of sibling IDs\n        \"\"\"\n        # Check if the individual has parents\n        if individual_id not in self.parents:\n            return set()\n            \n        mother_id, father_id = self.parents[individual_id]\n        siblings = set()\n        \n        # Look for individuals with the same mother\n        if mother_id is not None:\n            for child_id in self.children.get(mother_id, set()):\n                if child_id != individual_id:\n                    siblings.add(child_id)\n                    \n        # Look for individuals with the same father\n        if father_id is not None:\n            for child_id in self.children.get(father_id, set()):\n                if child_id != individual_id and child_id not in siblings:\n                    siblings.add(child_id)\n                    \n        return siblings\n    \n    def get_all_relatives(self, individual_id):\n        \"\"\"Get all relatives of an individual in the pedigree.\n        \n        Args:\n            individual_id: ID of the individual\n            \n        Returns:\n            Set of relative IDs\n        \"\"\"\n        relatives = set()\n        visited = set()\n        \n        def dfs(id):\n            if id in visited:\n                return\n            visited.add(id)\n            \n            # Add parents\n            if id in self.parents:\n                mother_id, father_id = self.parents[id]\n                if mother_id is not None:\n                    relatives.add(mother_id)\n                    dfs(mother_id)\n                if father_id is not None:\n                    relatives.add(father_id)\n                    dfs(father_id)\n            \n            # Add children\n            for child_id in self.children.get(id, set()):\n                relatives.add(child_id)\n                dfs(child_id)\n            \n            # Add siblings and their descendants\n            for sibling_id in self.get_siblings(id):\n                relatives.add(sibling_id)\n                dfs(sibling_id)\n        \n        dfs(individual_id)\n        \n        # Remove the individual themselves\n        if individual_id in relatives:\n            relatives.remove(individual_id)\n            \n        return relatives\n    \n    def to_networkx(self):\n        \"\"\"Convert the pedigree to a NetworkX graph for visualization.\n        \n        Returns:\n            NetworkX DiGraph object representing the pedigree\n        \"\"\"\n        import networkx as nx\n        \n        G = nx.DiGraph()\n        \n        # Add nodes (individuals)\n        for ind_id, attributes in self.individuals.items():\n            # Copy attributes\n            node_attrs = dict(attributes)\n            \n            # Add ID as an attribute\n            node_attrs['id'] = ind_id\n            \n            # Add node to the graph\n            G.add_node(ind_id, **node_attrs)\n        \n        # Add edges (parent-child relationships)\n        for child_id, (mother_id, father_id) in self.parents.items():\n            if mother_id is not None:\n                G.add_edge(mother_id, child_id, relationship='mother-child')\n            if father_id is not None:\n                G.add_edge(father_id, child_id, relationship='father-child')\n        \n        return G\n    \n    def plot(self, figsize=(12, 10), node_size=300, font_size=8):\n        \"\"\"Visualize the pedigree using NetworkX and matplotlib.\n        \n        Args:\n            figsize: Figure size as (width, height)\n            node_size: Base size of nodes\n            font_size: Size of text labels\n        \"\"\"\n        import networkx as nx\n        import matplotlib.pyplot as plt\n        \n        # Convert to NetworkX graph\n        G = self.to_networkx()\n        \n        # Create figure\n        plt.figure(figsize=figsize)\n        \n        # Use a hierarchical layout\n        pos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n        \n        # Create node colors based on sex\n        node_colors = []\n        for node in G.nodes():\n            sex = G.nodes[node].get('sex', None)\n            if sex == 'M':\n                node_colors.append('skyblue')\n            elif sex == 'F':\n                node_colors.append('pink')\n            else:\n                node_colors.append('lightgray')\n        \n        # Create node shapes based on genotyped status\n        node_shapes = []\n        for node in G.nodes():\n            genotyped = G.nodes[node].get('genotyped', True)\n            if genotyped:\n                node_shapes.append('o')  # Circle for genotyped\n            else:\n                node_shapes.append('s')  # Square for ungenotyped\n        \n        # Draw the graph\n        nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_size)\n        nx.draw_networkx_edges(G, pos, edge_color='gray', width=1.5, alpha=0.7)\n        nx.draw_networkx_labels(G, pos, font_size=font_size, font_color='black')\n        \n        plt.title(self.name)\n        plt.axis('off')\n        plt.tight_layout()\n        plt.show()\n\ndef build_pedigree_from_relationships(community, relationships, demographic_data=None):\n    \"\"\"Build a pedigree from pairwise relationships.\n    \n    Args:\n        community: Set of individual IDs in the community\n        relationships: Dictionary mapping pairs to relationship information\n        demographic_data: Dictionary mapping individual IDs to demographic information\n        \n    Returns:\n        Pedigree object representing the community\n    \"\"\"\n    # Create a new pedigree\n    pedigree = Pedigree(name=f\"Community of {len(community)} individuals\")\n    \n    # Add all individuals to the pedigree\n    for ind_id in community:\n        # Get demographic data if available\n        attributes = {}\n        if demographic_data and ind_id in demographic_data:\n            attributes = demographic_data[ind_id].copy()\n        \n        # Set as genotyped (observed in the data)\n        attributes['genotyped'] = True\n        \n        # Add to the pedigree\n        pedigree.add_individual(ind_id, **attributes)\n    \n    # First pass: add all clear parent-child relationships\n    parent_child_pairs = []\n    for pair, rel_info in relationships.items():\n        id1, id2 = pair\n        \n        # Skip relationships not in this community\n        if id1 not in community or id2 not in community:\n            continue\n        \n        # Check if this is a parent-child relationship\n        relationship = rel_info['relationship']\n        if 'Parent-child' in relationship:\n            if '(1\u21922)' in relationship:\n                parent_id, child_id = id1, id2\n            else:\n                parent_id, child_id = id2, id1\n                \n            parent_child_pairs.append((parent_id, child_id, rel_info['confidence']))\n    \n    # Sort by confidence to add most confident parent-child relationships first\n    parent_child_pairs.sort(key=lambda x: x[2], reverse=True)\n    \n    # Add parent-child relationships to the pedigree\n    for parent_id, child_id, confidence in parent_child_pairs:\n        try:\n            pedigree.set_parent_child(parent_id, child_id)\n        except Exception as e:\n            print(f\"Warning: Could not add parent-child relationship {parent_id}->{child_id}: {e}\")\n    \n    # Second pass: add sibling relationships\n    for pair, rel_info in relationships.items():\n        id1, id2 = pair\n        \n        # Skip relationships not in this community\n        if id1 not in community or id2 not in community:\n            continue\n        \n        # Check if this is a sibling relationship\n        relationship = rel_info['relationship']\n        if relationship == 'Full sibling':\n            # Create ungenotyped parents if needed\n            # First, check if either individual already has parents\n            has_parents1 = id1 in pedigree.parents and any(pedigree.parents[id1])\n            has_parents2 = id2 in pedigree.parents and any(pedigree.parents[id2])\n            \n            if not has_parents1 and not has_parents2:\n                # Neither has parents, create new ungenotyped parents\n                mother_id = pedigree.add_ungenotyped_individual(None, sex='F', note=\"Inferred from sibling relationship\")\n                father_id = pedigree.add_ungenotyped_individual(None, sex='M', note=\"Inferred from sibling relationship\")\n                \n                # Set as parents for both siblings\n                pedigree.set_parent_child(mother_id, id1)\n                pedigree.set_parent_child(mother_id, id2)\n                pedigree.set_parent_child(father_id, id1)\n                pedigree.set_parent_child(father_id, id2)\n                \n            elif has_parents1:\n                # Individual 1 has parents, use them for individual 2\n                mother_id, father_id = pedigree.parents[id1]\n                if mother_id:\n                    pedigree.set_parent_child(mother_id, id2)\n                if father_id:\n                    pedigree.set_parent_child(father_id, id2)\n                    \n            elif has_parents2:\n                # Individual 2 has parents, use them for individual 1\n                mother_id, father_id = pedigree.parents[id2]\n                if mother_id:\n                    pedigree.set_parent_child(mother_id, id1)\n                if father_id:\n                    pedigree.set_parent_child(father_id, id1)\n    \n    # Third pass: handle half-sibling, avuncular, and grandparent relationships\n    # ... These require more complex logic and would be added here\n    \n    return pedigree\n\n# Demonstrate pedigree construction for a community\ndef demonstrate_pedigree_construction():\n    # Get the largest community\n    largest_community = detected_communities[0] if detected_communities else set()\n    \n    if not largest_community:\n        print(\"No communities detected\")\n        return None\n        \n    print(f\"Building pedigree for largest community with {len(largest_community)} members\")\n    \n    # Build a pedigree from the relationships in this community\n    pedigree = build_pedigree_from_relationships(largest_community, pairwise_relationships, demographic_data)\n    \n    # Visualize the pedigree\n    pedigree.plot()\n    \n    # Print pedigree statistics\n    print(\"\\\nPedigree Statistics:\")\n    print(f\"  Total individuals: {len(pedigree.individuals)}\")\n    print(f\"  Genotyped individuals: {sum(1 for attrs in pedigree.individuals.values() if attrs.get('genotyped', False))}\")\n    print(f\"  Ungenotyped individuals: {sum(1 for attrs in pedigree.individuals.values() if not attrs.get('genotyped', True))}\")\n    print(f\"  Parent-child relationships: {len(pedigree.parents)}\")\n    \n    # Find the most connected individuals\n    individual_connections = {}\n    for ind_id in pedigree.individuals:\n        relatives = pedigree.get_all_relatives(ind_id)\n        individual_connections[ind_id] = len(relatives)\n    \n    # Sort by number of connections\n    sorted_connections = sorted(individual_connections.items(), key=lambda x: x[1], reverse=True)\n    \n    print(\"\\\nMost connected individuals:\")\n    for ind_id, connection_count in sorted_connections[:5]:\n        genotyped = \"genotyped\" if pedigree.individuals[ind_id].get('genotyped', True) else \"ungenotyped\"\n        print(f\"  {ind_id}: {connection_count} relatives ({genotyped})\")\n    \n    return pedigree\n\n# Run the demonstration\nconstructed_pedigree = demonstrate_pedigree_construction()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Part 4: Confidence Assessment and Result Interpretation\n\n### Theory and Background\n\nA critical aspect of pedigree reconstruction is evaluating the confidence of inferred relationships and pedigree structures. Even with high-quality IBD data, some relationships may be ambiguous or have multiple plausible explanations.\n\nEffective confidence assessment helps users:\n1. **Identify Reliable Results**: Distinguish between high and low confidence relationships\n2. **Focus Investigation**: Prioritize areas where additional evidence is needed\n3. **Make Informed Decisions**: Balance confidence levels against the implications of incorrect inferences\n4. **Communicate Uncertainty**: Present results to users with appropriate caveats\n\nIn Bonsai v3, confidence assessment is implemented at multiple levels:\n- **Pairwise Relationship Confidence**: How certain we are about the relationship between two individuals\n- **Pedigree Structure Confidence**: How well the overall structure is supported by the data\n- **Alternative Hypothesis Scoring**: Evaluating multiple possible pedigree configurations\n\nIn this section, we'll implement confidence assessment methods and interpret the reconstructed pedigrees.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def assess_pedigree_confidence(pedigree, relationships):\n    \"\"\"Assess confidence in the reconstructed pedigree.\n    \n    Args:\n        pedigree: Pedigree object\n        relationships: Dictionary mapping pairs to relationship information\n        \n    Returns:\n        Dictionary mapping relationship pairs to confidence scores\n        Overall pedigree confidence score\n    \"\"\"\n    print(\"Assessing pedigree confidence...\")\n    \n    # Initialize confidence scores\n    confidence_scores = {}\n    relationship_conflicts = {}\n    \n    # Assess each relationship in the pedigree\n    for pair, rel_type in pedigree.relationships.items():\n        id1, id2 = pair\n        \n        # If we have inferred this relationship from IBD data\n        if pair in relationships or (id2, id1) in relationships:\n            # Get the original relationship information\n            rel_info = relationships.get(pair, relationships.get((id2, id1)))\n            \n            # Compare the pedigree relationship with the inferred relationship\n            if rel_type == 'parent-child' and 'Parent-child' in rel_info['relationship']:\n                # Parent-child relationship matches\n                confidence = rel_info['confidence']\n                if confidence == 'high':\n                    score = 0.95\n                elif confidence == 'medium':\n                    score = 0.75\n                else:\n                    score = 0.5\n            elif rel_type == 'sibling' and rel_info['relationship'] in ['Full sibling', 'Half sibling']:\n                # Sibling relationship matches\n                confidence = rel_info['confidence']\n                if confidence == 'high':\n                    score = 0.9\n                elif confidence == 'medium':\n                    score = 0.7\n                else:\n                    score = 0.4\n            else:\n                # Relationship type mismatch\n                score = 0.3\n                relationship_conflicts[pair] = (rel_type, rel_info['relationship'])\n        else:\n            # This is an inferred relationship (e.g., through transitivity)\n            # For example, if A is parent of B and B is parent of C, then A is grandparent of C\n            score = 0.6  # Moderate confidence for transitive relationships\n            \n        # Store the confidence score\n        confidence_scores[pair] = score\n    \n    # Evaluate overall pedigree confidence\n    if confidence_scores:\n        overall_confidence = sum(confidence_scores.values()) / len(confidence_scores)\n    else:\n        overall_confidence = 0.0\n        \n    # Print confidence information\n    print(f\"Overall pedigree confidence: {overall_confidence:.2f}\")\n    print(f\"Assessed confidence for {len(confidence_scores)} relationships\")\n    \n    if relationship_conflicts:\n        print(f\"Found {len(relationship_conflicts)} relationship conflicts:\")\n        for pair, (ped_rel, inf_rel) in list(relationship_conflicts.items())[:5]:  # Show first 5\n            print(f\"  {pair[0]} and {pair[1]}: {ped_rel} in pedigree vs {inf_rel} from IBD\")\n    \n    return confidence_scores, overall_confidence\n\ndef visualize_confidence(pedigree, confidence_scores):\n    \"\"\"Visualize the pedigree with confidence information.\n    \n    Args:\n        pedigree: Pedigree object\n        confidence_scores: Dictionary mapping pairs to confidence scores\n    \"\"\"\n    import networkx as nx\n    import matplotlib.pyplot as plt\n    import matplotlib.cm as cm\n    \n    # Convert to NetworkX graph\n    G = pedigree.to_networkx()\n    \n    # Create figure\n    plt.figure(figsize=(14, 10))\n    \n    # Use a hierarchical layout\n    pos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n    \n    # Create node colors based on sex\n    node_colors = []\n    for node in G.nodes():\n        sex = G.nodes[node].get('sex', None)\n        if sex == 'M':\n            node_colors.append('skyblue')\n        elif sex == 'F':\n            node_colors.append('pink')\n        else:\n            node_colors.append('lightgray')\n    \n    # Draw nodes (different shape for genotyped vs ungenotyped)\n    genotyped_nodes = [node for node in G.nodes() if G.nodes[node].get('genotyped', True)]\n    ungenotyped_nodes = [node for node in G.nodes() if not G.nodes[node].get('genotyped', True)]\n    \n    nx.draw_networkx_nodes(G, pos, \n                          nodelist=genotyped_nodes,\n                          node_color=[node_colors[list(G.nodes()).index(node)] for node in genotyped_nodes],\n                          node_shape='o',\n                          node_size=300)\n    \n    nx.draw_networkx_nodes(G, pos, \n                          nodelist=ungenotyped_nodes,\n                          node_color=[node_colors[list(G.nodes()).index(node)] for node in ungenotyped_nodes],\n                          node_shape='s',\n                          node_size=200)\n    \n    # Draw edges with color based on confidence\n    edges = list(G.edges())\n    edge_colors = []\n    edge_widths = []\n    \n    # Color map for confidence: red (low) to green (high)\n    cmap = cm.get_cmap('RdYlGn')\n    \n    for u, v in edges:\n        # Check if we have a confidence score for this edge\n        if (u, v) in confidence_scores:\n            score = confidence_scores[(u, v)]\n        elif (v, u) in confidence_scores:\n            score = confidence_scores[(v, u)]\n        else:\n            score = 0.5  # Default medium confidence\n            \n        edge_colors.append(cmap(score))\n        edge_widths.append(1.0 + score)\n    \n    nx.draw_networkx_edges(G, pos, \n                          edgelist=edges,\n                          edge_color=edge_colors,\n                          width=edge_widths)\n    \n    # Draw labels\n    nx.draw_networkx_labels(G, pos, font_size=8, font_color='black')\n    \n    # Add a legend for confidence\n    import matplotlib.patches as mpatches\n    \n    legend_elements = [\n        mpatches.Patch(color=cmap(0.1), label='Low Confidence'),\n        mpatches.Patch(color=cmap(0.5), label='Medium Confidence'),\n        mpatches.Patch(color=cmap(0.9), label='High Confidence')\n    ]\n    \n    plt.legend(handles=legend_elements, loc='upper right')\n    \n    plt.title(f\"{pedigree.name} with Confidence Assessment\")\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\ndef generate_pedigree_report(pedigree, confidence_scores, overall_confidence):\n    \"\"\"Generate a detailed report about the pedigree.\n    \n    Args:\n        pedigree: Pedigree object\n        confidence_scores: Dictionary mapping pairs to confidence scores\n        overall_confidence: Overall confidence score for the pedigree\n    \"\"\"\n    from IPython.display import Markdown, display\n    \n    # Create a markdown report\n    report = [f\"# Pedigree Report: {pedigree.name}\"]\n    \n    # Add overall statistics\n    report.append(\"## Overall Statistics\")\n    report.append(f\"- **Total individuals:** {len(pedigree.individuals)}\")\n    report.append(f\"- **Genotyped individuals:** {sum(1 for attrs in pedigree.individuals.values() if attrs.get('genotyped', False))}\")\n    report.append(f\"- **Ungenotyped individuals:** {sum(1 for attrs in pedigree.individuals.values() if not attrs.get('genotyped', True))}\")\n    report.append(f\"- **Parent-child relationships:** {len(pedigree.parents)}\")\n    report.append(f\"- **Overall confidence score:** {overall_confidence:.2f}\")\n    \n    # Group individuals by families\n    families = {}\n    \n    for ind_id in pedigree.individuals:\n        # Find the top ancestor for this individual\n        current_id = ind_id\n        ancestors = []\n        \n        while current_id in pedigree.parents and any(pedigree.parents[current_id]):\n            mother_id, father_id = pedigree.parents[current_id]\n            if mother_id:\n                ancestors.append(mother_id)\n                current_id = mother_id\n            elif father_id:\n                ancestors.append(father_id)\n                current_id = father_id\n            else:\n                break\n        \n        # The top ancestor is the family identifier\n        if ancestors:\n            family_id = ancestors[-1]\n        else:\n            family_id = ind_id\n            \n        if family_id not in families:\n            families[family_id] = []\n        families[family_id].append(ind_id)\n    \n    # Add information about each family\n    report.append(f\"\\\n## Family Structures ({len(families)} families)\")\n    \n    for i, (family_id, members) in enumerate(sorted(families.items(), key=lambda x: len(x[1]), reverse=True)):\n        report.append(f\"\\\n### Family {i+1}: {family_id}\")\n        report.append(f\"- **Members:** {len(members)}\")\n        \n        # List key individuals in the family\n        genotyped_members = [m for m in members if pedigree.individuals[m].get('genotyped', True)]\n        if genotyped_members:\n            report.append(f\"- **Genotyped members:** {', '.join(genotyped_members[:5])}\" + \n                         (\"...\" if len(genotyped_members) > 5 else \"\"))\n        \n        # Find key relationships in this family\n        family_relationships = []\n        for pair, score in confidence_scores.items():\n            if pair[0] in members and pair[1] in members:\n                rel_type = pedigree.relationships.get(pair, \"unknown\")\n                family_relationships.append((pair, rel_type, score))\n        \n        # Sort by confidence (highest first)\n        family_relationships.sort(key=lambda x: x[2], reverse=True)\n        \n        if family_relationships:\n            report.append(\"- **Key relationships:**\")\n            for (id1, id2), rel_type, score in family_relationships[:5]:  # Show top 5\n                confidence = \"high\" if score > 0.8 else \"medium\" if score > 0.5 else \"low\"\n                report.append(f\"  - {id1} \u2014 {id2}: {rel_type} ({confidence} confidence: {score:.2f})\")\n    \n    # Add information about high and low confidence relationships\n    high_conf = {pair: score for pair, score in confidence_scores.items() if score > 0.8}\n    low_conf = {pair: score for pair, score in confidence_scores.items() if score < 0.5}\n    \n    report.append(\"\\\n## Confidence Assessment\")\n    report.append(f\"- **High confidence relationships:** {len(high_conf)} ({len(high_conf) / len(confidence_scores) * 100:.0f}%)\")\n    report.append(f\"- **Low confidence relationships:** {len(low_conf)} ({len(low_conf) / len(confidence_scores) * 100:.0f}%)\")\n    \n    if low_conf:\n        report.append(\"\\\n### Low Confidence Relationships (Requiring Further Investigation)\")\n        for pair, score in sorted(low_conf.items(), key=lambda x: x[1]):\n            rel_type = pedigree.relationships.get(pair, \"unknown\")\n            report.append(f\"- {pair[0]} \u2014 {pair[1]}: {rel_type} (confidence: {score:.2f})\")\n    \n    # Display the report\n    display(Markdown(\"\\\n\".join(report)))\n    \n    return \"\\\n\".join(report)\n\n# Evaluate and report on the pedigree\ndef demonstrate_pedigree_evaluation():\n    # Skip if no pedigree was constructed\n    if constructed_pedigree is None:\n        print(\"No pedigree available for evaluation\")\n        return\n    \n    # Assess confidence in the pedigree\n    confidence_scores, overall_confidence = assess_pedigree_confidence(\n        constructed_pedigree, pairwise_relationships)\n    \n    # Visualize the pedigree with confidence information\n    visualize_confidence(constructed_pedigree, confidence_scores)\n    \n    # Generate a report\n    report = generate_pedigree_report(constructed_pedigree, confidence_scores, overall_confidence)\n    \n    # Return for further analysis\n    return confidence_scores, overall_confidence, report\n\n# Run the demonstration\ntry:\n    confidence_scores, overall_confidence, pedigree_report = demonstrate_pedigree_evaluation()\nexcept Exception as e:\n    print(f\"Error evaluating pedigree: {e}\")\n    confidence_scores, overall_confidence, pedigree_report = None, None, None"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Conclusion and Key Takeaways\n\nIn this lab, we've built a complete end-to-end pedigree reconstruction pipeline using Bonsai v3. We've covered each major component of the pipeline:\n\n1. **Pipeline Architecture**: We designed a modular, robust pipeline architecture with well-defined interfaces between components\n2. **IBD Processing**: We implemented functions for loading, filtering, and analyzing IBD segments\n3. **Relationship Inference**: We developed algorithms for inferring relationships from IBD statistics and demographic data\n4. **Community Detection**: We used network analysis to identify clusters of related individuals\n5. **Pedigree Construction**: We built pedigree structures that respect biological constraints and explain observed IBD patterns\n6. **Confidence Assessment**: We evaluated the reliability of our reconstructed relationships and pedigrees\n\nKey takeaways from this lab include:\n\n- **Modular Design**: Breaking the pipeline into independent components allows for easier testing, maintenance, and improvement\n- **Data Quality**: Proper filtering and preprocessing of IBD data is critical for accurate results\n- **Demographic Integration**: Age and sex information significantly improves relationship inference\n- **Confidence Metrics**: Quantifying uncertainty helps users interpret and trust the results\n- **Visualization**: Effective visualization makes complex pedigree structures interpretable\n\nBonsai v3 provides a powerful framework for pedigree reconstruction, but real-world applications often require customization and fine-tuning based on the specific data and requirements of the project.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Exercise: End-to-End Integration\n\nFor this final exercise, you'll put together everything you've learned to implement a complete pedigree reconstruction pipeline for a real-world scenario.\n\n### Scenario\nYou've been given IBD data from a genetic ancestry testing company. The data includes IBD segments for 100 individuals, some of whom are known to be related. Your task is to reconstruct pedigrees for these individuals, providing confidence scores and visualizations.\n\n### Task\nImplement a complete end-to-end pipeline that:\n\n1. Processes and filters the IBD data appropriately\n2. Integrates available demographic information\n3. Detects communities of related individuals\n4. Reconstructs pedigrees within each community\n5. Assesses confidence in the reconstructed relationships\n6. Generates visualizations and reports\n\n### Implementation Guidelines\n\n1. Start with the `BonsaiPipeline` class we designed earlier.\n2. Fill in the implementation of each component.\n3. Add error handling and logging to ensure robustness.\n4. Include configuration options for different use cases.\n5. Think about how to parallelize processing for larger datasets.\n\n### Expected Output\nYour pipeline should produce:\n\n1. Filtered and processed IBD statistics\n2. Community assignments for all individuals\n3. Reconstructed pedigrees for each community\n4. Confidence scores for all relationships\n5. Visualizations of the pedigrees with confidence information\n6. A detailed report summarizing the findings\n\n### Template\n\n```python\nfrom typing import Dict, List, Set, Tuple, Optional, Any\nimport os\nimport logging\nimport time\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nclass CompleteBonsaiPipeline:\n    \"\"\"Complete end-to-end pedigree reconstruction pipeline using Bonsai v3.\"\"\"\n    \n    def __init__(self, config: Dict[str, Any] = None):\n        \"\"\"Initialize the pipeline.\n        \n        Args:\n            config: Configuration dictionary\n        \"\"\"\n        # Set up configuration\n        self.config = config or {}\n        self.config.setdefault('min_segment_cm', 7.0)\n        self.config.setdefault('max_pedigree_size', 100)\n        \n        # Initialize pipeline components\n        self.ibd_processor = None\n        self.relationship_inferrer = None\n        self.community_detector = None\n        self.pedigree_builder = None\n        self.confidence_assessor = None\n        self.visualizer = None\n        \n        # Set up logging\n        self._setup_logging()\n    \n    def _setup_logging(self):\n        \"\"\"Set up logging for the pipeline.\"\"\"\n        # ... implement logging setup ...\n        pass\n    \n    def run(self, ibd_file: str, demographic_file: Optional[str] = None):\n        \"\"\"Run the complete pipeline.\n        \n        Args:\n            ibd_file: Path to the IBD segments file\n            demographic_file: Path to the demographic data file (optional)\n        \"\"\"\n        start_time = time.time()\n        \n        # Step 1: Process IBD data\n        self.logger.info(\"Processing IBD data...\")\n        \n        # Step 2: Load demographic data\n        self.logger.info(\"Loading demographic data...\")\n        \n        # Step 3: Infer pairwise relationships\n        self.logger.info(\"Inferring pairwise relationships...\")\n        \n        # Step 4: Detect communities\n        self.logger.info(\"Detecting communities...\")\n        \n        # Step 5: Construct pedigrees\n        self.logger.info(\"Constructing pedigrees...\")\n        \n        # Step 6: Assess confidence\n        self.logger.info(\"Assessing confidence...\")\n        \n        # Step 7: Visualize results\n        self.logger.info(\"Visualizing results...\")\n        \n        # Step 8: Generate reports\n        self.logger.info(\"Generating reports...\")\n        \n        elapsed_time = time.time() - start_time\n        self.logger.info(f\"Pipeline completed in {elapsed_time:.2f} seconds\")\n        \n        return {\n            \"pedigrees\": self.pedigrees,\n            \"confidence_scores\": self.confidence_scores,\n            \"execution_time\": elapsed_time\n        }\n\n# Implement your complete pipeline here\n```\n\nUse the functions and classes we developed in this lab as building blocks for your implementation. You can simulate the input data if needed, or try to use a small subset of the class data if it's accessible in your environment.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## References and Further Reading\n\n### Bonsai v3 Documentation\n- Bonsai v3 User Guide: Comprehensive documentation of the Bonsai v3 codebase\n- Bonsai v3 API Reference: Detailed descriptions of all classes and functions\n\n### IBD Detection and Processing\n- Browning, B. L., & Browning, S. R. (2013). Improving the accuracy and efficiency of identity-by-descent detection in population data. *Genetics*, 194(2), 459-471.\n- Ramstetter, M. D., et al. (2018). Benchmarking relatedness inference methods with genome-wide data from thousands of relatives. *Genetics*, 207(1), 75-82.\n\n### Relationship Inference\n- Kling, D., et al. (2012). DNA microarray as a tool in establishing genetic relatedness\u2014Current status and future prospects. *Forensic Science International: Genetics*, 6(3), 322-329.\n- Staples, J., et al. (2016). PRIMUS: rapid reconstruction of pedigrees from genome-wide estimates of identity by descent. *The American Journal of Human Genetics*, 98(6), 1103-1113.\n\n### Pedigree Reconstruction\n- Ko, A., & Nielsen, R. (2017). Composite likelihood method for inferring local pedigrees. *PLoS Genetics*, 13(8), e1006963.\n- Shchur, V., et al. (2019). Fast and accurate pedigree reconstruction using proximity-dependent splitting. *bioRxiv*, 675462.\n\n### Community Detection in Networks\n- Blondel, V. D., et al. (2008). Fast unfolding of communities in large networks. *Journal of Statistical Mechanics: Theory and Experiment*, 2008(10), P10008.\n- Fortunato, S. (2010). Community detection in graphs. *Physics Reports*, 486(3-5), 75-174.\n\n### Genetic Genealogy Applications\n- Erlich, Y., et al. (2018). Identity inference of genomic data using long-range familial searches. *Science*, 362(6415), 690-694.\n- Edge, M. D., & Coop, G. (2019). Reconstructing the history of polygenic scores using coalescent trees. *Genetics*, 211(1), 235-262.\n\n### Software Tools\n- [PLINK](https://www.cog-genomics.org/plink/): Whole genome association analysis toolset\n- [IBDseq](https://faculty.washington.edu/sguy/ibdseq/): IBD segment detection tool\n- [GERMLINE](http://www1.cs.columbia.edu/~gusev/germline/): IBD detection software\n- [PRIMUS](https://primus.gs.washington.edu/): Pedigree reconstruction tool\n- [DRUID](https://github.com/23andMe/druid): Degree Relationship Using IBD Data\n\n### Related Jupyter Notebooks\n- **Lab 21: Pedigree Rendering**: Techniques for visualizing pedigree structures\n- **Lab 28: Integration with Other Genealogical Tools**: Working with external tools and formats",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}