{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyrnlNJ2hiso"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mInstalling dependencies from lock file\u001b[39m\n",
            "\n",
            "No dependencies to install or update\n"
          ]
        }
      ],
      "source": [
        "!poetry install --no-root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YZmLfSJqg2uR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "import logging\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "import IPython\n",
        "import pandas as pd\n",
        "import boto3\n",
        "import importlib.util\n",
        "import ast\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from scipy.stats import poisson\n",
        "import json\n",
        "import pygraphviz as pgv\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nduw3nmhg5kV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded environment variables from: /home/lakishadavid/computational_genetic_genealogy/.env\n",
            "Working Directory: /home/lakishadavid/computational_genetic_genealogy\n",
            "Data Directory: /home/lakishadavid/computational_genetic_genealogy/data\n",
            "References Directory: /home/lakishadavid/computational_genetic_genealogy/references\n",
            "Results Directory: /home/lakishadavid/computational_genetic_genealogy/results\n",
            "Utils Directory: /home/lakishadavid/computational_genetic_genealogy/utils\n",
            "The current directory is /home/lakishadavid/computational_genetic_genealogy\n"
          ]
        }
      ],
      "source": [
        "def find_comp_gen_dir():\n",
        "    \"\"\"Find the computational_genetic_genealogy directory by searching up from current directory.\"\"\"\n",
        "    current = Path.cwd()\n",
        "    \n",
        "    # Search up through parent directories\n",
        "    while current != current.parent:\n",
        "        # Check if target directory exists in current path\n",
        "        target = current / 'computational_genetic_genealogy'\n",
        "        if target.is_dir():\n",
        "            return target\n",
        "        # Move up one directory\n",
        "        current = current.parent\n",
        "    \n",
        "    raise FileNotFoundError(\"Could not find computational_genetic_genealogy directory\")\n",
        "\n",
        "def load_env_file():\n",
        "    \"\"\"Find and load the .env file from the computational_genetic_genealogy directory.\"\"\"\n",
        "    try:\n",
        "        # Find the computational_genetic_genealogy directory\n",
        "        comp_gen_dir = find_comp_gen_dir()\n",
        "        \n",
        "        # Look for .env file\n",
        "        env_path = comp_gen_dir / '.env'\n",
        "        if not env_path.exists():\n",
        "            print(f\"Warning: No .env file found in {comp_gen_dir}\")\n",
        "            return None\n",
        "        \n",
        "        # Load the .env file\n",
        "        load_dotenv(env_path, override=True)\n",
        "        print(f\"Loaded environment variables from: {env_path}\")\n",
        "        return env_path\n",
        "        \n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Use the function\n",
        "env_path = load_env_file()\n",
        "\n",
        "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
        "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
        "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
        "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
        "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
        "\n",
        "os.environ[\"WORKING_DIRECTORY\"] = working_directory\n",
        "os.environ[\"DATA_DIRECTORY\"] = data_directory\n",
        "os.environ[\"REFERENCES_DIRECTORY\"] = references_directory\n",
        "os.environ[\"RESULTS_DIRECTORY\"] = results_directory\n",
        "os.environ[\"UTILS_DIRECTORY\"] = utils_directory\n",
        "\n",
        "print(f\"Working Directory: {working_directory}\")\n",
        "print(f\"Data Directory: {data_directory}\")\n",
        "print(f\"References Directory: {references_directory}\")\n",
        "print(f\"Results Directory: {results_directory}\")\n",
        "print(f\"Utils Directory: {utils_directory}\")\n",
        "\n",
        "os.chdir(working_directory)\n",
        "print(f\"The current directory is {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7GlSu-GWsDS"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onCavOg0NoQt"
      },
      "source": [
        "Bonsai requires data on the age and sex of each individual. However, when we simulated data, we did not get an age. Bonsai also requires the the individual name to be an integer, which is not how our simulated data outputs names. This section of code will assign a random integer ID and age based on certain parameters and output this bioinfo variable as needed for Bonsai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "IYJRzLyBXzmh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of individuals: 520\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Read the seg file and extract unique individual IDs\n",
        "seg_file = os.path.join(data_directory, \"class_data/ped_sim_run2.seg\")\n",
        "seg_df = pd.read_csv(seg_file, sep=\"\\t\", header=None)\n",
        "seg_df.columns = [\"sample1\", \"sample2\", \"chrom\", \"phys_start\", \"phys_end\", \"ibd_type\", \"gen_start\", \"gen_end\", \"gen_seg_len\"]\n",
        "unique_individuals = set(seg_df[\"sample1\"]).union(set(seg_df[\"sample2\"]))\n",
        "unique_individuals = sorted(list(unique_individuals))\n",
        "print(\"Number of individuals:\", len(unique_individuals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1000, 1001, 1002, 1003, 1004]\n"
          ]
        }
      ],
      "source": [
        "# print the first 5 of unique_individuals\n",
        "print(unique_individuals[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TOdu2C-WYLpJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 lines of fam file:\n",
            "FAM1 FAM1_g1-b1-s1 0 0 2 1\n",
            "FAM1 FAM1_g1-b1-i1 0 0 1 1\n",
            "FAM1 FAM1_g2-b1-s1 0 0 2 1\n",
            "FAM1 FAM1_g2-b1-i1 FAM1_g1-b1-i1 FAM1_g1-b1-s1 1 1\n",
            "FAM1 FAM1_g2-b2-s1 0 0 1 1\n",
            "\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'FAM1_g1-b1-s1'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[33], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m fields \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m     27\u001b[0m original_id \u001b[38;5;241m=\u001b[39m fields[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 28\u001b[0m individual_id \u001b[38;5;241m=\u001b[39m \u001b[43mid_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43moriginal_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Skip individuals not present in the seg file\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m individual_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m unique_individuals:\n",
            "\u001b[0;31mKeyError\u001b[0m: 'FAM1_g1-b1-s1'"
          ]
        }
      ],
      "source": [
        "# Read the fam file\n",
        "with open(os.path.join(data_directory, \"class_data/ped_sim_run2-everyone.fam\"), 'r') as file:\n",
        "    fam_lines = file.readlines()\n",
        "    \n",
        "# Load ID mapping from the dictionary file\n",
        "id_mapping = {}\n",
        "dict_file_path = os.path.join(data_directory, \"class_data/ped_sim_run2.seg_dict.txt\")\n",
        "\n",
        "with open(dict_file_path, 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        original_id = parts[0]\n",
        "        numeric_id = int(parts[1])\n",
        "        id_mapping[original_id] = numeric_id\n",
        "\n",
        "# Create a dictionary to store individual information and Bonsai IDs\n",
        "individuals = {}\n",
        "bonsai_ids = {}\n",
        "\n",
        "# Debug: Print first few lines of fam file\n",
        "print(\"First 5 lines of fam file:\")\n",
        "print(\"\".join(fam_lines[:5]))\n",
        "\n",
        "# Process each line in the fam file\n",
        "for line in fam_lines:\n",
        "    fields = line.strip().split()\n",
        "    original_id = fields[1]\n",
        "    individual_id = id_mapping[original_id]\n",
        "    \n",
        "\n",
        "    # Skip individuals not present in the seg file\n",
        "    if individual_id not in unique_individuals:\n",
        "        continue\n",
        "\n",
        "    if fields[2] == str(0):\n",
        "        father_id = 0\n",
        "    else:\n",
        "        father_id = id_mapping[fields[2]]\n",
        "        \n",
        "    if fields[3] == str(0):\n",
        "        mother_id = 0\n",
        "    else:\n",
        "        mother_id = id_mapping[fields[3]]\n",
        "    sex = 'M' if fields[4] == '1' else 'F'\n",
        "\n",
        "    # Extract the generation number from the individual ID\n",
        "    generation = int(original_id.split('-')[0].split('_')[-1][1:])\n",
        "\n",
        "    # Store the individual information in the dictionary\n",
        "    individuals[individual_id] = {\n",
        "        'father_id': father_id,\n",
        "        'mother_id': mother_id,\n",
        "        'sex': sex,\n",
        "        'generation': generation\n",
        "    }\n",
        "    \n",
        "print(\"First 10 individuals:\")\n",
        "print({k: v for k, v in list(individuals.items())[:10]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8M707kiIZLxg"
      },
      "outputs": [],
      "source": [
        "# Get the earliest and latest generation numbers\n",
        "generation_numbers = [info['generation'] for info in individuals.values()]\n",
        "earliest_generation = min(generation_numbers)\n",
        "latest_generation = max(generation_numbers)\n",
        "print(f\"Earliest generation: {earliest_generation}, Latest generation: {latest_generation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlTPOT_wZQKO"
      },
      "source": [
        "This code block retrieves the earliest and latest generation numbers from the `individuals` dictionary. It creates a list comprehension to extract the 'generation' values from the dictionary values. The `min` and `max` functions are used to find the earliest and latest generation numbers, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ff8O_32Zike"
      },
      "outputs": [],
      "source": [
        "# Assign ages to individuals based on their generation\n",
        "for generation in range(latest_generation, earliest_generation - 1, -1):\n",
        "    for individual_id, info in individuals.items():\n",
        "        if info['generation'] == generation:\n",
        "            if generation == latest_generation:\n",
        "                # Assign ages between 18 and 40 for the latest generation\n",
        "                age = random.randint(18, 40)\n",
        "            else:\n",
        "                # Assign ages based on the descendants' ages\n",
        "                child_ages = []\n",
        "                for child_id, child_info in individuals.items():\n",
        "                    if child_info['father_id'] == individual_id or child_info['mother_id'] == individual_id:\n",
        "                        child_ages.append(child_info['age'])\n",
        "\n",
        "                if child_ages:\n",
        "                    min_child_age = min(child_ages)\n",
        "                    age = min_child_age + random.randint(12, 40)\n",
        "                else:\n",
        "                    # If no child information is available, assign a random age based on the generation gap\n",
        "                    age_gap = (latest_generation - generation) * random.randint(12, 40)\n",
        "                    age = random.randint(18, 40) + age_gap\n",
        "\n",
        "            individuals[individual_id]['age'] = age\n",
        "            \n",
        "\n",
        "print(\"First 10 individuals with ages:\")\n",
        "print({k: v for k, v in list(individuals.items())[:10]})\n",
        "print(\"\\n\")\n",
        "print(\"The age range is:\", min([info['age'] for info in individuals.values()]), \"-\", max([info['age'] for info in individuals.values()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9-RXmLYZjk-"
      },
      "source": [
        "This code block assigns ages to individuals based on their generation. It iterates over the generations in reverse order, starting from the latest generation and going backward to the earliest generation.\n",
        "\n",
        "For each generation:\n",
        "\n",
        "* If it's the latest generation, ages between 18 and 40 are randomly assigned using random.randint(18, 40).\n",
        "* For earlier generations, ages are assigned based on the descendants' ages. It iterates over the individuals and checks if the current individual is the father or mother of any other individual. If so, the age of the child is appended to the child_ages list.\n",
        "  * If the child_ages list is not empty, the minimum age among the children is found using min(child_ages), and the individual's age is assigned by adding a random value between 12 and 40 to the minimum child age.\n",
        "  * If the child_ages list is empty (i.e., the individual has no children), a random age is assigned based on the generation gap. The generation gap is calculated by subtracting the current generation from the latest generation, and then multiplying it by a random value between 12 and 40. The individual's age is then assigned by adding this age gap to a base age range of 18 to 40.\n",
        "* The assigned age is stored in the individuals dictionary under the 'age' key for each individual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nut1Oy6naLFJ"
      },
      "outputs": [],
      "source": [
        "# Create Genotype IDs for individuals\n",
        "for index, individual_id in enumerate(individuals.keys(), start=1000):\n",
        "    bonsai_id = str(index)\n",
        "    individuals[individual_id]['genotype_id'] = bonsai_id\n",
        "    \n",
        "print(\"First 10 individuals with Genotype IDs:\")\n",
        "print({k: v for k, v in list(individuals.items())[:10]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgzd1POsaI_U"
      },
      "source": [
        "This code block creates Bonsai IDs for each individual. It uses the enumerate function to iterate over the keys of the individuals dictionary, starting the index from 1000. For each individual ID, a corresponding Bonsai ID is created by converting the index to a string. The Bonsai ID is then stored in the bonsai_ids dictionary using the individual ID as the key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHywg178aRDh"
      },
      "outputs": [],
      "source": [
        "# Write the individual information to a new file\n",
        "with open(os.path.join(results_directory, 'individual_info.txt'), 'w') as file:\n",
        "    file.write(\"Individual ID\\tBonsai ID\\tAge\\tSex\\n\")\n",
        "    for individual_id, info in individuals.items():\n",
        "        genotype_id = info['genotype_id']\n",
        "        age = info['age']\n",
        "        sex = info['sex']\n",
        "        file.write(f\"{individual_id}\\t{genotype_id}\\t{age}\\t{sex}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTvuQ78eaR2w"
      },
      "source": [
        "This code block writes the individual information to a new file named \"individual_info.txt\" in the results_directory. It opens the file in write mode ('w').\n",
        "\n",
        "The header line `\"Individual ID\\tBonsai ID\\tAge\\tSex\\n\"` is written to the file first.\n",
        "\n",
        "Then, it iterates over the `individuals` dictionary items. For each individual:\n",
        "\n",
        "* The corresponding Bonsai ID is retrieved from the `bonsai_ids` dictionary using the individual ID as the key.\n",
        "* The age and sex information is retrieved from the `individuals` dictionary.\n",
        "* The individual information is written to the file in the format `\"Individual ID\\tBonsai ID\\tAge\\tSex\\n\"` using an f-string.\n",
        "\n",
        "Take a look at the `individual_info.txt` file in your results directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESFCtYDGaq9o"
      },
      "outputs": [],
      "source": [
        "# Create the bioinfo value in the desired format\n",
        "bioinfo = []\n",
        "for individual_id, info in individuals.items():\n",
        "    genotype_id = int(info['genotype_id'])\n",
        "    age = info['age']\n",
        "    sex = info['sex']\n",
        "    bioinfo.append({'genotype_id': genotype_id, 'age': age, 'sex': sex})\n",
        "    \n",
        "print(\"The first 10 bioinfo values:\")\n",
        "for i in range(10):\n",
        "    print(bioinfo[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzvNI8WAaubK"
      },
      "source": [
        "This code block creates the bioinfo value in the desired format. It initializes an empty list called `bioinfo`.\n",
        "\n",
        "It iterates over the `individuals` dictionary items. For each individual:\n",
        "\n",
        "* The corresponding Bonsai ID is retrieved from the `bonsai_ids` dictionary using the individual ID as the key.\n",
        "* The Bonsai ID is converted to an integer and assigned to the `genotype_id` variable.\n",
        "* The age and sex information is retrieved from the `individuals` dictionary.\n",
        "* A dictionary containing the `genotype_id`, `age`, and `sex` is appended to the `bioinfo` list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzxQ_H0UXDvr"
      },
      "source": [
        "Remember that Bonsai is designed to read the individal names as integers. We already assigned integer IDs for each individual in our segments file in the earlier code. Let's use those assignments to update our segments file by replacing the individual names with their integer IDs.\n",
        "\n",
        "**NOTE: The following code block can't run more than once unless you change the existing .seg_orig to .seg**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApvfuVGgddXY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "seg_file_orig = seg_file + \"_orig\"\n",
        "\n",
        "# Check for .seg_orig and .seg files in the results directory\n",
        "if os.path.exists(seg_file_orig) and os.path.exists(seg_file):\n",
        "    os.remove(seg_file)\n",
        "    os.rename(seg_file_orig, seg_file)\n",
        "elif os.path.exists(seg_file_orig):\n",
        "    os.rename(seg_file_orig, seg_file)\n",
        "    \n",
        "segments = seg_df.copy()\n",
        "\n",
        "# New file paths\n",
        "seg_file_new = seg_file\n",
        "dict_file = seg_file + \"_dict.txt\"\n",
        "\n",
        "# Read the individual_info.txt file\n",
        "individual_info = pd.read_csv(os.path.join(results_directory, 'individual_info.txt'), sep='\\t')\n",
        "\n",
        "# Create a dictionary to map individual IDs to Bonsai IDs\n",
        "individual_to_bonsai = dict(zip(individual_info['Individual ID'], individual_info['Bonsai ID']))\n",
        "\n",
        "# Replace sample names with their corresponding Bonsai IDs\n",
        "segments['sample1'] = segments['sample1'].map(individual_to_bonsai)\n",
        "segments['sample2'] = segments['sample2'].map(individual_to_bonsai)\n",
        "\n",
        "# Save the modified segments as .seg\n",
        "segments.to_csv(seg_file_new, sep='\\t', index=False, header=False)\n",
        "\n",
        "# Save the dictionary\n",
        "with open(dict_file, 'w') as f:\n",
        "    for individual, bonsai_id in individual_to_bonsai.items():\n",
        "        f.write(f\"{individual}\\t{bonsai_id}\\n\")\n",
        "\n",
        "print(\"Segments and dictionary saved successfully.\")\n",
        "display(segments.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the segment list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_unphased_ibd_seg_list(segments):\n",
        "    \"\"\"\n",
        "    Creates an unphased IBD segment list from the given DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        segments_ibd (pd.DataFrame): DataFrame containing the IBD segments with columns:\n",
        "                                     ['id1', 'id2', 'chromosome', 'physical_position_start',\n",
        "                                      'physical_position_end', 'IBD_type', 'genetic_length'].\n",
        "        numeric_ids (dict): Mapping of sample IDs (str) to numeric IDs (int).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of unphased IBD segments in the specified format:\n",
        "              [[id1, id2, chrom, start_bp, end_bp, is_full, len_cm], ...].\n",
        "    \"\"\"\n",
        "    unphased_ibd_seg_list = []\n",
        "\n",
        "    for _, row in segments.iterrows():\n",
        "        try:\n",
        "            id1 = int(row['sample1'])\n",
        "            id2 = int(row['sample2'])\n",
        "            chrom = str(row['chrom'])  # Convert chromosome to string if necessary\n",
        "            start_bp = float(row['phys_start'])\n",
        "            end_bp = float(row['phys_end'])\n",
        "            is_full = row['ibd_type'] == 2  # Assuming IBD2 indicates \"full\"\n",
        "            len_cm = float(row['gen_seg_len'])\n",
        "\n",
        "            unphased_ibd_seg_list.append([id1, id2, chrom, start_bp, end_bp, is_full, len_cm])\n",
        "        except KeyError as e:\n",
        "            print(f\"Error mapping ID: {e}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error converting row data: {e}\")\n",
        "\n",
        "    return unphased_ibd_seg_list\n",
        "\n",
        "unphased_ibd_seg_list = create_unphased_ibd_seg_list(segments)\n",
        "\n",
        "print(\"First 10 unphased IBD segments:\")\n",
        "for i in range(10):\n",
        "    print(unphased_ibd_seg_list[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh--6OMseIgp"
      },
      "source": [
        "## Run Bonsai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcLLLzrFVn_R"
      },
      "outputs": [],
      "source": [
        "from utils.bonsaitree.bonsaitree.v3 import bonsai\n",
        "\n",
        "up_dict_log_like_list = bonsai.build_pedigree(\n",
        "    bio_info=bioinfo,\n",
        "    unphased_ibd_seg_list=unphased_ibd_seg_list,\n",
        "    min_seg_len=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzp7Y7dKzo0o"
      },
      "source": [
        "## Louvain communities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR2eYQ_W7_t_"
      },
      "source": [
        "Louvain communities is a community detection algorithm that helps identify groups of nodes that are more densely connected to each other than to nodes in other groups. In the context of our problem, using Louvain communities allows us to partition the large network of individuals into smaller, more manageable communities.\n",
        "\n",
        "The Louvain algorithm is a hierarchical clustering algorithm that optimizes the modularity score of the network. Modularity is a measure of the strength of division of a network into communities. A high modularity score indicates that the nodes within a community have more connections among themselves than with nodes in other communities.\n",
        "\n",
        "By applying the Louvain algorithm to our network of individuals, we can identify communities of individuals that are more closely related to each other based on their shared IBD segments. This allows us to focus our analysis on smaller subsets of the data, reducing the computational burden and memory requirements.\n",
        "\n",
        "By leveraging Louvain communities, we can partition our large network into smaller communities and run Bonsai on each community separately. This approach enables us to work with larger datasets and overcome the memory limitations of the free version of Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLIHoAQgzsRP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create a graph from the hapibd_df DataFrame\n",
        "G = nx.Graph()\n",
        "\n",
        "with tqdm(total=len(segments), desc=\"Adding edges to the graph\") as pbar:\n",
        "    for _, row in segments.iterrows():\n",
        "        first_sample = row[\"sample1\"]\n",
        "        second_sample = row[\"sample2\"]\n",
        "        gen_seg_len = row[\"gen_seg_len\"]\n",
        "        G.add_edge(first_sample, second_sample, weight=gen_seg_len)\n",
        "        pbar.update(1)\n",
        "\n",
        "# Find Louvain communities\n",
        "communities = nx.community.louvain_communities(G, weight='weight')\n",
        "\n",
        "print(len(communities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJO4-Iwh6rZ7"
      },
      "outputs": [],
      "source": [
        "# Print the members of each community\n",
        "for i, community in enumerate(communities[:5], start=1):\n",
        "    print(f\"Community {i}:\")\n",
        "    print(list(community))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_vlJYp6k_qP"
      },
      "source": [
        "To make the Louvain communities smaller, you can adjust the `resolution` parameter in the `louvain_communities` function. The `resolution` parameter controls the size of the communities detected by the algorithm. By default, it is set to 1.0.\n",
        "\n",
        "* Decreasing the `resolution` parameter (e.g., setting it to a value less than 1.0) will result in larger communities. The algorithm will favor merging smaller communities into larger ones.\n",
        "* Increasing the `resolution` parameter (e.g., setting it to a value greater than 1.0) will result in smaller communities. The algorithm will favor splitting larger communities into smaller ones.\n",
        "\n",
        "Here's how you can modify the code to make the communities smaller:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSZVnG7PlPxV"
      },
      "outputs": [],
      "source": [
        "with tqdm(total=len(segments), desc=\"Adding edges to the graph\") as pbar:\n",
        "    for _, row in segments.iterrows():\n",
        "        first_sample = row[\"sample1\"]\n",
        "        second_sample = row[\"sample2\"]\n",
        "        gen_seg_len = row[\"gen_seg_len\"]\n",
        "        G.add_edge(first_sample, second_sample, weight=gen_seg_len)\n",
        "        pbar.update(1)\n",
        "\n",
        "# Find Louvain communities with a smaller resolution value\n",
        "resolution = 100  # Adjust this value to control the size of the communities\n",
        "communities_v2 = nx.community.louvain_communities(G, resolution=resolution, weight='weight')\n",
        "print(len(communities_v2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG30P4OplbB7"
      },
      "outputs": [],
      "source": [
        "# Print the members of each community\n",
        "for i, community in enumerate(communities_v2[:5], start=1):\n",
        "    print(f\"Community {i}:\")\n",
        "    print(list(community))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OezMpWaFnvGj"
      },
      "source": [
        "NOTE: It could be that you find Bonsai is more accurate for smaller, more related groups of individuals than for larger, more distantly related individuals. Bonsai has a `seed_pedigree_list` parameter that is an \"optional [list] of seed pedigrees to use as starting points for building the pedigree\". It also has a `validated_node_set_list` parameter where you can identify the nodes in the pedigrees in the `seed_pedigree_list` where you know the genealogical relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLXFu1nygNoc"
      },
      "source": [
        "# Run Bonsai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYYvmdK_l8g1"
      },
      "source": [
        "Rather than running Bonsai on our entire dataset, we can now run it on a Louvain community where we know there is relatedness among the members of the community. Because of this, we need to reduce our ibd_seg_list and bioinfo variables to only the inviduals in the community."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZxR8m1dJuM8"
      },
      "outputs": [],
      "source": [
        "# Choose the community you want to focus on (e.g., community 0)\n",
        "target_community = communities[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdfJlW1qqM7u"
      },
      "outputs": [],
      "source": [
        "target_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSc_Ym0h8Yb4"
      },
      "outputs": [],
      "source": [
        "def filter_ibd_seg_list(ibd_seg_list, community_ids, both_in_community=True):\n",
        "    if both_in_community:\n",
        "        filtered_ibd_seg_list = [\n",
        "            seg for seg in ibd_seg_list\n",
        "            if seg[0] in community_ids and seg[1] in community_ids\n",
        "        ]\n",
        "    # else:\n",
        "    #     filtered_ibd_seg_list = [\n",
        "    #         seg for seg in ibd_seg_list\n",
        "    #         if seg[0] in community_ids or seg[1] in community_ids\n",
        "    #     ]\n",
        "    return filtered_ibd_seg_list\n",
        "\n",
        "# Filter the ibd_seg_list based on the community IDs\n",
        "filtered_ibd_seg_list_v1 = filter_ibd_seg_list(unphased_ibd_seg_list, target_community, both_in_community=True)\n",
        "# filtered_ibd_seg_list_v2 = filter_ibd_seg_list(ibd_seg_list, target_community, both_in_community=False)\n",
        "\n",
        "# Filter the bioinfo based on the community IDs\n",
        "filtered_bioinfo = [info for info in bioinfo if info['genotype_id'] in target_community]\n",
        "filtered_bioinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QSOmfangdGs"
      },
      "source": [
        "### Option 1\n",
        "\n",
        "Run Bonsai without selecting a focal_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEe5Hjxxgmn0"
      },
      "outputs": [],
      "source": [
        "from utils.bonsaitree.bonsaitree.v3 import bonsai\n",
        "\n",
        "up_dict_log_like_list = bonsai.build_pedigree(\n",
        "    bio_info=filtered_bioinfo,\n",
        "    unphased_ibd_seg_list=filtered_ibd_seg_list_v1,\n",
        "    min_seg_len=3\n",
        ")\n",
        "\n",
        "# Takes about 5 - 10 mintues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for element in up_dict_log_like_list:\n",
        "    print(f\"pedigree {element[0]}\")\n",
        "    print(f\"likelihood {element[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def save_pedigrees(up_dict_log_like_list, results_directory):\n",
        "    \"\"\"\n",
        "    Save pedigrees from up_dict_log_like_list to JSON files.\n",
        "    \n",
        "    Parameters:\n",
        "    up_dict_log_like_list -- List of tuples (pedigree_dict, log_likelihood)\n",
        "    results_directory -- Directory to save results\n",
        "    \"\"\"\n",
        "    for i, (pedigree, log_likelihood) in enumerate(up_dict_log_like_list):\n",
        "        # Convert all dictionary keys to strings for JSON compatibility\n",
        "        str_pedigree = {}\n",
        "        for key, value in pedigree.items():\n",
        "            str_key = str(key)\n",
        "            \n",
        "            if isinstance(value, dict):\n",
        "                str_value = {}\n",
        "                for sub_key, sub_value in value.items():\n",
        "                    str_value[str(sub_key)] = sub_value\n",
        "            else:\n",
        "                str_value = value\n",
        "                \n",
        "            str_pedigree[str_key] = str_value\n",
        "        \n",
        "        # Save the pedigree\n",
        "        file_path = os.path.join(results_directory, f'bonsai_normed_pedigree_{i+1}.json')\n",
        "        with open(file_path, 'w') as f:\n",
        "            json.dump(str_pedigree, f)\n",
        "            \n",
        "        # Save the likelihood in a separate file\n",
        "        likelihood_path = os.path.join(results_directory, f'bonsai_likelihood_{i+1}.txt')\n",
        "        with open(likelihood_path, 'w') as f:\n",
        "            f.write(str(log_likelihood))\n",
        "        \n",
        "        print(f\"Saved pedigree {i+1} to {file_path}\")\n",
        "        print(f\"Saved likelihood for pedigree {i+1} to {likelihood_path}\")\n",
        "\n",
        "# Example usage:\n",
        "save_pedigrees(up_dict_log_like_list, results_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "\n",
        "def graph_pedigree(pedigree_file, output_file=None):\n",
        "    # Load the pedigree\n",
        "    with open(pedigree_file, 'r') as f:\n",
        "        pedigree = json.load(f)\n",
        "    \n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "    \n",
        "    # Add nodes and edges\n",
        "    for child, parents in pedigree.items():\n",
        "        G.add_node(child)\n",
        "        for parent in parents:\n",
        "            G.add_node(parent)\n",
        "            G.add_edge(parent, child)  # Direction from parent to child\n",
        "    \n",
        "    # Set node colors: green for real individuals (positive IDs), white for latent (negative IDs)\n",
        "    node_colors = ['green' if not str(node).startswith('-') else 'white' for node in G.nodes()]\n",
        "    \n",
        "    # Calculate layout\n",
        "    pos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n",
        "    \n",
        "    # Create figure\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    # Draw the graph\n",
        "    nx.draw(G, pos, with_labels=True, node_color=node_colors, node_size=500, arrows=True)\n",
        "    \n",
        "    # Save or display\n",
        "    if output_file:\n",
        "        plt.savefig(output_file, dpi=300)\n",
        "        print(f\"Saved graph to {output_file}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "    \n",
        "    plt.close()\n",
        "    return G\n",
        "\n",
        "# Create directory for plots\n",
        "plot_dir = os.path.join(results_directory, 'pedigree_plots')\n",
        "os.makedirs(plot_dir, exist_ok=True)\n",
        "\n",
        "# Graph each saved pedigree\n",
        "for i in range(len(up_dict_log_like_list)):\n",
        "    pedigree_file = os.path.join(results_directory, f'bonsai_normed_pedigree_{i+1}.json')\n",
        "    output_file = os.path.join(plot_dir, f'pedigree_{i+1}.png')\n",
        "    graph_pedigree(pedigree_file, output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WxC8Ejzrz2-"
      },
      "source": [
        "## Plot the true graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpmXIAwrr2rc"
      },
      "outputs": [],
      "source": [
        "# Creates the true graph (does not display)\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "# Load the fam file into a DataFrame\n",
        "fam_df = pd.read_csv(f\"{data_directory}/class_data/ped_sim_run2-everyone.fam\", sep=\" \", header=None)\n",
        "fam_df.columns = [\"family_id\", \"individual_id\", \"father_id\", \"mother_id\", \"sex\", \"phenotype\"]\n",
        "\n",
        "# Load the seg_dict file into a DataFrame\n",
        "seg_dict_df = pd.read_csv(f\"{data_directory}/class_data/ped_sim_run2.seg_dict.txt\", sep=\"\\t\", header=None)\n",
        "seg_dict_df.columns = [\"individual_id\", \"bonsai_id\"]\n",
        "\n",
        "# Create a dictionary to map individual_id to bonsai_id\n",
        "individual_to_bonsai = dict(zip(seg_dict_df[\"individual_id\"], seg_dict_df[\"bonsai_id\"]))\n",
        "\n",
        "# Create a graph using the fam data\n",
        "fam_graph = nx.DiGraph()\n",
        "for _, row in fam_df.iterrows():\n",
        "    individual_id = row[\"individual_id\"]\n",
        "    father_id = row[\"father_id\"]\n",
        "    mother_id = row[\"mother_id\"]\n",
        "\n",
        "    # Use Bonsai ID if available, otherwise use the original name\n",
        "    individual_node = individual_to_bonsai.get(individual_id, individual_id)\n",
        "    fam_graph.add_node(individual_node)\n",
        "\n",
        "    if father_id != \"0\":\n",
        "        father_node = individual_to_bonsai.get(father_id, father_id)\n",
        "        fam_graph.add_edge(father_node, individual_node)\n",
        "\n",
        "    if mother_id != \"0\":\n",
        "        mother_node = individual_to_bonsai.get(mother_id, mother_id)\n",
        "        fam_graph.add_edge(mother_node, individual_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy0buUYGr8nI"
      },
      "outputs": [],
      "source": [
        "# Check the number of nodes and edges in the graph\n",
        "print(\"Number of nodes:\", fam_graph.number_of_nodes())\n",
        "print(\"Number of edges:\", fam_graph.number_of_edges())\n",
        "\n",
        "# Print a few nodes\n",
        "print(\"\\nNodes:\")\n",
        "for node in list(fam_graph.nodes())[:5]:\n",
        "    print(node)\n",
        "\n",
        "# Print a few edges\n",
        "print(\"\\nEdges:\")\n",
        "for edge in list(fam_graph.edges())[:5]:\n",
        "    print(edge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMpkrcJNtI7J"
      },
      "outputs": [],
      "source": [
        "# Find the target community individuals\n",
        "target_community_individual_ids = [seg_dict_df.loc[seg_dict_df[\"bonsai_id\"] == int(bonsai_id), \"individual_id\"].values[0] for bonsai_id in target_community]\n",
        "\n",
        "# Find all connected individuals (relatives and ancestors) of the target community\n",
        "connected_individuals = set()\n",
        "for individual_id in target_community_individual_ids:\n",
        "    connected_individuals.update(nx.descendants(fam_graph, individual_to_bonsai.get(individual_id, individual_id)))\n",
        "    connected_individuals.update(nx.ancestors(fam_graph, individual_to_bonsai.get(individual_id, individual_id)))\n",
        "connected_individuals.update(target_community_individual_ids)\n",
        "\n",
        "# Create the true graph for the target community and their connected individuals\n",
        "true_graph = nx.subgraph(fam_graph, [individual_to_bonsai.get(individual_id, individual_id) for individual_id in connected_individuals])\n",
        "\n",
        "# Check the number of nodes and edges in the graph\n",
        "print(\"Number of nodes:\", true_graph.number_of_nodes())\n",
        "print(\"Number of edges:\", true_graph.number_of_edges())\n",
        "\n",
        "# Print a few nodes\n",
        "print(\"\\nNodes:\")\n",
        "for node in list(true_graph.nodes())[:5]:\n",
        "    print(node)\n",
        "\n",
        "# Print a few edges\n",
        "print(\"\\nEdges:\")\n",
        "for edge in list(true_graph.edges())[:5]:\n",
        "    print(edge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ_EBErc5BtX"
      },
      "outputs": [],
      "source": [
        "# Create a PyGraphviz graph\n",
        "A = pgv.AGraph(directed=True)\n",
        "\n",
        "# Add nodes and edges to the PyGraphviz graph\n",
        "for node in true_graph.nodes():\n",
        "    A.add_node(node)\n",
        "    if node in [individual_to_bonsai.get(individual_id, individual_id) for individual_id in target_community_individual_ids]:\n",
        "        A.get_node(node).attr['color'] = 'green'\n",
        "    else:\n",
        "        A.get_node(node).attr['color'] = 'white'\n",
        "\n",
        "for edge in true_graph.edges():\n",
        "    parent, child = edge\n",
        "    A.add_edge(parent, child)\n",
        "\n",
        "# Set Graphviz layout options\n",
        "A.layout(prog='dot')\n",
        "\n",
        "# Save and display the graph\n",
        "graph_filename = f\"{results_directory}/true_graph_target_community.png\"\n",
        "A.draw(graph_filename, format='png')\n",
        "\n",
        "# Load and display the image\n",
        "img = mpimg.imread(graph_filename)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How does Bonsai compare to the ground truth?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OddqX4zY6H8O"
      },
      "source": [
        "## Exploring Bonsai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Basic pedigree construction with different parameters\n",
        "from utils.bonsaitree.bonsaitree.v3 import bonsai, constants\n",
        "\n",
        "# Try building with different minimum segment lengths\n",
        "up_dict_log_like_list_7cm = bonsai.build_pedigree(\n",
        "    bio_info=filtered_bioinfo,\n",
        "    unphased_ibd_seg_list=filtered_ibd_seg_list_v1,\n",
        "    min_seg_len=7  # More stringent minimum segment length\n",
        ")\n",
        "\n",
        "# Try with restricted connections\n",
        "up_dict_log_like_list_restricted = bonsai.build_pedigree(\n",
        "    bio_info=filtered_bioinfo,\n",
        "    unphased_ibd_seg_list=filtered_ibd_seg_list_v1,\n",
        "    min_seg_len=3,\n",
        "    restrict_connection_points=True\n",
        ")\n",
        "\n",
        "print(f\"Number of pedigrees with 3cM threshold: {len(up_dict_log_like_list)}\")\n",
        "print(f\"Number of pedigrees with 7cM threshold: {len(up_dict_log_like_list_7cm)}\")\n",
        "print(f\"Number of pedigrees with restricted connections: {len(up_dict_log_like_list_restricted)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Examine pedigree likelihood differences\n",
        "if len(up_dict_log_like_list) > 1:\n",
        "    for i, (pedigree, log_like) in enumerate(up_dict_log_like_list):\n",
        "        print(f\"Pedigree {i+1} log likelihood: {log_like}\")\n",
        "        \n",
        "    # Calculate likelihood ratio between best and second best\n",
        "    if len(up_dict_log_like_list) >= 2:\n",
        "        best_ll = up_dict_log_like_list[0][1]\n",
        "        second_best_ll = up_dict_log_like_list[1][1]\n",
        "        likelihood_ratio = np.exp(best_ll - second_best_ll)\n",
        "        print(f\"Likelihood ratio between best and second-best pedigree: {likelihood_ratio:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Analyze the top pedigree from Bonsai\n",
        "if up_dict_log_like_list:\n",
        "    top_pedigree = up_dict_log_like_list[0][0]\n",
        "    \n",
        "    # Count individuals by type\n",
        "    real_individuals = [node for node in top_pedigree.keys() if isinstance(node, int) and node > 0]\n",
        "    inferred_ancestors = [node for node in top_pedigree.keys() if isinstance(node, int) and node < 0]\n",
        "    \n",
        "    print(f\"Top pedigree has {len(real_individuals)} real individuals\")\n",
        "    print(f\"Top pedigree has {len(inferred_ancestors)} inferred ancestors\")\n",
        "    \n",
        "    # Analyze pedigree depth (maximum generations)\n",
        "    max_depth = 0\n",
        "    for node in real_individuals:\n",
        "        depth = 0\n",
        "        current = node\n",
        "        while current in top_pedigree and top_pedigree[current]:\n",
        "            parent = list(top_pedigree[current].keys())[0]  # Get first parent\n",
        "            current = parent\n",
        "            depth += 1\n",
        "        max_depth = max(max_depth, depth)\n",
        "    \n",
        "    print(f\"Maximum depth in the pedigree: {max_depth} generations\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Find potential siblings in the pedigree\n",
        "def find_siblings(pedigree):\n",
        "    # Group children by their parents\n",
        "    parent_to_children = {}\n",
        "    for child, parents in pedigree.items():\n",
        "        if not parents:  # Skip nodes with no parents\n",
        "            continue\n",
        "        \n",
        "        # Convert parents dict to a frozenset for use as dictionary key\n",
        "        parent_key = frozenset(parents.keys())\n",
        "        if parent_key not in parent_to_children:\n",
        "            parent_to_children[parent_key] = []\n",
        "        parent_to_children[parent_key].append(child)\n",
        "    \n",
        "    # Return sibling groups (only those with at least 2 siblings)\n",
        "    sibling_groups = [children for children in parent_to_children.values() if len(children) >= 2]\n",
        "    return sibling_groups\n",
        "\n",
        "if up_dict_log_like_list:\n",
        "    top_pedigree = up_dict_log_like_list[0][0]\n",
        "    sibling_groups = find_siblings(top_pedigree)\n",
        "    \n",
        "    print(f\"Found {len(sibling_groups)} sibling groups:\")\n",
        "    for i, group in enumerate(sibling_groups):\n",
        "        real_siblings = [s for s in group if isinstance(s, int) and s > 0]\n",
        "        print(f\"Group {i+1}: {real_siblings}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Compare multiple communities using Bonsai\n",
        "def compare_communities(communities, bioinfo, ibd_seg_list):\n",
        "    results = {}\n",
        "    \n",
        "    for i, community in enumerate(communities[:3]):  # Compare first 3 communities\n",
        "        print(f\"Analyzing community {i+1} with {len(community)} members\")\n",
        "        \n",
        "        # Filter bioinfo and IBD segments for this community\n",
        "        community_bioinfo = [info for info in bioinfo if info['genotype_id'] in community]\n",
        "        \n",
        "        community_ibd = [\n",
        "            seg for seg in ibd_seg_list\n",
        "            if seg[0] in community and seg[1] in community\n",
        "        ]\n",
        "        \n",
        "        # Run Bonsai\n",
        "        up_dict_log_like_list = bonsai.build_pedigree(\n",
        "            bio_info=community_bioinfo,\n",
        "            unphased_ibd_seg_list=community_ibd,\n",
        "            min_seg_len=3\n",
        "        )\n",
        "        \n",
        "        if up_dict_log_like_list:\n",
        "            top_pedigree = up_dict_log_like_list[0][0]\n",
        "            top_likelihood = up_dict_log_like_list[0][1]\n",
        "            \n",
        "            results[i] = {\n",
        "                \"size\": len(community),\n",
        "                \"pedigree\": top_pedigree,\n",
        "                \"likelihood\": top_likelihood,\n",
        "                \"real_individuals\": len([n for n in top_pedigree.keys() if isinstance(n, int) and n > 0]),\n",
        "                \"inferred_ancestors\": len([n for n in top_pedigree.keys() if isinstance(n, int) and n < 0])\n",
        "            }\n",
        "    \n",
        "    return results\n",
        "\n",
        "compare_communities(communities_v2, bioinfo, unphased_ibd_seg_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Analyze specific relationships in the pedigree\n",
        "def analyze_relationship(pedigree, id1, id2):\n",
        "    \"\"\"Find the relationship between two individuals in the pedigree\"\"\"\n",
        "    \n",
        "    # Find path from id1 to root\n",
        "    path1 = []\n",
        "    current = id1\n",
        "    while current in pedigree and pedigree[current]:\n",
        "        parent = list(pedigree[current].keys())[0]  # Get first parent\n",
        "        path1.append((current, parent))\n",
        "        current = parent\n",
        "    \n",
        "    # Find path from id2 to root\n",
        "    path2 = []\n",
        "    current = id2\n",
        "    while current in pedigree and pedigree[current]:\n",
        "        parent = list(pedigree[current].keys())[0]  # Get first parent\n",
        "        path2.append((current, parent))\n",
        "        current = parent\n",
        "    \n",
        "    # Find common ancestor\n",
        "    common_ancestors = set([p for _, p in path1]) & set([p for _, p in path2])\n",
        "    if not common_ancestors:\n",
        "        return \"No relationship found\"\n",
        "    \n",
        "    # Find closest common ancestor\n",
        "    degrees = {}\n",
        "    for ancestor in common_ancestors:\n",
        "        degree1 = [p for _, p in path1].index(ancestor)\n",
        "        degree2 = [p for _, p in path2].index(ancestor)\n",
        "        degrees[ancestor] = (degree1, degree2)\n",
        "    \n",
        "    closest = min(degrees.items(), key=lambda x: sum(x[1]))\n",
        "    ancestor, (deg1, deg2) = closest\n",
        "    \n",
        "    # Interpret relationship\n",
        "    if deg1 == 0 and deg2 > 0:\n",
        "        return f\"{id1} is an ancestor of {id2}, {deg2} generations removed\"\n",
        "    elif deg2 == 0 and deg1 > 0:\n",
        "        return f\"{id2} is an ancestor of {id1}, {deg1} generations removed\"\n",
        "    elif deg1 == 1 and deg2 == 1:\n",
        "        return f\"{id1} and {id2} are siblings\"\n",
        "    elif deg1 == 1 and deg2 == 2:\n",
        "        return f\"{id1} is an aunt/uncle of {id2}\"\n",
        "    elif deg1 == 2 and deg2 == 1:\n",
        "        return f\"{id2} is an aunt/uncle of {id1}\"\n",
        "    elif deg1 == 2 and deg2 == 2:\n",
        "        return f\"{id1} and {id2} are first cousins\"\n",
        "    else:\n",
        "        return f\"{id1} and {id2} are related with common ancestor {ancestor}, {deg1} and {deg2} generations removed\"\n",
        "\n",
        "# Example usage\n",
        "if up_dict_log_like_list:\n",
        "    top_pedigree = up_dict_log_like_list[0][0]\n",
        "    \n",
        "    # Find relationships between several pairs of individuals\n",
        "    id_pairs = [(1000, 1003), (1005, 1007), (1010, 1015)]\n",
        "    for id1, id2 in id_pairs:\n",
        "        relationship = analyze_relationship(top_pedigree, id1, id2)\n",
        "        print(f\"Relationship between {id1} and {id2}: {relationship}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Validate Bonsai pedigree against truth (if available)\n",
        "def compare_to_truth(inferred_pedigree, truth_pedigree):\n",
        "    \"\"\"Compare the inferred pedigree to ground truth\"\"\"\n",
        "    \n",
        "    # Get all real individuals in both pedigrees\n",
        "    inferred_real_ids = [id for id in inferred_pedigree.keys() if isinstance(id, int) and id > 0]\n",
        "    truth_real_ids = [id for id in truth_pedigree.keys() if isinstance(id, int) and id > 0]\n",
        "    \n",
        "    common_ids = set(inferred_real_ids) & set(truth_real_ids)\n",
        "    print(f\"Common individuals: {len(common_ids)}\")\n",
        "    \n",
        "    # Check parent-child relationships\n",
        "    correct_relationships = 0\n",
        "    incorrect_relationships = 0\n",
        "    \n",
        "    for child in common_ids:\n",
        "        if child in inferred_pedigree and child in truth_pedigree:\n",
        "            inferred_parents = set(inferred_pedigree[child].keys())\n",
        "            truth_parents = set(truth_pedigree[child].keys())\n",
        "            \n",
        "            # In the inferred pedigree, parents are often inferred ancestors\n",
        "            # So we need to trace up to find real parents for comparison\n",
        "            \n",
        "            # This is a simplified approach:\n",
        "            if any(p in truth_parents for p in inferred_parents):\n",
        "                correct_relationships += 1\n",
        "            else:\n",
        "                incorrect_relationships += 1\n",
        "    \n",
        "    print(f\"Correctly inferred relationships: {correct_relationships}\")\n",
        "    print(f\"Incorrectly inferred relationships: {incorrect_relationships}\")\n",
        "    \n",
        "    accuracy = correct_relationships / (correct_relationships + incorrect_relationships) if (correct_relationships + incorrect_relationships) > 0 else 0\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "compare_to_truth(top_pedigree, truth_pedigree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Plot IBD sharing vs relationship degree in the pedigree\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_ibd_vs_relationship(pedigree, ibd_seg_list):\n",
        "    \"\"\"Plot the relationship between IBD sharing and relationship degree\"\"\"\n",
        "    # Calculate total IBD sharing between all pairs\n",
        "    ibd_sharing = {}\n",
        "    for seg in ibd_seg_list:\n",
        "        id1, id2 = seg[0], seg[1]\n",
        "        pair = tuple(sorted([id1, id2]))\n",
        "        ibd_sharing[pair] = ibd_sharing.get(pair, 0) + seg[6]  # Add segment length\n",
        "    \n",
        "    # Analyze relationships in the pedigree\n",
        "    relationships = []\n",
        "    ibd_amounts = []\n",
        "    \n",
        "    for pair, ibd_amount in ibd_sharing.items():\n",
        "        id1, id2 = pair\n",
        "        if id1 in pedigree and id2 in pedigree:\n",
        "            relationship = analyze_relationship(pedigree, id1, id2)\n",
        "            # Extract degree from relationship string (simplified)\n",
        "            if \"generations removed\" in relationship:\n",
        "                try:\n",
        "                    degree = sum([int(s) for s in relationship.split() if s.isdigit()])\n",
        "                    relationships.append(degree)\n",
        "                    ibd_amounts.append(ibd_amount)\n",
        "                except:\n",
        "                    pass\n",
        "    \n",
        "    # Plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=relationships, y=ibd_amounts)\n",
        "    plt.xlabel(\"Relationship Degree\")\n",
        "    plt.ylabel(\"Total IBD Sharing (cM)\")\n",
        "    plt.title(\"IBD Sharing vs Relationship Degree\")\n",
        "    plt.show()\n",
        "\n",
        "plot_ibd_vs_relationship(top_pedigree, filtered_ibd_seg_list_v1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10. Export pedigree in a standard format (e.g., GEDCOM-like)\n",
        "def export_pedigree(pedigree, bioinfo, output_file):\n",
        "    \"\"\"Export the pedigree in a standard format\"\"\"\n",
        "    # Create a mapping of ID to sex and age\n",
        "    id_to_info = {info['genotype_id']: (info['sex'], info['age']) for info in bioinfo}\n",
        "    \n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"# Exported Pedigree\\n\")\n",
        "        f.write(\"# Format: ID Sex Age Parent1 Parent2\\n\")\n",
        "        \n",
        "        # Process all individuals, starting with real ones\n",
        "        real_ids = sorted([id for id in pedigree.keys() if isinstance(id, int) and id > 0])\n",
        "        inferred_ids = sorted([id for id in pedigree.keys() if isinstance(id, int) and id < 0])\n",
        "        \n",
        "        # Write real individuals first\n",
        "        for id in real_ids:\n",
        "            sex, age = id_to_info.get(id, ('U', 0))\n",
        "            parents = list(pedigree.get(id, {}).keys())\n",
        "            parent1 = parents[0] if len(parents) > 0 else 0\n",
        "            parent2 = parents[1] if len(parents) > 1 else 0\n",
        "            \n",
        "            f.write(f\"{id} {sex} {age} {parent1} {parent2}\\n\")\n",
        "        \n",
        "        # Then write inferred individuals\n",
        "        for id in inferred_ids:\n",
        "            # For inferred individuals, we can assume they're one generation older than their children\n",
        "            children = [child for child, parents in pedigree.items() if id in parents]\n",
        "            \n",
        "            # Infer sex based on placement if possible\n",
        "            inferred_sex = 'U'  # Unknown\n",
        "            \n",
        "            # Infer approximate age based on children's ages if possible\n",
        "            inferred_age = 0\n",
        "            for child in children:\n",
        "                if child in id_to_info:\n",
        "                    child_age = id_to_info[child][1]\n",
        "                    if inferred_age == 0 or child_age + 20 < inferred_age:\n",
        "                        inferred_age = child_age + 20\n",
        "            \n",
        "            parents = list(pedigree.get(id, {}).keys())\n",
        "            parent1 = parents[0] if len(parents) > 0 else 0\n",
        "            parent2 = parents[1] if len(parents) > 1 else 0\n",
        "            \n",
        "            f.write(f\"{id} {inferred_sex} {inferred_age} {parent1} {parent2}\\n\")\n",
        "    \n",
        "    print(f\"Pedigree exported to {output_file}\")\n",
        "\n",
        "# Example usage\n",
        "if up_dict_log_like_list:\n",
        "    export_pedigree(\n",
        "        up_dict_log_like_list[0][0], \n",
        "        filtered_bioinfo, \n",
        "        os.path.join(results_directory, 'exported_pedigree.txt')\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conver this notebook to PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!poetry run jupyter nbconvert --to pdf Lab11_Bonsai.ipynb"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
