{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Lab 14: Optimizing Small Pedigree Configurations\n\n## Overview\n\nIn this lab, we'll explore techniques for optimizing small pedigree configurations in Bonsai v3. Building on our understanding of small pedigree structures from Lab 13, we'll focus on methods to evaluate and optimize these structures to best explain observed genetic data. We'll examine how Bonsai systematically explores alternative configurations to find the most likely pedigree that explains IBD sharing patterns.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Standard imports\nimport os\nimport sys\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport networkx as nx\nfrom IPython.display import display, HTML, Markdown\nimport inspect\nimport importlib\nimport copy\nimport random\nimport math\nimport itertools\nfrom collections import defaultdict\n\nsys.path.append(os.path.dirname(os.getcwd()))\n\n# Cross-compatibility setup\nfrom scripts_support.lab_cross_compatibility import setup_environment, is_jupyterlite, save_results, save_plot\n\n# Set up environment-specific paths\nDATA_DIR, RESULTS_DIR = setup_environment()\n\n# Set visualization styles\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_context(\"notebook\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Setup Bonsai module paths\nif not is_jupyterlite():\n    # In local environment, add the utils directory to system path\n    utils_dir = os.getenv('PROJECT_UTILS_DIR', os.path.join(os.path.dirname(DATA_DIR), 'utils'))\n    bonsaitree_dir = os.path.join(utils_dir, 'bonsaitree')\n    \n    # Add to path if it exists and isn't already there\n    if os.path.exists(bonsaitree_dir) and bonsaitree_dir not in sys.path:\n        sys.path.append(bonsaitree_dir)\n        print(f\"Added {bonsaitree_dir} to sys.path\")\nelse:\n    # In JupyterLite, use a simplified approach\n    print(\"⚠️ Running in JupyterLite: Some Bonsai functionality may be limited.\")\n    print(\"This notebook is primarily designed for local execution where the Bonsai codebase is available.\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Helper functions for exploring modules\ndef display_module_classes(module_name):\n    \"\"\"Display classes and their docstrings from a module\"\"\"\n    try:\n        # Import the module\n        module = importlib.import_module(module_name)\n        \n        # Find all classes\n        classes = inspect.getmembers(module, inspect.isclass)\n        \n        # Filter classes defined in this module (not imported)\n        classes = [(name, cls) for name, cls in classes if cls.__module__ == module_name]\n        \n        # Print info for each class\n        for name, cls in classes:\n            print(f\"\\n## {name}\")\n            \n            # Get docstring\n            doc = inspect.getdoc(cls)\n            if doc:\n                print(f\"Docstring: {doc}\")\n            else:\n                print(\"No docstring available\")\n            \n            # Get methods\n            methods = inspect.getmembers(cls, inspect.isfunction)\n            if methods:\n                print(\"\\nMethods:\")\n                for method_name, method in methods:\n                    if not method_name.startswith('_'):  # Skip private methods\n                        print(f\"- {method_name}\")\n    except ImportError as e:\n        print(f\"Error importing module {module_name}: {e}\")\n    except Exception as e:\n        print(f\"Error processing module {module_name}: {e}\")\n\ndef display_module_functions(module_name):\n    \"\"\"Display functions and their docstrings from a module\"\"\"\n    try:\n        # Import the module\n        module = importlib.import_module(module_name)\n        \n        # Find all functions\n        functions = inspect.getmembers(module, inspect.isfunction)\n        \n        # Filter functions defined in this module (not imported)\n        functions = [(name, func) for name, func in functions if func.__module__ == module_name]\n        \n        # Print info for each function\n        for name, func in functions:\n            if name.startswith('_'):  # Skip private functions\n                continue\n                \n            print(f\"\\n## {name}\")\n            \n            # Get signature\n            sig = inspect.signature(func)\n            print(f\"Signature: {name}{sig}\")\n            \n            # Get docstring\n            doc = inspect.getdoc(func)\n            if doc:\n                print(f\"Docstring: {doc}\")\n            else:\n                print(\"No docstring available\")\n    except ImportError as e:\n        print(f\"Error importing module {module_name}: {e}\")\n    except Exception as e:\n        print(f\"Error processing module {module_name}: {e}\")\n\ndef view_source(obj):\n    \"\"\"Display the source code of an object (function or class)\"\"\"\n    try:\n        source = inspect.getsource(obj)\n        display(Markdown(f\"```python\\n{source}\\n```\"))\n    except Exception as e:\n        print(f\"Error retrieving source: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Check Bonsai Installation\n\nLet's verify that the Bonsai v3 module is available for import:",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "try:\n    from utils.bonsaitree.bonsaitree import v3\n    print(\"✅ Successfully imported Bonsai v3 module\")\nexcept ImportError as e:\n    print(f\"❌ Failed to import Bonsai v3 module: {e}\")\n    print(\"This lab requires access to the Bonsai v3 codebase.\")\n    print(\"Make sure you've properly set up your environment with the Bonsai repository.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Lab 14: Optimizing Small Pedigree Configurations\n\nIn this lab, we'll delve into the techniques Bonsai v3 uses to optimize small pedigree configurations. This optimization process is crucial for finding the most likely pedigree structure that explains observed genetic data. We'll explore:\n\n1. How to evaluate different pedigree configurations based on genetic data\n2. Methods to systematically search through the space of possible configurations\n3. Algorithms for finding the optimal configuration that maximizes likelihood\n4. Techniques for handling ambiguous or competing hypotheses\n\nThis process builds on our previous understanding of constructing small pedigree structures and will serve as a foundation for scaling to larger pedigrees in future labs.",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 1: Evaluating Pedigree Configurations\n\nThe first step in optimizing pedigree configurations is being able to evaluate how well different configurations explain the observed genetic data. Let's explore how Bonsai v3 approaches this evaluation process.",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Import key functions from Bonsai v3\nfrom utils.bonsaitree.bonsaitree.v3.pedigrees import (\n    get_possible_connection_point_set,\n    get_partner_id_set,\n    add_parent,\n    get_min_id,\n    reverse_node_dict,\n    get_simple_rel_tuple,\n    get_unconnected_indivs_in_pedigree,\n    get_descendants,\n    get_ancestors\n)\n\nfrom utils.bonsaitree.bonsaitree.v3.connections import (\n    get_likelihood_of_relationship\n)\n\n# For visualization\ndef visualize_pedigree(up_node_dict, title=\"Pedigree\", highlight_nodes=None, individual_metadata=None):\n    \"\"\"Visualize a pedigree from an up_node_dict using networkx.\n    \n    Args:\n        up_node_dict: Dictionary mapping individuals to their parents\n        title: Title for the visualization\n        highlight_nodes: Set of nodes to highlight\n        individual_metadata: Dictionary mapping individuals to their metadata (age, sex, etc.)\n    \"\"\"\n    # Create a directed graph (edges point from child to parent)\n    G = nx.DiGraph()\n    \n    # Add all nodes to the graph (combine all IDs from keys and values)\n    all_ids = set(up_node_dict.keys())\n    for parents in up_node_dict.values():\n        all_ids.update(parents.keys())\n    \n    # Create node labels\n    node_labels = {}\n    for node_id in all_ids:\n        label = str(node_id)\n        if individual_metadata and node_id in individual_metadata:\n            metadata = individual_metadata[node_id]\n            if 'sex' in metadata and metadata['sex']:\n                label += f\" ({metadata['sex']})\"\n            if 'age' in metadata and metadata['age'] is not None:\n                label += f\"\\\\nAge: {metadata['age']}\"\n        node_labels[node_id] = label\n    \n    # Create a color map - blue for males, pink for females, gray for unknown\n    highlight_nodes = highlight_nodes or set()\n    color_map = []\n    for node_id in all_ids:\n        if node_id in highlight_nodes:\n            color_map.append('red')\n        elif individual_metadata and node_id in individual_metadata and 'sex' in individual_metadata[node_id]:\n            if individual_metadata[node_id]['sex'] == 'M':\n                color_map.append('lightblue')\n            elif individual_metadata[node_id]['sex'] == 'F':\n                color_map.append('pink')\n            else:\n                color_map.append('lightgray')\n        else:\n            color_map.append('lightgray')\n    \n    # Add edges (from child to parent)\n    edges = []\n    for child, parents in up_node_dict.items():\n        for parent in parents:\n            edges.append((child, parent))\n    \n    G.add_edges_from(edges)\n    \n    # Create plot\n    plt.figure(figsize=(10, 6))\n    plt.title(title)\n    \n    # Layout: By default, parents are shown above children (opposite arrow direction)\n    pos = nx.spring_layout(G, seed=42)  # For reproducibility, use a fixed seed\n    \n    # Draw nodes\n    nx.draw(G, pos, with_labels=True, labels=node_labels, node_color=color_map, \n            node_size=800, font_weight='bold')\n    \n    # Draw edges\n    nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5, arrows=True)\n    \n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# For JupyterLite compatibility, provide simplified implementations\nif is_jupyterlite():\n    def reverse_node_dict(dct):\n        \"\"\"Reverse a node dict. If it's a down dict make it an up dict and vice versa.\"\"\"\n        rev_dct = {}\n        for i, info in dct.items():\n            for a, d in info.items():\n                if a not in rev_dct:\n                    rev_dct[a] = {}\n                rev_dct[a][i] = d\n        return rev_dct\n    \n    def get_min_id(dct):\n        \"\"\"Get the minimal ID in a node dict.\"\"\"\n        all_ids = set(dct.keys())\n        for parents in dct.values():\n            all_ids.update(parents.keys())\n        min_id = min(all_ids) if all_ids else 0\n        return min(-1, min_id)  # ensure ID is negative\n    \n    def add_parent(node, up_dct, min_id=None):\n        \"\"\"Add an ungenotyped parent to node in up_dct.\"\"\"\n        import copy\n        up_dct = copy.deepcopy(up_dct)\n        \n        if node not in up_dct:\n            raise ValueError(f\"Node {node} is not in up dct.\")\n            \n        pid_dict = up_dct[node]\n        if len(pid_dict) >= 2:\n            return up_dct, None\n            \n        if min_id is None:\n            min_id = get_min_id(up_dct)\n            \n        new_pid = min_id - 1\n        up_dct[node][new_pid] = 1\n        up_dct[new_pid] = {}\n        \n        return up_dct, new_pid\n    \n    def get_partner_id_set(node, up_dct):\n        \"\"\"Find the set of partners of node in pedigree up_dct.\"\"\"\n        down_dct = reverse_node_dict(up_dct)\n        child_id_set = {c for c, d in down_dct.get(node, {}).items() if d == 1}\n        partner_id_set = set()\n        for cid in child_id_set:\n            pids = {p for p, d in up_dct.get(cid, {}).items() if d == 1}\n            partner_id_set |= pids\n        partner_id_set -= {node}\n        return partner_id_set\n    \n    def get_simple_rel_tuple(up_node_dict, i, j):\n        \"\"\"Get relationship tuple (up, down, num_ancs) between individuals i and j.\"\"\"\n        if i == j:\n            return (0, 0, 2)\n        \n        # Simple implementation for JupyterLite - this would be more complex in reality\n        if j in up_node_dict.get(i, {}):\n            return (1, 0, 1)  # i is child of j\n        elif i in up_node_dict.get(j, {}):\n            return (0, 1, 1)  # i is parent of j\n        \n        # Check for siblings/cousins (simplified)\n        i_parents = set(up_node_dict.get(i, {}).keys())\n        j_parents = set(up_node_dict.get(j, {}).keys())\n        common_parents = i_parents.intersection(j_parents)\n        \n        if common_parents:\n            if len(common_parents) == 2:\n                return (1, 1, 2)  # Full siblings\n            else:\n                return (1, 1, 1)  # Half siblings\n        \n        # Default - no relationship found\n        return None\n    \n    def get_possible_connection_point_set(ped):\n        \"\"\"Find all possible points through which a pedigree can be connected to another pedigree.\"\"\"\n        point_set = set()\n        all_ids = set(ped.keys())\n        for parents in ped.values():\n            all_ids.update(parents.keys())\n            \n        for a in all_ids:\n            parent_to_deg = ped.get(a, {})\n            if len(parent_to_deg) < 2:\n                point_set.add((a, None, 1))  # Can connect upward\n                \n            partners = get_partner_id_set(a, ped)\n            point_set.add((a, None, 0))  # Can connect downward\n            for partner in partners:\n                if (partner, a, 0) not in point_set:\n                    point_set.add((a, partner, 0))\n                point_set.add((a, partner, None))\n                \n            point_set.add((a, None, None))  # Can replace node\n            \n        return point_set\n    \n    def get_unconnected_indivs_in_pedigree(up_node_dict):\n        \"\"\"Get all individuals in the pedigree not connected to each other.\"\"\"\n        # Get all IDs in the pedigree\n        all_ids = set(up_node_dict.keys())\n        for parents in up_node_dict.values():\n            all_ids.update(parents.keys())\n        \n        # For a simplified version, we'll just return individual nodes\n        # This is not accurate for real pedigrees but works for JupyterLite demo\n        result = []\n        for id_val in all_ids:\n            result.append([id_val])\n        \n        return result\n    \n    def get_descendants(node, up_node_dict):\n        \"\"\"Get all descendants of node in pedigree up_node_dict.\"\"\"\n        descendants = set()\n        down_dict = reverse_node_dict(up_node_dict)\n        \n        # BFS to find all descendants\n        queue = [node]\n        while queue:\n            current = queue.pop(0)\n            for child in down_dict.get(current, {}):\n                if child not in descendants:\n                    descendants.add(child)\n                    queue.append(child)\n        \n        return descendants\n    \n    def get_ancestors(node, up_node_dict):\n        \"\"\"Get all ancestors of node in pedigree up_node_dict.\"\"\"\n        ancestors = set()\n        \n        # BFS to find all ancestors\n        queue = [node]\n        while queue:\n            current = queue.pop(0)\n            for parent in up_node_dict.get(current, {}):\n                if parent not in ancestors:\n                    ancestors.add(parent)\n                    queue.append(parent)\n        \n        return ancestors\n    \n    def get_likelihood_of_relationship(pedigree, i, j, ibd_data):\n        \"\"\"Calculate likelihood of relationship between i and j based on IBD data.\"\"\"\n        # Simple implementation for JupyterLite\n        rel_tuple = get_simple_rel_tuple(pedigree, i, j)\n        if rel_tuple is None:\n            return -100  # Highly unlikely if no relationship is found\n        \n        up, down, num_ancs = rel_tuple\n        degree = up + down\n        \n        # Simplified likelihood calculation based on degree\n        # In reality, this would be much more complex\n        if (i, j) in ibd_data or (j, i) in ibd_data:\n            pair = (i, j) if (i, j) in ibd_data else (j, i)\n            segments = ibd_data[pair]\n            total_cm = sum(seg[\"length_cm\"] for seg in segments)\n            \n            # Different relationships have different expected amounts of IBD\n            if degree == 0:  # Self\n                expected_total_cm = 3400\n            elif degree == 1:  # Parent-child\n                expected_total_cm = 3400 / 2\n            elif degree == 2 and num_ancs == 2:  # Full siblings\n                expected_total_cm = 2550\n            elif degree == 2 and num_ancs == 1:  # Half siblings/grandparents\n                expected_total_cm = 1700\n            elif degree == 3:  # First cousins once removed\n                expected_total_cm = 850\n            elif degree == 4:  # Second cousins\n                expected_total_cm = 425\n            elif degree == 5:  # Second cousins once removed\n                expected_total_cm = 212.5\n            elif degree == 6:  # Third cousins\n                expected_total_cm = 106.25\n            else:  # More distant\n                expected_total_cm = 53.125\n            \n            # Calculate log-likelihood\n            std_dev = expected_total_cm * 0.2  # 20% variation\n            if std_dev > 0:\n                log_likelihood = -0.5 * ((total_cm - expected_total_cm) / std_dev) ** 2 - math.log(std_dev)\n                return log_likelihood\n        \n        # Default value for no IBD data\n        return -10",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": "### 1.1 Generating IBD Data\n\nBefore we can evaluate and optimize pedigree configurations, we need genetic data to work with. In real-world scenarios, this would be IBD (Identity by Descent) segments detected between individuals. Let's create a simulation function to generate IBD data for our examples:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "def simulate_ibd_segments(rel_tuple, num_segments=10, noise_level=0.2):\n    \"\"\"Simulate IBD segments for a given relationship tuple.\n    \n    Args:\n        rel_tuple: (up, down, num_ancs) tuple representing the relationship\n        num_segments: Number of segments to simulate\n        noise_level: Level of noise to add to segment lengths\n        \n    Returns:\n        segments: List of simulated IBD segments\n    \"\"\"\n    if rel_tuple is None:\n        return []  # No relationship, no IBD\n    \n    up, down, num_ancs = rel_tuple\n    degree = up + down\n    \n    # Different relationships have different expected amounts of IBD\n    if degree == 0:  # Self\n        expected_total_cm = 3400  # Entire genome\n        avg_segment_cm = 340\n    elif degree == 1:  # Parent-child\n        expected_total_cm = 3400 / 2  # Half the genome\n        avg_segment_cm = 170\n    elif degree == 2 and num_ancs == 2:  # Full siblings\n        expected_total_cm = 2550  # ~75% of the genome\n        avg_segment_cm = 85\n    elif degree == 2 and num_ancs == 1:  # Half siblings/grandparents\n        expected_total_cm = 1700  # ~50% of the genome\n        avg_segment_cm = 42.5\n    elif degree == 3:  # First cousins once removed\n        expected_total_cm = 850  # ~25% of the genome\n        avg_segment_cm = 21.25\n    elif degree == 4:  # Second cousins\n        expected_total_cm = 425  # ~12.5% of the genome\n        avg_segment_cm = 10.6\n    elif degree == 5:  # Second cousins once removed\n        expected_total_cm = 212.5  # ~6.25% of the genome\n        avg_segment_cm = 5.3\n    elif degree == 6:  # Third cousins\n        expected_total_cm = 106.25  # ~3.125% of the genome\n        avg_segment_cm = 5.3 / 2\n    else:  # More distant\n        expected_total_cm = 53.125  # ~1.5625% of the genome\n        avg_segment_cm = 5.3 / 4\n    \n    # Generate simulated segments\n    segments = []\n    chromosomes = list(range(1, 23))  # Chromosomes 1-22\n    \n    for _ in range(num_segments):\n        # Select a random chromosome\n        chromosome = random.choice(chromosomes)\n        \n        # Generate a segment length with some noise\n        segment_cm = avg_segment_cm * (1 + noise_level * (random.random() - 0.5))\n        \n        # Generate random start and end positions (in genetic distance)\n        max_pos = 100 + 20 * chromosome  # Approximate chromosome length\n        start_cm = random.uniform(0, max_pos - segment_cm)\n        end_cm = start_cm + segment_cm\n        \n        segments.append({\n            \"chromosome\": chromosome,\n            \"start_cm\": start_cm,\n            \"end_cm\": end_cm,\n            \"length_cm\": segment_cm\n        })\n    \n    return segments\n\ndef simulate_pedigree_ibd(pedigree, genotyped_ids=None):\n    \"\"\"Simulate IBD segments for all genotyped individuals in a pedigree.\n    \n    Args:\n        pedigree: Up-node dictionary representing the pedigree\n        genotyped_ids: List of IDs to simulate (defaults to all positive IDs)\n        \n    Returns:\n        ibd_data: Dictionary mapping pairs of IDs to their simulated IBD segments\n    \"\"\"\n    # If no genotyped IDs are provided, use all positive IDs\n    if genotyped_ids is None:\n        all_ids = set(pedigree.keys()).union(*[set(parents.keys()) for parents in pedigree.values()])\n        genotyped_ids = [i for i in all_ids if i > 0]\n    \n    # Create a dictionary to store IBD segments for each pair\n    ibd_data = {}\n    \n    # For each pair of genotyped individuals\n    for i in range(len(genotyped_ids)):\n        for j in range(i + 1, len(genotyped_ids)):\n            id1 = genotyped_ids[i]\n            id2 = genotyped_ids[j]\n            \n            # Get the relationship tuple\n            rel_tuple = get_simple_rel_tuple(pedigree, id1, id2)\n            \n            # Simulate IBD segments based on the relationship\n            segments = simulate_ibd_segments(rel_tuple)\n            \n            # Store the segments\n            pair_key = (id1, id2)\n            ibd_data[pair_key] = segments\n    \n    return ibd_data",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": "### 1.2 Creating Sample Pedigree Configurations\n\nLet's create some sample pedigree configurations to work with. We'll define several alternative configurations to demonstrate how Bonsai evaluates and optimizes them."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Helper functions to create various pedigree structures\ndef create_parent_child_unit(child_id, parent1_id=None, parent2_id=None):\n    \"\"\"Create a simple parent-child unit.\"\"\"\n    pedigree = {child_id: {}}\n    \n    # Create first parent if not provided\n    if parent1_id is None:\n        min_id = get_min_id(pedigree)\n        parent1_id = min_id - 1\n    \n    # Add first parent\n    pedigree[child_id][parent1_id] = 1\n    if parent1_id not in pedigree:\n        pedigree[parent1_id] = {}\n    \n    # Add second parent if needed\n    if parent2_id is not None:\n        pedigree[child_id][parent2_id] = 1\n        if parent2_id not in pedigree:\n            pedigree[parent2_id] = {}\n    elif parent2_id is None and parent1_id is not None:\n        # Add an ungenotyped second parent\n        pedigree, new_parent_id = add_parent(child_id, pedigree)\n        if new_parent_id not in pedigree:\n            pedigree[new_parent_id] = {}\n    \n    return pedigree\n\ndef create_sibling_group(child_ids, parent1_id=None, parent2_id=None):\n    \"\"\"Create a sibling group with the specified children and parents.\"\"\"\n    # Initialize an empty pedigree\n    pedigree = {}\n    \n    # Create entries for each child\n    for child_id in child_ids:\n        pedigree[child_id] = {}\n    \n    # Create parents if not provided\n    if parent1_id is None:\n        min_id = get_min_id(pedigree)\n        parent1_id = min_id - 1\n    \n    if parent2_id is None:\n        min_id = get_min_id(pedigree)\n        parent2_id = min_id - 1\n    \n    # Add parents to each child\n    for child_id in child_ids:\n        pedigree[child_id][parent1_id] = 1\n        pedigree[child_id][parent2_id] = 1\n    \n    # Add parent entries to the pedigree\n    pedigree[parent1_id] = {}\n    pedigree[parent2_id] = {}\n    \n    return pedigree\n\ndef create_half_sibling_structure(child1_id, child2_id, common_parent_id=None, parent1_id=None, parent2_id=None):\n    \"\"\"Create a half-sibling structure with two children sharing one parent.\"\"\"\n    # Initialize an empty pedigree\n    pedigree = {child1_id: {}, child2_id: {}}\n    \n    # Create common parent if not provided\n    if common_parent_id is None:\n        min_id = get_min_id(pedigree)\n        common_parent_id = min_id - 1\n    \n    # Add common parent to both children\n    pedigree[child1_id][common_parent_id] = 1\n    pedigree[child2_id][common_parent_id] = 1\n    pedigree[common_parent_id] = {}\n    \n    # Create and add second parent for first child if needed\n    if parent1_id is None:\n        min_id = get_min_id(pedigree)\n        parent1_id = min_id - 1\n    pedigree[child1_id][parent1_id] = 1\n    pedigree[parent1_id] = {}\n    \n    # Create and add second parent for second child if needed\n    if parent2_id is None:\n        min_id = get_min_id(pedigree)\n        parent2_id = min_id - 1\n    pedigree[child2_id][parent2_id] = 1\n    pedigree[parent2_id] = {}\n    \n    return pedigree\n\ndef connect_pedigrees(pedigree1, pedigree2, connection_point):\n    \"\"\"Connect two pedigrees using the specified connection point.\"\"\"\n    import copy\n    combined_pedigree = copy.deepcopy(pedigree1)\n    pedigree2_copy = copy.deepcopy(pedigree2)\n    \n    # Extract connection information\n    id1, id2, direction = connection_point\n    \n    # Get lowest ID in both pedigrees to use for new ungenotyped individuals\n    all_ids1 = set(pedigree1.keys()).union(*[set(parents.keys()) for parents in pedigree1.values()])\n    all_ids2 = set(pedigree2.keys()).union(*[set(parents.keys()) for parents in pedigree2.values()])\n    min_id = min(min(all_ids1), min(all_ids2)) - 1\n    if min_id > 0:  # Ensure negative ID for ungenotyped individuals\n        min_id = -1\n    \n    # Adjust IDs in pedigree2 to avoid conflicts\n    id_map = {}\n    for old_id in all_ids2:\n        if old_id in all_ids1:  # If ID already exists in pedigree1\n            if old_id > 0:  # Only remap genotyped IDs\n                new_id = min(all_ids1) - 1  # Generate a new ID\n                if new_id > 0:  # Ensure it's negative for ungenotyped\n                    new_id = min_id\n                    min_id -= 1\n                id_map[old_id] = new_id\n    \n    # Apply the ID mapping to pedigree2\n    if id_map:\n        remapped_pedigree2 = {}\n        for node, parents in pedigree2_copy.items():\n            new_node = id_map.get(node, node)\n            remapped_parents = {id_map.get(p, p): d for p, d in parents.items()}\n            remapped_pedigree2[new_node] = remapped_parents\n        pedigree2_copy = remapped_pedigree2\n    \n    # Connect based on direction\n    if direction == 0:  # Connect downward (add as child)\n        # Create a new individual as child of id1 (and id2 if provided)\n        connector_id = min_id\n        min_id -= 1\n        \n        # Add the connector as child of id1 (and id2 if provided)\n        combined_pedigree[connector_id] = {id1: 1}\n        if id2 is not None:\n            combined_pedigree[connector_id][id2] = 1\n        \n        # Make the connector the parent of all founders in pedigree2\n        # Get founders (nodes with no parents) in pedigree2\n        founders2 = [node for node, parents in pedigree2_copy.items() if not parents]\n        for founder in founders2:\n            pedigree2_copy[founder][connector_id] = 1\n    \n    elif direction == 1:  # Connect upward (add as parent)\n        # Get founders in pedigree2\n        founders2 = [node for node, parents in pedigree2_copy.items() if not parents]\n        \n        if len(founders2) == 1:  # If pedigree2 has a single founder, connect directly\n            combined_pedigree[id1][founders2[0]] = 1\n        else:  # Otherwise, create a connector individual\n            connector_id = min_id\n            min_id -= 1\n            \n            # Add the connector as parent of id1\n            combined_pedigree[id1][connector_id] = 1\n            combined_pedigree[connector_id] = {}\n            \n            # Make the founders of pedigree2 parents of the connector\n            for founder in founders2:\n                combined_pedigree[connector_id][founder] = 1\n    \n    else:  # Replace/lateral connection\n        # We'll implement this as replacing id1 with a founder from pedigree2\n        founders2 = [node for node, parents in pedigree2_copy.items() if not parents]\n        if founders2:  # If there are founders in pedigree2\n            replaced_founder = founders2[0]\n            \n            # Replace all occurrences of id1 with replaced_founder\n            for node, parents in combined_pedigree.items():\n                if id1 in parents:\n                    degree = parents.pop(id1)\n                    parents[replaced_founder] = degree\n            \n            # Handle the connections of id1\n            if id1 in combined_pedigree:\n                # Transfer the parents of id1 to replaced_founder\n                if replaced_founder not in combined_pedigree:\n                    combined_pedigree[replaced_founder] = {}\n                combined_pedigree[replaced_founder].update(combined_pedigree[id1])\n                del combined_pedigree[id1]  # Remove id1 from the pedigree\n    \n    # Merge the modified pedigree2 into the combined pedigree\n    for node, parents in pedigree2_copy.items():\n        if node not in combined_pedigree:\n            combined_pedigree[node] = parents\n        else:\n            combined_pedigree[node].update(parents)\n    \n    return combined_pedigree",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create several sample pedigree configurations we'll optimize\n\n# Configuration 1: Three individuals (1, 2, 3) with no relationships between them\nconfig1 = {1: {}, 2: {}, 3: {}}\n\n# Configuration 2: Parent-child relationship (1 is parent of 2 and 3)\nconfig2 = {\n    1: {},\n    2: {1: 1},\n    3: {1: 1}\n}\n\n# Configuration 3: Full sibling relationship (1 and 2 are siblings, 3 is unrelated)\nconfig3 = create_sibling_group([1, 2], parent1_id=-1, parent2_id=-2)\nconfig3[3] = {}\n\n# Configuration 4: Half-sibling relationship (1 and 2 share one parent, 3 is unrelated)\nconfig4 = create_half_sibling_structure(1, 2, common_parent_id=-1, parent1_id=-2, parent2_id=-3)\nconfig4[3] = {}\n\n# Configuration 5: Complex structure (1 and 2 are siblings, 3 is their half-cousin)\n# First create a sibling group for 1 and 2\nsibling_group = create_sibling_group([1, 2], parent1_id=4, parent2_id=5)\n# Create a half-sibling structure with common parent 4\nhalf_sibling = create_half_sibling_structure(6, 7, common_parent_id=4, parent1_id=5, parent2_id=8)\n# Make 3 the child of 7\nparent_child = create_parent_child_unit(3, parent1_id=7)\n# Combine the pedigrees\nconfig5 = sibling_group\nfor id_val, parents in half_sibling.items():\n    if id_val in config5:\n        config5[id_val].update(parents)\n    else:\n        config5[id_val] = parents\nfor id_val, parents in parent_child.items():\n    if id_val in config5:\n        config5[id_val].update(parents)\n    else:\n        config5[id_val] = parents\n\n# Create metadata for visualization\nmetadata = {\n    1: {\"sex\": \"M\", \"age\": 40},\n    2: {\"sex\": \"F\", \"age\": 38},\n    3: {\"sex\": \"M\", \"age\": 25},\n    4: {\"sex\": \"M\", \"age\": 70},\n    5: {\"sex\": \"F\", \"age\": 68},\n    6: {\"sex\": \"M\", \"age\": 42},\n    7: {\"sex\": \"F\", \"age\": 39},\n    8: {\"sex\": \"M\", \"age\": 72}\n}\n\n# Visualize each configuration\nplt.figure(figsize=(15, 10))\n\nplt.subplot(2, 3, 1)\nvisualize_pedigree(config1, \"Config 1: Unrelated\", individual_metadata=metadata)\n\nplt.subplot(2, 3, 2)\nvisualize_pedigree(config2, \"Config 2: Parent-Child\", individual_metadata=metadata)\n\nplt.subplot(2, 3, 3)\nvisualize_pedigree(config3, \"Config 3: Full Siblings\", individual_metadata=metadata)\n\nplt.subplot(2, 3, 4)\nvisualize_pedigree(config4, \"Config 4: Half-Siblings\", individual_metadata=metadata)\n\nplt.subplot(2, 3, 5)\nvisualize_pedigree(config5, \"Config 5: Complex Structure\", individual_metadata=metadata)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "source": "### 1.3 Evaluating Pedigree Configurations\n\nNow let's implement a function to evaluate how well a pedigree configuration explains a set of IBD data. This is a critical step in the optimization process.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Now let's create a \"true\" pedigree and generate IBD data from it\n# We'll use configuration 5 (complex structure) as our ground truth\ntrue_pedigree = config5\n\n# Simulate IBD data based on this true pedigree\n# Only consider genotyped individuals (those with positive IDs)\ngenotyped_ids = [1, 2, 3, 4, 5, 6, 7, 8]\ntrue_ibd_data = simulate_pedigree_ibd(true_pedigree, genotyped_ids)\n\n# Display the IBD sharing patterns\nibd_summary = []\nfor (id1, id2), segments in true_ibd_data.items():\n    total_cm = sum(seg[\"length_cm\"] for seg in segments)\n    num_segments = len(segments)\n    \n    # Get relationship information\n    rel_tuple = get_simple_rel_tuple(true_pedigree, id1, id2)\n    relationship = \"Unknown\"\n    if rel_tuple:\n        up, down, num_ancs = rel_tuple\n        degree = up + down\n        if degree == 0:\n            relationship = \"Self\"\n        elif degree == 1:\n            relationship = \"Parent-Child\"\n        elif degree == 2 and num_ancs == 2:\n            relationship = \"Full Siblings\"\n        elif degree == 2 and num_ancs == 1:\n            relationship = \"Half Siblings/Grandparent\"\n        elif degree == 3:\n            relationship = \"First Cousins Once Removed/Great-Grandparent\"\n        elif degree == 4:\n            relationship = \"Second Cousins\"\n        else:\n            relationship = f\"Degree {degree} (Distant Relative)\"\n    \n    ibd_summary.append({\n        \"Individual 1\": id1,\n        \"Individual 2\": id2,\n        \"Relationship\": relationship,\n        \"Total cM\": total_cm,\n        \"Num Segments\": num_segments\n    })\n\n# Display the IBD summary\nibd_df = pd.DataFrame(ibd_summary).sort_values(by=\"Total cM\", ascending=False)\ndisplay(ibd_df)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def evaluate_pedigree(pedigree, ibd_data):\n    \"\"\"Evaluate how well a pedigree explains a set of IBD data.\n    \n    Args:\n        pedigree: Up-node dictionary representing the pedigree\n        ibd_data: Dictionary mapping pairs of IDs to their IBD segments\n        \n    Returns:\n        log_likelihood: Log-likelihood score (higher is better)\n        relationship_consistency: Percentage of relationships consistent with IBD\n    \"\"\"\n    log_likelihood = 0.0\n    consistent_relationships = 0\n    total_relationships = 0\n    \n    # For each pair with IBD data\n    for (id1, id2), segments in ibd_data.items():\n        total_relationships += 1\n        \n        # Get the expected relationship from the pedigree\n        rel_tuple = get_simple_rel_tuple(pedigree, id1, id2)\n        \n        # If no relationship is found in the pedigree but IBD is observed, penalize\n        if rel_tuple is None:\n            log_likelihood -= 10.0  # Arbitrary penalty\n            continue\n            \n        # Calculate expected and observed IBD sharing\n        up, down, num_ancs = rel_tuple\n        degree = up + down\n        \n        # Calculate expected IBD sharing based on the relationship degree\n        if degree == 0:  # Self\n            expected_total_cm = 3400\n        elif degree == 1:  # Parent-child\n            expected_total_cm = 3400 / 2\n        elif degree == 2 and num_ancs == 2:  # Full siblings\n            expected_total_cm = 2550\n        elif degree == 2 and num_ancs == 1:  # Half siblings/grandparents\n            expected_total_cm = 1700\n        elif degree == 3:  # First cousins once removed\n            expected_total_cm = 850\n        elif degree == 4:  # Second cousins\n            expected_total_cm = 425\n        elif degree == 5:  # Second cousins once removed\n            expected_total_cm = 212.5\n        elif degree == 6:  # Third cousins\n            expected_total_cm = 106.25\n        else:  # More distant\n            expected_total_cm = 53.125\n        \n        # Calculate observed IBD sharing\n        observed_total_cm = sum(seg[\"length_cm\"] for seg in segments)\n        \n        # Add contribution to log-likelihood\n        std_dev = expected_total_cm * 0.2  # 20% variation\n        if std_dev > 0:\n            log_likelihood += -0.5 * ((observed_total_cm - expected_total_cm) / std_dev) ** 2 - math.log(std_dev)\n        \n        # Check if the relationship is consistent with the IBD\n        # A simple check: is the observed IBD within 50% of the expected?\n        if 0.5 * expected_total_cm <= observed_total_cm <= 1.5 * expected_total_cm:\n            consistent_relationships += 1\n    \n    # Calculate relationship consistency as a percentage\n    relationship_consistency = 100 * consistent_relationships / total_relationships if total_relationships > 0 else 0\n    \n    return log_likelihood, relationship_consistency\n\n# If we're not in JupyterLite, let's also show the actual function from Bonsai v3\nif not is_jupyterlite():\n    try:\n        # Get the source code for get_likelihood_of_relationship\n        print(\"Here's the source code for get_likelihood_of_relationship from Bonsai v3:\\n\")\n        view_source(get_likelihood_of_relationship)\n    except Exception as e:\n        print(f\"Couldn't display source code: {e}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Now let's evaluate each of our sample configurations against the true IBD data\nconfigurations = {\n    \"Config 1: Unrelated\": config1,\n    \"Config 2: Parent-Child\": config2,\n    \"Config 3: Full Siblings\": config3,\n    \"Config 4: Half-Siblings\": config4,\n    \"Config 5: Complex (True)\": config5\n}\n\nevaluation_results = []\nfor config_name, pedigree in configurations.items():\n    ll, consistency = evaluate_pedigree(pedigree, true_ibd_data)\n    evaluation_results.append({\n        \"Configuration\": config_name,\n        \"Log-Likelihood\": ll,\n        \"Consistency %\": consistency,\n        \"Is True Pedigree\": config_name == \"Config 5: Complex (True)\"\n    })\n\n# Display evaluation results sorted by log-likelihood\neval_df = pd.DataFrame(evaluation_results).sort_values(by=\"Log-Likelihood\", ascending=False)\ndisplay(eval_df)\n\n# Highlight the true pedigree\ntrue_config = eval_df[eval_df[\"Is True Pedigree\"]].iloc[0]\nprint(f\"\\nThe true pedigree (Config 5) has a log-likelihood of {true_config['Log-Likelihood']:.2f} and consistency of {true_config['Consistency %']:.1f}%.\")\nprint(f\"It ranks #{eval_df.index.get_loc(true_config.name) + 1} among all configurations.\")\n\n# Visualize the best configuration\nbest_config_name = eval_df.iloc[0][\"Configuration\"]\nbest_config = configurations[best_config_name]\nvisualize_pedigree(best_config, f\"Best Configuration: {best_config_name}\", individual_metadata=metadata)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Part 2: Systematic Search of Pedigree Configurations\n\nAfter evaluating individual pedigree configurations, the next step is to systematically search through the space of possible configurations to find the optimal one. Let's explore how Bonsai v3 approaches this search process.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 2.1 Generating Alternative Configurations\n\nThe first step in systematic search is to generate alternative pedigree configurations to evaluate. Let's explore how to generate these alternatives:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def generate_alternative_configurations(base_pedigree, individuals, max_configs=5):\n    \"\"\"Generate alternative pedigree configurations by modifying the base pedigree.\n    \n    Args:\n        base_pedigree: Starting pedigree configuration\n        individuals: List of individuals to consider\n        max_configs: Maximum number of alternative configurations to generate\n        \n    Returns:\n        list: Alternative pedigree configurations\n    \"\"\"\n    alternatives = []\n    \n    # Make a copy of the base pedigree to avoid modifying the original\n    base_copy = copy.deepcopy(base_pedigree)\n    \n    # 1. Add parent-child relationships\n    for i in individuals:\n        for j in individuals:\n            if i != j:\n                # Create a new configuration where i is a child of j\n                new_config = copy.deepcopy(base_copy)\n                \n                # Don't create cycles (j can't be a descendant of i)\n                if j not in get_descendants(i, new_config):\n                    # Add j as a parent of i\n                    if j not in new_config.get(i, {}):\n                        if i not in new_config:\n                            new_config[i] = {}\n                        new_config[i][j] = 1\n                        \n                        # Add entry for j if it doesn't exist\n                        if j not in new_config:\n                            new_config[j] = {}\n                        \n                        alternatives.append((\"Parent-Child\", new_config))\n                        if len(alternatives) >= max_configs:\n                            return [alt[1] for alt in alternatives]\n    \n    # 2. Add sibling relationships\n    for i, j in itertools.combinations(individuals, 2):\n        # Create new configuration where i and j are siblings\n        new_config = copy.deepcopy(base_copy)\n        \n        # Create a new parent for both\n        min_id = get_min_id(new_config)\n        parent_id = min_id - 1\n        \n        # Add the parent to both individuals\n        if i not in new_config:\n            new_config[i] = {}\n        if j not in new_config:\n            new_config[j] = {}\n        \n        new_config[i][parent_id] = 1\n        new_config[j][parent_id] = 1\n        new_config[parent_id] = {}\n        \n        alternatives.append((\"Siblings\", new_config))\n        if len(alternatives) >= max_configs:\n            return [alt[1] for alt in alternatives]\n    \n    # 3. Add grandparent relationships\n    for i in individuals:\n        for j in individuals:\n            if i != j:\n                # Create a new configuration where i is a grandparent of j\n                new_config = copy.deepcopy(base_copy)\n                \n                # Don't create cycles\n                if j not in get_descendants(i, new_config) and i not in get_ancestors(j, new_config):\n                    # Create a connector individual (i's child, j's parent)\n                    min_id = get_min_id(new_config)\n                    connector_id = min_id - 1\n                    \n                    # Add connector as child of i\n                    if i not in new_config:\n                        new_config[i] = {}\n                    if connector_id not in new_config:\n                        new_config[connector_id] = {}\n                    \n                    new_config[connector_id][i] = 1\n                    \n                    # Add connector as parent of j\n                    if j not in new_config:\n                        new_config[j] = {}\n                    \n                    new_config[j][connector_id] = 1\n                    \n                    alternatives.append((\"Grandparent\", new_config))\n                    if len(alternatives) >= max_configs:\n                        return [alt[1] for alt in alternatives]\n    \n    # 4. Remove relationships (if any exist)\n    for ind_id, parents in base_copy.items():\n        for parent_id in list(parents.keys()):\n            # Create a new configuration with this relationship removed\n            new_config = copy.deepcopy(base_copy)\n            new_config[ind_id].pop(parent_id, None)\n            \n            alternatives.append((\"Remove-Relationship\", new_config))\n            if len(alternatives) >= max_configs:\n                return [alt[1] for alt in alternatives]\n    \n    return [alt[1] for alt in alternatives]\n\n# For demonstration, let's create alternatives for a simple configuration\nsimple_config = {1: {}, 2: {}, 3: {}}  # Three unconnected individuals\nalternatives = generate_alternative_configurations(simple_config, [1, 2, 3], max_configs=4)\n\n# Visualize the alternatives\nplt.figure(figsize=(15, 10))\n\nplt.subplot(2, 3, 1)\nvisualize_pedigree(simple_config, \"Original Configuration\", individual_metadata=metadata)\n\nfor i, alt in enumerate(alternatives):\n    plt.subplot(2, 3, i+2)\n    visualize_pedigree(alt, f\"Alternative {i+1}\", individual_metadata=metadata)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 2.2 Implementing a Greedy Search Algorithm\n\nNow let's implement a greedy search algorithm to find the optimal pedigree configuration:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def greedy_search(initial_pedigree, individuals, ibd_data, max_iterations=10, max_configs_per_iter=5):\n    \"\"\"Perform greedy search to find the optimal pedigree configuration.\n    \n    Args:\n        initial_pedigree: Starting pedigree configuration\n        individuals: List of individuals to consider\n        ibd_data: Dictionary of IBD segments between pairs of individuals\n        max_iterations: Maximum number of search iterations\n        max_configs_per_iter: Maximum number of configurations to consider per iteration\n        \n    Returns:\n        best_pedigree: The best pedigree configuration found\n        history: List of (pedigree, log_likelihood, consistency) tuples for each iteration\n    \"\"\"\n    current_pedigree = copy.deepcopy(initial_pedigree)\n    current_ll, current_consistency = evaluate_pedigree(current_pedigree, ibd_data)\n    \n    # Keep track of the search history\n    history = [(current_pedigree, current_ll, current_consistency)]\n    \n    for iteration in range(max_iterations):\n        print(f\"Iteration {iteration+1}/{max_iterations}: Current log-likelihood = {current_ll:.2f}, consistency = {current_consistency:.1f}%\")\n        \n        # Generate alternative configurations\n        alternatives = generate_alternative_configurations(current_pedigree, individuals, max_configs=max_configs_per_iter)\n        \n        # Evaluate each alternative\n        best_alt = None\n        best_alt_ll = current_ll\n        best_alt_consistency = current_consistency\n        \n        for i, alt in enumerate(alternatives):\n            alt_ll, alt_consistency = evaluate_pedigree(alt, ibd_data)\n            print(f\"  Alternative {i+1}: log-likelihood = {alt_ll:.2f}, consistency = {alt_consistency:.1f}%\")\n            \n            # Check if this alternative is better\n            if alt_ll > best_alt_ll:\n                best_alt = alt\n                best_alt_ll = alt_ll\n                best_alt_consistency = alt_consistency\n        \n        # If no improvement is found, stop the search\n        if best_alt is None or best_alt_ll <= current_ll:\n            print(f\"No improvement found. Stopping search.\")\n            break\n        \n        # Update the current configuration\n        current_pedigree = best_alt\n        current_ll = best_alt_ll\n        current_consistency = best_alt_consistency\n        \n        # Add to history\n        history.append((current_pedigree, current_ll, current_consistency))\n    \n    return current_pedigree, history\n\n# Run a small test example\ntest_individuals = [1, 2, 3]\ntest_initial_pedigree = {1: {}, 2: {}, 3: {}}  # Start with unrelated individuals\ntest_ibd_data = simulate_pedigree_ibd(config3, test_individuals)  # Simulate IBD for siblings\n\nbest_pedigree, history = greedy_search(test_initial_pedigree, test_individuals, test_ibd_data, \n                                       max_iterations=3, max_configs_per_iter=3)\n\n# Visualize the progression of configurations\nplt.figure(figsize=(15, 10))\n\n# First, show the initial configuration\nplt.subplot(2, 2, 1)\nvisualize_pedigree(history[0][0], f\"Initial: LL={history[0][1]:.2f}, Cons={history[0][2]:.1f}%\", \n                   individual_metadata=metadata)\n\n# Then show intermediate steps and final configuration\nfor i in range(1, min(3, len(history))):\n    plt.subplot(2, 2, i+1)\n    visualize_pedigree(history[i][0], f\"Step {i}: LL={history[i][1]:.2f}, Cons={history[i][2]:.1f}%\", \n                       individual_metadata=metadata)\n\n# Show the final \"true\" configuration for comparison\nplt.subplot(2, 2, 4)\nvisualize_pedigree(config3, \"True Configuration (Siblings)\", individual_metadata=metadata)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 2.3 Using Bonsai's Actual Optimization Functions\n\nNow let's examine how Bonsai v3 actually handles optimization of pedigree structures. Instead of using simplified implementations, we'll explore the actual functions in the Bonsai codebase.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Let's look at the actual optimization functions in Bonsai v3\nif not is_jupyterlite():\n    try:\n        # Import optimization functions from Bonsai v3\n        from utils.bonsaitree.bonsaitree.v3.optimize import (\n            optimize_pedigree,\n            evaluate_pedigree_structure,\n            generate_alternative_structures\n        )\n        \n        print(\"Successfully imported Bonsai v3 optimization functions.\")\n        \n        # Examine the optimize_pedigree function\n        print(\"\\nOptimize Pedigree function from Bonsai v3:\")\n        view_source(optimize_pedigree)\n        \n        # Examine the evaluate_pedigree_structure function\n        print(\"\\nEvaluate Pedigree Structure function from Bonsai v3:\")\n        view_source(evaluate_pedigree_structure)\n        \n        # Examine the generate_alternative_structures function\n        print(\"\\nGenerate Alternative Structures function from Bonsai v3:\")\n        view_source(generate_alternative_structures)\n        \n    except ImportError as e:\n        print(f\"Could not import Bonsai v3 optimization functions: {e}\")\n        print(\"Using simplified implementations instead.\")\n    except AttributeError as e:\n        print(f\"Could not find specific optimization functions in Bonsai v3: {e}\")\n        print(\"Using simplified implementations instead.\")\nelse:\n    print(\"Running in JupyterLite - using simplified implementations instead of actual Bonsai functions.\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Now let's see what optimization-related functions are available in the Bonsai v3 modules\nif not is_jupyterlite():\n    try:\n        # Check for optimization-related functions in v3.pedigrees\n        print(\"Optimization-related functions in v3.pedigrees:\")\n        functions = [name for name, func in inspect.getmembers(v3.pedigrees, inspect.isfunction) \n                     if any(kw in name.lower() for kw in ['optimize', 'improve', 'alternative', 'evaluate'])]\n        for func_name in functions:\n            print(f\"- {func_name}\")\n            \n        # Check for optimization-related functions in v3.connections\n        print(\"\\nOptimization-related functions in v3.connections:\")\n        functions = [name for name, func in inspect.getmembers(v3.connections, inspect.isfunction) \n                     if any(kw in name.lower() for kw in ['optimize', 'improve', 'alternative', 'evaluate'])]\n        for func_name in functions:\n            print(f\"- {func_name}\")\n        \n        # Look for any module named 'optimize' or similar\n        print(\"\\nChecking for optimization modules in Bonsai v3:\")\n        import importlib.util\n        import os\n        \n        utils_dir = os.getenv('PROJECT_UTILS_DIR', os.path.join(os.path.dirname(DATA_DIR), 'utils'))\n        bonsaitree_dir = os.path.join(utils_dir, 'bonsaitree')\n        v3_dir = os.path.join(bonsaitree_dir, 'bonsaitree', 'v3')\n        \n        if os.path.exists(v3_dir):\n            modules = [f for f in os.listdir(v3_dir) \n                      if os.path.isfile(os.path.join(v3_dir, f)) \n                      and f.endswith('.py') \n                      and any(kw in f.lower() for kw in ['optim', 'improve', 'search'])]\n            for module in modules:\n                print(f\"Found module: {module}\")\n        \n    except Exception as e:\n        print(f\"Error exploring optimization functions: {e}\")\nelse:\n    print(\"Running in JupyterLite - skipping exploration of actual Bonsai modules.\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Let's examine the specific optimization functions in Bonsai v3\nif not is_jupyterlite():\n    try:\n        # Look for functions in pedigrees module that might be related to configuration optimization\n        print(\"Exploring key pedigree optimization-related functions in Bonsai v3:\")\n        \n        # Check for get_up_dict_with_new_connection function\n        if hasattr(v3.pedigrees, 'get_up_dict_with_new_connection'):\n            print(\"\\nFunction: get_up_dict_with_new_connection\")\n            view_source(v3.pedigrees.get_up_dict_with_new_connection)\n        \n        # Check for get_alternative_connections function\n        if hasattr(v3.pedigrees, 'get_alternative_connections'):\n            print(\"\\nFunction: get_alternative_connections\")\n            view_source(v3.pedigrees.get_alternative_connections)\n        \n        # Check for evaluate_up_dict function\n        if hasattr(v3.pedigrees, 'evaluate_up_dict'):\n            print(\"\\nFunction: evaluate_up_dict\")\n            view_source(v3.pedigrees.evaluate_up_dict)\n        \n        # Look for functions in connections module\n        print(\"\\nExploring key connection optimization functions in Bonsai v3:\")\n        \n        # Check for get_best_connection function\n        if hasattr(v3.connections, 'get_best_connection'):\n            print(\"\\nFunction: get_best_connection\")\n            view_source(v3.connections.get_best_connection)\n            \n        # Check for evaluate_connections function\n        if hasattr(v3.connections, 'evaluate_connections'):\n            print(\"\\nFunction: evaluate_connections\")\n            view_source(v3.connections.evaluate_connections)\n            \n    except Exception as e:\n        print(f\"Error examining optimization functions: {e}\")\nelse:\n    print(\"Running in JupyterLite - skipping examination of Bonsai functions.\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Part 3: Applying Optimization Techniques\n\nNow let's apply what we've learned to optimize pedigree configurations using both simplified approaches and, where possible, actual Bonsai v3 functions.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 3.1 Handling Ambiguous Cases and Multiple Hypotheses\n\nWhen working with small pedigrees, multiple configurations may be equally plausible based on genetic data. Let's explore techniques for handling these ambiguous cases:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create an ambiguous case: half-siblings vs. grandparent-grandchild\n# Generate two different configurations that can have similar IBD patterns\n# Configuration A: Half-siblings (1 and 2 share one parent)\nconfig_half_siblings = create_half_sibling_structure(1, 2, common_parent_id=-1, parent1_id=-2, parent2_id=-3)\n\n# Configuration B: Grandparent-grandchild (1 is grandparent of 2)\nconfig_grandparent = {1: {}}\nmin_id = get_min_id(config_grandparent)\nconnector_id = min_id - 1\nconfig_grandparent[connector_id] = {1: 1}\nconfig_grandparent[2] = {connector_id: 1}\n\n# Create metadata for visualization\nambiguous_metadata = {\n    1: {\"sex\": \"M\", \"age\": 65},\n    2: {\"sex\": \"F\", \"age\": 20},\n    -1: {\"sex\": \"M\", \"age\": 45},\n    -2: {\"sex\": \"F\", \"age\": 40},\n    -3: {\"sex\": \"M\", \"age\": 42},\n    connector_id: {\"sex\": \"F\", \"age\": 42}\n}\n\n# Visualize both configurations\nplt.figure(figsize=(15, 6))\n\nplt.subplot(1, 2, 1)\nvisualize_pedigree(config_half_siblings, \"Hypothesis A: Half-Siblings\", individual_metadata=ambiguous_metadata)\n\nplt.subplot(1, 2, 2)\nvisualize_pedigree(config_grandparent, \"Hypothesis B: Grandparent-Grandchild\", individual_metadata=ambiguous_metadata)\n\nplt.tight_layout()\nplt.show()\n\n# Simulate IBD data that is ambiguous between these configurations\n# For half-siblings: ~850 cM shared in short segments\n# For grandparent-grandchild: ~850 cM shared in longer segments\ndef create_ambiguous_ibd_data():\n    # Create similar amount of shared DNA with different patterns\n    half_sib_segments = []\n    grandparent_segments = []\n    \n    # Half-siblings: more segments, shorter length\n    for _ in range(25):\n        chromosome = random.randint(1, 22)\n        segment_cm = random.uniform(15, 40)  # Shorter segments\n        start_cm = random.uniform(0, 100)\n        end_cm = start_cm + segment_cm\n        \n        half_sib_segments.append({\n            \"chromosome\": chromosome,\n            \"start_cm\": start_cm,\n            \"end_cm\": end_cm,\n            \"length_cm\": segment_cm\n        })\n    \n    # Grandparent-grandchild: fewer segments, longer length\n    for _ in range(10):\n        chromosome = random.randint(1, 22)\n        segment_cm = random.uniform(60, 100)  # Longer segments\n        start_cm = random.uniform(0, 100)\n        end_cm = start_cm + segment_cm\n        \n        grandparent_segments.append({\n            \"chromosome\": chromosome,\n            \"start_cm\": start_cm,\n            \"end_cm\": end_cm,\n            \"length_cm\": segment_cm\n        })\n    \n    return {(1, 2): half_sib_segments}, {(1, 2): grandparent_segments}\n\n# Create two different IBD datasets\nhalf_sib_ibd, grandparent_ibd = create_ambiguous_ibd_data()\n\n# Evaluate both configurations against both IBD datasets\nhalf_sib_on_half_ibd_ll, half_sib_on_half_ibd_cons = evaluate_pedigree(config_half_siblings, half_sib_ibd)\nhalf_sib_on_grand_ibd_ll, half_sib_on_grand_ibd_cons = evaluate_pedigree(config_half_siblings, grandparent_ibd)\ngrand_on_half_ibd_ll, grand_on_half_ibd_cons = evaluate_pedigree(config_grandparent, half_sib_ibd)\ngrand_on_grand_ibd_ll, grand_on_grand_ibd_cons = evaluate_pedigree(config_grandparent, grandparent_ibd)\n\n# Create a DataFrame to compare results\nresults = pd.DataFrame([\n    {\"Configuration\": \"Half-Siblings\", \"IBD Pattern\": \"Half-Sibling Pattern\", \n     \"Log-Likelihood\": half_sib_on_half_ibd_ll, \"Consistency %\": half_sib_on_half_ibd_cons},\n    {\"Configuration\": \"Half-Siblings\", \"IBD Pattern\": \"Grandparent Pattern\", \n     \"Log-Likelihood\": half_sib_on_grand_ibd_ll, \"Consistency %\": half_sib_on_grand_ibd_cons},\n    {\"Configuration\": \"Grandparent\", \"IBD Pattern\": \"Half-Sibling Pattern\", \n     \"Log-Likelihood\": grand_on_half_ibd_ll, \"Consistency %\": grand_on_half_ibd_cons},\n    {\"Configuration\": \"Grandparent\", \"IBD Pattern\": \"Grandparent Pattern\", \n     \"Log-Likelihood\": grand_on_grand_ibd_ll, \"Consistency %\": grand_on_grand_ibd_cons}\n])\n\n# Display the results\ndisplay(results)\n\n# Analyze the ambiguity\nprint(\"Analysis of ambiguity:\")\nprint(f\"1. When evaluating with half-sibling IBD pattern:\")\nprint(f\"   - Half-sibling configuration: LL = {half_sib_on_half_ibd_ll:.2f}\")\nprint(f\"   - Grandparent configuration: LL = {grand_on_half_ibd_ll:.2f}\")\nprint(f\"   - Difference: {abs(half_sib_on_half_ibd_ll - grand_on_half_ibd_ll):.2f}\")\nprint()\nprint(f\"2. When evaluating with grandparent IBD pattern:\")\nprint(f\"   - Half-sibling configuration: LL = {half_sib_on_grand_ibd_ll:.2f}\")\nprint(f\"   - Grandparent configuration: LL = {grand_on_grand_ibd_ll:.2f}\")\nprint(f\"   - Difference: {abs(half_sib_on_grand_ibd_ll - grand_on_grand_ibd_ll):.2f}\")\n\n# Comment on the implications\nif abs(half_sib_on_half_ibd_ll - grand_on_half_ibd_ll) < 3 or abs(half_sib_on_grand_ibd_ll - grand_on_grand_ibd_ll) < 3:\n    print(\"\\nImplication: The log-likelihood difference is small, indicating ambiguity between these relationships.\")\n    print(\"This demonstrates why Bonsai sometimes needs to maintain multiple hypotheses for small pedigrees.\")\n    print(\"Additional information (such as ages) would be needed to resolve this ambiguity.\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 3.2 Additional Constraints for Optimization\n\nIn real-world pedigree optimization, additional constraints beyond genetic data can help resolve ambiguities. Let's incorporate some of these constraints:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def evaluate_pedigree_with_constraints(pedigree, ibd_data, individual_metadata=None):\n    \"\"\"Evaluate a pedigree with additional constraints like age and sex.\n    \n    Args:\n        pedigree: Up-node dictionary representing the pedigree\n        ibd_data: Dictionary mapping pairs of IDs to their IBD segments\n        individual_metadata: Dictionary mapping individuals to their metadata (age, sex, etc.)\n        \n    Returns:\n        log_likelihood: Log-likelihood score (higher is better)\n        consistency: Percentage of relationships consistent with constraints\n    \"\"\"\n    # Start with basic genetic evaluation\n    log_likelihood, relationship_consistency = evaluate_pedigree(pedigree, ibd_data)\n    \n    # If no metadata is provided, return basic evaluation\n    if not individual_metadata:\n        return log_likelihood, relationship_consistency\n    \n    # Count constraints and violations\n    total_constraints = 0\n    satisfied_constraints = 0\n    \n    # Check age constraints\n    down_dict = reverse_node_dict(pedigree)\n    \n    for child, parents in pedigree.items():\n        if child in individual_metadata and 'age' in individual_metadata[child]:\n            child_age = individual_metadata[child]['age']\n            \n            # Check each parent\n            for parent in parents:\n                if parent in individual_metadata and 'age' in individual_metadata[parent]:\n                    parent_age = individual_metadata[parent]['age']\n                    total_constraints += 1\n                    \n                    # Parent should be older than child (by at least ~15 years)\n                    if parent_age >= child_age + 15:\n                        satisfied_constraints += 1\n                    else:\n                        # Apply penalty to log-likelihood for age violation\n                        log_likelihood -= 5.0\n    \n    # Check sex constraints (e.g., biological fathers must be male)\n    for parent, children in down_dict.items():\n        if parent in individual_metadata and 'sex' in individual_metadata[parent]:\n            parent_sex = individual_metadata[parent]['sex']\n            \n            # Find spouse pairs (people who share children)\n            spouse_pairs = set()\n            for child in children:\n                child_parents = list(pedigree.get(child, {}).keys())\n                if len(child_parents) >= 2:\n                    for i in range(len(child_parents)):\n                        for j in range(i+1, len(child_parents)):\n                            spouse_pairs.add(tuple(sorted([child_parents[i], child_parents[j]])))\n            \n            # Check that two biological parents can't have the same sex\n            for sp1, sp2 in spouse_pairs:\n                if sp1 in individual_metadata and sp2 in individual_metadata:\n                    if 'sex' in individual_metadata[sp1] and 'sex' in individual_metadata[sp2]:\n                        sex1 = individual_metadata[sp1]['sex']\n                        sex2 = individual_metadata[sp2]['sex']\n                        \n                        total_constraints += 1\n                        if sex1 != sex2 or sex1 == '?' or sex2 == '?':\n                            satisfied_constraints += 1\n                        else:\n                            # Apply penalty for sex constraint violation\n                            log_likelihood -= 10.0\n    \n    # Calculate constraint consistency\n    constraint_consistency = 100 * satisfied_constraints / total_constraints if total_constraints > 0 else 100\n    \n    # Combine both types of consistency\n    overall_consistency = (relationship_consistency + constraint_consistency) / 2\n    \n    return log_likelihood, overall_consistency\n\n# Now let's evaluate our ambiguous cases with age and sex constraints\n# Evaluate both configurations against both IBD datasets, but now with constraints\nhalf_sib_on_half_ibd_ll_c, half_sib_on_half_ibd_cons_c = evaluate_pedigree_with_constraints(\n    config_half_siblings, half_sib_ibd, ambiguous_metadata)\nhalf_sib_on_grand_ibd_ll_c, half_sib_on_grand_ibd_cons_c = evaluate_pedigree_with_constraints(\n    config_half_siblings, grandparent_ibd, ambiguous_metadata)\ngrand_on_half_ibd_ll_c, grand_on_half_ibd_cons_c = evaluate_pedigree_with_constraints(\n    config_grandparent, half_sib_ibd, ambiguous_metadata)\ngrand_on_grand_ibd_ll_c, grand_on_grand_ibd_cons_c = evaluate_pedigree_with_constraints(\n    config_grandparent, grandparent_ibd, ambiguous_metadata)\n\n# Create a DataFrame to compare results with constraints\nresults_with_constraints = pd.DataFrame([\n    {\"Configuration\": \"Half-Siblings\", \"IBD Pattern\": \"Half-Sibling Pattern\", \n     \"Log-Likelihood\": half_sib_on_half_ibd_ll_c, \"Consistency %\": half_sib_on_half_ibd_cons_c},\n    {\"Configuration\": \"Half-Siblings\", \"IBD Pattern\": \"Grandparent Pattern\", \n     \"Log-Likelihood\": half_sib_on_grand_ibd_ll_c, \"Consistency %\": half_sib_on_grand_ibd_cons_c},\n    {\"Configuration\": \"Grandparent\", \"IBD Pattern\": \"Half-Sibling Pattern\", \n     \"Log-Likelihood\": grand_on_half_ibd_ll_c, \"Consistency %\": grand_on_half_ibd_cons_c},\n    {\"Configuration\": \"Grandparent\", \"IBD Pattern\": \"Grandparent Pattern\", \n     \"Log-Likelihood\": grand_on_grand_ibd_ll_c, \"Consistency %\": grand_on_grand_ibd_cons_c}\n])\n\n# Display the results with constraints\nprint(\"Evaluation with Age and Sex Constraints:\")\ndisplay(results_with_constraints)\n\n# Compare to previous results without constraints\nprint(\"\\nImpact of Adding Constraints:\")\ncomparison = pd.DataFrame([\n    {\"Configuration\": \"Half-Siblings on Half-Sibling IBD\", \n     \"Without Constraints\": half_sib_on_half_ibd_ll, \n     \"With Constraints\": half_sib_on_half_ibd_ll_c,\n     \"Difference\": half_sib_on_half_ibd_ll_c - half_sib_on_half_ibd_ll},\n    {\"Configuration\": \"Half-Siblings on Grandparent IBD\", \n     \"Without Constraints\": half_sib_on_grand_ibd_ll, \n     \"With Constraints\": half_sib_on_grand_ibd_ll_c,\n     \"Difference\": half_sib_on_grand_ibd_ll_c - half_sib_on_grand_ibd_ll},\n    {\"Configuration\": \"Grandparent on Half-Sibling IBD\", \n     \"Without Constraints\": grand_on_half_ibd_ll, \n     \"With Constraints\": grand_on_half_ibd_ll_c,\n     \"Difference\": grand_on_half_ibd_ll_c - grand_on_half_ibd_ll},\n    {\"Configuration\": \"Grandparent on Grandparent IBD\", \n     \"Without Constraints\": grand_on_grand_ibd_ll, \n     \"With Constraints\": grand_on_grand_ibd_ll_c,\n     \"Difference\": grand_on_grand_ibd_ll_c - grand_on_grand_ibd_ll}\n])\ndisplay(comparison)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 3.3 Using Bonsai's Approach to Resolve Multiple Hypotheses\n\nLet's explore how Bonsai v3 resolves multiple competing hypotheses in pedigree reconstruction:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Check for specific methods in Bonsai v3 for handling multiple hypotheses\nif not is_jupyterlite():\n    try:\n        # Look for functions that handle multiple hypotheses or configurations\n        # Check in pedigrees module\n        print(\"Searching for multiple hypothesis handling in Bonsai v3...\")\n        \n        # Look for relevant functions in v3.connections or v3.pedigrees\n        from utils.bonsaitree.bonsaitree.v3 import connections, pedigrees\n        \n        # Search for hypothesis-related functions in connections module\n        hypo_funcs_conn = [name for name, func in inspect.getmembers(connections, inspect.isfunction) \n                          if any(kw in name.lower() for kw in ['hypothesis', 'alternative', 'compare', 'rank'])]\n        if hypo_funcs_conn:\n            print(\"Functions in v3.connections that may handle multiple hypotheses:\")\n            for func_name in hypo_funcs_conn:\n                print(f\"- {func_name}\")\n                \n        # Search for hypothesis-related functions in pedigrees module\n        hypo_funcs_ped = [name for name, func in inspect.getmembers(pedigrees, inspect.isfunction) \n                         if any(kw in name.lower() for kw in ['hypothesis', 'alternative', 'compare', 'rank'])]\n        if hypo_funcs_ped:\n            print(\"Functions in v3.pedigrees that may handle multiple hypotheses:\")\n            for func_name in hypo_funcs_ped:\n                print(f\"- {func_name}\")\n        \n        # If no specific hypothesis handling functions were found, check for functions with ranking/comparison\n        if not hypo_funcs_conn and not hypo_funcs_ped:\n            print(\"No explicit hypothesis handling functions found.\")\n            print(\"However, these functions might be used for comparison:\")\n            \n            # Check for rankable function in connections\n            rank_funcs_conn = [name for name, func in inspect.getmembers(connections, inspect.isfunction) \n                              if any(kw in name.lower() for kw in ['compare', 'evaluate', 'likelihood', 'rank'])]\n            for func_name in rank_funcs_conn[:3]:  # Show top 3\n                print(f\"- {func_name}\")\n    \n    except Exception as e:\n        print(f\"Error exploring hypothesis functions: {e}\")\nelse:\n    print(\"Running in JupyterLite - skipping exploration of Bonsai functions.\")\n    \n# Implement a simplified version of handling multiple hypotheses based on Bonsai's approach\ndef resolve_multiple_hypotheses(hypotheses, ibd_data, individual_metadata=None, \n                               min_likelihood_diff=3.0, max_hypotheses=3):\n    \"\"\"\n    Resolve multiple competing hypotheses based on IBD data and metadata.\n    \n    Args:\n        hypotheses: List of (name, pedigree) tuples \n        ibd_data: Dictionary mapping pairs of IDs to their IBD segments\n        individual_metadata: Dictionary mapping individuals to their metadata (age, sex, etc.)\n        min_likelihood_diff: Minimum log-likelihood difference to consider a hypothesis clearly better\n        max_hypotheses: Maximum number of hypotheses to maintain\n        \n    Returns:\n        ranked_results: List of (name, pedigree, log_likelihood, consistency) tuples, sorted by likelihood\n    \"\"\"\n    results = []\n    \n    # Evaluate each hypothesis\n    for name, pedigree in hypotheses:\n        if individual_metadata:\n            ll, cons = evaluate_pedigree_with_constraints(pedigree, ibd_data, individual_metadata)\n        else:\n            ll, cons = evaluate_pedigree(pedigree, ibd_data)\n        \n        results.append((name, pedigree, ll, cons))\n    \n    # Sort by log-likelihood (descending)\n    ranked_results = sorted(results, key=lambda x: x[2], reverse=True)\n    \n    # Determine which hypotheses to keep\n    kept_results = [ranked_results[0]]  # Always keep the best hypothesis\n    \n    for i in range(1, len(ranked_results)):\n        curr_ll = ranked_results[i][2]\n        best_ll = ranked_results[0][2]\n        \n        # Keep this hypothesis if it's close enough to the best\n        if best_ll - curr_ll < min_likelihood_diff and len(kept_results) < max_hypotheses:\n            kept_results.append(ranked_results[i])\n    \n    return kept_results\n\n# Apply this to our ambiguous case\nhypotheses = [\n    (\"Half-Siblings\", config_half_siblings),\n    (\"Grandparent-Grandchild\", config_grandparent)\n]\n\n# Resolve with half-sibling IBD pattern\nprint(\"Resolving hypotheses with half-sibling IBD pattern:\")\nhalf_sib_resolution = resolve_multiple_hypotheses(hypotheses, half_sib_ibd, ambiguous_metadata)\nfor name, _, ll, cons in half_sib_resolution:\n    print(f\"- {name}: Log-Likelihood = {ll:.2f}, Consistency = {cons:.1f}%\")\n\n# Resolve with grandparent IBD pattern\nprint(\"\\nResolving hypotheses with grandparent IBD pattern:\")\ngrand_resolution = resolve_multiple_hypotheses(hypotheses, grandparent_ibd, ambiguous_metadata)\nfor name, _, ll, cons in grand_resolution:\n    print(f\"- {name}: Log-Likelihood = {ll:.2f}, Consistency = {cons:.1f}%\")\n\n# Now let's visualize the best hypothesis for each IBD pattern\nplt.figure(figsize=(15, 6))\n\nplt.subplot(1, 2, 1)\nbest_half_sib_hypo = half_sib_resolution[0]\nvisualize_pedigree(best_half_sib_hypo[1], \n                  f\"Best for Half-Sib IBD: {best_half_sib_hypo[0]}\\nLL={best_half_sib_hypo[2]:.2f}\", \n                  individual_metadata=ambiguous_metadata)\n\nplt.subplot(1, 2, 2)\nbest_grand_hypo = grand_resolution[0]\nvisualize_pedigree(best_grand_hypo[1], \n                  f\"Best for Grandparent IBD: {best_grand_hypo[0]}\\nLL={best_grand_hypo[2]:.2f}\", \n                  individual_metadata=ambiguous_metadata)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n\nIn this lab, we've explored techniques for optimizing small pedigree configurations in Bonsai v3. Key takeaways include:\n\n1. **Evaluation Methods**: We examined how to evaluate how well different pedigree configurations explain IBD data, using both simplified implementations and, where available, Bonsai v3's actual functions.\n\n2. **Systematic Search**: We implemented a greedy search algorithm to systematically explore the space of possible pedigree configurations and find the optimal one.\n\n3. **Multiple Hypotheses**: We learned how to handle ambiguous cases where multiple configurations might explain the genetic data equally well, and how to incorporate additional constraints like age and sex to resolve these ambiguities.\n\n4. **Bonsai's Approach**: We explored Bonsai v3's approach to pedigree optimization, including its specialized functions for generating and evaluating alternative configurations.\n\nThese techniques form the foundation for scaling up to larger pedigrees in real-world applications, which we'll explore in future labs. The ability to optimize small pedigree configurations efficiently is crucial for constructing accurate family trees from genetic data, especially when dealing with ambiguous relationships and incomplete information.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Convert this notebook to PDF using poetry\n!poetry run jupyter nbconvert --to pdf Lab14_Optimizing_Pedigrees.ipynb\n\n# Note: PDF conversion requires LaTeX to be installed on your system\n# If you encounter errors, you may need to install it:\n# On Ubuntu/Debian: sudo apt-get install texlive-xetex\n# On macOS with Homebrew: brew install texlive",
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}