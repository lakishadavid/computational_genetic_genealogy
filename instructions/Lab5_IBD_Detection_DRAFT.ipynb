{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from: /home/lakishadavid/computational_genetic_genealogy/.env\n"
     ]
    }
   ],
   "source": [
    "def find_comp_gen_dir():\n",
    "    \"\"\"Find the computational_genetic_genealogy directory by searching up from current directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Search up through parent directories\n",
    "    while current != current.parent:\n",
    "        # Check if target directory exists in current path\n",
    "        target = current / 'computational_genetic_genealogy'\n",
    "        if target.is_dir():\n",
    "            return target\n",
    "        # Move up one directory\n",
    "        current = current.parent\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find computational_genetic_genealogy directory\")\n",
    "\n",
    "def load_env_file():\n",
    "    \"\"\"Find and load the .env file from the computational_genetic_genealogy directory.\"\"\"\n",
    "    try:\n",
    "        # Find the computational_genetic_genealogy directory\n",
    "        comp_gen_dir = find_comp_gen_dir()\n",
    "        \n",
    "        # Look for .env file\n",
    "        env_path = comp_gen_dir / '.env'\n",
    "        if not env_path.exists():\n",
    "            print(f\"Warning: No .env file found in {comp_gen_dir}\")\n",
    "            return None\n",
    "        \n",
    "        # Load the .env file\n",
    "        load_dotenv(env_path, override=True)\n",
    "        print(f\"Loaded environment variables from: {env_path}\")\n",
    "        return env_path\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use the function\n",
    "env_path = load_env_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /home/lakishadavid/computational_genetic_genealogy\n",
      "Data Directory: /home/lakishadavid/computational_genetic_genealogy/data\n",
      "References Directory: /home/lakishadavid/computational_genetic_genealogy/references\n",
      "Results Directory: /home/lakishadavid/computational_genetic_genealogy/results\n",
      "Utils Directory: /home/lakishadavid/computational_genetic_genealogy/utils\n",
      "The current directory is /home/lakishadavid/computational_genetic_genealogy\n"
     ]
    }
   ],
   "source": [
    "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
    "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
    "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
    "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
    "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
    "\n",
    "print(f\"Working Directory: {working_directory}\")\n",
    "print(f\"Data Directory: {data_directory}\")\n",
    "print(f\"References Directory: {references_directory}\")\n",
    "print(f\"Results Directory: {results_directory}\")\n",
    "print(f\"Utils Directory: {utils_directory}\")\n",
    "\n",
    "os.chdir(working_directory)\n",
    "print(f\"The current directory is {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\"):\n",
    "    \"\"\"\n",
    "    Configure logging for both file and console handlers.\n",
    "\n",
    "    Args:\n",
    "        log_filename (str): Path to the log file where logs will be written.\n",
    "        log_file_debug_level (str): Logging level for the file handler.\n",
    "        console_debug_level (str): Logging level for the console handler.\n",
    "    \"\"\"\n",
    "    # Create a root logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)  # Capture all messages at the root level\n",
    "\n",
    "    # Convert level names to numeric levels\n",
    "    file_level = getattr(logging, log_file_debug_level.upper(), logging.INFO)\n",
    "    console_level = getattr(logging, console_debug_level.upper(), logging.INFO)\n",
    "\n",
    "    # File handler: Logs messages at file_level and above to the file\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(file_level)\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "\n",
    "    # Console handler: Logs messages at console_level and above to the console\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(console_level)\n",
    "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "\n",
    "    # Add handlers to the root logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "def clear_logger():\n",
    "    \"\"\"Remove all handlers from the root logger.\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lab 5 log file is located at /home/lakishadavid/computational_genetic_genealogy/results/lab5.log.\n"
     ]
    }
   ],
   "source": [
    "log_filename = os.path.join(results_directory, \"lab5.log\")\n",
    "print(f\"The Lab 5 log file is located at {log_filename}.\")\n",
    "\n",
    "# Ensure the results_directory exists\n",
    "if not os.path.exists(results_directory):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "# Check if the file exists; if not, create it\n",
    "if not os.path.exists(log_filename):\n",
    "    with open(log_filename, 'w') as file:\n",
    "        pass  # The file is now created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_logger() # Clear the logger before reconfiguring it\n",
    "configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your existing Beagle genetic maps to create the genetic maps for IBIS. If you already have these genetic maps, you do not need to rerun these cells to download the genetic maps again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ibis_map():\n",
    "    beagle_map_dir = os.path.join(references_directory, \"genetic_maps/beagle_genetic_maps\")\n",
    "    ibis_map_dir = os.path.join(references_directory, \"genetic_maps/ibis_genetic_maps\")\n",
    "    os.makedirs(ibis_map_dir, exist_ok=True)\n",
    "    \n",
    "    for map_file in os.listdir(beagle_map_dir):\n",
    "        if map_file.endswith(\".map\"):\n",
    "            beagle_map_filename = os.path.join(beagle_map_dir, map_file)\n",
    "            ibis_map_filename = os.path.join(ibis_map_dir, map_file)\n",
    "            print(f\"Processing {beagle_map_filename} to create IBIS map...\")\n",
    "            command = f\"awk '{{print $1, $4, ($2 == \\\".\\\" ? 0 : $2), $3}}' {beagle_map_filename} > {ibis_map_filename}\"\n",
    "            subprocess.run(command, shell=True, check=True)\n",
    "    print(\"All Beagle genetic maps converted to IBIS format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chrX_par1.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr14.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr12.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr11.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr18.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chrX_par2.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr21.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr4.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr16.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr13.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr22.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr9.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr1.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr17.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr15.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr20.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr6.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr10.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chrX.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr2.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr3.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr19.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr8.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr5.GRCh38.map to create IBIS map...\n",
      "Processing /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/beagle_genetic_maps/plink.chr7.GRCh38.map to create IBIS map...\n",
      "All Beagle genetic maps converted to IBIS format.\n"
     ]
    }
   ],
   "source": [
    "# Set up output directories\n",
    "genetic_maps_dir = os.path.join(references_directory, \"genetic_maps\")\n",
    "os.makedirs(genetic_maps_dir, exist_ok=True)\n",
    "\n",
    "ibis_genetic_maps = os.path.join(genetic_maps_dir, \"ibis_genetic_maps\")\n",
    "os.makedirs(ibis_genetic_maps, exist_ok=True)\n",
    "\n",
    "assembly = \"GRCh38\"\n",
    "preprocess_ibis_map()\n",
    "\n",
    "# # Alternative source\n",
    "# plink2_genetic_map_url=\"https://alkesgroup.broadinstitute.org/Eagle/downloads/tables/genetic_map_hg38_withX.txt.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual Inspection**\n",
    "\n",
    "The above code should have created a set of genetic map files in the format that IBIS use. Look in your `references/genetic_mpas` directory and check for the `ibis_genetic_maps` subdirectory and individual by chromosome files within `ibis_genetic_maps`. Open the chromosome 1 file of both `ibis_genetic_maps` and `beagle_genetic_maps`. Compare them, visually. How are they similar? How are they different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate phased VCF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating list of phased VCF files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking the headers and starting positions of 22 files\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr1.vcf.gz\t0.033714 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr2.vcf.gz\t0.035030 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr3.vcf.gz\t0.028771 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr4.vcf.gz\t0.026724 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr5.vcf.gz\t0.027721 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr6.vcf.gz\t0.029012 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr7.vcf.gz\t0.023776 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr8.vcf.gz\t0.022632 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr9.vcf.gz\t0.021286 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr10.vcf.gz\t0.022779 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr11.vcf.gz\t0.021488 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr12.vcf.gz\t0.022196 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr13.vcf.gz\t0.017060 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr14.vcf.gz\t0.015674 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr15.vcf.gz\t0.014344 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr16.vcf.gz\t0.016514 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr17.vcf.gz\t0.014646 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr18.vcf.gz\t0.014391 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr19.vcf.gz\t0.009733 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr20.vcf.gz\t0.013520 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr21.vcf.gz\t0.007175 seconds\n",
      "Concatenating /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr22.vcf.gz\t0.007638 seconds\n",
      "Writing to /tmp/bcftools.2yEzRI\n",
      "Merging 1 temporary files\n",
      "Done\n",
      "Cleaning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phasing, cleanup, and concatenation completed successfully.\n",
      "Removing individual phased VCF files...\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr1.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr2.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr3.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr4.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr5.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr6.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr7.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr8.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr9.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr10.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr11.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr12.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr13.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr14.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr15.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr16.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr17.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr18.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr19.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr20.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr21.vcf.gz and its index.\n",
      "Removed /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_phased_chr22.vcf.gz and its index.\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$data_directory\" \"$utils_directory\" \"$results_directory\"\n",
    "\n",
    "data_directory=\"$1\"\n",
    "utils_directory=\"$2\"\n",
    "results_directory=\"$3\"\n",
    "\n",
    "# Define the directory containing phased VCF files\n",
    "phased_samples_dir=\"${results_directory}/phased_samples\"\n",
    "\n",
    "# Concatenate phased VCF files\n",
    "echo \"Creating list of phased VCF files...\"\n",
    "PHASED_FILE_LIST=\"${phased_samples_dir}/phased_file_list_sample.txt\"\n",
    "\n",
    "# Empty the file list if it already exists\n",
    "> \"$PHASED_FILE_LIST\"\n",
    "\n",
    "for CHR in {1..22}; do\n",
    "    PHASED_VCF=\"${phased_samples_dir}/merged_opensnps_phased_chr${CHR}.vcf.gz\"\n",
    "    if [ -f \"$PHASED_VCF\" ]; then\n",
    "        echo \"$PHASED_VCF\" >> \"$PHASED_FILE_LIST\"\n",
    "    else\n",
    "        echo \"Phased VCF missing for chromosome $CHR\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "CONCATENATED_VCF=\"${phased_samples_dir}/merged_opensnps_autosomes.vcf\"\n",
    "SORTED_VCF=\"${phased_samples_dir}/merged_opensnps_autosomes_sorted.vcf.gz\"\n",
    "STATS_OUTPUT=\"${phased_samples_dir}/merged_opensnps_autosomes_sorted_stats.vchk\"\n",
    "\n",
    "# Concatenate VCF files\n",
    "bcftools concat -o \"$CONCATENATED_VCF\" --file-list \"$PHASED_FILE_LIST\"\n",
    "\n",
    "if [ -f \"$CONCATENATED_VCF\" ]; then\n",
    "    # Sort and compress the concatenated VCF\n",
    "    bcftools sort -Oz -o \"$SORTED_VCF\" \"$CONCATENATED_VCF\"\n",
    "\n",
    "    # Index the sorted VCF\n",
    "    bcftools index --tbi -f \"$SORTED_VCF\"\n",
    "\n",
    "    # Generate stats\n",
    "    bcftools stats -s - \"$SORTED_VCF\" > \"$STATS_OUTPUT\"\n",
    "\n",
    "    rm -f \"${results_directory}/merged_opensnps_autosomes_step1*\"\n",
    "    rm -f \"${results_directory}/merged_opensnps_autosomes_step2*\"\n",
    "\n",
    "    echo \"Phasing, cleanup, and concatenation completed successfully.\"\n",
    "\n",
    "    # Remove individual phased VCF files\n",
    "    echo \"Removing individual phased VCF files...\"\n",
    "    for CHR in {1..22}; do\n",
    "        PHASED_VCF=\"${phased_samples_dir}/merged_opensnps_phased_chr${CHR}.vcf.gz\"\n",
    "        if [ -f \"${PHASED_VCF}\" ]; then\n",
    "            rm -f \"${PHASED_VCF}\"\n",
    "            rm -f \"${PHASED_VCF}.tbi\"\n",
    "            rm -f \"${phased_samples_dir}/merged_opensnps_phased_chr${CHR}.log\"\n",
    "            rm -f \"${phased_samples_dir}/merged_opensnps_phased_chr${CHR}_stats.vchk\"\n",
    "            echo \"Removed $PHASED_VCF and its index.\"\n",
    "        fi\n",
    "    done\n",
    "    rm -f \"${phased_samples_dir}/merged_opensnps_autosomes.vcf\"\n",
    "else\n",
    "    echo \"Concatenated VCF file missing. Pipeline aborted.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the format of the data files from VCF to BED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v2.0.0-a.6.4LM 64-bit Intel (6 Dec 2024)     cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.log.\n",
      "Options in effect:\n",
      "  --autosome\n",
      "  --make-bed\n",
      "  --out /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted\n",
      "  --vcf /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.vcf.gz\n",
      "\n",
      "Start time: Mon Feb 17 00:36:59 2025\n",
      "7789 MiB RAM detected, ~4754 available; reserving 3894 MiB for main workspace.\n",
      "Using up to 12 threads (change this with --threads).\n",
      "--vcf: 400582 variants scanned.\n",
      "--vcf: 393k variants converted. \n",
      "/home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted-temporary.pgen\n",
      "+\n",
      "/home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted-temporary.pvar.zst\n",
      "+\n",
      "/home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted-temporary.psam\n",
      "written.\n",
      "106 samples (0 females, 0 males, 106 ambiguous; 106 founders) loaded from\n",
      "/home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted-temporary.psam.\n",
      "400582 variants loaded from\n",
      "/home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted-temporary.pvar.zst.\n",
      "Note: No phenotype data present.\n",
      "Writing\n",
      "/home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.fam\n",
      "... done.\n",
      "Writing\n",
      "/home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.bim\n",
      "... done.\n",
      "Writing\n",
      "/home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.bed\n",
      "... 163249658198done.\n",
      "End time: Mon Feb 17 00:36:59 2025\n",
      "PLINK2 successfully processed: /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.vcf.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$data_directory\" \"$utils_directory\" \"$results_directory\"\n",
    "\n",
    "data_directory=\"$1\"\n",
    "utils_directory=\"$2\"\n",
    "results_directory=\"$3\"\n",
    "\n",
    "# Define\n",
    "phased_samples_dir=\"${results_directory}/phased_samples\"\n",
    "vcf_file=\"${phased_samples_dir}/merged_opensnps_autosomes_sorted.vcf.gz\"\n",
    "\n",
    "# Ensure the PLINK2 executable exists\n",
    "if [[ ! -f \"${utils_directory}/plink2\" ]]; then\n",
    "    echo \"Error: PLINK2 executable not found: ${utils_directory}/plink2\" >&2\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Ensure the phased samples directory exists\n",
    "if [[ ! -d \"${phased_samples_dir}\" ]]; then\n",
    "    echo \"Error: Phased samples directory not found: ${phased_samples_dir}\" >&2\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Check if the file exists\n",
    "if [[ ! -f \"$vcf_file\" ]]; then\n",
    "    echo \"No matching VCF file found in $phased_samples_dir\" >&2\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Extract the file prefix (removing .vcf.gz extension)\n",
    "output_prefix=\"${vcf_file%.vcf.gz}\"\n",
    "\n",
    "# Convert the VCF file to PLINK format\n",
    "${utils_directory}/plink2 --vcf \"$vcf_file\" --autosome --make-bed --out \"$output_prefix\"\n",
    "\n",
    "# Check exit status\n",
    "if [[ $? -eq 0 ]]; then\n",
    "    echo \"PLINK2 successfully processed: ${vcf_file}\"\n",
    "else\n",
    "    echo \"Error processing ${vcf_file}\" >&2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "- `data_directory`, `utils_directory`, and `results_directory` are passed as arguments and assigned.\n",
    "- The script verifies that plink2 exists and that the phased_samples_dir is a valid directory.\n",
    "- It loops over files matching opensnps_phased_*.vcf.gz, checking if they exist before processing.\n",
    "- Uses PLINK2 to convert each .vcf.gz file to PLINK binary format (.bed, .bim, .fam).\n",
    "- Handles errors and prints appropriate messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Genetic Map to Bim File\n",
    "(as per the IBIS developer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr1.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr2.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr3.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr4.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr5.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr6.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr7.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr8.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr9.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr10.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr11.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr12.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr13.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr14.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr15.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr16.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr17.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr18.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr19.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr20.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr21.GRCh38.map... done\n",
      "Reading map file /home/lakishadavid/computational_genetic_genealogy/references/genetic_maps/ibis_genetic_maps/plink.chr22.GRCh38.map... done\n",
      "Processing bim/map file /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.bim... \n",
      "Warning: position 18551346 before chrom 14 start; map and physical pos set to 0\n",
      "Warning: position 163755 before chrom 17 start; map and physical pos set to 0\n",
      "Warning: position 164114 before chrom 17 start; map and physical pos set to 0\n",
      "Warning: position 165672 before chrom 17 start; map and physical pos set to 0\n",
      "Warning: position 169110 before chrom 17 start; map and physical pos set to 0\n",
      "Warning: position 169598 before chrom 17 start; map and physical pos set to 0\n",
      "Warning: position 83088537 after chrom 17 end; map and physical pos set to 0\n",
      "done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic map added to: /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.bim\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$results_directory\" \"$references_directory\" \"$utils_directory\"\n",
    "\n",
    "results_directory=\"$1\"\n",
    "references_directory=\"$2\"\n",
    "utils_directory=\"$3\"\n",
    "\n",
    "# Define the script for adding the genetic map\n",
    "add_map_script=\"${utils_directory}/ibis/add-map-plink.pl\"\n",
    "if [[ ! -f \"${add_map_script}\" ]]; then\n",
    "    echo \"Error: Add-map script not found: $add_map_script\" >&2\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "bim_file=\"${results_directory}/phased_samples/merged_opensnps_autosomes_sorted.bim\"\n",
    "if [[ ! -f \"${bim_file}\" ]]; then\n",
    "    echo \"NOT FOUND: ${bim_file}\" >&2\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "map_directory=\"${references_directory}/genetic_maps/ibis_genetic_maps\"\n",
    "output_bim=\"${results_directory}/phased_samples/merged_opensnps_autosomes_sorted.bim.gm\"\n",
    "\n",
    "# Run the add-map script\n",
    "${add_map_script} ${bim_file} ${map_directory}/plink.chr{1..22}.GRCh38.map > \"${output_bim}\"\n",
    "\n",
    "# Check exit status\n",
    "if [[ $? -eq 0 ]]; then\n",
    "    echo \"Genetic map added to: ${bim_file}\"\n",
    "else\n",
    "    echo \"Error adding genetic map to: ${bim_file}\" >&2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "- The script assigns arguments to data_directory, references_directory, and utils_directory.\n",
    "- It verifies the existence of the add-map-plink.pl script.\n",
    "- It checks for .bim files in data_directory, ensuring at least one exists.\n",
    "- Extracts the chromosome number from the .bim filename.\n",
    "- Determines the corresponding genetic map file.\n",
    "- If the necessary files exist, it runs the Perl script to append the genetic map.\n",
    "- The new .bim file is saved with a _gm.bim suffix.\n",
    "- Errors are handled with messages and exit codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the IBD Detection Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBIS Segment Caller!  v1.20.9    (Released December 7, 2020)\n",
      "\n",
      "Viewing arguments...\n",
      "-ibd2 - running with IBD2 detection enabled\n",
      "-min_l - running with minimum IBD1 length 7.000000\n",
      "-mt - running with minimum IBD1 marker threshold of 499.000000\n",
      "-er - running with error rate 0.004000\n",
      "-min_l2 - running with minimum IBD2 length 2.000000\n",
      "-mt2 - running with minimum IBD2 marker threshold of 185.000000\n",
      "-er2 - running with IBD2 error rate 0.008000\n",
      "-o - setting output file /home/lakishadavid/computational_genetic_genealogy/results/merged_opensnps_autosomes_ibis.seg\n",
      "-printCoef - printing coefficient file\n",
      "-noFamID - assuming no Family ID in input\n",
      "No -b or -bfile - Running with input files: /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.bed, /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.bim.gm, /home/lakishadavid/computational_genetic_genealogy/results/phased_samples/merged_opensnps_autosomes_sorted.fam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Omitting marker rs28699618: missing physical position\n",
      "Omitting marker rs6565704: missing physical position\n",
      "Omitting marker rs6565705: missing physical position\n",
      "Omitting marker rs7502403: missing physical position\n",
      "Omitting marker rs8064924: missing physical position\n",
      "Omitting marker rs8075072: missing physical position\n",
      "Omitting marker rs7221348: missing physical position\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing SNP file... done.\n",
      "Parsing individual file... done.\n",
      "Parsing genotype file... initiated, to complete later.\n",
      "Chromosome map shorter than 6 units of genetic distance.\n",
      " Morgan input detected - Converting to centimorgans. (Prevent this by running with -noConvert argument)\n",
      "Defining Windows... done.\n",
      "Total Genetic Length in use:3536.001953\n",
      "Organizing genotype data for analysis... done.\n",
      "Beginning segment detection with 1 thread(s)...Total Segments Found: 108\n",
      "done.\n",
      "IBIS analysis completed successfully.\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$data_directory\" \"$results_directory\" \"$utils_directory\"\n",
    "\n",
    "data_directory=\"$1\"\n",
    "results_directory=\"$2\"\n",
    "utils_directory=\"$3\"\n",
    "\n",
    "# Define the IBIS executable path\n",
    "ibis=\"${utils_directory}/ibis/ibis\"\n",
    "\n",
    "# Ensure the IBIS executable exists\n",
    "if [[ ! -f \"${ibis}\" ]]; then\n",
    "    echo \"Error: IBIS executable not found: ${ibis}\" >&2\n",
    "fi\n",
    "\n",
    "bed_file=\"${results_directory}/phased_samples/merged_opensnps_autosomes_sorted.bed\"\n",
    "bim_file=\"${results_directory}/phased_samples/merged_opensnps_autosomes_sorted.bim.gm\"\n",
    "fam_file=\"${results_directory}/phased_samples/merged_opensnps_autosomes_sorted.fam\"\n",
    "${ibis} ${bed_file} ${bim_file} ${fam_file} -ibd2 -min_l 7 -mt 500 -er .004 \\\n",
    "    -min_l2 2 -mt2 186 -er2 .008 \\\n",
    "    -o \"${results_directory}/merged_opensnps_autosomes_ibis\" \\\n",
    "    -printCoef -noFamID\n",
    "\n",
    "# Check exit status\n",
    "if [[ $? -eq 0 ]]; then\n",
    "    echo \"IBIS analysis completed successfully.\"\n",
    "else\n",
    "    echo \"Error running IBIS analysis.\" >&2\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBIS Output File Descriptions\n",
    "\n",
    "## IBIS\n",
    "This file contains detailed information about identity-by-descent (IBD) segments shared between pairs of individuals.\n",
    "\n",
    "### Columns:\n",
    "- **sample1, sample2**: IDs of the two individuals being compared for shared genetic segments.\n",
    "- **chrom**: Chromosome number where the IBD segment is located.\n",
    "- **phys_start_pos, phys_end_pos**: Start and end positions of the IBD segment in base pairs (physical positions).\n",
    "- **IBD_type**: Type of IBD segment (e.g., IBD1 for sharing one parental haplotype or IBD2 for sharing both parental haplotypes).\n",
    "- **genetic_start_pos, genetic_end_pos**: Start and end positions of the segment in genetic map units (centiMorgans).\n",
    "- **genetic_seg_length**: Length of the IBD segment in centiMorgans (genetic distance).\n",
    "- **marker_count**: Number of genetic markers (SNPs) within the segment.\n",
    "- **error_count**: Total number of mismatches or genotyping errors detected in the segment.\n",
    "- **error_density**: Average error rate per marker in the segment (error_count divided by marker_count).\n",
    "\n",
    "---\n",
    "\n",
    "## Coef\n",
    "This file provides information about pairwise kinship coefficients and degrees of relatedness.\n",
    "\n",
    "### Columns:\n",
    "- **sample1, sample2**: IDs of the two individuals being compared.\n",
    "- **kinship_coefficient**: A measure of genetic similarity between the individuals, ranging from 0 (no relation) to higher values for close relatives.\n",
    "- **IBD2_fraction**: Proportion of the genome where both parental haplotypes are shared between the individuals.\n",
    "- **segment_count**: Total number of IBD segments identified between the individuals.\n",
    "- **degree_of_relatedness**: Classification of the relationship based on kinship (e.g., siblings, cousins).\n",
    "\n",
    "---\n",
    "\n",
    "## IBD2\n",
    "Represents segments where two individuals share both parental haplotypes.  \n",
    "IBD2 is particularly useful in identifying siblings or individuals with close familial ties, as these segments indicate inheritance from both sides of the family.\n",
    "\n",
    "---\n",
    "\n",
    "## HBD (Runs of Homozygosity)\n",
    "Indicates segments where an individual has matching haplotypes on both chromosomes, likely due to inheritance from a common ancestor.  \n",
    "This is a measure of inbreeding or autozygosity (when an individual inherits identical haplotypes from both parents).\n",
    "\n",
    "### Columns:\n",
    "- **sample_id**: ID of the individual being analyzed for HBD segments.\n",
    "- **chrom**: Chromosome number where the HBD segment is located.\n",
    "- **phys_start_pos, phys_end_pos**: Start and end positions of the HBD segment in base pairs.\n",
    "- **HBD_type**: Type or classification of the HBD segment.\n",
    "- **genetic_start_pos, genetic_end_pos**: Start and end positions of the segment in genetic map units (centiMorgans).\n",
    "- **genetic_seg_length**: Length of the HBD segment in centiMorgans.\n",
    "- **marker_count**: Number of genetic markers (SNPs) in the segment.\n",
    "- **error_count**: Total number of mismatches or genotyping errors detected in the segment.\n",
    "- **error_density**: Average error rate per marker in the segment.\n",
    "\n",
    "---\n",
    "\n",
    "## Incoef\n",
    "Provides inbreeding coefficients for individuals, based on HBD analysis.\n",
    "\n",
    "### Columns:\n",
    "- **sample_id**: ID of the individual being analyzed.\n",
    "- **inbreeding_coefficient**: A measure of inbreeding for the individual, reflecting the proportion of the genome covered by HBD segments.\n",
    "- **segment_count**: Total number of HBD segments identified in the individual's genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def explore_coefficients(results_directory, filename=\"ibis_MergedSamples.coef\", focus_on_related=True, save_plots=True, output_subdir=\"segments\"):\n",
    "    \"\"\"\n",
    "    Reads and explores the coefficients file from the results directory.\n",
    "    Includes handling for missing values and options to focus on related individuals.\n",
    "    \n",
    "    Parameters:\n",
    "        results_directory (str): Directory containing the result files.\n",
    "        filename (str): Filename of the coefficients file.\n",
    "        focus_on_related (bool): If True, focuses analysis on related individuals (Degree > 0).\n",
    "        save_plots (bool): If True, saves plots to the specified output directory.\n",
    "        output_dir (str): Directory to save plots.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed coefficients DataFrame for further analysis.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Ensure output directory exists\n",
    "    output_dir = os.path.join(results_directory, output_subdir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Step 1: Read the coefficients file\n",
    "    file_path = os.path.join(results_directory, filename)\n",
    "    coefficients = pd.read_csv(file_path, sep=\"\\t\", low_memory=False)\n",
    "\n",
    "    # Save both full and filtered data if focus_on_related is True\n",
    "    full_data = coefficients.copy()\n",
    "    filtered_data = None\n",
    "\n",
    "    if focus_on_related:\n",
    "        print(\"\\nFocusing on related individuals (Degree > 0).\")\n",
    "        filtered_data = full_data[full_data['Degree'] > 0]\n",
    "        print(f\"Filtered DataFrame Info (Degree > 0):\")\n",
    "        filtered_data.info()\n",
    "        print(\"\\n=== Descriptive Statistics (Filtered) ===\")\n",
    "        print(filtered_data.describe())\n",
    "        print(\"\\n\")\n",
    "        filtered_file_path = os.path.join(output_dir, \"filtered_coefficients.csv\")\n",
    "        filtered_data.to_csv(filtered_file_path, index=False)\n",
    "        print(f\"Filtered coefficients saved to: {filtered_file_path}\")\n",
    "\n",
    "    # Save and print the full data\n",
    "    print(\"\\nFull DataFrame Info:\")\n",
    "    full_data.info()\n",
    "    print(\"\\n=== Descriptive Statistics (Full) ===\")\n",
    "    print(full_data.describe())\n",
    "    print(\"\\n\")\n",
    "    full_file_path = os.path.join(output_dir, \"full_coefficients.csv\")\n",
    "    full_data.to_csv(full_file_path, index=False)\n",
    "    print(f\"Full coefficients saved to: {full_file_path}\")\n",
    "\n",
    "    # Analyze both datasets\n",
    "    datasets = {\"Full\": full_data, \"Filtered\": filtered_data} if focus_on_related else {\"Full\": full_data}\n",
    "\n",
    "    for name, data in datasets.items():\n",
    "        if data is not None:\n",
    "            print(f\"\\n=== Analyzing {name} Data ===\")\n",
    "            \n",
    "            # Counts by Degree\n",
    "            degree_grouped_counts = data['Degree'].value_counts().sort_index()\n",
    "            degree_grouped_counts_df = degree_grouped_counts.reset_index(name='Count')\n",
    "            degree_grouped_counts_df.columns = ['Degree', 'Count']\n",
    "            print(f\"=== Counts by Degree ({name}) ===\")\n",
    "            print(degree_grouped_counts_df)\n",
    "            \n",
    "            # Save HTML table\n",
    "            # html_table = degree_grouped_counts_df.to_html(index=False)\n",
    "            # html_file_path = os.path.join(output_dir, f\"{name.lower()}_degree_counts.html\")\n",
    "            # with open(html_file_path, \"w\") as f:\n",
    "            #     f.write(html_table)\n",
    "            # print(f\"HTML table for {name} data saved to: {html_file_path}\")\n",
    "\n",
    "            # # Display in Jupyter if available\n",
    "            # if hasattr(IPython, 'get_ipython') and IPython.get_ipython() is not None:\n",
    "            #     display(HTML(html_table))\n",
    "\n",
    "            # # Visualizations\n",
    "            # def save_or_show_plot(fig, filename):\n",
    "            #     if save_plots:\n",
    "            #         fig.savefig(os.path.join(output_dir, f\"{name.lower()}_{filename}\"))\n",
    "            #     plt.close(fig)\n",
    "\n",
    "            # # Degree distribution\n",
    "            # fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            # sns.histplot(data['Degree'], bins=10, kde=False, ax=ax)\n",
    "            # ax.set_title(f'Degree Distribution ({name})')\n",
    "            # ax.set_xlabel('Degree')\n",
    "            # ax.set_ylabel('Frequency')\n",
    "            # save_or_show_plot(fig, \"degree_distribution.png\")\n",
    "\n",
    "            # # Other plots\n",
    "            # if 'Kinship_Coefficient' in data.columns:\n",
    "            #     fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            #     sns.histplot(data['Kinship_Coefficient'], bins=30, kde=True, ax=ax)\n",
    "            #     ax.set_title(f'Kinship Coefficient Distribution ({name})')\n",
    "            #     ax.set_xlabel('Kinship Coefficient')\n",
    "            #     ax.set_ylabel('Frequency')\n",
    "            #     save_or_show_plot(fig, \"kinship_coefficient_distribution.png\")\n",
    "\n",
    "            # if 'IBD2_Fraction' in data.columns:\n",
    "            #     fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            #     sns.histplot(data['IBD2_Fraction'], bins=30, kde=True, ax=ax)\n",
    "            #     ax.set_title(f'IBD2 Fraction Distribution ({name})')\n",
    "            #     ax.set_xlabel('IBD2 Fraction')\n",
    "            #     ax.set_ylabel('Frequency')\n",
    "            #     save_or_show_plot(fig, \"ibd2_fraction_distribution.png\")\n",
    "\n",
    "            # if all(col in data.columns for col in ['Kinship_Coefficient', 'IBD2_Fraction']):\n",
    "            #     fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            #     sns.scatterplot(\n",
    "            #         data=data,\n",
    "            #         x='Kinship_Coefficient',\n",
    "            #         y='IBD2_Fraction',\n",
    "            #         hue='Degree', palette='viridis', ax=ax\n",
    "            #     )\n",
    "            #     ax.set_title(f'Kinship vs. IBD2 Fraction ({name})')\n",
    "            #     ax.set_xlabel('Kinship Coefficient')\n",
    "            #     ax.set_ylabel('IBD2 Fraction')\n",
    "            #     plt.legend(title='Degree')\n",
    "            #     save_or_show_plot(fig, \"kinship_vs_ibd2_fraction.png\")\n",
    "\n",
    "            # # Correlation matrix\n",
    "            # numeric_cols = ['Kinship_Coefficient', 'IBD2_Fraction', 'Segment_Count']\n",
    "            # existing_cols = [col for col in numeric_cols if col in data.columns]\n",
    "            # if existing_cols:\n",
    "            #     fig, ax = plt.subplots(figsize=(6, 5))\n",
    "            #     corr = data[existing_cols].corr()\n",
    "            #     sns.heatmap(corr, annot=True, cmap='Blues', square=True, ax=ax)\n",
    "            #     ax.set_title(f'Correlation Matrix ({name})')\n",
    "            #     save_or_show_plot(fig, \"correlation_matrix.png\")\n",
    "\n",
    "    print(\"\\nAnalysis completed.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Focusing on related individuals (Degree > 0).\n",
      "Filtered DataFrame Info (Degree > 0):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6 entries, 1966 to 4747\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Individual1          6 non-null      object \n",
      " 1   Individual2          6 non-null      object \n",
      " 2   Kinship_Coefficient  6 non-null      float64\n",
      " 3   IBD2_Fraction        6 non-null      float64\n",
      " 4   Segment_Count        6 non-null      int64  \n",
      " 5   Degree               6 non-null      int64  \n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 336.0+ bytes\n",
      "\n",
      "=== Descriptive Statistics (Filtered) ===\n",
      "       Kinship_Coefficient  IBD2_Fraction  Segment_Count    Degree\n",
      "count             6.000000       6.000000       6.000000  6.000000\n",
      "mean              0.063810       0.000835      10.333333  5.166667\n",
      "std               0.103334       0.002044      14.500575  2.857738\n",
      "min               0.002778       0.000000       1.000000  1.000000\n",
      "25%               0.002851       0.000000       1.000000  3.250000\n",
      "50%               0.003074       0.000000       1.500000  7.000000\n",
      "75%               0.089885       0.000000      17.750000  7.000000\n",
      "max               0.252333       0.005007      34.000000  7.000000\n",
      "\n",
      "\n",
      "Filtered coefficients saved to: /home/lakishadavid/computational_genetic_genealogy/results/segments/filtered_coefficients.csv\n",
      "\n",
      "Full DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5565 entries, 0 to 5564\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Individual1          5565 non-null   object \n",
      " 1   Individual2          5565 non-null   object \n",
      " 2   Kinship_Coefficient  5565 non-null   float64\n",
      " 3   IBD2_Fraction        5565 non-null   float64\n",
      " 4   Segment_Count        5565 non-null   int64  \n",
      " 5   Degree               5565 non-null   int64  \n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 261.0+ KB\n",
      "\n",
      "=== Descriptive Statistics (Full) ===\n",
      "       Kinship_Coefficient  IBD2_Fraction  Segment_Count       Degree\n",
      "count          5565.000000   5.565000e+03    5565.000000  5565.000000\n",
      "mean              0.001453   8.997305e-07       0.019407    -0.993351\n",
      "std               0.003714   6.711893e-05       0.558881     0.219778\n",
      "min               0.001380   0.000000e+00       0.000000    -1.000000\n",
      "25%               0.001380   0.000000e+00       0.000000    -1.000000\n",
      "50%               0.001380   0.000000e+00       0.000000    -1.000000\n",
      "75%               0.001380   0.000000e+00       0.000000    -1.000000\n",
      "max               0.252333   5.007000e-03      34.000000     7.000000\n",
      "\n",
      "\n",
      "Full coefficients saved to: /home/lakishadavid/computational_genetic_genealogy/results/segments/full_coefficients.csv\n",
      "\n",
      "=== Analyzing Full Data ===\n",
      "=== Counts by Degree (Full) ===\n",
      "   Degree  Count\n",
      "0      -1   5559\n",
      "1       1      1\n",
      "2       2      1\n",
      "3       7      4\n",
      "\n",
      "=== Analyzing Filtered Data ===\n",
      "=== Counts by Degree (Filtered) ===\n",
      "   Degree  Count\n",
      "0       1      1\n",
      "1       2      1\n",
      "2       7      4\n",
      "\n",
      "Analysis completed.\n"
     ]
    }
   ],
   "source": [
    "explore_coefficients(results_directory, filename=\"merged_opensnps_autosomes_ibis.coef\", focus_on_related=True, save_plots=True, output_subdir=\"segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seg_file = os.path.join(results_directory, \"merged_opensnps_autosomes_ibis.seg\")\n",
    "coef_file = os.path.join(results_directory, \"merged_opensnps_autosomes_ibis.coef\")\n",
    "\n",
    "\n",
    "seg_data_temp = pd.read_csv(seg_file, sep=\"\\t\", header=None)\n",
    "seg_data_temp.columns = [\n",
    "    \"sample1\", \"sample2\", \"chrom\", \n",
    "    \"phys_start_pos\", \"phys_end_pos\", \n",
    "    \"IBD_type\", \"genetic_start_pos\", \n",
    "    \"genetic_end_pos\", \"genetic_seg_length\", \n",
    "    \"marker_count\", \"error_count\", \"error_density\"\n",
    "    ]\n",
    "seg_data = seg_data_temp.sort_values(\n",
    "    by=[\"chrom\", \"phys_start_pos\", \"phys_end_pos\", \"IBD_type\"],\n",
    "    ascending=[True, True, True, True]\n",
    ")\n",
    "\n",
    "output_file = os.path.join(results_directory, \"merged_opensnps_autosomes_ibis.csv\")\n",
    "seg_data.to_csv(output_file, sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_segments_ibis(\n",
    "        results_directory, \n",
    "        filename=\"merged_opensnps_autosomes_ibis.seg\",\n",
    "        min_length=7, \n",
    "        min_markers=436, \n",
    "        max_error_density=0.004,\n",
    "        save_plots=True, \n",
    "        output_subdir=\"segments\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Explores and optionally filters the segments DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        results_directory (str): Directory containing the segments file.\n",
    "        filename (str): Filename of the segments file.\n",
    "        min_length (float): Minimum genetic length threshold for filtering.\n",
    "        min_markers (int): Minimum marker count threshold for filtering.\n",
    "        max_error_density (float): Maximum error density threshold for filtering.\n",
    "        filter_segments_enabled (bool): If True, apply filtering to the segments.\n",
    "        save_plots (bool): If True, save plots to the specified directory.\n",
    "        output_dir (str): Directory to save outputs and plots.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The segments DataFrame (filtered or unfiltered based on input).\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    output_dir = os.path.join(results_directory, output_subdir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Step 1: Read the segments file\n",
    "    file_path = os.path.join(results_directory, filename)\n",
    "    segments = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
    "    segments.columns = [\n",
    "        \"id1\", \"id2\", \"chromosome\", \"physical_position_start\", \n",
    "        \"physical_position_end\", \"IBD_type\", \"genetic_position_start\", \n",
    "        \"genetic_position_end\", \"genetic_length\", \"marker_count\", \n",
    "        \"error_count\", \"error_density\"\n",
    "    ]\n",
    "\n",
    "    # Ensure numeric columns are properly parsed\n",
    "    numeric_columns = [\"genetic_length\", \"marker_count\", \"error_density\", \"chromosome\"]\n",
    "    for col in numeric_columns:\n",
    "        if col in segments.columns:\n",
    "            segments[col] = pd.to_numeric(segments[col], errors='coerce')\n",
    "\n",
    "    # Drop rows with NaN values in numeric columns\n",
    "    nan_rows = segments[segments[numeric_columns].isnull().any(axis=1)]\n",
    "    if not nan_rows.empty:\n",
    "        nan_file_path = os.path.join(output_dir, \"nan_segments_ibis.csv\")\n",
    "        nan_rows.to_csv(nan_file_path, sep=\"\\t\", index=False)\n",
    "        print(f\"Rows with NaN values saved to: {nan_file_path}\")\n",
    "    segments = segments.dropna(subset=numeric_columns).reset_index(drop=True)\n",
    "\n",
    "    # Step 2: Basic info and descriptive statistics\n",
    "    print(\"=== Segments DataFrame Info ===\")\n",
    "    segments.info()\n",
    "    print(\"\\n=== Descriptive Statistics ===\")\n",
    "    print(segments[['genetic_length', 'marker_count', 'error_density']].describe())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Save the unfiltered data\n",
    "    unfiltered_file_path = os.path.join(output_dir, \"unfiltered_segments_ibis.csv\")\n",
    "    segments.to_csv(unfiltered_file_path, sep=\"\\t\", index=False)\n",
    "    print(f\"Unfiltered segments saved to: {unfiltered_file_path}\")\n",
    "    print()\n",
    "\n",
    "    filtered_segments = segments[\n",
    "        (segments['genetic_length'] >= min_length) &\n",
    "        (segments['marker_count'] >= min_markers) &\n",
    "        (segments['error_density'] <= max_error_density)\n",
    "    ].copy()\n",
    "    \n",
    "    print(\"=== Filtered Segments Info ===\")\n",
    "    filtered_segments.info()\n",
    "    print(\"\\n=== Descriptive Statistics (Filtered) ===\")\n",
    "    print(filtered_segments[['genetic_length', 'marker_count', 'error_density']].describe())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Save filtered segments to a new file\n",
    "    filtered_filename = \"filtered_segments_ibis.csv\"\n",
    "    filtered_file_path = os.path.join(output_dir, filtered_filename)\n",
    "    filtered_segments.to_csv(filtered_file_path, sep=\"\\t\", index=False)\n",
    "    print(f\"Filtered segments saved to: {filtered_file_path}\")\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total segments: {len(segments)}\")\n",
    "    print(f\"Filtered segments: {len(filtered_segments)}\")\n",
    "    if not nan_rows.empty:\n",
    "        print(f\"Rows with NaN values: {len(nan_rows)} (saved to: {nan_file_path})\")\n",
    "\n",
    "\n",
    "    # # Step 4: Visualizations\n",
    "    # def save_or_show_plot(fig, filename):\n",
    "    #     if save_plots:\n",
    "    #         fig.savefig(os.path.join(output_dir, filename))\n",
    "    #     plt.close(fig)\n",
    "\n",
    "    # def plot_distribution(data, column, title, xlabel, ylabel, filename, bins=30, kde=True):\n",
    "    #     fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    #     sns.histplot(data[column], bins=bins, kde=kde, ax=ax)\n",
    "    #     ax.set_title(title)\n",
    "    #     ax.set_xlabel(xlabel)\n",
    "    #     ax.set_ylabel(ylabel)\n",
    "    #     save_or_show_plot(fig, filename)\n",
    "\n",
    "    # # Visualize genetic_length distribution\n",
    "    # plot_distribution(\n",
    "    #     segments, \"genetic_length\", \"Distribution of Genetic Length\", \n",
    "    #     \"Genetic Length (cM)\", \"Frequency\", \"genetic_length_distribution_unfiltered.png\"\n",
    "    # )\n",
    "\n",
    "    # plot_distribution(\n",
    "    #     filtered_segments, \"genetic_length\", \"Distribution of Genetic Length (Filtered)\", \n",
    "    #     \"Genetic Length (cM)\", \"Frequency\", \"genetic_length_distribution_filtered.png\"\n",
    "    # )\n",
    "\n",
    "    # # Visualize marker_count distribution\n",
    "    # plot_distribution(\n",
    "    #     segments, \"marker_count\", \"Distribution of Marker Count\", \n",
    "    #     \"Marker Count\", \"Frequency\", \"marker_count_distribution_unfiltered.png\"\n",
    "    # )\n",
    "    # plot_distribution(\n",
    "    #     filtered_segments, \"marker_count\", \"Distribution of Marker Count (Filtered)\", \n",
    "    #     \"Marker Count\", \"Frequency\", \"marker_count_distribution_filtered.png\"\n",
    "    # )\n",
    "\n",
    "    # # Boxplot of genetic_length by chromosome\n",
    "    # def plot_boxplot(data, x_col, y_col, title, xlabel, ylabel, filename):\n",
    "    #     fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    #     sns.boxplot(x=x_col, y=y_col, data=data, ax=ax)\n",
    "    #     ax.set_title(title)\n",
    "    #     ax.set_xlabel(xlabel)\n",
    "    #     ax.set_ylabel(ylabel)\n",
    "    #     plt.xticks(rotation=45)\n",
    "    #     plt.tight_layout()\n",
    "    #     save_or_show_plot(fig, filename)\n",
    "\n",
    "    # plot_boxplot(\n",
    "    #     segments, \"chromosome\", \"genetic_length\", \n",
    "    #     \"Distribution of Genetic Length by Chromosome\", \n",
    "    #     \"Chromosome\", \"Genetic Length (cM)\", \"genetic_length_by_chromosome_unfiltered.png\"\n",
    "    # )\n",
    "    # plot_boxplot(\n",
    "    #     filtered_segments, \"chromosome\", \"genetic_length\", \n",
    "    #     \"Distribution of Genetic Length by Chromosome (Filtered)\", \n",
    "    #     \"Chromosome\", \"Genetic Length (cM)\", \"genetic_length_by_chromosome_filtered.png\"\n",
    "    # )\n",
    "\n",
    "    print(\"\\nAnalysis completed.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Segments DataFrame Info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108 entries, 0 to 107\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id1                      108 non-null    object \n",
      " 1   id2                      108 non-null    object \n",
      " 2   chromosome               108 non-null    int64  \n",
      " 3   physical_position_start  108 non-null    int64  \n",
      " 4   physical_position_end    108 non-null    int64  \n",
      " 5   IBD_type                 108 non-null    object \n",
      " 6   genetic_position_start   108 non-null    float64\n",
      " 7   genetic_position_end     108 non-null    float64\n",
      " 8   genetic_length           108 non-null    float64\n",
      " 9   marker_count             108 non-null    int64  \n",
      " 10  error_count              108 non-null    int64  \n",
      " 11  error_density            108 non-null    float64\n",
      "dtypes: float64(4), int64(5), object(3)\n",
      "memory usage: 10.2+ KB\n",
      "\n",
      "=== Descriptive Statistics ===\n",
      "       genetic_length  marker_count  error_density\n",
      "count      108.000000    108.000000     108.000000\n",
      "mean        52.976966   6008.879630       0.000236\n",
      "std         63.704260   7555.383443       0.000638\n",
      "min          2.675621    320.000000      -0.000372\n",
      "25%          8.478889    896.000000       0.000000\n",
      "50%         15.923481   1824.000000       0.000000\n",
      "75%         84.262470   9953.000000       0.000095\n",
      "max        268.819244  32053.000000       0.003472\n",
      "\n",
      "\n",
      "Unfiltered segments saved to: /home/lakishadavid/computational_genetic_genealogy/results/segments/unfiltered_segments_ibis.csv\n",
      "\n",
      "=== Filtered Segments Info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 103 entries, 0 to 107\n",
      "Data columns (total 12 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id1                      103 non-null    object \n",
      " 1   id2                      103 non-null    object \n",
      " 2   chromosome               103 non-null    int64  \n",
      " 3   physical_position_start  103 non-null    int64  \n",
      " 4   physical_position_end    103 non-null    int64  \n",
      " 5   IBD_type                 103 non-null    object \n",
      " 6   genetic_position_start   103 non-null    float64\n",
      " 7   genetic_position_end     103 non-null    float64\n",
      " 8   genetic_length           103 non-null    float64\n",
      " 9   marker_count             103 non-null    int64  \n",
      " 10  error_count              103 non-null    int64  \n",
      " 11  error_density            103 non-null    float64\n",
      "dtypes: float64(4), int64(5), object(3)\n",
      "memory usage: 10.5+ KB\n",
      "\n",
      "=== Descriptive Statistics (Filtered) ===\n",
      "       genetic_length  marker_count  error_density\n",
      "count      103.000000    103.000000     103.000000\n",
      "mean        55.376759   6279.446602       0.000247\n",
      "std         64.276964   7634.456716       0.000651\n",
      "min          7.029106    512.000000      -0.000372\n",
      "25%          8.645655    960.000000       0.000000\n",
      "50%         17.631163   1920.000000       0.000000\n",
      "75%         89.394333  10080.500000       0.000101\n",
      "max        268.819244  32053.000000       0.003472\n",
      "\n",
      "\n",
      "Filtered segments saved to: /home/lakishadavid/computational_genetic_genealogy/results/segments/filtered_segments_ibis.csv\n",
      "\n",
      "Summary:\n",
      "Total segments: 108\n",
      "Filtered segments: 103\n",
      "\n",
      "Analysis completed.\n"
     ]
    }
   ],
   "source": [
    "explore_segments_ibis(\n",
    "        results_directory, \n",
    "        filename=\"merged_opensnps_autosomes_ibis.seg\",\n",
    "        min_length=7, \n",
    "        min_markers=436, \n",
    "        max_error_density=0.004,\n",
    "        save_plots=True, \n",
    "        output_subdir=\"segments\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
