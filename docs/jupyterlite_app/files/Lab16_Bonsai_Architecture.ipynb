{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 16: Bonsai Architecture and Implementation\n",
    "\n",
    "In this lab, we will explore the architectural design and implementation details of the Bonsai algorithm. Building upon our understanding of IBD segments and pedigree reconstruction concepts from previous labs, we'll examine how Bonsai's modular components work together to build accurate pedigree structures from genetic data.\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Understanding the architecture of Bonsai is crucial for computational genetic genealogists who want to:\n",
    "- Modify the algorithm for specific research needs\n",
    "- Optimize performance for large-scale pedigree reconstruction\n",
    "- Extend the algorithm with new features or relationship models\n",
    "- Debug issues in pedigree reconstruction\n",
    "- Implement similar algorithms for related applications\n",
    "\n",
    "**Learning Objectives**:\n",
    "- Understand Bonsai's overall modular architecture\n",
    "- Examine the core components and their interactions\n",
    "- Analyze the implementation of key algorithms\n",
    "- Explore optimization strategies for performance and memory usage\n",
    "- Investigate extension mechanisms for customizing Bonsai\n",
    "- Practice modifying components to address specific use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install --no-root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "import pygraphviz as pgv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import random\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup for cross-compatibility\n",
    "from scripts_support.lab_cross_compatibility import setup_environment, is_jupyterlite\n\n",
    "# Set up environment-specific paths\n",
    "DATA_DIR, RESULTS_DIR = setup_environment()\n\n",
    "# Now you can use DATA_DIR and RESULTS_DIR consistently across environments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bonsai's Overall Architecture\n",
    "\n",
    "Before diving into specific components, let's understand the overall architecture of Bonsai. The algorithm follows a modular design pattern that separates concerns and allows for flexibility in implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Architectural Overview\n",
    "\n",
    "Bonsai's architecture consists of several interconnected modules, each with a specific responsibility:\n",
    "\n",
    "1. **Input Processing Module**: Handles reading and validating input data (IBD segments, bioinfo)\n",
    "2. **Relationship Model Module**: Defines genetic relationship patterns and likelihoods\n",
    "3. **Up-Node Dictionary Module**: Represents the pedigree structure as a dictionary of nodes\n",
    "4. **Optimization Engine**: Searches for the optimal pedigree structure\n",
    "5. **Constraint Handler**: Ensures biological and logical constraints are met\n",
    "6. **Output Generator**: Formats and returns the final pedigree structure\n",
    "\n",
    "Let's visualize this architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directed graph for the Bonsai architecture\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes for each component\n",
    "components = [\n",
    "    \"Input Data\", \"Input Processing\", \"Relationship Model\", \n",
    "    \"Up-Node Dictionary\", \"Optimization Engine\", \"Constraint Handler\",\n",
    "    \"Output Generator\", \"Final Pedigree\"\n",
    "]\n",
    "\n",
    "for component in components:\n",
    "    G.add_node(component)\n",
    "\n",
    "# Add edges to show data flow\n",
    "edges = [\n",
    "    (\"Input Data\", \"Input Processing\"),\n",
    "    (\"Input Processing\", \"Relationship Model\"),\n",
    "    (\"Input Processing\", \"Up-Node Dictionary\"),\n",
    "    (\"Relationship Model\", \"Optimization Engine\"),\n",
    "    (\"Up-Node Dictionary\", \"Optimization Engine\"),\n",
    "    (\"Optimization Engine\", \"Constraint Handler\"),\n",
    "    (\"Constraint Handler\", \"Optimization Engine\"),\n",
    "    (\"Optimization Engine\", \"Up-Node Dictionary\"),\n",
    "    (\"Up-Node Dictionary\", \"Output Generator\"),\n",
    "    (\"Output Generator\", \"Final Pedigree\")\n",
    "]\n",
    "\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Create a hierarchical layout\n",
    "pos = nx.nx_agraph.graphviz_layout(G, prog=\"dot\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", node_size=3000, \n",
    "        font_size=10, font_weight=\"bold\", arrows=True, arrowsize=20)\n",
    "plt.title(\"Bonsai Algorithm Architecture\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Module Interactions\n",
    "\n",
    "Let's explore how these modules interact with a simplified code example that traces the flow of data through the Bonsai algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bonsai module\n",
    "import sys\n",
    "sys.path.append(utils_directory)\n",
    "from bonsaitree.bonsaitree.v3 import bonsai\n",
    "\n",
    "# Examine the main entry point function\n",
    "print(\"Bonsai's main entry point function:\")\n",
    "print(bonsai.build_pedigree.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 The Build Pedigree Function\n",
    "\n",
    "The `build_pedigree` function is the main entry point for the Bonsai algorithm. Let's create a simplified version to understand its overall structure and flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplified_build_pedigree(bio_info, unphased_ibd_seg_list, min_seg_len=7):\n",
    "    \"\"\"Simplified version of Bonsai's build_pedigree function for educational purposes.\n",
    "    \n",
    "    Args:\n",
    "        bio_info: List of dictionaries with information about individuals\n",
    "        unphased_ibd_seg_list: List of IBD segments\n",
    "        min_seg_len: Minimum segment length to consider\n",
    "        \n",
    "    Returns:\n",
    "        List of (pedigree, log_likelihood) tuples\n",
    "    \"\"\"\n",
    "    # 1. Input Processing\n",
    "    print(\"1. Input Processing\")\n",
    "    print(f\"  Processing {len(bio_info)} individuals\")\n",
    "    print(f\"  Processing {len(unphased_ibd_seg_list)} IBD segments\")\n",
    "    print(f\"  Using minimum segment length of {min_seg_len} cM\")\n",
    "    \n",
    "    # 2. Initialize Up-Node Dictionary\n",
    "    print(\"\\n2. Initialize Up-Node Dictionary\")\n",
    "    up_dict = {}\n",
    "    # In the real implementation, this would create initial nodes for each individual\n",
    "    for i, person in enumerate(bio_info):\n",
    "        genotype_id = person['genotype_id']\n",
    "        up_dict[genotype_id] = {}\n",
    "        print(f\"  Added individual {genotype_id} to up_dict\")\n",
    "        if i >= 2:  # Just show a few for demonstration\n",
    "            print(\"  ...\")\n",
    "            break\n",
    "    \n",
    "    # 3. Initialize Relationship Model\n",
    "    print(\"\\n3. Initialize Relationship Model\")\n",
    "    # In the real implementation, this would create models for different relationship types\n",
    "    print(\"  Initializing models for: Parent-Child, Siblings, Cousins, etc.\")\n",
    "    \n",
    "    # 4. Run Optimization Engine\n",
    "    print(\"\\n4. Run Optimization Engine\")\n",
    "    print(\"  Starting pedigree search...\")\n",
    "    print(\"  Iteratively building and refining pedigree structure\")\n",
    "    print(\"  Applying constraints during optimization\")\n",
    "    \n",
    "    # 5. Generate Output\n",
    "    print(\"\\n5. Generate Output\")\n",
    "    print(\"  Finalizing pedigree structure\")\n",
    "    print(\"  Calculating final log likelihood\")\n",
    "    \n",
    "    # Return a simplified result\n",
    "    mock_pedigree = {i: {} for i in range(1, 4)}  # Mock pedigree with 3 individuals\n",
    "    mock_log_like = -100.5  # Mock log likelihood\n",
    "    \n",
    "    return [(mock_pedigree, mock_log_like)]\n",
    "\n",
    "# Create some dummy data for demonstration\n",
    "dummy_bio_info = [\n",
    "    {'genotype_id': 1, 'age': 30, 'sex': 'M'},\n",
    "    {'genotype_id': 2, 'age': 60, 'sex': 'F'},\n",
    "    {'genotype_id': 3, 'age': 35, 'sex': 'F'},\n",
    "    {'genotype_id': 4, 'age': 10, 'sex': 'M'}\n",
    "]\n",
    "\n",
    "dummy_ibd_seg_list = [\n",
    "    [1, 2, '1', 1000000, 5000000, False, 10.5],\n",
    "    [1, 3, '2', 2000000, 7000000, False, 15.2],\n",
    "    [2, 3, '3', 3000000, 9000000, False, 8.7]\n",
    "]\n",
    "\n",
    "# Run the simplified function\n",
    "result = simplified_build_pedigree(dummy_bio_info, dummy_ibd_seg_list)\n",
    "print(\"\\nResult:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Components\n",
    "\n",
    "Now that we understand the overall architecture, let's examine each of the core components in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Input Processing Module\n",
    "\n",
    "The Input Processing Module is responsible for reading, validating, and preparing the input data for use by the rest of the algorithm. The two main inputs to Bonsai are:\n",
    "\n",
    "1. **IBD Segments**: Detected identity-by-descent segments between pairs of individuals\n",
    "2. **Bioinfo**: Biological information about individuals (age, sex, etc.)\n",
    "\n",
    "Let's look at how Bonsai processes these inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ibd_segments(unphased_ibd_seg_list, min_seg_len=7):\n",
    "    \"\"\"Process and filter IBD segments.\n",
    "    \n",
    "    Args:\n",
    "        unphased_ibd_seg_list: List of IBD segments in format [id1, id2, chr, start, end, is_full, length]\n",
    "        min_seg_len: Minimum segment length in centiMorgans\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping pairs of individuals to their shared IBD segments\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store segments between pairs\n",
    "    ibd_dict = defaultdict(list)\n",
    "    \n",
    "    # Count of filtered segments\n",
    "    total_segments = len(unphased_ibd_seg_list)\n",
    "    filtered_segments = 0\n",
    "    \n",
    "    # Process each segment\n",
    "    for segment in unphased_ibd_seg_list:\n",
    "        id1, id2, chrom, start, end, is_full, length = segment\n",
    "        \n",
    "        # Filter segments by length\n",
    "        if length < min_seg_len:\n",
    "            filtered_segments += 1\n",
    "            continue\n",
    "        \n",
    "        # Store the segment (ensure consistent ordering of pairs)\n",
    "        pair = tuple(sorted([id1, id2]))\n",
    "        ibd_dict[pair].append({\n",
    "            'chromosome': chrom,\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'is_ibd2': is_full,\n",
    "            'length_cm': length\n",
    "        })\n",
    "    \n",
    "    print(f\"Processed {total_segments} segments\")\n",
    "    print(f\"Filtered out {filtered_segments} segments below {min_seg_len} cM\")\n",
    "    print(f\"Retained {total_segments - filtered_segments} segments\")\n",
    "    print(f\"Found IBD sharing between {len(ibd_dict)} pairs of individuals\")\n",
    "    \n",
    "    return ibd_dict\n",
    "\n",
    "def process_bioinfo(bio_info):\n",
    "    \"\"\"Process biological information for individuals.\n",
    "    \n",
    "    Args:\n",
    "        bio_info: List of dictionaries with information about individuals\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping individual IDs to their biological information\n",
    "    \"\"\"\n",
    "    bioinfo_dict = {}\n",
    "    \n",
    "    for person in bio_info:\n",
    "        genotype_id = person['genotype_id']\n",
    "        \n",
    "        # Extract required fields\n",
    "        processed_info = {\n",
    "            'sex': person.get('sex', 'U'),  # Default to Unknown if not provided\n",
    "            'age': person.get('age', None),\n",
    "            'birth_year': person.get('birth_year', None)\n",
    "        }\n",
    "        \n",
    "        # Validate sex information\n",
    "        if processed_info['sex'] not in ['M', 'F', 'U']:\n",
    "            print(f\"Warning: Invalid sex '{processed_info['sex']}' for individual {genotype_id}. Setting to Unknown.\")\n",
    "            processed_info['sex'] = 'U'\n",
    "            \n",
    "        bioinfo_dict[genotype_id] = processed_info\n",
    "    \n",
    "    print(f\"Processed bioinfo for {len(bioinfo_dict)} individuals\")\n",
    "    return bioinfo_dict\n",
    "\n",
    "# Test with our dummy data\n",
    "ibd_dict = process_ibd_segments(dummy_ibd_seg_list, min_seg_len=7)\n",
    "bioinfo_dict = process_bioinfo(dummy_bio_info)\n",
    "\n",
    "# Display a sample of the processed data\n",
    "print(\"\\nSample of IBD data:\")\n",
    "for pair, segments in list(ibd_dict.items())[:2]:  # Show first 2 pairs\n",
    "    print(f\"  {pair}: {segments}\")\n",
    "    \n",
    "print(\"\\nSample of bioinfo data:\")\n",
    "for id, info in list(bioinfo_dict.items())[:2]:  # Show first 2 individuals\n",
    "    print(f\"  {id}: {info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Relationship Model Module\n",
    "\n",
    "The Relationship Model Module defines the genetic relationship patterns and calculates likelihoods for different relationship hypotheses. This is one of the most critical components of Bonsai, as it determines how genetic evidence is evaluated.\n",
    "\n",
    "Let's implement a simplified version of the relationship model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationshipModel:\n",
    "    \"\"\"Models genetic relationships and calculates likelihoods based on IBD sharing.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize relationship model parameters.\"\"\"\n",
    "        # Define expected sharing for common relationships\n",
    "        # Format: (total_cm, num_segments)\n",
    "        self.expected_sharing = {\n",
    "            'parent-child': (3500, 40),\n",
    "            'full-siblings': (2500, 35),\n",
    "            'half-siblings': (1700, 25),\n",
    "            'grandparent': (1700, 25),\n",
    "            'aunt-uncle': (1700, 25),\n",
    "            'first-cousins': (850, 15),\n",
    "            'second-cousins': (212, 5),\n",
    "            'unrelated': (0, 0)\n",
    "        }\n",
    "        \n",
    "        # Standard deviations for expected sharing\n",
    "        self.sharing_sd = {\n",
    "            'total_cm': 0.1,  # As fraction of expected value\n",
    "            'num_segments': 0.2  # As fraction of expected value\n",
    "        }\n",
    "    \n",
    "    def calculate_relationship_likelihood(self, pair, segments, relationship_type):\n",
    "        \"\"\"Calculate likelihood of a specific relationship given IBD sharing.\n",
    "        \n",
    "        Args:\n",
    "            pair: Tuple of individual IDs\n",
    "            segments: List of IBD segments between the pair\n",
    "            relationship_type: String indicating relationship type\n",
    "            \n",
    "        Returns:\n",
    "            Log likelihood of the relationship\n",
    "        \"\"\"\n",
    "        if relationship_type not in self.expected_sharing:\n",
    "            raise ValueError(f\"Unknown relationship type: {relationship_type}\")\n",
    "        \n",
    "        # Calculate observed sharing\n",
    "        total_cm = sum(seg['length_cm'] for seg in segments)\n",
    "        num_segments = len(segments)\n",
    "        \n",
    "        # Get expected sharing for this relationship\n",
    "        expected_cm, expected_segments = self.expected_sharing[relationship_type]\n",
    "        \n",
    "        # Calculate standard deviations\n",
    "        sd_cm = expected_cm * self.sharing_sd['total_cm'] if expected_cm > 0 else 1\n",
    "        sd_segments = expected_segments * self.sharing_sd['num_segments'] if expected_segments > 0 else 1\n",
    "        \n",
    "        # Calculate log likelihood using normal distribution\n",
    "        from scipy.stats import norm\n",
    "        \n",
    "        # Log likelihood for total cM\n",
    "        ll_cm = norm.logpdf(total_cm, expected_cm, sd_cm) if expected_cm > 0 else 0\n",
    "        \n",
    "        # Log likelihood for number of segments\n",
    "        ll_segments = norm.logpdf(num_segments, expected_segments, sd_segments) if expected_segments > 0 else 0\n",
    "        \n",
    "        # Combined log likelihood\n",
    "        log_likelihood = ll_cm + ll_segments\n",
    "        \n",
    "        return log_likelihood\n",
    "    \n",
    "    def find_most_likely_relationship(self, pair, segments):\n",
    "        \"\"\"Find the most likely relationship type given IBD sharing.\n",
    "        \n",
    "        Args:\n",
    "            pair: Tuple of individual IDs\n",
    "            segments: List of IBD segments between the pair\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (relationship_type, log_likelihood)\n",
    "        \"\"\"\n",
    "        best_relationship = None\n",
    "        best_likelihood = float('-inf')\n",
    "        \n",
    "        for relationship in self.expected_sharing.keys():\n",
    "            likelihood = self.calculate_relationship_likelihood(pair, segments, relationship)\n",
    "            \n",
    "            if likelihood > best_likelihood:\n",
    "                best_likelihood = likelihood\n",
    "                best_relationship = relationship\n",
    "        \n",
    "        return (best_relationship, best_likelihood)\n",
    "\n",
    "# Create a relationship model\n",
    "relationship_model = RelationshipModel()\n",
    "\n",
    "# Test with a sample pair and their segments\n",
    "sample_pair = next(iter(ibd_dict.keys()))\n",
    "sample_segments = ibd_dict[sample_pair]\n",
    "\n",
    "print(f\"Testing relationship model with pair {sample_pair} who share {len(sample_segments)} segments\")\n",
    "print(f\"Total shared cM: {sum(seg['length_cm'] for seg in sample_segments):.2f}\")\n",
    "\n",
    "# Calculate likelihoods for different relationships\n",
    "print(\"\\nRelationship likelihoods:\")\n",
    "for relationship in relationship_model.expected_sharing.keys():\n",
    "    likelihood = relationship_model.calculate_relationship_likelihood(sample_pair, sample_segments, relationship)\n",
    "    print(f\"  {relationship}: {likelihood:.2f}\")\n",
    "\n",
    "# Find most likely relationship\n",
    "most_likely = relationship_model.find_most_likely_relationship(sample_pair, sample_segments)\n",
    "print(f\"\\nMost likely relationship: {most_likely[0]} (log likelihood: {most_likely[1]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Up-Node Dictionary Module\n",
    "\n",
    "The Up-Node Dictionary is the core data structure that represents the pedigree in Bonsai. It's called an \"Up-Node\" dictionary because it represents individuals and their upward connections in the pedigree (i.e., to parents, grandparents, etc.).\n",
    "\n",
    "Let's explore this data structure:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpNodeDictionary:\n    \"\"\"Represents a pedigree structure using an Up-Node Dictionary.\"\"\"\n    \n    def __init__(self, bioinfo_dict):\n        \"\"\"Initialize an empty pedigree with known individuals.\n        \n        Args:\n            bioinfo_dict: Dictionary mapping individual IDs to biological information\n        \"\"\"\n        self.up_dict = {}\n        self.next_internal_id = -1  # Negative IDs for inferred ancestors\n        \n        # Add known individuals to the pedigree\n        for individual_id, bio_info in bioinfo_dict.items():\n            self.up_dict[individual_id] = {\n                'father': None,\n                'mother': None,\n                'sex': bio_info['sex'],\n                'age': bio_info.get('age'),\n                'type': 'known'  # Known individual, not inferred\n            }\n    \n    def get_next_internal_id(self):\n        \"\"\"Get the next available internal ID for inferred ancestors.\"\"\"\n        internal_id = self.next_internal_id\n        self.next_internal_id -= 1\n        return internal_id\n    \n    def add_parent(self, child_id, parent_sex):\n        \"\"\"Add a parent to an individual.\n        \n        Args:\n            child_id: ID of the child\n            parent_sex: Sex of the parent ('M' for father, 'F' for mother)\n            \n        Returns:\n            ID of the added parent\n        \"\"\"\n        if child_id not in self.up_dict:\n            raise ValueError(f\"Individual {child_id} not found in pedigree\")\n        \n        # Create a new parent node\n        parent_id = self.get_next_internal_id()\n        self.up_dict[parent_id] = {\n            'father': None,\n            'mother': None,\n            'sex': parent_sex,\n            'age': None,  # Unknown age for inferred ancestors\n            'type': 'inferred'  # Inferred ancestor\n        }\n        \n        # Update the child's parent\n        if parent_sex == 'M':\n            self.up_dict[child_id]['father'] = parent_id\n        elif parent_sex == 'F':\n            self.up_dict[child_id]['mother'] = parent_id\n        else:\n            raise ValueError(f\"Invalid parent sex: {parent_sex}. Must be 'M' or 'F'.\")\n        \n        return parent_id\n    \n    def add_relationship(self, id1, id2, relationship):\n        \"\"\"Add a relationship between two individuals by adding common ancestors.\n        \n        Args:\n            id1: ID of the first individual\n            id2: ID of the second individual\n            relationship: Relationship type ('sibling', 'half-sibling', etc.)\n            \n        Returns:\n            IDs of added ancestors\n        \"\"\"\n        if relationship == 'full-siblings':\n            # Add common father and mother\n            father_id = self.add_parent(id1, 'M')\n            mother_id = self.add_parent(id1, 'F')\n            \n            # Connect second individual to the same parents\n            self.up_dict[id2]['father'] = father_id\n            self.up_dict[id2]['mother'] = mother_id\n            \n            return [father_id, mother_id]\n            \n        elif relationship == 'half-siblings':\n            # Add common parent (arbitrarily choose father)\n            father_id = self.add_parent(id1, 'M')\n            \n            # Connect second individual to the same father\n            self.up_dict[id2]['father'] = father_id\n            \n            # Add separate mothers\n            mother1_id = self.add_parent(id1, 'F')\n            mother2_id = self.add_parent(id2, 'F')\n            \n            return [father_id, mother1_id, mother2_id]\n            \n        elif relationship == 'first-cousins':\n            # Create grandparents\n            grandfather_id = self.get_next_internal_id()\n            grandmother_id = self.get_next_internal_id()\n            \n            # Create parents for id1\n            parent1_id = self.add_parent(id1, 'M')  # Father\n            self.up_dict[parent1_id]['father'] = grandfather_id\n            self.up_dict[parent1_id]['mother'] = grandmother_id\n            \n            # Create parents for id2\n            parent2_id = self.add_parent(id2, 'F')  # Mother (different from id1's parent)\n            self.up_dict[parent2_id]['father'] = grandfather_id\n            self.up_dict[parent2_id]['mother'] = grandmother_id\n            \n            # Add grandparents to the dictionary\n            self.up_dict[grandfather_id] = {\n                'father': None, 'mother': None, 'sex': 'M', 'age': None, 'type': 'inferred'\n            }\n            self.up_dict[grandmother_id] = {\n                'father': None, 'mother': None, 'sex': 'F', 'age': None, 'type': 'inferred'\n            }\n            \n            return [grandfather_id, grandmother_id, parent1_id, parent2_id]\n            \n        else:\n            raise ValueError(f\"Unsupported relationship type: {relationship}\")\n    \n    def visualize_pedigree(self):\n        \"\"\"Visualize the pedigree as a graph.\"\"\"\n        G = nx.DiGraph()\n        \n        # Add nodes\n        for individual_id, info in self.up_dict.items():\n            node_type = info['type']\n            sex = info['sex']\n            \n            # Choose node shape and color based on sex and type\n            if sex == 'M':\n                node_shape = 's'  # Square for males\n                node_color = 'lightblue' if node_type == 'known' else 'skyblue'\n            elif sex == 'F':\n                node_shape = 'o'  # Circle for females\n                node_color = 'pink' if node_type == 'known' else 'lightpink'\n            else:\n                node_shape = 'd'  # Diamond for unknown\n                node_color = 'lightgray' if node_type == 'known' else 'gray'\n            \n            G.add_node(individual_id, shape=node_shape, color=node_color, type=node_type)\n            \n            # Add edges to parents\n            if info['father'] is not None:\n                G.add_edge(info['father'], individual_id)\n            if info['mother'] is not None:\n                G.add_edge(info['mother'], individual_id)\n        \n        # Create positions using a hierarchical layout\n        pos = nx.nx_agraph.graphviz_layout(G, prog=\"dot\")\n        \n        plt.figure(figsize=(12, 8))\n        \n        # Draw nodes by sex\n        node_shapes = nx.get_node_attributes(G, 'shape')\n        node_colors = nx.get_node_attributes(G, 'color')\n        node_types = nx.get_node_attributes(G, 'type')\n        \n        # Draw males (squares)\n        male_nodes = [n for n, s in node_shapes.items() if s == 's']\n        male_colors = [node_colors[n] for n in male_nodes]\n        nx.draw_networkx_nodes(G, pos, nodelist=male_nodes, node_color=male_colors,\n                              node_shape='s', node_size=500)\n        \n        # Draw females (circles)\n        female_nodes = [n for n, s in node_shapes.items() if s == 'o']\n        female_colors = [node_colors[n] for n in female_nodes]\n        nx.draw_networkx_nodes(G, pos, nodelist=female_nodes, node_color=female_colors,\n                              node_shape='o', node_size=500)\n        \n        # Draw unknown (diamonds)\n        unknown_nodes = [n for n, s in node_shapes.items() if s == 'd']\n        unknown_colors = [node_colors[n] for n in unknown_nodes]\n        nx.draw_networkx_nodes(G, pos, nodelist=unknown_nodes, node_color=unknown_colors,\n                              node_shape='d', node_size=500)\n        \n        # Draw edges\n        nx.draw_networkx_edges(G, pos, arrows=False)\n        \n        # Draw labels\n        labels = {}\n        for node in G.nodes():\n            if node_types[node] == 'known':\n                labels[node] = str(node)\n            else:\n                labels[node] = f\"A{abs(node)}\"\n        nx.draw_networkx_labels(G, pos, labels=labels)\n        \n        plt.title(\"Pedigree Visualization\")\n        plt.axis('off')\n        plt.show()\n        \n        return G\n\n# Create an Up-Node Dictionary with our sample data\nup_node_dict = UpNodeDictionary(bioinfo_dict)\n\n# Display the initial state\nprint(\"Initial Up-Node Dictionary:\")\nfor id, info in up_node_dict.up_dict.items():\n    print(f\"  {id}: {info}\")\n\n# Add some relationships\nprint(\"\\nAdding full-sibling relationship between 1 and 3...\")\nadded_nodes = up_node_dict.add_relationship(1, 3, 'full-siblings')\nprint(f\"Added nodes: {added_nodes}\")\n\nprint(\"\\nAdding first-cousin relationship between 2 and 4...\")\nadded_nodes = up_node_dict.add_relationship(2, 4, 'first-cousins')\nprint(f\"Added nodes: {added_nodes}\")\n\n# Visualize the pedigree\nprint(\"\\nVisualizing the pedigree...\")\nup_node_dict.visualize_pedigree()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_pedigree_likelihood(up_dict, ibd_dict, relationship_model):\n    \"\"\"Calculate the overall likelihood of a pedigree given observed IBD sharing.\n    \n    Args:\n        up_dict: Up-Node Dictionary representing the pedigree\n        ibd_dict: Dictionary of IBD segments between pairs\n        relationship_model: Relationship model for likelihood calculations\n        \n    Returns:\n        Log likelihood of the pedigree\n    \"\"\"\n    total_log_likelihood = 0\n    \n    # Process each pair with observed IBD segments\n    for pair, segments in ibd_dict.items():\n        id1, id2 = pair\n        \n        # Infer the relationship type from the pedigree\n        relationship_type = infer_relationship_from_pedigree(up_dict.up_dict, id1, id2)\n        \n        # Calculate likelihood of this relationship given the observed segments\n        if relationship_type is not None:\n            try:\n                log_likelihood = relationship_model.calculate_relationship_likelihood(pair, segments, relationship_type)\n                total_log_likelihood += log_likelihood\n                print(f\"Pair {pair}: Inferred {relationship_type}, Log likelihood: {log_likelihood:.2f}\")\n            except ValueError:\n                # If the relationship type is not supported by the model\n                print(f\"Warning: Relationship type '{relationship_type}' not supported by the model\")\n        else:\n            print(f\"Warning: Could not infer relationship between {id1} and {id2}\")\n    \n    return total_log_likelihood\n\ndef infer_relationship_from_pedigree(up_dict, id1, id2):\n    \"\"\"Infer the relationship type between two individuals in a pedigree.\n    \n    Args:\n        up_dict: Up-Node Dictionary representing the pedigree\n        id1: ID of first individual\n        id2: ID of second individual\n        \n    Returns:\n        String indicating the relationship type, or None if it couldn't be determined\n    \"\"\"\n    # Check for direct parent-child relationship\n    if (up_dict[id1].get('father') == id2 or up_dict[id1].get('mother') == id2 or\n        up_dict[id2].get('father') == id1 or up_dict[id2].get('mother') == id1):\n        return 'parent-child'\n    \n    # Check for full siblings\n    if (up_dict[id1].get('father') is not None and up_dict[id2].get('father') is not None and\n        up_dict[id1].get('mother') is not None and up_dict[id2].get('mother') is not None and\n        up_dict[id1].get('father') == up_dict[id2].get('father') and\n        up_dict[id1].get('mother') == up_dict[id2].get('mother')):\n        return 'full-siblings'\n    \n    # Check for half siblings (same father)\n    if (up_dict[id1].get('father') is not None and up_dict[id2].get('father') is not None and\n        up_dict[id1].get('father') == up_dict[id2].get('father') and\n        up_dict[id1].get('mother') != up_dict[id2].get('mother')):\n        return 'half-siblings'\n    \n    # Check for half siblings (same mother)\n    if (up_dict[id1].get('mother') is not None and up_dict[id2].get('mother') is not None and\n        up_dict[id1].get('mother') == up_dict[id2].get('mother') and\n        up_dict[id1].get('father') != up_dict[id2].get('father')):\n        return 'half-siblings'\n    \n    # For simplicity, we'll stop at these basic relationships\n    # In a real implementation, we would trace through the pedigree to find grandparent-grandchild,\n    # first cousin, etc. relationships\n    \n    return None\n\n# Calculate the likelihood of our sample pedigree\nprint(\"Calculating pedigree likelihood...\")\npedigree_likelihood = calculate_pedigree_likelihood(up_node_dict, ibd_dict, relationship_model)\nprint(f\"Total log likelihood of the pedigree: {pedigree_likelihood:.2f}\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Optimization Engine\n\nThe Optimization Engine is responsible for searching through the space of possible pedigrees to find the structure that best explains the observed IBD sharing. This is the heart of the Bonsai algorithm, where the computational magic happens.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 3.1 Search Algorithms\n\nBonsai uses several search algorithms to explore the space of possible pedigrees:\n\n1. **Greedy Search**: Iteratively adds the most likely relationship at each step\n2. **Simulated Annealing**: Uses randomization to avoid getting stuck in local optima\n3. **Markov Chain Monte Carlo (MCMC)**: Samples from the space of possible pedigrees\n\nLet's implement a simplified version of the greedy search algorithm:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def greedy_pedigree_search(bioinfo_dict, ibd_dict, relationship_model, max_iterations=10):\n    \"\"\"Perform a greedy search for the best pedigree structure.\n    \n    Args:\n        bioinfo_dict: Dictionary of biological information for individuals\n        ibd_dict: Dictionary of IBD segments between pairs\n        relationship_model: Relationship model for likelihood calculations\n        max_iterations: Maximum number of iterations to perform\n        \n    Returns:\n        Tuple of (best_pedigree, best_likelihood)\n    \"\"\"\n    # Initialize an empty pedigree\n    current_pedigree = UpNodeDictionary(bioinfo_dict)\n    current_likelihood = calculate_pedigree_likelihood(current_pedigree, ibd_dict, relationship_model)\n    \n    print(f\"Initial pedigree likelihood: {current_likelihood:.2f}\")\n    \n    # Keep track of pairs that have been processed\n    processed_pairs = set()\n    \n    # Perform greedy search\n    for iteration in range(max_iterations):\n        print(f\"\\nIteration {iteration + 1}/{max_iterations}\")\n        \n        best_move = None\n        best_move_likelihood = current_likelihood\n        \n        # Try adding each possible relationship\n        for pair, segments in ibd_dict.items():\n            if pair in processed_pairs:\n                continue\n                \n            id1, id2 = pair\n            \n            # Find the most likely relationship for this pair\n            relationship, _ = relationship_model.find_most_likely_relationship(pair, segments)\n            \n            # Create a copy of the current pedigree\n            test_pedigree = UpNodeDictionary(bioinfo_dict)\n            test_pedigree.up_dict = current_pedigree.up_dict.copy()\n            \n            # Try adding this relationship\n            try:\n                test_pedigree.add_relationship(id1, id2, relationship)\n                test_likelihood = calculate_pedigree_likelihood(test_pedigree, ibd_dict, relationship_model)\n                \n                print(f\"Trying {relationship} between {id1} and {id2}: Likelihood {test_likelihood:.2f}\")\n                \n                # If this move improves the likelihood, remember it\n                if test_likelihood > best_move_likelihood:\n                    best_move = (id1, id2, relationship)\n                    best_move_likelihood = test_likelihood\n            except ValueError as e:\n                print(f\"Error adding {relationship} between {id1} and {id2}: {e}\")\n        \n        # If we found a better move, apply it\n        if best_move is not None:\n            id1, id2, relationship = best_move\n            print(f\"Applying best move: {relationship} between {id1} and {id2}\")\n            current_pedigree.add_relationship(id1, id2, relationship)\n            current_likelihood = best_move_likelihood\n            processed_pairs.add((id1, id2))\n            processed_pairs.add((id2, id1))  # Add both orderings of the pair\n        else:\n            print(\"No improving moves found. Stopping search.\")\n            break\n    \n    print(f\"\\nFinal pedigree likelihood: {current_likelihood:.2f}\")\n    return current_pedigree, current_likelihood\n\n# Run the greedy search algorithm on our sample data\n# Note: This could take a while, so we'll limit to just a few iterations\nprint(\"Running greedy pedigree search...\")\nbest_pedigree, best_likelihood = greedy_pedigree_search(\n    bioinfo_dict, ibd_dict, relationship_model, max_iterations=3)\n\nprint(\"\\nVisualizing the best pedigree found...\")\nbest_pedigree.visualize_pedigree()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 3.2 Simulated Annealing\n\nThe greedy search algorithm can get stuck in local optima. Simulated annealing addresses this by occasionally accepting moves that decrease the likelihood, with a probability that depends on a \"temperature\" parameter that decreases over time.\n\nHere's a simplified implementation of simulated annealing for pedigree reconstruction:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def simulated_annealing_pedigree_search(bioinfo_dict, ibd_dict, relationship_model, \n                                  max_iterations=100, initial_temp=10.0, cooling_rate=0.95):\n    \"\"\"Perform a simulated annealing search for the best pedigree structure.\n    \n    Args:\n        bioinfo_dict: Dictionary of biological information for individuals\n        ibd_dict: Dictionary of IBD segments between pairs\n        relationship_model: Relationship model for likelihood calculations\n        max_iterations: Maximum number of iterations to perform\n        initial_temp: Initial temperature for simulated annealing\n        cooling_rate: Rate at which temperature decreases\n        \n    Returns:\n        Tuple of (best_pedigree, best_likelihood)\n    \"\"\"\n    # Initialize an empty pedigree\n    current_pedigree = UpNodeDictionary(bioinfo_dict)\n    current_likelihood = calculate_pedigree_likelihood(current_pedigree, ibd_dict, relationship_model)\n    \n    # Keep track of the best pedigree seen so far\n    best_pedigree = current_pedigree\n    best_likelihood = current_likelihood\n    \n    # Initialize temperature\n    temperature = initial_temp\n    \n    print(f\"Initial pedigree likelihood: {current_likelihood:.2f}\")\n    print(f\"Initial temperature: {temperature:.2f}\")\n    \n    # Perform simulated annealing\n    for iteration in range(max_iterations):\n        # Generate a random move: add a relationship between a random pair\n        pairs = list(ibd_dict.keys())\n        if not pairs:\n            print(\"No pairs to process. Stopping search.\")\n            break\n            \n        pair = random.choice(pairs)\n        id1, id2 = pair\n        \n        # Find a random relationship to try (in a real implementation, we would use\n        # the relationship model to guide this choice)\n        relationship = random.choice(['full-siblings', 'half-siblings', 'first-cousins'])\n        \n        # Create a copy of the current pedigree\n        test_pedigree = UpNodeDictionary(bioinfo_dict)\n        test_pedigree.up_dict = current_pedigree.up_dict.copy()\n        \n        # Try applying the move\n        try:\n            test_pedigree.add_relationship(id1, id2, relationship)\n            test_likelihood = calculate_pedigree_likelihood(test_pedigree, ibd_dict, relationship_model)\n            \n            # Calculate change in likelihood\n            delta_likelihood = test_likelihood - current_likelihood\n            \n            # Decide whether to accept the move\n            if delta_likelihood > 0:\n                # Always accept improving moves\n                current_pedigree = test_pedigree\n                current_likelihood = test_likelihood\n                print(f\"Iteration {iteration + 1}/{max_iterations}: Accepted improving move. Likelihood: {current_likelihood:.2f}\")\n                \n                # Update best pedigree if this is the best seen so far\n                if current_likelihood > best_likelihood:\n                    best_pedigree = current_pedigree\n                    best_likelihood = current_likelihood\n            else:\n                # Accept worsening moves with a probability that depends on temperature\n                acceptance_probability = np.exp(delta_likelihood / temperature)\n                if random.random() < acceptance_probability:\n                    current_pedigree = test_pedigree\n                    current_likelihood = test_likelihood\n                    print(f\"Iteration {iteration + 1}/{max_iterations}: Accepted worsening move with probability {acceptance_probability:.4f}. Likelihood: {current_likelihood:.2f}\")\n                else:\n                    print(f\"Iteration {iteration + 1}/{max_iterations}: Rejected worsening move with probability {1 - acceptance_probability:.4f}\")\n        except ValueError as e:\n            print(f\"Iteration {iteration + 1}/{max_iterations}: Error adding {relationship} between {id1} and {id2}: {e}\")\n        \n        # Cool the temperature\n        temperature *= cooling_rate\n        \n        # Print status every 10 iterations\n        if (iteration + 1) % 10 == 0:\n            print(f\"Iteration {iteration + 1}/{max_iterations}: Temperature: {temperature:.4f}, Current likelihood: {current_likelihood:.2f}, Best likelihood: {best_likelihood:.2f}\")\n    \n    print(f\"\\nFinal best pedigree likelihood: {best_likelihood:.2f}\")\n    return best_pedigree, best_likelihood\n\n# For demonstration, we'll just describe the algorithm without running it\nprint(\"Simulated Annealing Pedigree Search:\")\nprint(\"  1. Start with an initial pedigree and temperature\")\nprint(\"  2. Iteratively propose random changes to the pedigree\")\nprint(\"  3. Always accept changes that improve the likelihood\")\nprint(\"  4. Sometimes accept changes that worsen the likelihood, with probability dependent on temperature\")\nprint(\"  5. Gradually decrease the temperature over time\")\nprint(\"  6. Return the best pedigree found during the search\")\nprint(\"\\nNote: We won't run this algorithm here due to time constraints, but in a real application,\")\nprint(\"      it would be used to escape local optima that the greedy search might get stuck in.\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Constraint Handler\n\nThe Constraint Handler ensures that the pedigree respects biological and logical constraints. Examples of constraints include:\n\n1. **Biological constraints**:\n   - Age constraints (parents must be older than children)\n   - Reproductive age limits\n   - Sex-specific constraints (e.g., only females can be mothers)\n\n2. **Logical constraints**:\n   - No cycles in the pedigree (a person cannot be their own ancestor)\n   - No duplicate relationships (a person cannot have multiple biological fathers)\n   - Consistency with known relationships\n\nLet's implement a simplified constraint handler:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class ConstraintHandler:\n    \"\"\"Handles biological and logical constraints for pedigree structures.\"\"\"\n    \n    def __init__(self, bioinfo_dict):\n        \"\"\"Initialize constraint handler with biological information.\n        \n        Args:\n            bioinfo_dict: Dictionary mapping individual IDs to biological information\n        \"\"\"\n        self.bioinfo_dict = bioinfo_dict\n        self.min_reproductive_age = 15  # Minimum age to have children\n        self.max_reproductive_age = {\n            'F': 50,  # Maximum age for females to have children\n            'M': 80   # Maximum age for males to have children\n        }\n        self.min_parent_child_age_diff = 15  # Minimum age difference between parent and child\n    \n    def check_constraints(self, up_dict):\n        \"\"\"Check if a pedigree satisfies all constraints.\n        \n        Args:\n            up_dict: Up-Node Dictionary representing the pedigree\n            \n        Returns:\n            Tuple of (is_valid, list_of_violations)\n        \"\"\"\n        violations = []\n        \n        # Check for cycles\n        if self._has_cycles(up_dict):\n            violations.append(\"Pedigree contains cycles\")\n        \n        # Check for duplicate parents\n        for individual_id, info in up_dict.items():\n            father = info.get('father')\n            mother = info.get('mother')\n            \n            if father is not None and mother is not None:\n                # Check if father is male and mother is female\n                if father in up_dict and up_dict[father].get('sex') != 'M':\n                    violations.append(f\"Individual {father} is not male but is set as father\")\n                \n                if mother in up_dict and up_dict[mother].get('sex') != 'F':\n                    violations.append(f\"Individual {mother} is not female but is set as mother\")\n            \n            # Check age constraints\n            if self._has_age_violations(up_dict, individual_id):\n                violations.append(f\"Age constraints violated for individual {individual_id}\")\n        \n        return len(violations) == 0, violations\n    \n    def _has_cycles(self, up_dict):\n        \"\"\"Check if the pedigree contains cycles.\n        \n        Args:\n            up_dict: Up-Node Dictionary representing the pedigree\n            \n        Returns:\n            Boolean indicating whether cycles exist\n        \"\"\"\n        # Create a directed graph\n        G = nx.DiGraph()\n        \n        # Add nodes and edges\n        for individual_id, info in up_dict.items():\n            G.add_node(individual_id)\n            \n            # Add edges to parents\n            father = info.get('father')\n            mother = info.get('mother')\n            \n            if father is not None:\n                G.add_edge(individual_id, father)\n            \n            if mother is not None:\n                G.add_edge(individual_id, mother)\n        \n        # Check for cycles\n        try:\n            nx.find_cycle(G)\n            return True  # Cycle found\n        except nx.NetworkXNoCycle:\n            return False  # No cycle found\n    \n    def _has_age_violations(self, up_dict, individual_id):\n        \"\"\"Check for age-related constraint violations.\n        \n        Args:\n            up_dict: Up-Node Dictionary representing the pedigree\n            individual_id: ID of the individual to check\n            \n        Returns:\n            Boolean indicating whether age constraints are violated\n        \"\"\"\n        # Skip if this is not a known individual or age information is missing\n        if individual_id not in self.bioinfo_dict or 'age' not in self.bioinfo_dict[individual_id]:\n            return False\n        \n        individual_age = self.bioinfo_dict[individual_id].get('age')\n        \n        # Skip if age is unknown\n        if individual_age is None:\n            return False\n        \n        # Check parents' ages\n        father_id = up_dict[individual_id].get('father')\n        mother_id = up_dict[individual_id].get('mother')\n        \n        if father_id is not None and father_id in self.bioinfo_dict:\n            father_age = self.bioinfo_dict[father_id].get('age')\n            \n            if father_age is not None:\n                # Father must be older than child\n                if father_age <= individual_age:\n                    return True\n                \n                # Father must be at least min_parent_child_age_diff years older\n                if father_age - individual_age < self.min_parent_child_age_diff:\n                    return True\n                \n                # Father must have been of reproductive age when child was born\n                father_age_at_birth = father_age - individual_age\n                if father_age_at_birth < self.min_reproductive_age or father_age_at_birth > self.max_reproductive_age['M']:\n                    return True\n        \n        if mother_id is not None and mother_id in self.bioinfo_dict:\n            mother_age = self.bioinfo_dict[mother_id].get('age')\n            \n            if mother_age is not None:\n                # Mother must be older than child\n                if mother_age <= individual_age:\n                    return True\n                \n                # Mother must be at least min_parent_child_age_diff years older\n                if mother_age - individual_age < self.min_parent_child_age_diff:\n                    return True\n                \n                # Mother must have been of reproductive age when child was born\n                mother_age_at_birth = mother_age - individual_age\n                if mother_age_at_birth < self.min_reproductive_age or mother_age_at_birth > self.max_reproductive_age['F']:\n                    return True\n        \n        return False\n    \n    def enforce_constraints(self, up_dict):\n        \"\"\"Modify a pedigree to enforce constraints.\n        \n        Args:\n            up_dict: Up-Node Dictionary representing the pedigree\n            \n        Returns:\n            Modified Up-Node Dictionary\n        \"\"\"\n        # Create a copy of the pedigree\n        enforced_up_dict = up_dict.copy()\n        \n        # Check for violations and remove problematic relationships\n        for individual_id, info in up_dict.items():\n            father = info.get('father')\n            mother = info.get('mother')\n            \n            # Fix sex constraints\n            if father is not None and father in up_dict and up_dict[father].get('sex') != 'M':\n                enforced_up_dict[individual_id]['father'] = None\n            \n            if mother is not None and mother in up_dict and up_dict[mother].get('sex') != 'F':\n                enforced_up_dict[individual_id]['mother'] = None\n            \n            # Fix age constraints\n            if self._has_age_violations(up_dict, individual_id):\n                # If age constraints are violated, remove parent relationships\n                enforced_up_dict[individual_id]['father'] = None\n                enforced_up_dict[individual_id]['mother'] = None\n        \n        # If cycles exist, we would need to break them\n        # This is a complex problem that would require a more sophisticated algorithm\n        # For simplicity, we'll just remove all relationships if cycles are detected\n        if self._has_cycles(up_dict):\n            for individual_id in enforced_up_dict:\n                enforced_up_dict[individual_id]['father'] = None\n                enforced_up_dict[individual_id]['mother'] = None\n        \n        return enforced_up_dict\n\n# Create a constraint handler for our sample data\nconstraint_handler = ConstraintHandler(bioinfo_dict)\n\n# Check if our pedigree satisfies constraints\nis_valid, violations = constraint_handler.check_constraints(up_node_dict.up_dict)\n\nprint(f\"Is the pedigree valid? {is_valid}\")\nif not is_valid:\n    print(\"Constraint violations:\")\n    for violation in violations:\n        print(f\"  - {violation}\")\n    \n    print(\"\\nEnforcing constraints...\")\n    enforced_up_dict = constraint_handler.enforce_constraints(up_node_dict.up_dict)\n    \n    # Create a new pedigree with the enforced up_dict\n    enforced_pedigree = UpNodeDictionary(bioinfo_dict)\n    enforced_pedigree.up_dict = enforced_up_dict\n    \n    # Check if the enforced pedigree satisfies constraints\n    is_valid, violations = constraint_handler.check_constraints(enforced_pedigree.up_dict)\n    print(f\"Is the enforced pedigree valid? {is_valid}\")\n    \n    # Visualize the enforced pedigree\n    if not is_valid:\n        print(\"Constraint violations still exist:\")\n        for violation in violations:\n            print(f\"  - {violation}\")\n    else:\n        print(\"Constraints successfully enforced.\")\n        enforced_pedigree.visualize_pedigree()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Performance Optimization\n\nBonsai's architecture is designed with performance in mind, as it needs to handle large-scale pedigree reconstruction with potentially thousands of individuals. Let's explore some of the key optimization strategies used in Bonsai:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 5.1 Memory Management\n\nPedigree reconstruction with large datasets can be memory-intensive. Bonsai implements several strategies to minimize memory usage:\n\n1. **Sparse representation**: The Up-Node Dictionary only stores non-null relationships\n2. **On-demand computation**: Some values are computed as needed rather than stored\n3. **Data filtering**: IBD segments below a certain threshold are filtered out early\n4. **Incremental processing**: The pedigree is built incrementally, focusing on the most important relationships first\n\nHere's a simple example of memory usage benchmarking:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_synthetic_data(num_individuals, num_segments_per_pair, min_segment_len=7):\n    \"\"\"Generate synthetic data for benchmarking.\n    \n    Args:\n        num_individuals: Number of individuals to generate\n        num_segments_per_pair: Average number of IBD segments per pair\n        min_segment_len: Minimum segment length\n        \n    Returns:\n        Tuple of (bioinfo_dict, ibd_dict)\n    \"\"\"\n    import sys\n    import time\n    import random\n    from collections import defaultdict\n    \n    # Generate synthetic bioinfo\n    bioinfo_dict = {}\n    for i in range(1, num_individuals + 1):\n        bioinfo_dict[i] = {\n            'sex': random.choice(['M', 'F']),\n            'age': random.randint(20, 80),\n            'birth_year': None\n        }\n    \n    # Generate synthetic IBD segments\n    ibd_dict = defaultdict(list)\n    for i in range(1, num_individuals + 1):\n        for j in range(i+1, num_individuals + 1):\n            if random.random() < 0.3:  # Only generate segments for 30% of pairs\n                num_segments = max(1, int(random.gauss(num_segments_per_pair, 2)))\n                for _ in range(num_segments):\n                    chromosome = random.randint(1, 22)\n                    start = random.randint(1000000, 200000000)\n                    end = start + random.randint(1000000, 10000000)\n                    length = min_segment_len + random.expovariate(1/20)  # Mean length of 20 cM\n                    is_ibd2 = random.random() < 0.05  # 5% chance of IBD2\n                    \n                    ibd_dict[(i, j)].append({\n                        'chromosome': str(chromosome),\n                        'start': start,\n                        'end': end,\n                        'is_ibd2': is_ibd2,\n                        'length_cm': length\n                    })\n    \n    return bioinfo_dict, ibd_dict\n\ndef measure_memory_usage(func):\n    \"\"\"Measure memory usage of a function.\"\"\"\n    import tracemalloc\n    import time\n    \n    tracemalloc.start()\n    start_time = time.time()\n    \n    result = func()\n    \n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    \n    print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n    print(f\"Current memory usage: {current / 10**6:.2f} MB\")\n    print(f\"Peak memory usage: {peak / 10**6:.2f} MB\")\n    \n    return result\n\n# Define benchmark scenarios\ndef benchmark_small():\n    \"\"\"Benchmark with small dataset (10 individuals).\"\"\"\n    bioinfo_dict, ibd_dict = generate_synthetic_data(10, 5)\n    pedigree = UpNodeDictionary(bioinfo_dict)\n    return pedigree, len(bioinfo_dict), sum(len(segments) for segments in ibd_dict.values())\n\ndef benchmark_medium():\n    \"\"\"Benchmark with medium dataset (100 individuals).\"\"\"\n    bioinfo_dict, ibd_dict = generate_synthetic_data(100, 5)\n    pedigree = UpNodeDictionary(bioinfo_dict)\n    return pedigree, len(bioinfo_dict), sum(len(segments) for segments in ibd_dict.values())\n\n# Uncomment to run the medium benchmark - it might take a while\n# def benchmark_large():\n#     \"\"\"Benchmark with large dataset (1000 individuals).\"\"\"\n#     bioinfo_dict, ibd_dict = generate_synthetic_data(1000, 5)\n#     pedigree = UpNodeDictionary(bioinfo_dict)\n#     return pedigree, len(bioinfo_dict), sum(len(segments) for segments in ibd_dict.values())\n\n# Run benchmarks\nprint(\"Running small benchmark...\")\nsmall_result = measure_memory_usage(benchmark_small)\nprint(f\"Created pedigree with {small_result[1]} individuals and {small_result[2]} segments\")\n\nprint(\"\\nRunning medium benchmark...\")\nmedium_result = measure_memory_usage(benchmark_medium)\nprint(f\"Created pedigree with {medium_result[1]} individuals and {medium_result[2]} segments\")\n\n# Uncomment to run the large benchmark - it might take a while\n# print(\"\\nRunning large benchmark...\")\n# large_result = measure_memory_usage(benchmark_large)\n# print(f\"Created pedigree with {large_result[1]} individuals and {large_result[2]} segments\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.2 Computational Optimizations\n\nIn addition to memory optimizations, Bonsai employs several strategies to reduce computational complexity:\n\n1. **Parallel processing**: Independent likelihood calculations can be parallelized\n2. **Caching**: Frequently accessed values are cached to avoid redundant computation\n3. **Heuristic pruning**: The search space is pruned using heuristics to focus on promising pedigree structures\n4. **Incremental likelihood calculation**: When making small changes to a pedigree, only affected likelihoods are recalculated\n\nLet's implement a simple example of caching and incremental likelihood calculation:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class OptimizedRelationshipModel(RelationshipModel):\n    \"\"\"Optimized version of the RelationshipModel with caching.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize relationship model with caching.\"\"\"\n        super().__init__()\n        self.likelihood_cache = {}  # Cache for likelihood calculations\n    \n    def calculate_relationship_likelihood(self, pair, segments, relationship_type):\n        \"\"\"Calculate likelihood of a specific relationship with caching.\n        \n        Args:\n            pair: Tuple of individual IDs\n            segments: List of IBD segments between the pair\n            relationship_type: String indicating relationship type\n            \n        Returns:\n            Log likelihood of the relationship\n        \"\"\"\n        # Create a cache key\n        cache_key = (pair, relationship_type, len(segments), \n                    sum(seg['length_cm'] for seg in segments))\n        \n        # Check if result is in cache\n        if cache_key in self.likelihood_cache:\n            return self.likelihood_cache[cache_key]\n        \n        # Calculate likelihood (same as in base class)\n        if relationship_type not in self.expected_sharing:\n            raise ValueError(f\"Unknown relationship type: {relationship_type}\")\n        \n        # Calculate observed sharing\n        total_cm = sum(seg['length_cm'] for seg in segments)\n        num_segments = len(segments)\n        \n        # Get expected sharing for this relationship\n        expected_cm, expected_segments = self.expected_sharing[relationship_type]\n        \n        # Calculate standard deviations\n        sd_cm = expected_cm * self.sharing_sd['total_cm'] if expected_cm > 0 else 1\n        sd_segments = expected_segments * self.sharing_sd['num_segments'] if expected_segments > 0 else 1\n        \n        # Calculate log likelihood using normal distribution\n        from scipy.stats import norm\n        \n        # Log likelihood for total cM\n        ll_cm = norm.logpdf(total_cm, expected_cm, sd_cm) if expected_cm > 0 else 0\n        \n        # Log likelihood for number of segments\n        ll_segments = norm.logpdf(num_segments, expected_segments, sd_segments) if expected_segments > 0 else 0\n        \n        # Combined log likelihood\n        log_likelihood = ll_cm + ll_segments\n        \n        # Store in cache\n        self.likelihood_cache[cache_key] = log_likelihood\n        \n        return log_likelihood\n\nclass OptimizedPedigreeLikelihood:\n    \"\"\"Calculates pedigree likelihoods with optimizations for incremental updates.\"\"\"\n    \n    def __init__(self, up_dict, ibd_dict, relationship_model):\n        \"\"\"Initialize with a pedigree and relationship model.\n        \n        Args:\n            up_dict: Up-Node Dictionary representing the pedigree\n            ibd_dict: Dictionary of IBD segments between pairs\n            relationship_model: Relationship model for likelihood calculations\n        \"\"\"\n        self.up_dict = up_dict\n        self.ibd_dict = ibd_dict\n        self.relationship_model = relationship_model\n        self.pair_likelihoods = {}\n        \n        # Calculate initial likelihoods for all pairs\n        self.calculate_all_likelihoods()\n    \n    def calculate_all_likelihoods(self):\n        \"\"\"Calculate likelihoods for all pairs.\"\"\"\n        self.pair_likelihoods = {}\n        \n        for pair, segments in self.ibd_dict.items():\n            id1, id2 = pair\n            relationship_type = infer_relationship_from_pedigree(self.up_dict.up_dict, id1, id2)\n            \n            if relationship_type is not None:\n                try:\n                    log_likelihood = self.relationship_model.calculate_relationship_likelihood(\n                        pair, segments, relationship_type\n                    )\n                    self.pair_likelihoods[pair] = log_likelihood\n                except ValueError:\n                    self.pair_likelihoods[pair] = float('-inf')\n            else:\n                # Default to unrelated if no relationship is inferred\n                try:\n                    log_likelihood = self.relationship_model.calculate_relationship_likelihood(\n                        pair, segments, 'unrelated'\n                    )\n                    self.pair_likelihoods[pair] = log_likelihood\n                except ValueError:\n                    self.pair_likelihoods[pair] = float('-inf')\n    \n    def get_total_likelihood(self):\n        \"\"\"Get total log likelihood of the pedigree.\"\"\"\n        return sum(self.pair_likelihoods.values())\n    \n    def update_likelihood_for_pairs(self, affected_pairs):\n        \"\"\"Update likelihoods only for affected pairs.\n        \n        Args:\n            affected_pairs: List of pairs whose relationships have changed\n        \"\"\"\n        for pair in affected_pairs:\n            if pair in self.ibd_dict:\n                id1, id2 = pair\n                segments = self.ibd_dict[pair]\n                relationship_type = infer_relationship_from_pedigree(self.up_dict.up_dict, id1, id2)\n                \n                if relationship_type is not None:\n                    try:\n                        log_likelihood = self.relationship_model.calculate_relationship_likelihood(\n                            pair, segments, relationship_type\n                        )\n                        self.pair_likelihoods[pair] = log_likelihood\n                    except ValueError:\n                        self.pair_likelihoods[pair] = float('-inf')\n                else:\n                    # Default to unrelated if no relationship is inferred\n                    try:\n                        log_likelihood = self.relationship_model.calculate_relationship_likelihood(\n                            pair, segments, 'unrelated'\n                        )\n                        self.pair_likelihoods[pair] = log_likelihood\n                    except ValueError:\n                        self.pair_likelihoods[pair] = float('-inf')\n    \n    def simulate_pedigree_change(self, test_up_dict, affected_pairs):\n        \"\"\"Simulate a change to the pedigree and calculate new likelihood.\n        \n        Args:\n            test_up_dict: Test Up-Node Dictionary with the proposed change\n            affected_pairs: List of pairs whose relationships would be affected\n            \n        Returns:\n            Log likelihood of the test pedigree\n        \"\"\"\n        # Save current state\n        original_up_dict = self.up_dict\n        original_likelihoods = self.pair_likelihoods.copy()\n        \n        # Apply test changes\n        self.up_dict = test_up_dict\n        self.update_likelihood_for_pairs(affected_pairs)\n        \n        # Calculate new likelihood\n        new_likelihood = self.get_total_likelihood()\n        \n        # Restore original state\n        self.up_dict = original_up_dict\n        self.pair_likelihoods = original_likelihoods\n        \n        return new_likelihood\n\n# Create an optimized relationship model\noptimized_model = OptimizedRelationshipModel()\n\n# Calculate relationships with and without optimization to compare\nprint(\"Calculating relationship likelihoods without optimization...\")\nstart_time = time.time()\nfor pair, segments in ibd_dict.items():\n    for relationship in optimized_model.expected_sharing.keys():\n        relationship_model.calculate_relationship_likelihood(pair, segments, relationship)\nend_time = time.time()\nprint(f\"Time without optimization: {end_time - start_time:.4f} seconds\")\n\nprint(\"\\nCalculating relationship likelihoods with optimization (first run)...\")\nstart_time = time.time()\nfor pair, segments in ibd_dict.items():\n    for relationship in optimized_model.expected_sharing.keys():\n        optimized_model.calculate_relationship_likelihood(pair, segments, relationship)\nend_time = time.time()\nprint(f\"Time with optimization (first run): {end_time - start_time:.4f} seconds\")\n\nprint(\"\\nCalculating relationship likelihoods with optimization (second run)...\")\nstart_time = time.time()\nfor pair, segments in ibd_dict.items():\n    for relationship in optimized_model.expected_sharing.keys():\n        optimized_model.calculate_relationship_likelihood(pair, segments, relationship)\nend_time = time.time()\nprint(f\"Time with optimization (second run): {end_time - start_time:.4f} seconds\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Extension Mechanisms\n\nBonsai's modular architecture allows for easy extension and customization. Here are some of the key extension points:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 6.1 Custom Relationship Models\n\nOne of the most common extensions is to create custom relationship models for specific populations or research questions. For example, you might want to create a model that accounts for endogamy (intermarriage within a small community) or population-specific recombination rates.\n\nHere's an example of how to create a custom relationship model for a population with higher endogamy:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class EndogamousPopulationModel(RelationshipModel):\n    \"\"\"Relationship model for a population with higher endogamy.\n    \n    In endogamous populations, individuals share more IBD segments than expected\n    because of multiple distant relationships.\n    \"\"\"\n    \n    def __init__(self, endogamy_factor=1.5):\n        \"\"\"Initialize model with endogamy factor.\n        \n        Args:\n            endogamy_factor: Factor by which to increase expected IBD sharing\n        \"\"\"\n        super().__init__()\n        self.endogamy_factor = endogamy_factor\n        \n        # Adjust expected sharing for endogamy\n        # In endogamous populations, we expect more IBD sharing\n        for relationship, (expected_cm, expected_segments) in self.expected_sharing.items():\n            if relationship != 'parent-child' and relationship != 'full-siblings':\n                # Parent-child and full sibling relationships aren't affected by endogamy\n                self.expected_sharing[relationship] = (\n                    expected_cm * endogamy_factor,\n                    expected_segments * endogamy_factor\n                )\n    \n    def calculate_relationship_likelihood(self, pair, segments, relationship_type):\n        \"\"\"Calculate likelihood of a specific relationship in an endogamous population.\n        \n        Args:\n            pair: Tuple of individual IDs\n            segments: List of IBD segments between the pair\n            relationship_type: String indicating relationship type\n            \n        Returns:\n            Log likelihood of the relationship\n        \"\"\"\n        # Add a background IBD sharing component for distant relationships\n        if relationship_type in ['unrelated', 'second-cousins', 'first-cousins']:\n            # Calculate likelihood as in base class\n            base_likelihood = super().calculate_relationship_likelihood(pair, segments, relationship_type)\n            \n            # Add a small bonus to account for potential multiple distant relationships\n            bonus = 0.1 * np.log(self.endogamy_factor)\n            \n            return base_likelihood + bonus\n        else:\n            # For close relationships, use standard calculation\n            return super().calculate_relationship_likelihood(pair, segments, relationship_type)\n\nclass AshkenaziJewishModel(EndogamousPopulationModel):\n    \"\"\"Relationship model specifically for Ashkenazi Jewish populations.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize with Ashkenazi-specific parameters.\"\"\"\n        # Higher endogamy factor for Ashkenazi populations\n        super().__init__(endogamy_factor=2.0)\n        \n        # Adjust expected sharing based on Ashkenazi-specific studies\n        self.expected_sharing.update({\n            'first-cousins': (950, 17),  # Higher than standard\n            'second-cousins': (275, 6),  # Higher than standard\n            'unrelated': (30, 1)  # Background IBD sharing in Ashkenazi populations\n        })\n\n# Test the endogamous population model\nendogamous_model = EndogamousPopulationModel(endogamy_factor=1.5)\nashkenazi_model = AshkenaziJewishModel()\n\n# Compare expected sharing across models\nprint(\"Expected sharing by relationship type:\")\nprint(\"Standard Model:\")\nfor relationship, (expected_cm, expected_segments) in relationship_model.expected_sharing.items():\n    print(f\"  {relationship}: {expected_cm:.1f} cM, {expected_segments:.1f} segments\")\n\nprint(\"\\nEndogamous Model (factor=1.5):\")\nfor relationship, (expected_cm, expected_segments) in endogamous_model.expected_sharing.items():\n    print(f\"  {relationship}: {expected_cm:.1f} cM, {expected_segments:.1f} segments\")\n\nprint(\"\\nAshkenazi Jewish Model:\")\nfor relationship, (expected_cm, expected_segments) in ashkenazi_model.expected_sharing.items():\n    print(f\"  {relationship}: {expected_cm:.1f} cM, {expected_segments:.1f} segments\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 6.2 Integration with External Tools\n\nBonsai can be integrated with external tools for IBD detection, visualization, and analysis. Here's a simple example of how Bonsai can be integrated with visualization tools to create interactive pedigree visualizations:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def convert_pedigree_to_graphviz(up_dict):\n    \"\"\"Convert a pedigree to Graphviz format for interactive visualization.\n    \n    Args:\n        up_dict: Up-Node Dictionary representing the pedigree\n        \n    Returns:\n        Graphviz object containing the pedigree\n    \"\"\"\n    # Create a new Graphviz graph\n    G = pgv.AGraph(strict=False, directed=True)\n    \n    # Set graph attributes for better visualization\n    G.graph_attr['rankdir'] = 'BT'  # Bottom to Top layout\n    G.graph_attr['splines'] = 'ortho'  # Orthogonal lines\n    G.graph_attr['nodesep'] = '0.5'\n    G.graph_attr['ranksep'] = '0.5'\n    \n    # Add nodes\n    for individual_id, info in up_dict.items():\n        # Node attributes based on sex and type\n        node_attrs = {\n            'shape': 'box' if info.get('sex') == 'M' else 'ellipse',\n            'style': 'filled',\n            'fillcolor': 'lightblue' if info.get('sex') == 'M' else 'pink',\n            'width': '1.0',\n            'height': '0.6',\n            'fontsize': '10'\n        }\n        \n        # Add age to label if available\n        label = str(individual_id)\n        if info.get('age') is not None:\n            label += f\" ({info.get('age')})\"\n        \n        node_attrs['label'] = label\n        \n        # Add the node\n        G.add_node(individual_id, **node_attrs)\n    \n    # Add edges (parent-child relationships)\n    for individual_id, info in up_dict.items():\n        father = info.get('father')\n        mother = info.get('mother')\n        \n        if father is not None:\n            G.add_edge(father, individual_id, color='blue')\n        \n        if mother is not None:\n            G.add_edge(mother, individual_id, color='red')\n    \n    return G\n\ndef save_pedigree_visualization(up_dict, output_path, format='png'):\n    \"\"\"Save a visualization of the pedigree to a file.\n    \n    Args:\n        up_dict: Up-Node Dictionary representing the pedigree\n        output_path: Path to save the visualization\n        format: Output format (png, pdf, svg, etc.)\n    \"\"\"\n    # Convert pedigree to Graphviz\n    G = convert_pedigree_to_graphviz(up_dict)\n    \n    # Save to file\n    G.draw(output_path, prog='dot', format=format)\n    \n    print(f\"Pedigree visualization saved to {output_path}\")\n    \n    # Display the image if in a notebook\n    if format in ['png', 'jpg', 'jpeg']:\n        plt.figure(figsize=(12, 8))\n        img = mpimg.imread(output_path)\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title(\"Pedigree Visualization\")\n        plt.show()\n\n# Create a visualization of our pedigree\noutput_path = os.path.join(results_directory, \"pedigree_visualization.png\")\nsave_pedigree_visualization(up_node_dict.up_dict, output_path)\n\nprint(\"\\nBonsai can integrate with various tools for:\")\nprint(\"  1. IBD Detection: IBIS, Refined-IBD, hap-IBD, GERMLINE, etc.\")\nprint(\"  2. Visualization: Graphviz, D3.js, Cytoscape.js, etc.\")\nprint(\"  3. Analysis: R, Python pandas, NetworkX, etc.\")\nprint(\"  4. Data Management: PostgreSQL, MongoDB, etc.\")"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Exercises\n\nNow that we've explored the architecture and implementation of Bonsai, let's complete some exercises to deepen our understanding.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 1: Implement a New Constraint\n\nCreate a new constraint that ensures that the number of children per individual doesn't exceed a certain threshold (e.g., 10 children maximum per individual). Implement this constraint in the `ConstraintHandler` class.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Exercise 1: Your solution here\n# Hint: Implement a method to count children and check against a threshold"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 2: Create a Custom Relationship Model\n\nCreate a custom relationship model for a specific population or research question (e.g., a population with high consanguinity, or a model that takes into account the length distribution of IBD segments).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Exercise 2: Your solution here\n# Hint: Extend the RelationshipModel class with customized parameters"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 3: Implement Additional Optimization Strategies\n\nImplement an additional optimization strategy for Bonsai, such as parallel processing, pruning the search space using heuristics, or improving caching.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Exercise 3: Your solution here\n# Hint: Consider using Python's multiprocessing package for parallel processing"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 4: Extend the Up-Node Dictionary\n\nExtend the Up-Node Dictionary to include additional information, such as:\n- Confidence scores for inferred relationships\n- Alternative relationship hypotheses\n- Support for half-identical regions (HIRs) in addition to fully-identical regions (FIRs)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Exercise 4: Your solution here\n# Hint: Modify the UpNodeDictionary class to store additional information"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 5: Integration with External Tools\n\nDesign and implement a function to export Bonsai pedigrees to a standard format (e.g., GEDCOM, GraphML) that can be imported into other genealogy software.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Exercise 5: Your solution here\n# Hint: Create functions to convert the Up-Node Dictionary to GEDCOM or GraphML format"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Conclusion\n\nIn this lab, we've explored the architectural design and implementation details of the Bonsai algorithm. We've examined the core components of Bonsai, including the Input Processing Module, Relationship Model, Up-Node Dictionary, Optimization Engine, and Constraint Handler. We've also implemented simplified versions of these components to understand how they work together to build pedigree structures from genetic data.\n\nKey takeaways:\n- Bonsai follows a modular architecture that separates concerns and allows for easy extension\n- The Up-Node Dictionary is the core data structure that represents the pedigree\n- The Optimization Engine searches for the optimal pedigree structure\n- The Constraint Handler ensures that the pedigree respects biological and logical constraints\n- Performance optimization is crucial for handling large-scale pedigree reconstruction\n- Bonsai can be customized and extended to address specific research questions\n\nIn the next lab, we'll explore advanced topics in pedigree reconstruction, including dealing with missing data, handling complex relationships, and evaluating pedigree quality.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}