{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 14: Data Structures and Algorithmic Design in Bonsai\n",
    "\n",
    "Building upon our exploration of the mathematical foundations of Bonsai in Lab 13, we now delve into the data structures and algorithmic design that power Bonsai's pedigree reconstruction capabilities. This lab focuses on how Bonsai organizes and processes genetic data for efficient relationship inference and pedigree construction.\n",
    "\n",
    "> **Why This Matters:** The efficacy of pedigree reconstruction algorithms depends heavily on the design of their underlying data structures. Understanding how Bonsai organizes and processes genetic data allows researchers to optimize algorithm performance, implement custom extensions, and interpret complex outputs accurately.\n",
    "\n",
    "**Learning Objectives**:\n",
    "- Analyze the core data structures that power the Bonsai algorithm\n",
    "- Understand how IBD segment data is preprocessed and organized for efficient access\n",
    "- Explore the up-node dictionary structure and its role in representing pedigree relationships\n",
    "- Examine the graph-theoretical foundations of pedigree representation\n",
    "- Learn how Bonsai's data structures enable efficient search and optimization\n",
    "- Implement key data structures and operations used in pedigree reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from scipy.stats import poisson, expon, norm, multivariate_normal\n",
    "from collections import defaultdict, deque\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from dotenv import load_dotenv\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Core Data Structures in Bonsai\n",
    "\n",
    "Bonsai's effectiveness stems from its carefully designed data structures that balance computational efficiency with biological accuracy. Let's examine the key structures that power the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBD Segment Representation\n",
    "\n",
    "The fundamental input to Bonsai is Identity-By-Descent (IBD) segment data, which is structured to facilitate rapid relationship inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBDSegment:\n",
    "    def __init__(self, ind1, ind2, chrom, start_pos, end_pos, is_ibd2, length_cm):\n",
    "        self.ind1 = ind1          # First individual ID\n",
    "        self.ind2 = ind2          # Second individual ID\n",
    "        self.chrom = chrom        # Chromosome number\n",
    "        self.start_pos = start_pos  # Start position (base pairs)\n",
    "        self.end_pos = end_pos    # End position (base pairs)\n",
    "        self.is_ibd2 = is_ibd2    # Whether this is an IBD2 segment\n",
    "        self.length_cm = length_cm  # Genetic length in centiMorgans\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"IBDSegment({self.ind1}, {self.ind2}, chr{self.chrom}, {self.length_cm:.2f}cM, {'IBD2' if self.is_ibd2 else 'IBD1'})\"\n",
    "\n",
    "# Example of how segments are organized in Bonsai\n",
    "def organize_segments_by_pair(ibd_segments):\n",
    "    segments_by_pair = {}\n",
    "    for seg in ibd_segments:\n",
    "        pair = tuple(sorted([seg.ind1, seg.ind2]))\n",
    "        if pair not in segments_by_pair:\n",
    "            segments_by_pair[pair] = []\n",
    "        segments_by_pair[pair].append(seg)\n",
    "    return segments_by_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some example IBD segments to work with throughout this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example IBD segments\n",
    "example_segments = [\n",
    "    # Parent-child segments (extensive IBD1 sharing)\n",
    "    IBDSegment(1000, 1001, 1, 10000000, 50000000, False, 45.5),  # IBD1 segment on chr1\n",
    "    IBDSegment(1000, 1001, 1, 60000000, 125000000, False, 65.2),  # IBD1 segment on chr1\n",
    "    IBDSegment(1000, 1001, 2, 5000000, 80000000, False, 75.0),   # IBD1 segment on chr2\n",
    "    \n",
    "    # Sibling segments (mix of IBD1 and IBD2)\n",
    "    IBDSegment(1001, 1002, 1, 15000000, 45000000, True, 30.1),   # IBD2 segment on chr1\n",
    "    IBDSegment(1001, 1002, 1, 50000000, 90000000, False, 40.3),  # IBD1 segment on chr1\n",
    "    IBDSegment(1001, 1002, 2, 10000000, 45000000, False, 35.5),  # IBD1 segment on chr2\n",
    "    IBDSegment(1001, 1002, 2, 50000000, 70000000, True, 20.8),   # IBD2 segment on chr2\n",
    "    \n",
    "    # First cousin segments (modest IBD1 sharing)\n",
    "    IBDSegment(1000, 1003, 1, 25000000, 50000000, False, 25.0),  # IBD1 segment on chr1\n",
    "    IBDSegment(1000, 1003, 3, 15000000, 35000000, False, 20.5),  # IBD1 segment on chr3\n",
    "    \n",
    "    # Distant relative (single small segment)\n",
    "    IBDSegment(1002, 1004, 5, 30000000, 45000000, False, 15.2),  # IBD1 segment on chr5\n",
    "]\n",
    "\n",
    "# Organize segments by pair\n",
    "segments_by_pair = organize_segments_by_pair(example_segments)\n",
    "\n",
    "# Display the organized segments\n",
    "for pair, segs in segments_by_pair.items():\n",
    "    print(f\"Pair {pair}:\")\n",
    "    for seg in segs:\n",
    "        print(f\"  {seg}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This organization allows Bonsai to efficiently access all IBD segments between a specific pair of individuals, which is crucial for calculating relationship likelihoods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Up-Node Dictionary\n",
    "\n",
    "The core data structure for representing pedigrees in Bonsai is the \"up-node dictionary,\" which encodes parent-child relationships in a compact format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example up-node dictionary structure\n",
    "up_node_dict = {\n",
    "    1000: {1001: 1, 1002: 1},  # Individual 1000 has parents 1001 and 1002\n",
    "    1003: {1001: 1, 1002: 1},  # Individual 1003 has the same parents\n",
    "    1004: {-1: 1, -2: 1},      # Individual 1004 has inferred parents -1 and -2\n",
    "    -1: {1005: 1, 1006: 1},    # Inferred individual -1 has parents 1005 and 1006\n",
    "    1005: {},                  # Individual 1005 has no recorded parents\n",
    "    1006: {},                  # Individual 1006 has no recorded parents\n",
    "    1001: {},                  # Individual 1001 has no recorded parents\n",
    "    1002: {}                   # Individual 1002 has no recorded parents\n",
    "}\n",
    "\n",
    "# Function to visualize pedigree from up-node dictionary\n",
    "def visualize_pedigree(up_node_dict):\n",
    "    \"\"\"Create a visualization of the pedigree from an up-node dictionary.\"\"\"\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for child, parents in up_node_dict.items():\n",
    "        G.add_node(child)\n",
    "        for parent in parents:\n",
    "            G.add_node(parent)\n",
    "            G.add_edge(parent, child)  # Direction from parent to child\n",
    "    \n",
    "    # Set node colors: green for real individuals (positive IDs), gray for latent (negative IDs)\n",
    "    node_colors = ['lightgreen' if isinstance(node, int) and node > 0 else 'lightgray' \n",
    "                   for node in G.nodes()]\n",
    "    \n",
    "    # Calculate layout\n",
    "    try:\n",
    "        pos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n",
    "    except:\n",
    "        pos = nx.spring_layout(G)  # Fallback if graphviz is not available\n",
    "    \n",
    "    # Draw the graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, \n",
    "            node_size=700, font_size=10, arrows=True)\n",
    "    plt.title('Pedigree Structure')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the example pedigree\n",
    "visualize_pedigree(up_node_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key features of the up-node dictionary:\n",
    "- Each key represents an individual ID (positive for observed individuals, negative for inferred ancestors)\n",
    "- Each value is a dictionary mapping parent IDs to 1 (the value 1 is a placeholder; the structure could be extended to include additional information)\n",
    "- An empty dictionary indicates an individual with no recorded parents (either a founder or an individual with unknown parentage)\n",
    "- The structure supports efficient traversal of ancestors and descendants\n",
    "- It can represent complex multi-generational pedigrees with inferred latent ancestors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioInfo Structure\n",
    "\n",
    "Bonsai incorporates biological metadata about individuals through the BioInfo structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example BioInfo structure\n",
    "bio_info = [\n",
    "    {'genotype_id': 1000, 'age': 75, 'sex': 'F'},\n",
    "    {'genotype_id': 1001, 'age': 80, 'sex': 'M'},\n",
    "    {'genotype_id': 1002, 'age': 78, 'sex': 'F'},\n",
    "    {'genotype_id': 1003, 'age': 45, 'sex': 'M'},\n",
    "    {'genotype_id': 1004, 'age': 43, 'sex': 'F'},\n",
    "    {'genotype_id': 1005, 'age': 20, 'sex': 'M'}\n",
    "]\n",
    "\n",
    "# Display the information\n",
    "bio_df = pd.DataFrame(bio_info)\n",
    "bio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This structure is used to enforce biological constraints (e.g., age-appropriate relationships, sex-specific reproduction) and to enhance the accuracy of pedigree reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing IBD Data for Efficient Access\n",
    "\n",
    "Before pedigree reconstruction begins, Bonsai preprocesses the IBD data to optimize subsequent operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and Filtering\n",
    "\n",
    "The preprocessing pipeline includes several key steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ibd_segments(segments, min_cm=7):\n",
    "    \"\"\"Preprocess IBD segments for efficient access.\"\"\"\n",
    "    # 1. Filter by minimum length\n",
    "    filtered_segments = [seg for seg in segments if seg.length_cm >= min_cm]\n",
    "    \n",
    "    # 2. Create pair-based index\n",
    "    pair_index = {}\n",
    "    for seg in filtered_segments:\n",
    "        pair = tuple(sorted([seg.ind1, seg.ind2]))\n",
    "        if pair not in pair_index:\n",
    "            pair_index[pair] = []\n",
    "        pair_index[pair].append(seg)\n",
    "    \n",
    "    # 3. Create individual-based index\n",
    "    ind_index = {}\n",
    "    for seg in filtered_segments:\n",
    "        for ind in [seg.ind1, seg.ind2]:\n",
    "            if ind not in ind_index:\n",
    "                ind_index[ind] = []\n",
    "            ind_index[ind].append(seg)\n",
    "    \n",
    "    # 4. Calculate summary statistics\n",
    "    pair_stats = {}\n",
    "    for pair, segs in pair_index.items():\n",
    "        ind1, ind2 = pair\n",
    "        total_ibd1_cm = sum(seg.length_cm for seg in segs if not seg.is_ibd2)\n",
    "        total_ibd2_cm = sum(seg.length_cm for seg in segs if seg.is_ibd2)\n",
    "        ibd1_count = sum(1 for seg in segs if not seg.is_ibd2)\n",
    "        ibd2_count = sum(1 for seg in segs if seg.is_ibd2)\n",
    "        \n",
    "        pair_stats[pair] = {\n",
    "            'total_ibd1_cm': total_ibd1_cm,\n",
    "            'total_ibd2_cm': total_ibd2_cm,\n",
    "            'ibd1_count': ibd1_count,\n",
    "            'ibd2_count': ibd2_count,\n",
    "            'total_cm': total_ibd1_cm + total_ibd2_cm,\n",
    "            'segment_count': len(segs)\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'filtered_segments': filtered_segments,\n",
    "        'pair_index': pair_index,\n",
    "        'ind_index': ind_index,\n",
    "        'pair_stats': pair_stats\n",
    "    }\n",
    "\n",
    "# Preprocess our example segments\n",
    "preprocessed_data = preprocess_ibd_segments(example_segments)\n",
    "\n",
    "# Display the summary statistics\n",
    "print(\"Pair Statistics:\")\n",
    "for pair, stats in preprocessed_data['pair_stats'].items():\n",
    "    print(f\"\\nPair {pair}:\")\n",
    "    for stat, value in stats.items():\n",
    "        print(f\"  {stat}: {value:.2f}\" if isinstance(value, float) else f\"  {stat}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preprocessing creates several indexes that enable efficient data access during pedigree reconstruction:\n",
    "- The pair index allows quick lookup of all segments between a specific pair of individuals\n",
    "- The individual index facilitates finding all segments involving a particular individual\n",
    "- The pair statistics cache frequently used summary metrics to avoid redundant calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moment-Based Summary Statistics\n",
    "\n",
    "Bonsai relies heavily on \"IBD moments\" to summarize the IBD sharing between individuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ibd_moments(pair, pair_index, min_cm=7):\n",
    "    \"\"\"Calculate IBD moments for a pair of individuals.\"\"\"\n",
    "    if pair not in pair_index:\n",
    "        return {'m1': 0, 'm2': 0, 'm3': 0}  # No segments\n",
    "    \n",
    "    segments = pair_index[pair]\n",
    "    filtered_segments = [seg for seg in segments if seg.length_cm >= min_cm]\n",
    "    \n",
    "    # First moment: number of segments\n",
    "    m1 = len(filtered_segments)\n",
    "    \n",
    "    # Second moment: total length\n",
    "    m2 = sum(seg.length_cm for seg in filtered_segments)\n",
    "    \n",
    "    # Third moment: sum of squares (optional)\n",
    "    m3 = sum(seg.length_cm ** 2 for seg in filtered_segments)\n",
    "    \n",
    "    return {'m1': m1, 'm2': m2, 'm3': m3}\n",
    "\n",
    "# Calculate moments for each pair in our example data\n",
    "pair_moments = {}\n",
    "for pair in preprocessed_data['pair_index']:\n",
    "    pair_moments[pair] = calculate_ibd_moments(pair, preprocessed_data['pair_index'])\n",
    "\n",
    "# Display the moments\n",
    "print(\"IBD Moments by Pair:\")\n",
    "for pair, moments in pair_moments.items():\n",
    "    print(f\"\\nPair {pair}:\")\n",
    "    print(f\"  First moment (count): {moments['m1']}\")\n",
    "    print(f\"  Second moment (total length): {moments['m2']:.2f} cM\")\n",
    "    print(f\"  Third moment (sum of squares): {moments['m3']:.2f} cM\u00b2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These moments are used in the likelihood calculations that drive pedigree reconstruction. By caching them, Bonsai avoids recalculating these statistics repeatedly during optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph-Theoretical Representation of Pedigrees\n",
    "\n",
    "Pedigrees are fundamentally graph structures, with individuals as nodes and parent-child relationships as edges. Bonsai leverages graph theory to represent and manipulate pedigrees efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed Acyclic Graphs (DAGs)\n",
    "\n",
    "A valid pedigree forms a directed acyclic graph (DAG), where:\n",
    "- Nodes represent individuals\n",
    "- Directed edges represent parent-child relationships (pointing from parent to child)\n",
    "- The graph is acyclic (no cycles allowed, as individuals cannot be their own ancestors)\n",
    "\n",
    "Bonsai enforces these properties through constraints in its optimization algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def would_create_cycle(up_node_dict, child_id, proposed_parent_id):\n",
    "    \"\"\"Check if adding a parent-child relationship would create a cycle.\"\"\"\n",
    "    # If the proposed parent is already a descendant of the child,\n",
    "    # adding this relationship would create a cycle\n",
    "    \n",
    "    # Start with the proposed parent\n",
    "    current_ids = [proposed_parent_id]\n",
    "    visited = set(current_ids)\n",
    "    \n",
    "    # Traverse up the pedigree\n",
    "    while current_ids:\n",
    "        next_ids = []\n",
    "        for current_id in current_ids:\n",
    "            # If we've reached the child, a cycle would be created\n",
    "            if current_id == child_id:\n",
    "                return True\n",
    "                \n",
    "            # Add this individual's parents to the search\n",
    "            if current_id in up_node_dict:\n",
    "                parents = up_node_dict[current_id].keys()\n",
    "                for parent_id in parents:\n",
    "                    if parent_id not in visited:\n",
    "                        next_ids.append(parent_id)\n",
    "                        visited.add(parent_id)\n",
    "        \n",
    "        current_ids = next_ids\n",
    "    \n",
    "    # No cycle found\n",
    "    return False\n",
    "\n",
    "# Test the cycle detection function\n",
    "test_pedigree = {\n",
    "    1000: {1001: 1, 1002: 1},  # 1000 has parents 1001 and 1002\n",
    "    1001: {1003: 1, 1004: 1},  # 1001 has parents 1003 and 1004\n",
    "    1002: {},\n",
    "    1003: {},\n",
    "    1004: {}\n",
    "}\n",
    "\n",
    "# Would adding 1000 as a parent of 1003 create a cycle?\n",
    "# (1000 -> 1001 -> 1003 -> 1000 would form a cycle)\n",
    "cycle_detected = would_create_cycle(test_pedigree, 1003, 1000)\n",
    "print(f\"Would adding 1000 as a parent of 1003 create a cycle? {cycle_detected}\")\n",
    "\n",
    "# Would adding 1002 as a parent of 1003 create a cycle?\n",
    "cycle_detected = would_create_cycle(test_pedigree, 1003, 1002)\n",
    "print(f\"Would adding 1002 as a parent of 1003 create a cycle? {cycle_detected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Detection and Graph Partitioning\n",
    "\n",
    "For large datasets, Bonsai uses graph-based community detection algorithms (e.g., Louvain method) to partition the data into more manageable subproblems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_with_community_detection(segments):\n",
    "    \"\"\"Partition individuals into communities based on IBD sharing.\"\"\"\n",
    "    # Create a graph where nodes are individuals and edges represent IBD sharing\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add edges with weights based on IBD sharing\n",
    "    for seg in segments:\n",
    "        ind1, ind2 = seg.ind1, seg.ind2\n",
    "        weight = seg.length_cm\n",
    "        \n",
    "        if G.has_edge(ind1, ind2):\n",
    "            G[ind1][ind2]['weight'] += weight\n",
    "        else:\n",
    "            G.add_edge(ind1, ind2, weight=weight)\n",
    "    \n",
    "    # Apply Louvain community detection if available\n",
    "    try:\n",
    "        communities = nx.community.louvain_communities(G, weight='weight')\n",
    "    except AttributeError:\n",
    "        # Fallback to connected components if Louvain isn't available\n",
    "        communities = [c for c in nx.connected_components(G)]\n",
    "    \n",
    "    # Return communities as lists of individual IDs\n",
    "    return [list(community) for community in communities]\n",
    "\n",
    "# Apply community detection to our example segments\n",
    "communities = partition_with_community_detection(example_segments)\n",
    "\n",
    "# Display the communities\n",
    "print(f\"Detected {len(communities)} communities:\")\n",
    "for i, community in enumerate(communities):\n",
    "    print(f\"Community {i+1}: {community}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This partitioning strategy offers several advantages:\n",
    "- Reduces computational complexity by breaking a large problem into smaller subproblems\n",
    "- Focuses reconstruction on groups of individuals that are likely related\n",
    "- Enables parallel processing of different communities\n",
    "- Improves scalability to handle large datasets with thousands of individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the communities based on IBD sharing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ibd_communities(segments, communities):\n",
    "    \"\"\"Visualize communities based on IBD sharing.\"\"\"\n",
    "    # Create a graph where nodes are individuals and edges represent IBD sharing\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add edges with weights based on IBD sharing\n",
    "    for seg in segments:\n",
    "        ind1, ind2 = seg.ind1, seg.ind2\n",
    "        weight = seg.length_cm\n",
    "        \n",
    "        if G.has_edge(ind1, ind2):\n",
    "            G[ind1][ind2]['weight'] += weight\n",
    "        else:\n",
    "            G.add_edge(ind1, ind2, weight=weight)\n",
    "    \n",
    "    # Create a mapping from individual to community\n",
    "    community_map = {}\n",
    "    for i, community in enumerate(communities):\n",
    "        for ind in community:\n",
    "            community_map[ind] = i\n",
    "    \n",
    "    # Create node colors based on community\n",
    "    cmap = plt.cm.get_cmap('tab10', len(communities))\n",
    "    node_colors = [cmap(community_map[node]) for node in G.nodes()]\n",
    "    \n",
    "    # Create edge weights based on IBD sharing\n",
    "    edge_weights = [G[u][v]['weight'] / 10 for u, v in G.edges()]\n",
    "    \n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    pos = nx.spring_layout(G, seed=42)  # Consistent layout\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, \n",
    "            edge_color='gray', width=edge_weights, alpha=0.7,\n",
    "            node_size=500, font_size=10)\n",
    "    \n",
    "    # Add edge labels (IBD sharing in cM)\n",
    "    edge_labels = {(u, v): f\"{d['weight']:.1f} cM\" for u, v, d in G.edges(data=True)}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "    \n",
    "    plt.title('IBD Sharing Communities')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the communities\n",
    "visualize_ibd_communities(example_segments, communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building and Manipulating Pedigrees\n",
    "\n",
    "Bonsai includes operations for building and modifying pedigree structures during the reconstruction process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pedigree Modification Operations\n",
    "\n",
    "These operations form the basis of Bonsai's optimization algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_parent(up_node_dict, child_id, parent_id):\n",
    "    \"\"\"Add a parent-child relationship to the pedigree.\"\"\"\n",
    "    # Ensure child exists in dictionary\n",
    "    if child_id not in up_node_dict:\n",
    "        up_node_dict[child_id] = {}\n",
    "    \n",
    "    # Check if adding this parent would create a cycle\n",
    "    if would_create_cycle(up_node_dict, child_id, parent_id):\n",
    "        return False  # Cannot add this relationship\n",
    "    \n",
    "    # Check if child already has two parents\n",
    "    if len(up_node_dict[child_id]) >= 2:\n",
    "        return False  # Child already has maximum number of parents\n",
    "    \n",
    "    # Add the parent\n",
    "    up_node_dict[child_id][parent_id] = 1\n",
    "    \n",
    "    # Ensure parent exists in dictionary\n",
    "    if parent_id not in up_node_dict:\n",
    "        up_node_dict[parent_id] = {}\n",
    "    \n",
    "    return True\n",
    "\n",
    "def remove_parent(up_node_dict, child_id, parent_id):\n",
    "    \"\"\"Remove a parent-child relationship from the pedigree.\"\"\"\n",
    "    if child_id not in up_node_dict or parent_id not in up_node_dict[child_id]:\n",
    "        return False  # Relationship doesn't exist\n",
    "    \n",
    "    # Remove the relationship\n",
    "    del up_node_dict[child_id][parent_id]\n",
    "    return True\n",
    "\n",
    "def swap_parent(up_node_dict, child_id, old_parent_id, new_parent_id):\n",
    "    \"\"\"Replace one parent with another.\"\"\"\n",
    "    # Remove old parent\n",
    "    if not remove_parent(up_node_dict, child_id, old_parent_id):\n",
    "        return False\n",
    "    \n",
    "    # Add new parent\n",
    "    if not add_parent(up_node_dict, child_id, new_parent_id):\n",
    "        # If adding new parent fails, restore old parent\n",
    "        add_parent(up_node_dict, child_id, old_parent_id)\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Create a simple pedigree\n",
    "test_pedigree = {\n",
    "    1000: {},\n",
    "    1001: {},\n",
    "    1002: {}\n",
    "}\n",
    "\n",
    "# Add a parent-child relationship\n",
    "add_parent(test_pedigree, 1000, 1001)\n",
    "print(\"After adding 1001 as parent of 1000:\")\n",
    "print(test_pedigree)\n",
    "\n",
    "# Add another parent\n",
    "add_parent(test_pedigree, 1000, 1002)\n",
    "print(\"\\nAfter adding 1002 as parent of 1000:\")\n",
    "print(test_pedigree)\n",
    "\n",
    "# Visualize the pedigree\n",
    "visualize_pedigree(test_pedigree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Inferred Ancestors\n",
    "\n",
    "A key feature of Bonsai is its ability to infer missing ancestors. This is implemented by creating \"latent nodes\" with negative IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_latent_ancestor(up_node_dict, next_latent_id=-1):\n",
    "    \"\"\"Create a new latent ancestor node in the pedigree.\"\"\"\n",
    "    # Find an unused negative ID\n",
    "    while next_latent_id in up_node_dict:\n",
    "        next_latent_id -= 1\n",
    "    \n",
    "    # Create the new latent node with no parents\n",
    "    up_node_dict[next_latent_id] = {}\n",
    "    \n",
    "    return next_latent_id\n",
    "\n",
    "def add_latent_parent_pair(up_node_dict, child_id):\n",
    "    \"\"\"Add a pair of latent parents to a child.\"\"\"\n",
    "    # Create two latent parents\n",
    "    latent_parent1 = create_latent_ancestor(up_node_dict)\n",
    "    latent_parent2 = create_latent_ancestor(up_node_dict, latent_parent1 - 1)\n",
    "    \n",
    "    # Add them as parents of the child\n",
    "    add_parent(up_node_dict, child_id, latent_parent1)\n",
    "    add_parent(up_node_dict, child_id, latent_parent2)\n",
    "    \n",
    "    return latent_parent1, latent_parent2\n",
    "\n",
    "# Extend our test pedigree with latent ancestors\n",
    "test_pedigree = {\n",
    "    1000: {},\n",
    "    1001: {},\n",
    "    1002: {},\n",
    "    1003: {}\n",
    "}\n",
    "\n",
    "# Add observed relationships\n",
    "add_parent(test_pedigree, 1000, 1001)\n",
    "add_parent(test_pedigree, 1000, 1002)\n",
    "\n",
    "# Add latent parents for 1003\n",
    "latent_parent1, latent_parent2 = add_latent_parent_pair(test_pedigree, 1003)\n",
    "print(f\"Added latent parents {latent_parent1} and {latent_parent2} to individual 1003\")\n",
    "\n",
    "# Connect latent parents to observed individuals to create a more complex pedigree\n",
    "add_parent(test_pedigree, latent_parent1, 1001)\n",
    "print(\"\\nFinal pedigree with latent ancestors:\")\n",
    "print(test_pedigree)\n",
    "\n",
    "# Visualize the extended pedigree\n",
    "visualize_pedigree(test_pedigree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This capability allows Bonsai to reconstruct more complete pedigrees even when data for some ancestors is unavailable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Efficient Search and Optimization\n",
    "\n",
    "Bonsai's data structures are designed to support efficient search and optimization of pedigree structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching and Memoization\n",
    "\n",
    "To avoid redundant calculations, Bonsai extensively uses caching and memoization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationshipCalculator:\n",
    "    def __init__(self, up_node_dict):\n",
    "        self.up_node_dict = up_node_dict\n",
    "        self.coefficient_cache = {}  # Cache for relationship coefficients\n",
    "    \n",
    "    def get_coefficient(self, id1, id2):\n",
    "        \"\"\"Get the relationship coefficient between two individuals.\"\"\"\n",
    "        # Check cache first\n",
    "        pair = tuple(sorted([id1, id2]))\n",
    "        if pair in self.coefficient_cache:\n",
    "            return self.coefficient_cache[pair]\n",
    "        \n",
    "        # Calculate coefficient\n",
    "        coefficient = self._calculate_coefficient(id1, id2)\n",
    "        \n",
    "        # Cache the result\n",
    "        self.coefficient_cache[pair] = coefficient\n",
    "        return coefficient\n",
    "    \n",
    "    def _calculate_coefficient(self, id1, id2):\n",
    "        \"\"\"Calculate the relationship coefficient (actual implementation).\"\"\"\n",
    "        # Self-relationship\n",
    "        if id1 == id2:\n",
    "            return 1.0\n",
    "        \n",
    "        # Direct parent-child relationship\n",
    "        if id1 in self.up_node_dict.get(id2, {}) or id2 in self.up_node_dict.get(id1, {}):\n",
    "            return 0.5\n",
    "        \n",
    "        # Calculate common ancestor contributions\n",
    "        paths1 = self._get_paths_to_ancestors(id1)\n",
    "        paths2 = self._get_paths_to_ancestors(id2)\n",
    "        \n",
    "        # Find common ancestors\n",
    "        common_ancestors = set(paths1.keys()).intersection(set(paths2.keys()))\n",
    "        \n",
    "        # Sum contributions from each common ancestor\n",
    "        coefficient = 0.0\n",
    "        for ancestor in common_ancestors:\n",
    "            for path1 in paths1[ancestor]:\n",
    "                for path2 in paths2[ancestor]:\n",
    "                    # Contribution is 0.5^(length of paths)\n",
    "                    contribution = (0.5 ** len(path1)) * (0.5 ** len(path2))\n",
    "                    coefficient += contribution\n",
    "        \n",
    "        return coefficient\n",
    "    \n",
    "    def _get_paths_to_ancestors(self, individual_id):\n",
    "        \"\"\"Find all paths from an individual to ancestors.\"\"\"\n",
    "        paths = {individual_id: [[]]}\n",
    "        \n",
    "        # Queue of (individual, current_path) tuples to process\n",
    "        queue = [(individual_id, [])]\n",
    "        \n",
    "        while queue:\n",
    "            current_id, current_path = queue.pop(0)\n",
    "            \n",
    "            # Get parents of current individual\n",
    "            parents = self.up_node_dict.get(current_id, {})\n",
    "            \n",
    "            for parent_id in parents:\n",
    "                # Create a new path that includes this parent\n",
    "                new_path = current_path + [parent_id]\n",
    "                \n",
    "                # Add path to parent's paths\n",
    "                if parent_id not in paths:\n",
    "                    paths[parent_id] = []\n",
    "                paths[parent_id].append(new_path)\n",
    "                \n",
    "                # Add parent to queue for further processing\n",
    "                queue.append((parent_id, new_path))\n",
    "        \n",
    "        return paths\n",
    "    \n",
    "    def invalidate_cache_for_individual(self, individual_id):\n",
    "        \"\"\"Invalidate cache entries involving a specific individual.\"\"\"\n",
    "        # When the pedigree changes, we need to invalidate affected cache entries\n",
    "        keys_to_remove = []\n",
    "        for key in self.coefficient_cache:\n",
    "            if individual_id in key:\n",
    "                keys_to_remove.append(key)\n",
    "        \n",
    "        for key in keys_to_remove:\n",
    "            del self.coefficient_cache[key]\n",
    "\n",
    "# Test the relationship calculator with our example pedigree\n",
    "calculator = RelationshipCalculator(test_pedigree)\n",
    "\n",
    "# Calculate some relationships\n",
    "relationships = [\n",
    "    (1000, 1001),  # Parent-child\n",
    "    (1000, 1002),  # Parent-child\n",
    "    (1003, 1001),  # Grandparent-grandchild (through latent parent)\n",
    "    (1000, 1003)   # Half-siblings or cousins (depending on exact structure)\n",
    "]\n",
    "\n",
    "for id1, id2 in relationships:\n",
    "    coef = calculator.get_coefficient(id1, id2)\n",
    "    print(f\"Relationship coefficient between {id1} and {id2}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This caching strategy dramatically improves performance, especially during optimization when many similar pedigree configurations are evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priority-Based Processing\n",
    "\n",
    "Bonsai processes relationships in order of confidence, focusing computational resources on the most reliable inferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_relationships_by_priority(pair_stats):\n",
    "    \"\"\"Process relationships in order of priority (higher IBD sharing first).\"\"\"\n",
    "    # Create priority queue\n",
    "    priority_queue = []\n",
    "    \n",
    "    # Add all pairs to the queue with priority based on IBD sharing\n",
    "    for pair, stats in pair_stats.items():\n",
    "        # Priority is negative of total IBD sharing (so higher sharing = higher priority)\n",
    "        priority = -stats['total_cm']\n",
    "        heapq.heappush(priority_queue, (priority, pair))\n",
    "    \n",
    "    # Process queue\n",
    "    processed_pairs = []\n",
    "    while priority_queue:\n",
    "        _, pair = heapq.heappop(priority_queue)\n",
    "        processed_pairs.append(pair)\n",
    "    \n",
    "    return processed_pairs\n",
    "\n",
    "# Process our preprocessed data by priority\n",
    "prioritized_pairs = process_relationships_by_priority(preprocessed_data['pair_stats'])\n",
    "\n",
    "# Display the pairs in priority order\n",
    "print(\"Pairs in order of processing priority:\")\n",
    "for i, pair in enumerate(prioritized_pairs):\n",
    "    stats = preprocessed_data['pair_stats'][pair]\n",
    "    print(f\"{i+1}. Pair {pair}: {stats['total_cm']:.2f} cM total sharing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach helps Bonsai establish the most obvious relationships first, which constrains the search space for more ambiguous relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Structure Implementation Challenges\n",
    "\n",
    "Implementing Bonsai's data structures involves several challenges that must be addressed for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Efficiency\n",
    "\n",
    "For large datasets with thousands of individuals and millions of IBD segments, memory usage becomes a critical concern. Bonsai employs several strategies to minimize memory footprint:\n",
    "\n",
    "* **Sparse representation:** The up-node dictionary only stores relationships that exist, making it memory-efficient for sparse pedigrees\n",
    "* **Data filtering:** IBD segments below a minimum threshold are filtered out early in the preprocessing pipeline\n",
    "* **Community partitioning:** By breaking the problem into communities, each subproblem can be processed with a smaller memory footprint\n",
    "* **Selective caching:** Caching strategies that prioritize frequently used data while allowing less frequent data to be recalculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Complexity Considerations\n",
    "\n",
    "The time complexity of key operations in Bonsai:\n",
    "\n",
    "| Operation | Time Complexity | Notes |\n",
    "|-----------|-----------------|-------|\n",
    "| Accessing IBD segments for a pair | O(1) | Using pair-based index |\n",
    "| Finding all pairs involving an individual | O(d) where d is degree | Using individual-based index |\n",
    "| Calculating relationship coefficient | O(a) where a is number of ancestors | With caching, subsequent lookups are O(1) |\n",
    "| Checking for cycles | O(n) where n is individuals in pedigree | Worst case, but typically much faster |\n",
    "| Community detection | O(m log n) where m is number of IBD segments | Using optimized Louvain algorithm |\n",
    "| Overall reconstruction | O(i * p^2) where i is iterations, p is pairs | With optimizations, scales to thousands of individuals |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Extensions and Adaptations\n",
    "\n",
    "The modular design of Bonsai's data structures facilitates custom extensions for specialized applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating Additional Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended BioInfo structure with additional metadata\n",
    "extended_bio_info = [\n",
    "    {\n",
    "        'genotype_id': 1000,\n",
    "        'age': 75,\n",
    "        'sex': 'F',\n",
    "        'population': 'EUR',\n",
    "        'birth_year': 1947,\n",
    "        'is_genotyped': True,\n",
    "        'phenotypes': {'height': 165, 'weight': 68},\n",
    "        'haplogroups': {'mt': 'H1', 'y': None}\n",
    "    },\n",
    "    # ... additional individuals ...\n",
    "]\n",
    "\n",
    "# Display the extended metadata\n",
    "extended_bio_df = pd.DataFrame(extended_bio_info)\n",
    "extended_bio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This extended metadata can be used to enhance pedigree reconstruction accuracy or to analyze the resulting pedigrees in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Relationship Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended up-node dictionary with relationship types\n",
    "extended_up_node_dict = {\n",
    "    1000: {\n",
    "        1001: {'type': 'biological', 'confidence': 0.98},\n",
    "        1002: {'type': 'biological', 'confidence': 0.97}\n",
    "    },\n",
    "    1003: {\n",
    "        1001: {'type': 'adoptive', 'confidence': 0.99},\n",
    "        1004: {'type': 'biological', 'confidence': 0.95}\n",
    "    },\n",
    "    # ... additional relationships ...\n",
    "}\n",
    "\n",
    "# Function to visualize extended pedigree\n",
    "def visualize_extended_pedigree(extended_dict):\n",
    "    \"\"\"Visualize pedigree with extended relationship information.\"\"\"\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes\n",
    "    for indiv_id in extended_dict.keys():\n",
    "        G.add_node(indiv_id)\n",
    "    \n",
    "    # Add edges with attributes\n",
    "    for child, parents in extended_dict.items():\n",
    "        for parent, attrs in parents.items():\n",
    "            G.add_edge(parent, child, **attrs)\n",
    "    \n",
    "    # Set up the visualization\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_color='lightgreen', node_size=500)\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    \n",
    "    # Draw edges with different styles based on relationship type\n",
    "    biological_edges = [(p, c) for c, parents in extended_dict.items() \n",
    "                        for p, attrs in parents.items() if attrs.get('type') == 'biological']\n",
    "    adoptive_edges = [(p, c) for c, parents in extended_dict.items() \n",
    "                      for p, attrs in parents.items() if attrs.get('type') == 'adoptive']\n",
    "    \n",
    "    nx.draw_networkx_edges(G, pos, edgelist=biological_edges, edge_color='blue')\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=adoptive_edges, edge_color='red', style='dashed')\n",
    "    \n",
    "    # Add edge labels with confidence scores\n",
    "    edge_labels = {(p, c): f\"{attrs.get('confidence', 1.0):.2f}\" \n",
    "                  for c, parents in extended_dict.items() \n",
    "                  for p, attrs in parents.items()}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "    \n",
    "    plt.title('Extended Pedigree with Relationship Types')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the extended pedigree\n",
    "visualize_extended_pedigree(extended_up_node_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This extension allows the representation of more complex family structures, such as adoptive relationships, step-relationships, or relationships with uncertain confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercises\n",
    "\n",
    "Complete the following exercises to deepen your understanding of the data structures and algorithmic design in Bonsai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Implement an efficient IBD segment indexing structure and benchmark its performance on a large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Extend the up-node dictionary implementation to handle additional relationship metadata, such as relationship confidence or type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Implement and test the cycle detection algorithm for pedigree validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Create a visualization function that renders a pedigree from an up-node dictionary, highlighting different generations and relationship types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Implement a memory-efficient version of the relationship coefficient calculator using sparse matrix representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Tip:** When designing data structures for pedigree reconstruction, always consider the trade-offs between memory usage, computational complexity, and biological accuracy. For large datasets, efficient data structures can make the difference between a reconstruction that completes in minutes versus one that takes days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab, we explored the data structures and algorithmic design that power the Bonsai pedigree reconstruction algorithm. We implemented key components such as the IBD segment representation, up-node dictionary, preprocessing pipelines, and graph-theoretical analyses. We also examined how these structures enable efficient pedigree manipulation, search, and optimization.\n",
    "\n",
    "Key takeaways:\n",
    "- Bonsai's effectiveness stems from carefully designed data structures that balance computational efficiency with biological accuracy\n",
    "- The up-node dictionary provides a compact and efficient representation of pedigree structures\n",
    "- Preprocessing and indexing IBD segment data is crucial for efficient access during pedigree reconstruction\n",
    "- Graph theory provides valuable tools for representing and analyzing pedigree structures\n",
    "- Caching and prioritization strategies significantly improve computational performance\n",
    "- The modular design facilitates custom extensions for specialized applications\n",
    "\n",
    "In the next lab, we will explore model calibration techniques to ensure that Bonsai's likelihood calculations accurately reflect real-world genetic inheritance patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}