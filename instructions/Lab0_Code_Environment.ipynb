{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0: Code Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0: Code Environment\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook guides you through the final steps of setting up your local Ubuntu 24.04 environment for the Computational Genetic Genealogy course. It focuses on installing specific bioinformatics tools and verifying the configuration after you have completed the initial setup described in the `README.md` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites Check\n",
    "\n",
    "Before proceeding with this notebook, ensure you have completed the **initial setup steps outlined in the `README.md` file** under the \"Ubuntu 24.04 Local Setup\" section. This includes:\n",
    "\n",
    "1.  ✅ Cloning the `computational_genetic_genealogy` repository (referred to as `PROJECT_BASE_DIR`).\n",
    "2.  ✅ Manually creating the subdirectories (`data`, `results`, `references`, `utils`) within `PROJECT_BASE_DIR`.\n",
    "3.  ✅ Manually creating the `~/.env` file (in your home directory) with the correct absolute paths pointing to `PROJECT_BASE_DIR` and its subdirectories.\n",
    "4.  ✅ Installing all required system packages via `sudo apt install ...` (including Java 21, Python 3.12, build tools, R, TeX, etc.).\n",
    "5.  ✅ **Building and installing HTSlib, Samtools, and BCFtools version 1.18 from source** using the commands provided in the README.\n",
    "6.  ✅ Installing `poetry` via `pipx` and ensuring `~/.local/bin` is in your PATH.\n",
    "7.  ✅ Running `poetry install --no-root` within the `PROJECT_BASE_DIR` directory to install Python dependencies into `./.venv`.\n",
    "8.  ✅ Manually adding the `${PROJECT_BASE_DIR}/utils` directory to your `~/.bashrc` PATH and sourcing the file (e.g., `source ~/.bashrc`).\n",
    "9.  ✅ Configuring the `JAVA_HOME` environment variable in `~/.bashrc`.\n",
    "\n",
    "**Important Note:** This notebook assumes the `.env` file is located in your **home directory (`~/.env`)**, aligning with the Docker environment setup, and therefore **does not run** the `scripts_env/directory_setup.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Python Interpreter in VS Code\n",
    "\n",
    "Your Jupyter Notebook needs to know which Python environment (including installed packages) to use. Select the interpreter created by Poetry in the previous steps:\n",
    "\n",
    "1.  Open the Command Palette in VS Code (Ctrl+Shift+P or Cmd+Shift+P).\n",
    "2.  Type and select `Python: Select Interpreter`.\n",
    "3.  Choose the option that points to the `.venv` directory within your project folder (`computational_genetic_genealogy`). It might look like `Python 3.12 ('computational_genetic_genealogy/.venv': Poetry)` or similar.\n",
    "\n",
    "If you don't see the correct interpreter, ensure you successfully ran `poetry install --no-root` in the terminal within your `PROJECT_BASE_DIR`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Environment Variables and Verify Setup\n",
    "\n",
    "First, we load necessary libraries and the directory paths defined in your `~/.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "# Configure basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def load_env_file():\n",
    "    \"\"\"Load the .env file from the user's home directory.\"\"\"\n",
    "    env_path = Path.home() / '.env'\n",
    "    logging.info(f\"Attempting to load environment variables from: {env_path}\")\n",
    "    if not env_path.exists():\n",
    "        logging.error(f\"'.env' file not found in home directory ({Path.home()}).\")\n",
    "        logging.error(\"Please ensure you have created it as per the README instructions.\")\n",
    "        raise FileNotFoundError(f\"'.env' file not found at {env_path}\")\n",
    "\n",
    "    try:\n",
    "        # Load the .env file, overriding existing environment variables\n",
    "        load_dotenv(env_path, override=True)\n",
    "        logging.info(f\"Successfully loaded environment variables from: {env_path}\")\n",
    "        return env_path\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading .env file: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Load and Set Environment Variables ---\n",
    "try:\n",
    "    env_path = load_env_file()\n",
    "\n",
    "    # Get variables from environment (loaded from .env)\n",
    "    working_directory = os.getenv('PROJECT_WORKING_DIR')\n",
    "    data_directory = os.getenv('PROJECT_DATA_DIR')\n",
    "    references_directory = os.getenv('PROJECT_REFERENCES_DIR')\n",
    "    results_directory = os.getenv('PROJECT_RESULTS_DIR')\n",
    "    utils_directory = os.getenv('PROJECT_UTILS_DIR')\n",
    "\n",
    "    # Verify paths were loaded\n",
    "    required_paths = {\n",
    "        'PROJECT_WORKING_DIR': working_directory,\n",
    "        'PROJECT_DATA_DIR': data_directory,\n",
    "        'PROJECT_REFERENCES_DIR': references_directory,\n",
    "        'PROJECT_RESULTS_DIR': results_directory,\n",
    "        'PROJECT_UTILS_DIR': utils_directory\n",
    "    }\n",
    "    missing_vars = [name for name, path in required_paths.items() if not path]\n",
    "    if missing_vars:\n",
    "        logging.error(f\"Missing environment variables in {env_path}: {', '.join(missing_vars)}\")\n",
    "        raise ValueError(f\"Missing required paths in {env_path}. Please check the file.\")\n",
    "\n",
    "    # Set environment variables for shell commands (! or %%) within the notebook\n",
    "    # Note: Python's os.environ affects subprocesses launched *from* this notebook process.\n",
    "    os.environ[\"PROJECT_WORKING_DIR\"] = working_directory\n",
    "    os.environ[\"PROJECT_DATA_DIR\"] = data_directory\n",
    "    os.environ[\"PROJECT_REFERENCES_DIR\"] = references_directory\n",
    "    os.environ[\"PROJECT_RESULTS_DIR\"] = results_directory\n",
    "    os.environ[\"PROJECT_UTILS_DIR\"] = utils_directory\n",
    "\n",
    "    logging.info(f\"Working Directory set to: {working_directory}\")\n",
    "    logging.info(f\"Data Directory set to: {data_directory}\")\n",
    "    logging.info(f\"References Directory set to: {references_directory}\")\n",
    "    logging.info(f\"Results Directory set to: {results_directory}\")\n",
    "    logging.info(f\"Utils Directory set to: {utils_directory}\")\n",
    "\n",
    "    # Change Notebook's Current Working Directory (CWD)\n",
    "    if working_directory and Path(working_directory).is_dir():\n",
    "        os.chdir(working_directory)\n",
    "        logging.info(f\"Changed notebook CWD to: {os.getcwd()}\")\n",
    "    else:\n",
    "        logging.warning(f\"Working directory '{working_directory}' not found or not a directory. Cannot change CWD.\")\n",
    "        raise NotADirectoryError(f\"Working directory path not valid: {working_directory}\")\n",
    "\n",
    "except (FileNotFoundError, ValueError, NotADirectoryError) as e:\n",
    "    logging.critical(f\"Critical setup error: {e}. Please fix the setup and restart the kernel.\")\n",
    "    # Optionally, stop execution more forcefully if needed, though this can be abrupt:\n",
    "    # raise SystemExit(\"Stopping execution due to critical setup error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Initial Setup\n",
    "\n",
    "Let's check the versions of key software installed via the terminal steps in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying Java (Should be OpenJDK 21) ---\n",
      "openjdk version \"21.0.6\" 2025-01-21\n",
      "OpenJDK Runtime Environment (build 21.0.6+7-Ubuntu-124.04.1)\n",
      "OpenJDK 64-Bit Server VM (build 21.0.6+7-Ubuntu-124.04.1, mixed mode, sharing)\n",
      "\n",
      "--- Verifying JAVA_HOME ---\n",
      "\n",
      "\n",
      "--- Verifying Samtools/BCFtools/Tabix (should be v1.18) ---\n",
      "samtools 1.19.2\n",
      "bcftools 1.19\n",
      "\n",
      "--- Checking Tabix --- \n",
      "/usr/bin/tabix\n",
      "tabix (htslib) 1.19\n",
      "Copyright (C) 2023 Genome Research Ltd.\n",
      "\n",
      "--- Verifying R ---\n",
      "R version 4.3.3 (2024-02-29) -- \"Angel Food Cake\"\n"
     ]
    }
   ],
   "source": [
    "# Verify Java Installation\n",
    "print(\"--- Verifying Java (Should be OpenJDK 21) ---\")\n",
    "!java -version\n",
    "print(\"\\n--- Verifying JAVA_HOME ---\")\n",
    "# Note: $JAVA_HOME might not be directly visible here if not exported correctly for the notebook kernel\n",
    "# Running java -version is a more reliable check within the notebook\n",
    "!echo $JAVA_HOME\n",
    "\n",
    "# Verify Samtools/BCFtools/Tabix Installation (Should be v1.18 from source)\n",
    "print(\"\\n--- Verifying Samtools/BCFtools/Tabix (should be v1.18) ---\")\n",
    "!samtools --version | head -n 1\n",
    "!bcftools --version | head -n 1\n",
    "print(\"\\n--- Checking Tabix --- \")\n",
    "!which tabix\n",
    "!tabix --version\n",
    "\n",
    "# Verify R Installation\n",
    "print(\"\\n--- Verifying R ---\")\n",
    "!R --version | head -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure sudo for Notebook (Optional)\n",
    "\n",
    "This step allows specific `sudo` commands (like `apt` or `rm`) to be run within notebook cells using `!sudo ...` without requiring a password. This can be convenient but modifies system configuration (`/etc/sudoers.d`). **Only run this if you understand the security implications and find it necessary.** You will need to copy and paste the command block into your Ubuntu terminal and enter your password there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# --- DO NOT RUN THIS CELL IN JUPYTER NOTEBOOK ---\n",
    "# --- COPY AND PASTE THE COMMANDS BELOW INTO YOUR UBUNTU TERMINAL WINDOW ---\n",
    "\n",
    "# echo \"$(whoami) ALL=(ALL) NOPASSWD: /usr/bin/apt-add-repository, /usr/bin/apt, /usr/bin/apt-get, /usr/bin/dpkg, /bin/rm\" | sudo tee /etc/sudoers.d/$(whoami)-notebook\n",
    "# sudo chmod 0440 /etc/sudoers.d/$(whoami)-notebook\n",
    "# echo \"Passwordless sudo configured for specific commands in /etc/sudoers.d/$(whoami)-notebook\"\n",
    "\n",
    "# --- Then you can run commands like !sudo apt update -y in the notebook ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Remaining Utilities\n",
    "\n",
    "Now we install the bioinformatics tools that were not covered by the initial system setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure R Library Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a personal R library directory and configure R to use it\n",
    "!mkdir -p ~/R/library/\n",
    "!grep -qxF '.libPaths(c(\"~/R/library/\", .libPaths()))' ~/.Rprofile || echo '.libPaths(c(\"~/R/library/\", .libPaths()))' >> ~/.Rprofile\n",
    "print(\"Contents of ~/.Rprofile:\")\n",
    "!cat ~/.Rprofile\n",
    "# You should see: .libPaths(c(\"~/R/library/\", .libPaths()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install LiftOver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install UCSC LiftOver tool and hg19->hg38 chain file\n",
    "utils_dir = os.getenv('PROJECT_UTILS_DIR')\n",
    "refs_dir = os.getenv('PROJECT_REFERENCES_DIR')\n",
    "\n",
    "if utils_dir and refs_dir:\n",
    "    print(\"--- Installing LiftOver ---\")\n",
    "    liftover_bin = Path(utils_dir) / \"liftOver\"\n",
    "    chain_file = Path(refs_dir) / \"hg19ToHg38.over.chain.gz\"\n",
    "\n",
    "    if not liftover_bin.exists():\n",
    "        print(\"Downloading LiftOver binary...\")\n",
    "        !wget -nv http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/liftOver -O \"{liftover_bin}\"\n",
    "        !chmod +x \"{liftover_bin}\"\n",
    "    else:\n",
    "        print(f\"LiftOver binary already exists: {liftover_bin}\")\n",
    "\n",
    "    if not chain_file.exists():\n",
    "        print(\"Downloading hg19ToHg38 chain file...\")\n",
    "        !wget -nv http://hgdownload.cse.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz -P \"{refs_dir}\"\n",
    "    else:\n",
    "        print(f\"Chain file already exists: {chain_file}\")\n",
    "\n",
    "    # Verify executable\n",
    "    if liftover_bin.exists() and os.access(liftover_bin, os.X_OK):\n",
    "        print(\"✅ LiftOver installed successfully.\")\n",
    "    else:\n",
    "        print(\"❌ LiftOver installation verification failed.\")\n",
    "else:\n",
    "    print(\"❌ Cannot install LiftOver: Utils or References directory path not set in environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install JAR Files (Beagle, HapIBD, RefinedIBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Download Java tools\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m utils_dir \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROJECT_UTILS_DIR\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils_dir:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Installing JAR Files ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Download Java tools\n",
    "utils_dir = os.getenv('PROJECT_UTILS_DIR')\n",
    "\n",
    "if utils_dir:\n",
    "    print(\"--- Installing JAR Files ---\")\n",
    "    # Define JARs and URLs based on the target Dockerfile\n",
    "    beagle_jar = \"beagle.27Feb25.75f.jar\"\n",
    "    hap_ibd_jar = \"hap-ibd.jar\"\n",
    "    refined_ibd_jar = \"refined-ibd.17Jan20.102.jar\"\n",
    "    refined_ibd_merge_jar = \"merge-ibd-segments.17Jan20.102.jar\"\n",
    "\n",
    "    beagle_url = f\"https://faculty.washington.edu/browning/beagle/{beagle_jar}\"\n",
    "    hap_ibd_url = f\"https://faculty.washington.edu/browning/{hap_ibd_jar}\"\n",
    "    refined_ibd_url = f\"https://faculty.washington.edu/browning/refined-ibd/{refined_ibd_jar}\"\n",
    "    refined_ibd_merge_url = f\"https://faculty.washington.edu/browning/refined-ibd/{refined_ibd_merge_jar}\"\n",
    "\n",
    "    jar_files = {\n",
    "        beagle_jar: beagle_url,\n",
    "        hap_ibd_jar: hap_ibd_url,\n",
    "        refined_ibd_jar: refined_ibd_url,\n",
    "        refined_ibd_merge_jar: refined_ibd_merge_url\n",
    "    }\n",
    "\n",
    "    print(\"Downloading JAR files (if missing)...\")\n",
    "    for jar, url in jar_files.items():\n",
    "        target_path = Path(utils_dir) / jar\n",
    "        if not target_path.exists():\n",
    "            logging.info(f\"Downloading {jar} from {url}...\")\n",
    "            # Use !wget for download progress in notebook\n",
    "            !wget --progress=dot:giga -O \"{target_path}\" \"{url}\"\n",
    "            if target_path.exists():\n",
    "                logging.info(f\"Successfully downloaded {jar}\")\n",
    "                # chmod +x might not be strictly necessary for jars but doesn't hurt\n",
    "                !chmod +x \"{target_path}\"\n",
    "            else:\n",
    "                logging.error(f\"Failed to download {jar}\")\n",
    "        else:\n",
    "            logging.info(f\"✅ File already exists: {target_path}\")\n",
    "\n",
    "    # Verify Beagle (example)\n",
    "    beagle_target_path = Path(utils_dir) / beagle_jar\n",
    "    if beagle_target_path.exists():\n",
    "         print(\"\\nTesting Beagle JAR execution...\")\n",
    "         # Running java -jar might produce non-zero exit code if no args are given, which is ok\n",
    "         !java -Xmx1g -jar \"{beagle_target_path}\" || echo \"Beagle test command finished (ignore non-zero exit code if help message shown).\"\n",
    "    else:\n",
    "         print(f\"❌ Beagle JAR not found at {beagle_target_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot install JARs: Utils directory path not set in environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install BonsaiTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install BonsaiTree\n",
    "utils_dir = os.getenv('PROJECT_UTILS_DIR')\n",
    "project_dir = os.getenv('PROJECT_WORKING_DIR')\n",
    "\n",
    "if utils_dir and project_dir:\n",
    "    bonsai_dir = Path(utils_dir) / \"bonsaitree\"\n",
    "    bonsai_repo = \"https://github.com/23andMe/bonsaitree.git\"\n",
    "    original_dir = Path.cwd()\n",
    "\n",
    "    print(\"--- Setting up BonsaiTree ---\")\n",
    "    if not bonsai_dir.is_dir():\n",
    "        print(f\"⬇️ Cloning BonsaiTree into {bonsai_dir}...\")\n",
    "        !git clone \"{bonsai_repo}\" \"{bonsai_dir}\"\n",
    "        # Change ownership after cloning (important!)\n",
    "        # Assumes user owns the directory where the repo was cloned (e.g., home dir)\n",
    "        !chown -R $(whoami):$(whoami) \"{bonsai_dir}\"\n",
    "    else:\n",
    "        print(f\"✅ BonsaiTree directory already exists: {bonsai_dir}\")\n",
    "\n",
    "    if bonsai_dir.is_dir():\n",
    "        print(f\"🛠️ Installing BonsaiTree package in {bonsai_dir}...\")\n",
    "        try:\n",
    "            os.chdir(bonsai_dir)\n",
    "            print(f\"Changed CWD to: {Path.cwd()}\")\n",
    "\n",
    "            # Ensure poetry is aware of the correct python interpreter\n",
    "            main_venv_path = Path(project_dir) / \".venv\" / \"bin\" / \"python\"\n",
    "            if main_venv_path.exists():\n",
    "                 print(f\"Using Python interpreter: {main_venv_path}\")\n",
    "                 !poetry env use \"{main_venv_path}\"\n",
    "            else:\n",
    "                 # Should not happen if README steps were followed, but fallback\n",
    "                 print(\"Warning: Main project venv python not found, falling back to python3.12\")\n",
    "                 !poetry env use python3.12\n",
    "\n",
    "            # Explicitly add dependencies via Poetry\n",
    "            print(\"Adding all BonsaiTree dependencies via Poetry...\")\n",
    "            !poetry add Cython funcy numpy scipy six setuptools-scm wheel pandas frozendict\n",
    "\n",
    "            # Build and install the package itself using pip --no-deps\n",
    "            print(\"Building and installing BonsaiTree package itself (dependencies handled by Poetry)...\")\n",
    "            !poetry run pip install . --no-deps\n",
    "\n",
    "            # Verify installation\n",
    "            print(\"Verifying BonsaiTree import...\")\n",
    "            verify_code = \"import sys; \"\n",
    "            # No need to add '.' to sys.path if installed correctly via pip\n",
    "            verify_code += \"from bonsaitree.v3.bonsai import build_pedigree; \"\n",
    "            verify_code += \"print('✅ BonsaiTree module imported successfully.')\"\n",
    "            !poetry run python -c \"{verify_code}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ An error occurred during BonsaiTree setup: {e}\")\n",
    "        finally:\n",
    "            # IMPORTANT: Change back to the original directory\n",
    "            os.chdir(original_dir)\n",
    "            print(f\"Returned CWD to: {Path.cwd()}\")\n",
    "    else:\n",
    "        # This case implies git clone failed\n",
    "        print(f\"❌ BonsaiTree directory does not exist after attempting clone: {bonsai_dir}\")\n",
    "else:\n",
    "    print(\"❌ Cannot install BonsaiTree: Utils or Working directory path not set in environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install IBIS, Ped-Sim, RFMix2 (Source Build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install tools that require compilation\n",
    "utils_dir = os.getenv('PROJECT_UTILS_DIR')\n",
    "project_dir = os.getenv('PROJECT_WORKING_DIR')\n",
    "\n",
    "if utils_dir and project_dir:\n",
    "    original_dir = Path.cwd() # Store current directory\n",
    "\n",
    "    # --- Tool Definitions ---\n",
    "    tools = {\n",
    "        'IBIS': {\n",
    "            'repo': \"https://github.com/williamslab/ibis.git\",\n",
    "            'dir': Path(utils_dir) / \"ibis\",\n",
    "            'build_cmd': \"make\",\n",
    "            'executable': \"ibis\",\n",
    "            'clone_opts': \"--recurse-submodules\"\n",
    "        },\n",
    "        'Ped-Sim': {\n",
    "            'repo': \"https://github.com/williamslab/ped-sim.git\",\n",
    "            'dir': Path(utils_dir) / \"ped-sim\",\n",
    "            'build_cmd': \"make && chmod +x ped-sim\",\n",
    "            'executable': \"ped-sim\",\n",
    "            'clone_opts': \"--recurse-submodules\"\n",
    "        },\n",
    "        'RFMix2': {\n",
    "            'repo': \"https://github.com/slowkoni/rfmix.git\",\n",
    "            'dir': Path(utils_dir) / \"rfmix2\",\n",
    "            'build_cmd': \"aclocal && autoheader && autoconf && automake --add-missing && ./configure && make\",\n",
    "            'executable': \"rfmix\",\n",
    "            'clone_opts': \"\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # --- Installation Loop ---\n",
    "    all_successful = True\n",
    "    for name, config in tools.items():\n",
    "        print(f\"\\n--- Setting up {name} ---\")\n",
    "        tool_dir = config['dir']\n",
    "        repo_url = config['repo']\n",
    "        build_cmd = config['build_cmd']\n",
    "        executable = tool_dir / config['executable']\n",
    "        clone_opts = config['clone_opts']\n",
    "\n",
    "        # Clone if directory doesn't exist\n",
    "        if not tool_dir.is_dir():\n",
    "            print(f\"⬇️ Cloning {name} repository...\")\n",
    "            # Use !git for simplicity in notebook\n",
    "            clone_command = f\"git clone {clone_opts} \\\"{repo_url}\\\" \\\"{tool_dir}\\\"\"\n",
    "            clone_result = !{clone_command}\n",
    "            if not tool_dir.is_dir(): # Check if clone succeeded\n",
    "               print(f\"❌ Git clone failed for {name}. Output:\")\n",
    "               print('\\n'.join(clone_result))\n",
    "               all_successful = False\n",
    "               continue # Skip to next tool\n",
    "            # Ensure user owns the directory\n",
    "            !chown -R $(whoami):$(whoami) \"{tool_dir}\"\n",
    "        else:\n",
    "            print(f\"✅ {name} directory already exists: {tool_dir}\")\n",
    "            # Optional: Add update logic here (e.g., git pull)\n",
    "\n",
    "        # Build if executable doesn't exist or isn't executable\n",
    "        if tool_dir.is_dir():\n",
    "            if not executable.exists() or not os.access(executable, os.X_OK):\n",
    "                print(f\"🛠️ Building {name} in {tool_dir}...\")\n",
    "                current_cwd = Path.cwd() # Remember where we are before changing\n",
    "                try:\n",
    "                    os.chdir(tool_dir) # Go into the tool directory\n",
    "                    print(f\"Changed CWD to: {Path.cwd()}\")\n",
    "                    # Execute the build command using bash -c\n",
    "                    build_script = f\"\"\"\n",
    "                    set -e\n",
    "                    echo 'Running build command for {name}...'\n",
    "                    {build_cmd}\n",
    "                    echo 'Build command finished for {name}.'\n",
    "                    \"\"\"\n",
    "                    # Using subprocess might capture errors better, but !bash is simpler for now\n",
    "                    build_process_result = !bash -c '{build_script}'\n",
    "                    # print('\\n'.join(build_process_result)) # Optional: Show build output\n",
    "\n",
    "                    # Check again if executable exists after build\n",
    "                    if executable.exists() and os.access(executable, os.X_OK):\n",
    "                        print(f\"✅ {name} build successful.\")\n",
    "                    else:\n",
    "                        print(f\"❌ {name} build failed (executable {executable.name} not found or not executable after build attempt).\")\n",
    "                        # Print output if build failed\n",
    "                        print(\"Build Output/Error:\")\n",
    "                        print('\\n'.join(build_process_result))\n",
    "                        all_successful = False\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ An error occurred during {name} build: {e}\")\n",
    "                    all_successful = False\n",
    "                finally:\n",
    "                    os.chdir(current_cwd) # Go back to where we were before cd'ing into tool dir\n",
    "                    print(f\"Returned CWD to: {Path.cwd()}\")\n",
    "            else:\n",
    "                 print(f\"✅ {name} executable already exists and is executable: {executable}\")\n",
    "        else:\n",
    "             # This case should not be reached if clone check works\n",
    "             print(f\"❌ Cannot build {name}, directory does not exist: {tool_dir}\")\n",
    "             all_successful = False\n",
    "\n",
    "    if not all_successful:\n",
    "         print(\"\\n⚠️ One or more tools failed to build. Please review the logs above.\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot install source tools: Utils or Working directory path not set in environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install PLINK2 Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PLINK2 binary\n",
    "utils_dir = os.getenv('PROJECT_UTILS_DIR')\n",
    "\n",
    "if utils_dir:\n",
    "    print(\"--- Setting up PLINK2 ---\")\n",
    "    plink2_zip_url = \"https://s3.amazonaws.com/plink2-assets/alpha6/plink2_linux_x86_64_20241206.zip\"\n",
    "    plink2_zip_file = Path(utils_dir) / \"plink2_linux_x86_64_20241206.zip\"\n",
    "    plink2_binary = Path(utils_dir) / \"plink2\"\n",
    "\n",
    "    if not plink2_binary.exists():\n",
    "        print(f\"⬇️ Downloading PLINK2 zip from {plink2_zip_url}...\")\n",
    "        !wget --progress=dot:giga \"{plink2_zip_url}\" -O \"{plink2_zip_file}\"\n",
    "\n",
    "        if plink2_zip_file.exists():\n",
    "            print(\"📦 Unzipping PLINK2...\")\n",
    "            # Use -o to overwrite if necessary, ensure it extracts directly to utils_dir\n",
    "            !unzip -o \"{plink2_zip_file}\" plink2 -d \"{utils_dir}\"\n",
    "\n",
    "            # Check if unzip created the binary directly\n",
    "            if plink2_binary.exists():\n",
    "                 print(\"✅ PLINK2 unzipped.\")\n",
    "                 !chmod +x \"{plink2_binary}\"\n",
    "                 !rm \"{plink2_zip_file}\" # Clean up zip\n",
    "            else:\n",
    "                 print(f\"❌ Failed to find plink2 binary directly in {utils_dir} after unzipping.\")\n",
    "                 # Check common issue: zip might contain parent dir; plink2 binary usually top-level in zip\n",
    "                 # If unzip command above failed, this check won't help much. Check unzip output.\n",
    "                 print(\"Please check unzip output and manually place 'plink2' in the utils directory if needed.\")\n",
    "        else:\n",
    "            print(\"❌ PLINK2 zip download failed.\")\n",
    "    else:\n",
    "        print(f\"✅ PLINK2 binary already exists: {plink2_binary}\")\n",
    "\n",
    "    # Verify PLINK2\n",
    "    if plink2_binary.exists() and os.access(plink2_binary, os.X_OK):\n",
    "        print(\"\\n🔍 Verifying PLINK2 version:\")\n",
    "        !\"{plink2_binary}\" --version\n",
    "    else:\n",
    "        print(\"❌ PLINK2 installation verification failed.\")\n",
    "else:\n",
    "    print(\"❌ Cannot install PLINK2: Utils directory path not set in environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Initial Data\n",
    "\n",
    "The project includes some initial data (`class_data`). This step copies it from the repository's default location into the `data` directory specified in your `~/.env` file, if they are different and the source exists. This replicates logic from the `scripts_env/directory_setup.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import logging # Use logging already configured\n",
    "\n",
    "logging.info(\"--- Checking and copying initial data ---\")\n",
    "\n",
    "# Get paths from environment (loaded from ~/.env)\n",
    "working_dir = os.getenv('PROJECT_WORKING_DIR')\n",
    "user_data_dir = os.getenv('PROJECT_DATA_DIR')\n",
    "\n",
    "if not working_dir or not user_data_dir:\n",
    "    logging.error(\"PROJECT_WORKING_DIR or PROJECT_DATA_DIR not found in environment. Cannot copy data.\")\n",
    "else:\n",
    "    # Define the potential source location within the cloned repository\n",
    "    repo_data_source_dir = Path(working_dir) / \"data\" / \"class_data\"\n",
    "\n",
    "    # Define the target location within the user-configured data directory\n",
    "    target_data_dest_dir = Path(user_data_dir) / \"class_data\"\n",
    "\n",
    "    logging.info(f\"Source data location (repo): {repo_data_source_dir}\")\n",
    "    logging.info(f\"Target data location (user): {target_data_dest_dir}\")\n",
    "\n",
    "    # Check if source exists\n",
    "    if repo_data_source_dir.is_dir():\n",
    "        # Use resolved paths for comparison to handle symlinks etc.\n",
    "        if repo_data_source_dir.resolve() != target_data_dest_dir.resolve():\n",
    "            logging.info(f\"Source and target differ. Preparing to copy data...\")\n",
    "            try:\n",
    "                # Ensure parent of target exists\n",
    "                target_data_dest_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "                logging.info(f\"Copying tree from {repo_data_source_dir} to {target_data_dest_dir}\")\n",
    "                # Copy tree, allowing overwrite of existing target directory content\n",
    "                shutil.copytree(repo_data_source_dir, target_data_dest_dir, dirs_exist_ok=True)\n",
    "                logging.info(f\"✅ Data successfully copied.\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error copying data: {e}\")\n",
    "        else:\n",
    "            logging.info(\"Source and target data directories are the same. Skipping copy.\")\n",
    "    else:\n",
    "        logging.warning(f\"Source data directory {repo_data_source_dir} not found. Cannot copy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting a Jupyter Notebook to PDF with Poetry\n",
    "\n",
    "This guide explains how to **export a Jupyter Notebook (`.ipynb`) to a PDF** using Poetry’s virtual environment. This process requires a LaTeX installation (`texlive` packages were installed in the initial setup).\n",
    "\n",
    "## **Running the Conversion in the Terminal (Recommended)**\n",
    "Running the conversion from your Ubuntu terminal is the most reliable method.\n",
    "\n",
    "1.  **Navigate to your project's base directory:**\n",
    "    ```bash\n",
    "    # If you cloned to your home directory:\n",
    "    cd ~/computational_genetic_genealogy\n",
    "    # Or navigate to the correct PROJECT_BASE_DIR you used during setup\n",
    "    ```\n",
    "\n",
    "2.  **Run the conversion command:**\n",
    "    Use `poetry run` to execute the `jupyter nbconvert` command within the project's Python environment.\n",
    "\n",
    "    *   **Example (Save PDF in the same directory as the notebook):**\n",
    "        To convert this notebook (`Lab0_Code_Environment.ipynb`), which is located in the `instructions/` subdirectory:\n",
    "        ```bash\n",
    "        poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb\n",
    "        ```\n",
    "        *(The PDF will appear inside the `instructions/` folder.)*\n",
    "\n",
    "    *   **Example (Save PDF to a specific directory, e.g., `results`):**\n",
    "        Use the `--output-dir` option. You need to provide the *actual path* to your results directory.\n",
    "        ```bash\n",
    "        # Replace '/path/to/your/computational_genetic_genealogy/results' with the real path\n",
    "        # This path should match the PROJECT_RESULTS_DIR value in your ~/.env file\n",
    "        poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb --output-dir='/path/to/your/computational_genetic_genealogy/results'\n",
    "\n",
    "        # Example if your project is in the home directory:\n",
    "        # poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb --output-dir=\"$HOME/computational_genetic_genealogy/results\"\n",
    "        ```\n",
    "\n",
    "---\n",
    "\n",
    "## **Running Conversion Inside This Jupyter Notebook (Alternative)**\n",
    "You can *attempt* to run the conversion from a code cell below, but be aware of potential issues:\n",
    "*   **Rendering:** Complex outputs or interactive elements might not render correctly in the PDF.\n",
    "*   **Environment:** Accessing the correct paths (like the results directory) requires using Python variables (e.g., `os.getenv`).\n",
    "\n",
    "The terminal method is generally preferred for stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert this Notebook to PDF (Optional)\n",
    "\n",
    "Run the following cell here in Jupyter Notebook to attempt the conversion. The PDF will be saved in the same directory as this notebook (`instructions/`). To access it from outside WSL (e.g., Windows File Explorer), navigate to `\\\\\\\\wsl$\\\\Ubuntu-24.04` (or your WSL distribution name) and then browse to the full path of the `instructions` directory within your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to convert this notebook to PDF using the Poetry environment\n",
    "# Note: The notebook's CWD should be the project's base directory now.\n",
    "print(f\"Current directory for conversion: {os.getcwd()}\")\n",
    "notebook_path = \"instructions/Lab0_Code_Environment.ipynb\"\n",
    "\n",
    "if Path(notebook_path).exists():\n",
    "    print(f\"Converting {notebook_path} to PDF...\")\n",
    "    !poetry run jupyter nbconvert --to pdf \"{notebook_path}\"\n",
    "else:\n",
    "    print(f\"Error: Notebook not found at relative path {notebook_path} from CWD {os.getcwd()}\")\n",
    "\n",
    "# Example: Convert and save to results directory using Python variable\n",
    "# results_dir = os.getenv('PROJECT_RESULTS_DIR')\n",
    "# if results_dir and Path(notebook_path).exists():\n",
    "#    print(f\"\\nConverting {notebook_path} and saving PDF to {results_dir}...\")\n",
    "#    !poetry run jupyter nbconvert --to pdf \"{notebook_path}\" --output-dir=\"{results_dir}\"\n",
    "# else:\n",
    "#    print(\"Could not save to results directory (path not set or notebook not found).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🚀 Start Your Labs in the Fully Configured Environment!**\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Setup Completed! Your Environment is Ready.**\n",
    "Your system has been successfully configured based on the project's Docker environment specification:\n",
    "\n",
    "- 🖥️ **OS:** Ubuntu 24.04\n",
    "- 🐍 **Python:** 3.12 managed by Poetry (`~/.local/bin/poetry`) in `./.venv`\n",
    "- ☕ **Java:** OpenJDK 21 (`$JAVA_HOME` configured)\n",
    "- 🧬 **Genomics Tools:**\n",
    "  - Samtools/BCFtools/Tabix v1.18 (Built from source)\n",
    "  - Beagle, HapIBD, RefinedIBD (JARs in `utils`)\n",
    "  - BonsaiTree (Installed via pip in Poetry env, source in `utils`)\n",
    "  - LiftOver (Binary in `utils`, Chain file in `references`)\n",
    "  - IBIS, Ped-Sim, RFMix2 (Built from source in `utils`)\n",
    "  - PLINK2 (Binary in `utils`)\n",
    "- 📁 **Directories:** Project structure created (`data`, `results`, `references`, `utils` within `PROJECT_BASE_DIR`).\n",
    "- ⚙️ **Configuration:** Environment variables loaded from `~/.env`.\n",
    "- ➕ **PATH:** Includes `~/.local/bin` and `${PROJECT_BASE_DIR}/utils`.\n",
    "- 🚀 **Notebook:** Ready to run analyses with the correct interpreter selected.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Your local Ubuntu environment is fully set up. Get started on your next lab now!** 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0: Code Environment\n",
    "\n",
    "## Introduction to Code Environments\n",
    "\n",
    "### What is a Code Environment?\n",
    "\n",
    "A **code environment** is the structured setup in which software applications run, including dependencies, libraries, and configurations necessary for execution. Code environments ensure that software behaves consistently across different machines and operating systems, preventing issues related to dependency conflicts and system inconsistencies.\n",
    "\n",
    "### Why Do Code Environments Matter?\n",
    "\n",
    "- **Reproducibility** – Ensures that code runs the same way across different systems, facilitating collaboration and research reproducibility.\n",
    "- **Dependency Management** – Prevents conflicts between different software packages by isolating dependencies.\n",
    "- **System Stability** – Protects the main operating system from unnecessary installations and modifications.\n",
    "- **Scalability** – Makes it easier to scale applications across multiple machines, cloud environments, or containerized deployments.\n",
    "\n",
    "## Virtual Environments with Poetry\n",
    "\n",
    "Our class is using **Poetry**, a modern dependency management tool for Python that simplifies package installation, versioning, and virtual environment creation. Poetry offers an elegant solution by combining dependency management and virtual environment creation into a single workflow.\n",
    "\n",
    "### Why Use Poetry?\n",
    "\n",
    "- **Automated Virtual Environments** – Poetry automatically creates and manages virtual environments for projects.\n",
    "- **Simplified Dependency Management** – Uses a `pyproject.toml` file instead of a `requirements.txt`, making package tracking more structured.\n",
    "- **Reproducibility** – The `poetry.lock` file ensures that everyone working on the project installs the exact same package versions.\n",
    "- **Seamless Package Publishing** – Poetry simplifies the process of building and publishing Python packages.\n",
    "\n",
    "### Key Poetry Commands\n",
    "\n",
    "| Command | Description |\n",
    "|---------|-------------|\n",
    "| `poetry new my_project` | Creates a new Poetry project with a `pyproject.toml` file |\n",
    "| `poetry install` | Installs dependencies and sets up the virtual environment |\n",
    "| `poetry add <package>` | Adds a new package to the project |\n",
    "| `poetry remove <package>` | Removes a package from the project |\n",
    "| `poetry shell` | Activates the project's virtual environment |\n",
    "| `poetry run <command>` | Runs a command inside the virtual environment |\n",
    "| `poetry lock` | Locks the dependencies to exact versions for consistency |\n",
    "\n",
    "## Docker: Containerized Code Environments\n",
    "\n",
    "While Poetry helps manage dependencies within Python projects, **Docker** provides an alternative approach by encapsulating an entire system environment, including the OS, into a container. Unlike virtual environments, which only manage dependencies at the application level, Docker offers a complete solution for deploying applications across different systems.\n",
    "\n",
    "### Key Features of Docker:\n",
    "- **Portability** – Containers run identically on any system with Docker installed.\n",
    "- **Isolation** – Each container runs independently, preventing dependency conflicts.\n",
    "- **Scalability** – Facilitates cloud-based and microservices architectures.\n",
    "\n",
    "### When to Use Poetry vs. Docker:\n",
    "\n",
    "| Feature            | Poetry (Virtual Environment) | Docker (Containerization) |\n",
    "|--------------------|---------------------------|--------------------------| \n",
    "| **Scope**         | Manages Python dependencies within a project | Encapsulates the entire OS and software stack |\n",
    "| **Reproducibility** | Ensures consistent package versions | Provides full OS-level consistency |\n",
    "| **Portability**   | Works across Python projects on the same system | Runs across different machines and cloud platforms |\n",
    "| **Resource Usage** | Lightweight | Slightly heavier due to system overhead |\n",
    "| **Best Use Case** | Managing dependencies for Python projects | Deploying applications in diverse environments |\n",
    "\n",
    "## Upgrading WSL2 Ubuntu to 24.04\n",
    "\n",
    "If you are using WSL2 with an older version of Ubuntu, you should upgrade to Ubuntu 24.04 for compatibility with this course environment.\n",
    "\n",
    "### Check Your Current Ubuntu Version\n",
    "\n",
    "First, check your current Ubuntu version:\n",
    "\n",
    "```bash\n",
    "lsb_release -a\n",
    "```\n",
    "\n",
    "If you're not running Ubuntu 24.04, follow these steps to upgrade:\n",
    "\n",
    "### Upgrading from Ubuntu 22.04 to 24.04\n",
    "\n",
    "1. **Update your package lists and upgrade installed packages**:\n",
    "   ```bash\n",
    "   sudo apt update && sudo apt upgrade -y\n",
    "   ```\n",
    "\n",
    "2. **Install the update-manager-core package**:\n",
    "   ```bash\n",
    "   sudo apt install update-manager-core -y\n",
    "   ```\n",
    "\n",
    "3. **Run the release upgrade**:\n",
    "   ```bash\n",
    "   sudo do-release-upgrade -d\n",
    "   ```\n",
    "\n",
    "4. **Follow the prompts** during the upgrade process. The upgrade may take some time and will ask you questions along the way.\n",
    "\n",
    "5. **Restart your WSL instance** after the upgrade completes:\n",
    "   ```bash\n",
    "   exec sudo /sbin/reboot\n",
    "   ```\n",
    "   Or from Windows PowerShell:\n",
    "   ```powershell\n",
    "   wsl --shutdown\n",
    "   ```\n",
    "   Then restart Ubuntu from your Start menu.\n",
    "\n",
    "6. **Verify your new Ubuntu version**:\n",
    "   ```bash\n",
    "   lsb_release -a\n",
    "   ```\n",
    "\n",
    "### Alternative: Install Fresh Ubuntu 24.04 in WSL\n",
    "\n",
    "If upgrading causes issues, you can install a fresh copy of Ubuntu 24.04:\n",
    "\n",
    "1. **From Windows PowerShell (as administrator)**:\n",
    "   ```powershell\n",
    "   # List your WSL distributions\n",
    "   wsl --list\n",
    "   \n",
    "   # Optionally backup your data first\n",
    "   # Copy your important files to Windows\n",
    "   \n",
    "   # Unregister your current Ubuntu (this will remove it)\n",
    "   wsl --unregister Ubuntu\n",
    "   \n",
    "   # Install Ubuntu 24.04\n",
    "   wsl --install -d Ubuntu-24.04\n",
    "   ```\n",
    "\n",
    "2. **Set up the new Ubuntu** by following the prompts to create a username and password.\n",
    "\n",
    "After upgrading or installing Ubuntu 24.04, continue with the setup instructions below.\n",
    "\n",
    "## Docker Environment: Ubuntu 24.04\n",
    "\n",
    "In our Docker setup, we are using **Ubuntu 24.04 (Noble Numbat)** as the base environment. This ensures consistency across different systems and provides a stable, long-term support (LTS) release with security updates and package support until **April 2029**. \n",
    "\n",
    "### Why Use Ubuntu 24.04?\n",
    "\n",
    "- **Long-Term Support (LTS)** – Ubuntu 24.04 is an LTS release, ensuring reliability and security updates for an extended period.\n",
    "- **Stability and Compatibility** – It is widely used in cloud computing, machine learning, and development environments, making it an ideal choice for reproducible research and software deployment.\n",
    "- **Lightweight and Efficient** – The minimal Ubuntu image is optimized for running applications in containers without unnecessary overhead.\n",
    "- **Extensive Package Support** – Ubuntu provides access to a vast software ecosystem, ensuring compatibility with necessary tools and dependencies.\n",
    "\n",
    "By using **Ubuntu 24.04** within Docker, we establish a controlled environment that minimizes discrepancies between development, testing, and production systems, ensuring consistency and reproducibility in our work.\n",
    "\n",
    "## Ensuring You Are Using the Latest Docker Image\n",
    "\n",
    "To maintain consistency and take advantage of the most up-to-date dependencies and security patches, it is important to ensure you are running the latest version of the **Ubuntu 24.04**-based Docker image. This prevents issues caused by outdated packages and ensures alignment with the current development environment.\n",
    "\n",
    "### Pulling the Latest Image\n",
    "\n",
    "Before running a container, always pull the latest version of the image by executing:\n",
    "\n",
    "```\n",
    "docker pull lakishadavid/cgg_image:latest\n",
    "```\n",
    "\n",
    "This command fetches the most recent version of the **cgg_image**, ensuring you are using the most up-to-date environment.\n",
    "\n",
    "### Running the Docker Container\n",
    "\n",
    "Once you have pulled the latest image, start a container interactively with:\n",
    "\n",
    "```\n",
    "docker run -it lakishadavid/cgg_image:latest bash\n",
    "```\n",
    "\n",
    "This command:\n",
    "- **Runs** a new container from the latest image.\n",
    "- **Opens an interactive terminal (`-it`)** to allow direct interaction with the container.\n",
    "- **Launches a Bash shell** so you can execute commands within the container.\n",
    "\n",
    "By following these steps, you ensure that your development environment is always using the most recent and properly configured version of the image.\n",
    "\n",
    "## Exiting the Docker Container\n",
    "\n",
    "Once you have finished working inside the Docker container, you will need to exit properly. There are multiple ways to leave the container depending on whether you want to stop it entirely or keep it running in the background.\n",
    "\n",
    "### Exit and Stop the Container\n",
    "\n",
    "The most common way to exit a Docker container is by using the `exit` command:\n",
    "\n",
    "```\n",
    "exit\n",
    "```\n",
    "\n",
    "This will terminate the container and return you to your local terminal.\n",
    "\n",
    "### When Should You Stop a Container?\n",
    "\n",
    "Stopping a container is necessary when:\n",
    "- You **no longer need** the application or environment running.\n",
    "- You want to **free up system resources** being used by the container.\n",
    "- You need to **apply updates** or modifications before restarting the container.\n",
    "- You want to **preserve changes** made inside the container so they are available the next time you start it.\n",
    "\n",
    "If the container is still running in the background, you can stop it from your terminal using:\n",
    "\n",
    "```\n",
    "docker stop <container_id>\n",
    "```\n",
    "\n",
    "To ensure a clean development workflow, it is good practice to stop containers when they are no longer needed, rather than letting them consume system resources indefinitely.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "A well-structured code environment is essential for ensuring software **stability**, **reproducibility**, and **efficiency**. In our setup:\n",
    "- **Poetry** simplifies dependency and virtual environment management, ensuring consistency across Python projects.\n",
    "- **Docker** provides an isolated, reproducible system environment, making it ideal for deploying applications across different machines.\n",
    "\n",
    "Understanding when to use each tool helps streamline development workflows. **Poetry** is best suited for managing dependencies within a Python project, while **Docker** ensures complete system encapsulation for broader deployment and portability needs. By combining both tools effectively, we create an environment that supports seamless collaboration, minimal dependency conflicts, and efficient software deployment.\n",
    "\n",
    "## Responsibility for the Code Environment\n",
    "\n",
    "While I will maintain the **Docker environment**, the focus of this class is on **running and understanding the genomic analysis code itself**. The Docker image provides a controlled and reproducible environment, ensuring that all necessary dependencies are pre-installed and configured correctly. By using Docker, you eliminate potential compatibility issues and can focus on the **analysis and interpretation of genomic data**.\n",
    "\n",
    "### Choosing How to Maintain Your Code Environment\n",
    "\n",
    "Students have two options for managing their code environment:\n",
    "\n",
    "1. **Use the Provided Docker Image**  \n",
    "   - I will maintain and update the Docker image to ensure compatibility and reproducibility.\n",
    "   - If you encounter any issues while using Docker, I will troubleshoot and resolve the problem.\n",
    "   - Using the Docker environment ensures that you are working in the exact same setup as me and others using the image.\n",
    "\n",
    "2. **Maintain Your Own Code Environment**  \n",
    "   - If you choose **not to use Docker**, you are responsible for setting up and maintaining your own code environment.\n",
    "   - You must ensure that all dependencies are correctly installed and compatible with the provided code.\n",
    "   - If issues arise due to your custom environment, I will offer support, but it is ultimately your responsibility to resolve them.\n",
    "\n",
    "### Required Setup for Non-Docker Users\n",
    "\n",
    "If you choose to work **outside of Docker**, you must manually install the required dependencies. The following code blocks have already been completed **within the Docker image**, meaning Docker users **do not need to run them**. However, **non-Docker users must run the following setup commands themselves** to ensure their environment is configured correctly.\n",
    "\n",
    "#### Important Notes:\n",
    "- The provided code blocks assume you are running **Ubuntu 24.04**.\n",
    "- If you are using a different system, you must adapt the installation steps accordingly.\n",
    "- While I can answer general questions about dependencies, my responsibility is to **maintain the code base within the Docker image**. Your responsibility is to effectively use that image—**either by running it directly or by correctly configuring your own system.**\n",
    "\n",
    "Below are the commands that **non-Docker Ubuntu users must run** to set up their environment properly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Begin**\n",
    "\n",
    "At this point, it is assumed that you have cloned the repository into your local Ubuntu envrionment, navigated to the course directory, opened VS Code, and opened Lab0_Code_Envronment on your local machine (e.g., your computer). If you haven't make sure to do that first. Then continue here with setting up your code environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python packages and system dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the next set of commands in your Ubuntu terminal window. Update where your system looks for system packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# DO NOT RUN IN JUPYTER NOTEBOOK. COPY AND PASTE TO TERMINAL WINDOW.\n",
    "\n",
    "sudo apt update -y && sudo apt upgrade -y\n",
    "sudo apt-add-repository -y universe && sudo apt-add-repository -y multiverse && sudo apt-add-repository -y ppa:deadsnakes/ppa && sudo apt update -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the next set of commands in your Ubuntu terminal window. This will install `pipx`. Your output should be something like `1.4.3`, indicating the `pipx` version number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# DO NOT RUN IN JUPYTER NOTEBOOK. COPY AND PASTE TO TERMINAL WINDOW.\n",
    "\n",
    "sudo apt update -y && sudo apt install pipx -y && pipx ensurepath && exec \"$SHELL\" && pipx --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the next set of commands in your Ubuntu terminal window. Use `pipx` to install `poetry`. The output should let you know what `poetry` version was installed, but you can check by running `poetry --version`. Then configure `poetry`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# DO NOT RUN IN JUPYTER NOTEBOOK. COPY AND PASTE TO TERMINAL WINDOW.\n",
    "\n",
    "sudo apt install -y python3.12 && pipx install poetry && poetry config virtualenvs.in-project true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the next set of commands in your Ubuntu terminal window. Install Python 3.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# DO NOT RUN IN JUPYTER NOTEBOOK. COPY AND PASTE TO TERMINAL WINDOW.\n",
    "\n",
    "sudo apt install -y python3.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the next set of commands in your Ubuntu terminal window. Navigate to project directory `computational_genetic_genealogy` and install Python dependencies. If you used the `git clone` command in your `HOME` directory, then the navigtion command is `cd ~/computational_genetic_genealogy`. Once you're in the project directory, run the `poetry install --no-root` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# DO NOT RUN IN JUPYTER NOTEBOOK. COPY AND PASTE TO TERMINAL WINDOW.\n",
    "\n",
    "cd ~/computational_genetic_genealogy\n",
    "poetry install --no-root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may get a notice indicating that VS Code noticed a new virtual environment. You can cancel (or select `yes`). We will handle virtual envrionments a little later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure sudo for Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the next set of commands in your Ubuntu terminal window. The next set of commands enables you to run certain commands without needing to enter your password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# DO NOT RUN IN JUPYTER NOTEBOOK. COPY AND PASTE TO TERMINAL WINDOW.\n",
    "\n",
    "# Add rule for passwordless sudo\n",
    "echo \"$(whoami) ALL=(ALL) NOPASSWD: /usr/bin/apt-add-repository, /usr/bin/apt, /usr/bin/apt-get, /usr/bin/dpkg, /usr/bin/apt, /bin/rm\" | sudo tee -a /etc/sudoers.d/$(whoami)\n",
    "\n",
    "# Verify and set permissions\n",
    "sudo cat /etc/sudoers.d/$(whoami) && sudo chmod 0440 /etc/sudoers.d/$(whoami)\n",
    "\n",
    "# Apply changes\n",
    "exec sudo su - $USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **You can now run system updates in Jupyter Notebook without entering a password!** 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Project Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the next set of commands in your Ubuntu terminal window. Run the directory setup script to create necessary project folders: Navigate to project directory `computational_genetic_genealogy` and install Python dependencies. If you used the `git clone` command in your `HOME` directory, then the navigtion command is `cd ~/computational_genetic_genealogy`. Once you're in the project directory, run the `poetry...` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# DO NOT RUN IN JUPYTER NOTEBOOK. COPY AND PASTE TO TERMINAL WINDOW.\n",
    "\n",
    "cd ~/computational_genetic_genealogy\n",
    "poetry run python scripts_env/directory_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Python Interpreter in VS Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Jupyter Notebook needs to know not only which Python to use, but what set of Python packages to use. Selecting the one described below does that by selecting the Python within the virtual envrionment you created with the `poetry install --no-root` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This first time, go to the VS Code menu and select `View` > `Command Palette` > `Python: Select Interpreter`.\n",
    "2. Select `Enter interpreter path...`\n",
    "3. Select `Find...`\n",
    "4. Note it suggests the `computational_genetic_genealogy/instructions/` directory. Select the `..` at the top of the list to go up one level\n",
    "5. Select `.venv`, `bin`, and `python`. NOTE: Select plain `python`, not one of the versions.\n",
    "6. Select the button `Select Interpreter`.\n",
    "\n",
    "After this, each time you open this Jupyter Notebook, VS Codes remembers which virtual environment to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ You can now run cells within the Jupyter Notebook. 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required System Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update system packages\n",
    "!sudo apt update -y\n",
    "!sudo apt upgrade -y\n",
    "\n",
    "# Install system\n",
    "!sudo apt install -y --no-install-recommends \\\n",
    "    build-essential \\\n",
    "    g++ \\\n",
    "    gcc \\\n",
    "    make \\\n",
    "    python3.12 \\\n",
    "    python3.12-dev \\\n",
    "    python3.12-venv \\\n",
    "    python3-pip \\\n",
    "    graphviz \\\n",
    "    libfreetype-dev \\\n",
    "    pkg-config \\\n",
    "    libpng-dev \\\n",
    "    zlib1g-dev \\\n",
    "    libbz2-dev \\\n",
    "    libharfbuzz-dev \\\n",
    "    libcurl4-openssl-dev \\\n",
    "    libssl-dev \\\n",
    "    libxml2-dev \\\n",
    "    wget \\\n",
    "    curl \\\n",
    "    git \\\n",
    "    unzip \\\n",
    "    default-jre \\\n",
    "    gawk \\\n",
    "    libboost-all-dev \\\n",
    "    texlive-xetex \\\n",
    "    texlive-fonts-recommended \\\n",
    "    texlive-plain-generic \\\n",
    "    pandoc\n",
    "\n",
    "!sudo apt-get clean\n",
    "!sudo rm -rf /var/lib/apt/lists/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get directory variables\n",
    "\n",
    "Now that you ran `directory_setup.py`, you should see your .env file in your file explorer. Let's make sure the notebook can see the file. Run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_comp_gen_dir():\n",
    "    \"\"\"Find the computational_genetic_genealogy directory by searching up from current directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Search up through parent directories\n",
    "    while current != current.parent:\n",
    "        # Check if target directory exists in current path\n",
    "        target = current / 'computational_genetic_genealogy'\n",
    "        if target.is_dir():\n",
    "            return target\n",
    "        # Move up one directory\n",
    "        current = current.parent\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find computational_genetic_genealogy directory\")\n",
    "\n",
    "def load_env_file():\n",
    "    \"\"\"Find and load the .env file from the computational_genetic_genealogy directory.\"\"\"\n",
    "    try:\n",
    "        # Find the computational_genetic_genealogy directory\n",
    "        comp_gen_dir = find_comp_gen_dir()\n",
    "        \n",
    "        # Look for .env file\n",
    "        env_path = comp_gen_dir / '.env'\n",
    "        if not env_path.exists():\n",
    "            print(f\"Warning: No .env file found in {comp_gen_dir}\")\n",
    "            return None\n",
    "        \n",
    "        # Load the .env file\n",
    "        load_dotenv(env_path, override=True)\n",
    "        print(f\"Loaded environment variables from: {env_path}\")\n",
    "        return env_path\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use the function\n",
    "env_path = load_env_file()\n",
    "\n",
    "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
    "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
    "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
    "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
    "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
    "\n",
    "os.environ[\"WORKING_DIRECTORY\"] = working_directory\n",
    "os.environ[\"DATA_DIRECTORY\"] = data_directory\n",
    "os.environ[\"REFERENCES_DIRECTORY\"] = references_directory\n",
    "os.environ[\"RESULTS_DIRECTORY\"] = results_directory\n",
    "os.environ[\"UTILS_DIRECTORY\"] = utils_directory\n",
    "\n",
    "print(f\"Working Directory: {working_directory}\")\n",
    "print(f\"Data Directory: {data_directory}\")\n",
    "print(f\"References Directory: {references_directory}\")\n",
    "print(f\"Results Directory: {results_directory}\")\n",
    "print(f\"Utils Directory: {utils_directory}\")\n",
    "\n",
    "os.chdir(working_directory)\n",
    "print(f\"The current directory is {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path above should point to your `.env` file in your `compuational_genetic_genealogy directory`. Please notify the instructor by email with a PDF of the Jupyter Notebook (with output) if this is not the case. The next cell should read the values of your .env for use in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update -y\n",
    "!sudo apt install -y r-base libtirpc-dev libcurl4-openssl-dev libxml2-dev libssl-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!R --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ~/R/library/\n",
    "grep -qxF '.libPaths(c(\"~/R/library/\", .libPaths()))' ~/.Rprofile || echo '.libPaths(c(\"~/R/library/\", .libPaths()))' >> ~/.Rprofile\n",
    "cat ~/.Rprofile\n",
    "# You should see: .libPaths(c(\"~/R/library/\", .libPaths()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install liftover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download the liftOver binary for Linux x86_64 and save it in utils_directory\n",
    "wget http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/liftOver -O \"${UTILS_DIRECTORY}/liftOver\"\n",
    "\n",
    "# Make the binary executable\n",
    "chmod +x \"${UTILS_DIRECTORY}/liftOver\"\n",
    "\n",
    "# Download the hg19ToHg38 chain file into the references directory\n",
    "wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz -P \"${REFERENCES_DIRECTORY}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install bcftools, samtools, and tabix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update -y\n",
    "!sudo apt-get install -y --no-install-recommends \\\n",
    "    libbz2-dev \\\n",
    "    liblzma-dev \\\n",
    "    zlib1g-dev \\\n",
    "    libgsl-dev \\\n",
    "    libcurl4-openssl-dev\n",
    "\n",
    "!sudo apt-get install -y bcftools samtools tabix\n",
    "!echo 'export BCFTOOLS_PLUGINS=/usr/lib/x86_64-linux-gnu/bcftools' >> ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bcftools --version\n",
    "!samtools --version\n",
    "!tabix --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if command -v java &> /dev/null; then\n",
    "    echo \"Java is already installed. Version: $(java -version 2>&1 | head -n 1)\"\n",
    "    exit 0\n",
    "fi\n",
    "\n",
    "sudo apt-get install -y default-jdk\n",
    "\n",
    "# Verify installation\n",
    "if command -v java &> /dev/null; then\n",
    "    echo \"Java installation successful. Version: $(java -version 2>&1 | head -n 1)\"\n",
    "else\n",
    "    echo \"Java installation failed. Please check the log at $LOGFILE for details.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Verify Java Home\n",
    "JAVA_HOME=$(readlink -f /usr/bin/java | sed \"s:/bin/java::\")\n",
    "if [ -n \"$JAVA_HOME\" ]; then\n",
    "    echo \"JAVA_HOME detected: $JAVA_HOME\"\n",
    "    if ! grep -q \"export JAVA_HOME=$JAVA_HOME\" \"$HOME/.bashrc\"; then\n",
    "        echo \"Adding JAVA_HOME to .bashrc...\"\n",
    "        echo \"export JAVA_HOME=$JAVA_HOME\" >> \"$HOME/.bashrc\"\n",
    "        echo \"export PATH=\\$JAVA_HOME/bin:\\$PATH\" >> \"$HOME/.bashrc\"\n",
    "        source \"$HOME/.bashrc\"\n",
    "    else\n",
    "        echo \"JAVA_HOME already set in .bashrc.\"\n",
    "    fi\n",
    "else\n",
    "    echo \"Failed to detect JAVA_HOME. Please set it manually if required.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install beagle, bref, and unbref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "BEAGLE_VERSION=\"17Dec24.224\"\n",
    "BEAGLE_JAR=\"beagle.${BEAGLE_VERSION}.jar\"\n",
    "BREF3_JAR=\"bref3.${BEAGLE_VERSION}.jar\"\n",
    "UNBREF3_JAR=\"unbref3.${BEAGLE_VERSION}.jar\"\n",
    "BEAGLE_URL=\"https://faculty.washington.edu/browning/beagle/${BEAGLE_JAR}\"\n",
    "BREF3_URL=\"https://faculty.washington.edu/browning/beagle/${BREF3_JAR}\"\n",
    "UNBREF3_URL=\"https://faculty.washington.edu/browning/beagle/${UNBREF3_JAR}\"\n",
    "\n",
    "# Function to download a file only if it does not exist\n",
    "download_if_missing() {\n",
    "    local file_path=\"${UTILS_DIRECTORY}/$1\"\n",
    "    local file_url=\"$2\"\n",
    "\n",
    "    if [ -f \"${file_path}\" ]; then\n",
    "        echo \"✅ File already exists: ${file_path}. Skipping download.\"\n",
    "    else\n",
    "        echo \"⬇️ Downloading $file_url...\"\n",
    "        wget -P \"${UTILS_DIRECTORY}\" \"${file_url}\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Check and download each required file\n",
    "download_if_missing \"$UNBREF3_JAR\" \"$UNBREF3_URL\"\n",
    "download_if_missing \"$BREF3_JAR\" \"$BREF3_URL\"\n",
    "download_if_missing \"$BEAGLE_JAR\" \"$BEAGLE_URL\"\n",
    "\n",
    "# Test Beagle installation\n",
    "echo \"🔍 Testing Beagle installation...\"\n",
    "java -jar \"${UTILS_DIRECTORY}/$BEAGLE_JAR\" 2>&1\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"❌ Beagle test run failed.\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"✅ Beagle installed successfully.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install bonsaitree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install BonsaiTree\n",
    "utils_dir = os.getenv('PROJECT_UTILS_DIR')\n",
    "project_dir = os.getenv('PROJECT_WORKING_DIR')\n",
    "\n",
    "if utils_dir and project_dir:\n",
    "    bonsai_dir = Path(utils_dir) / \"bonsaitree\"\n",
    "    bonsai_repo = \"https://github.com/23andMe/bonsaitree.git\"\n",
    "    original_dir = Path.cwd()\n",
    "\n",
    "    print(\"--- Setting up BonsaiTree ---\")\n",
    "    if not bonsai_dir.is_dir():\n",
    "        print(f\"⬇️ Cloning BonsaiTree into {bonsai_dir}...\")\n",
    "        !git clone \"{bonsai_repo}\" \"{bonsai_dir}\"\n",
    "    else:\n",
    "        print(f\"✅ BonsaiTree directory already exists: {bonsai_dir}\")\n",
    "\n",
    "    if bonsai_dir.is_dir():\n",
    "        print(f\"🛠️ Installing BonsaiTree package in {bonsai_dir}...\")\n",
    "        try:\n",
    "            os.chdir(bonsai_dir)\n",
    "            print(f\"Changed CWD to: {Path.cwd()}\")\n",
    "\n",
    "            # Ensure poetry is aware of the correct python interpreter\n",
    "            main_venv_path = Path(project_dir) / \".venv\" / \"bin\" / \"python\"\n",
    "            if main_venv_path.exists():\n",
    "                 print(f\"Using Python interpreter: {main_venv_path}\")\n",
    "                 !poetry env use \"{main_venv_path}\"\n",
    "            else:\n",
    "                 print(\"Main project venv python not found, falling back to python3.12\")\n",
    "                 !poetry env use python3.12\n",
    "\n",
    "            # Install the package using pip install . within the poetry env\n",
    "            # This handles setup/build/install dependencies from setup.py\n",
    "            print(\"Running 'poetry run pip install .'...\")\n",
    "            !poetry run pip install .\n",
    "\n",
    "            # Verify installation\n",
    "            print(\"Verifying BonsaiTree import...\")\n",
    "            verify_code = \"import sys; sys.path.append('.'); \" # May not be needed now it's installed\n",
    "            verify_code += \"from bonsaitree.v3.bonsai import build_pedigree; \"\n",
    "            verify_code += \"print('✅ BonsaiTree module imported successfully.')\"\n",
    "            !poetry run python -c \"{verify_code}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ An error occurred during BonsaiTree setup: {e}\")\n",
    "        finally:\n",
    "            os.chdir(original_dir)\n",
    "            print(f\"Returned CWD to: {Path.cwd()}\")\n",
    "    else:\n",
    "        print(f\"❌ BonsaiTree directory cloning appears to have failed: {bonsai_dir}\")\n",
    "else:\n",
    "    print(\"❌ Cannot install BonsaiTree: Utils or Working directory path not set in environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Hap-IBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Define variables\n",
    "HAP_IBD_URL=\"https://faculty.washington.edu/browning/hap-ibd.jar\"\n",
    "HAP_IBD_JAR=\"hap-ibd.jar\"\n",
    "\n",
    "# Function to download a file only if it does not exist\n",
    "download_if_missing() {\n",
    "    local file_path=\"${UTILS_DIRECTORY}/$1\"\n",
    "    local file_url=\"$2\"\n",
    "\n",
    "    if [ -f \"$file_path\" ]; then\n",
    "        echo \"✅ File already exists: $file_path. Skipping download.\"\n",
    "    else\n",
    "        echo \"⬇️ Downloading $file_url...\"\n",
    "        wget -P \"${UTILS_DIRECTORY}\" \"$file_url\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Check and download each required file\n",
    "download_if_missing \"$HAP_IBD_JAR\" \"$HAP_IBD_URL\"\n",
    "\n",
    "# Test installation\n",
    "echo \"Testing installation...\"\n",
    "java -jar \"${UTILS_DIRECTORY}/$HAP_IBD_JAR\" 2>&1\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"Test run failed.\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"Installed successfully.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Refined IBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Define variables\n",
    "Refined_IBD_URL=\"https://faculty.washington.edu/browning/refined-ibd/refined-ibd.17Jan20.102.jar\"\n",
    "Refined_IBD_JAR=\"refined-ibd.17Jan20.102.jar\"\n",
    "\n",
    "# Function to download a file only if it does not exist\n",
    "download_if_missing() {\n",
    "    local file_path=\"${UTILS_DIRECTORY}/$1\"\n",
    "    local file_url=\"$2\"\n",
    "\n",
    "    if [ -f \"$file_path\" ]; then\n",
    "        echo \"✅ File already exists: $file_path. Skipping download.\"\n",
    "    else\n",
    "        echo \"⬇️ Downloading $file_url...\"\n",
    "        wget -P \"${UTILS_DIRECTORY}\" \"$file_url\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Check and download each required file\n",
    "download_if_missing \"$Refined_IBD_JAR\" \"$Refined_IBD_URL\"\n",
    "\n",
    "# Test installation\n",
    "echo \"Testing installation...\"\n",
    "java -jar \"${UTILS_DIRECTORY}/$Refined_IBD_JAR\" 2>&1\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"Test run failed.\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"Installed successfully.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Merge IBD Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Define variables\n",
    "Refined_IBD_Merge_URL=\"https://faculty.washington.edu/browning/refined-ibd/merge-ibd-segments.17Jan20.102.jar\"\n",
    "Refined_IBD_Merge_JAR=\"merge-ibd-segments.17Jan20.102.jar\"\n",
    "\n",
    "# Function to download a file only if it does not exist\n",
    "download_if_missing() {\n",
    "    local file_path=\"${UTILS_DIRECTORY}/$1\"\n",
    "    local file_url=\"$2\"\n",
    "\n",
    "    if [ -f \"$file_path\" ]; then\n",
    "        echo \"✅ File already exists: $file_path. Skipping download.\"\n",
    "    else\n",
    "        echo \"⬇️ Downloading $file_url...\"\n",
    "        wget -P \"${UTILS_DIRECTORY}\" \"$file_url\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Check and download each required file\n",
    "download_if_missing \"$Refined_IBD_Merge_JAR\" \"$Refined_IBD_Merge_URL\"\n",
    "\n",
    "# Test installation\n",
    "echo \"Testing installation...\"\n",
    "java -jar \"${UTILS_DIRECTORY}/$Refined_IBD_Merge_JAR\" 2>&1\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"Test run failed.\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"Installed successfully.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install IBIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "IBIS_REPO=\"https://github.com/williamslab/ibis.git\"\n",
    "IBIS_DIR=\"${UTILS_DIRECTORY}/ibis\"\n",
    "\n",
    "# Handle existing IBIS directory\n",
    "if [ -d \"$IBIS_DIR\" ]; then\n",
    "    echo \"📂 IBIS directory already exists at $IBIS_DIR.\"\n",
    "    \n",
    "    # Check if it is a valid Git repo\n",
    "    if [ -d \"$IBIS_DIR/.git\" ]; then\n",
    "        echo \"🔄 Updating IBIS repository...\"\n",
    "        cd \"$IBIS_DIR\" || { echo \"❌ Failed to navigate to IBIS directory.\"; exit 1; }\n",
    "        git pull origin master\n",
    "    else\n",
    "        echo \"⚠️ Directory exists but is not a Git repository. Consider removing it manually.\"\n",
    "        exit 1  # Stop execution\n",
    "    fi\n",
    "else\n",
    "    # Clone IBIS repository\n",
    "    echo \"⬇️ Cloning IBIS repository...\"\n",
    "    git clone --recurse-submodules \"$IBIS_REPO\" \"$IBIS_DIR\" || { echo \"❌ Git clone failed.\"; exit 1; }\n",
    "    \n",
    "    # Navigate to IBIS directory and build\n",
    "    cd \"$IBIS_DIR\" || { echo \"❌ Failed to navigate to $IBIS_DIR.\"; exit 1; }\n",
    "    echo \"🔨 Building IBIS using make...\"\n",
    "    make || { echo \"❌ Build failed.\"; exit 1; }\n",
    "fi\n",
    "\n",
    "# Verify IBIS installation\n",
    "if [ -x \"./ibis\" ]; then\n",
    "    echo \"✅ IBIS installed successfully.\"\n",
    "else\n",
    "    echo \"❌ IBIS executable not found. Build might have failed.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sudo apt-get install -y libboost-all-dev make\n",
    "\n",
    "PED_SIM_REPO=\"https://github.com/williamslab/ped-sim.git\"\n",
    "PED_SIM_DIR=\"${UTILS_DIRECTORY}/ped-sim\"\n",
    "\n",
    "# Handle existing IBIS directory\n",
    "if [ -d \"$PED_SIM_DIR\" ]; then\n",
    "    echo \"📂 Ped-Sim directory already exists at $PED_SIM_DIR.\"\n",
    "    \n",
    "    # Check if it is a valid Git repo\n",
    "    if [ -d \"$PED_SIM_DIR/.git\" ]; then\n",
    "        echo \"🔄 Updating IBIS repository...\"\n",
    "        cd \"$PED_SIM_DIR\" || { echo \"❌ Failed to navigate to Ped-Sim directory.\"; exit 1; }\n",
    "        git pull origin master\n",
    "    else\n",
    "        echo \"⚠️ Directory exists but is not a Git repository. Consider removing it manually.\"\n",
    "        exit 1  # Stop execution\n",
    "    fi\n",
    "else\n",
    "    # Clone Ped-Sim repository\n",
    "    echo \"⬇️ Cloning Ped-Sim repository...\"\n",
    "    git clone --recurse-submodules \"$PED_SIM_REPO\" \"$PED_SIM_DIR\" || { echo \"❌ Git clone failed.\"; exit 1; }\n",
    "    \n",
    "    # Navigate to Ped-Sim directory and build\n",
    "    cd \"$PED_SIM_DIR\" || { echo \"❌ Failed to navigate to $PED_SIM_DIR.\"; exit 1; }\n",
    "    echo \"🔨 Building Ped-Sim using make...\"\n",
    "    make || { echo \"❌ Build failed.\"; exit 1; }\n",
    "fi\n",
    "\n",
    "chmod +x ./ped-sim\n",
    "\n",
    "# Verify Ped-Sim installation\n",
    "if [ -x \"./ped-sim\" ]; then\n",
    "    echo \"✅ Ped-Sim installed successfully.\"\n",
    "else\n",
    "    echo \"❌ Ped-Sim executable not found. Build might have failed.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Define PLINK2 download URL and file\n",
    "plink2_file_url=\"https://s3.amazonaws.com/plink2-assets/alpha6/plink2_linux_x86_64_20241206.zip\"\n",
    "plink2_zip_file=\"${UTILS_DIRECTORY}/plink2_linux_x86_64_20241206.zip\"\n",
    "plink2_binary=\"${UTILS_DIRECTORY}/plink2\"\n",
    "\n",
    "# Download and unzip PLINK2 if not already present\n",
    "if [ ! -f \"$plink2_binary\" ]; then\n",
    "    echo\n",
    "    echo \"Downloading PLINK2...\"\n",
    "    echo\n",
    "    wget --progress=bar:force:noscroll \"$plink2_file_url\" -P \"${UTILS_DIRECTORY}\"\n",
    "    \n",
    "    # Ensure the file is downloaded before unzipping\n",
    "    while [ ! -f \"$plink2_zip_file\" ]; do\n",
    "        sleep 1\n",
    "    done\n",
    "\n",
    "    echo\n",
    "    echo \"Unzipping PLINK2...\"\n",
    "    echo\n",
    "    unzip \"$plink2_zip_file\" -d \"${UTILS_DIRECTORY}\"\n",
    "\n",
    "    # Remove the zip file after extraction\n",
    "    rm \"$plink2_zip_file\"\n",
    "fi\n",
    "\n",
    "# Check if the PLINK2 binary was installed correctly\n",
    "if [ -f \"$plink2_binary\" ] && [ -x \"$plink2_binary\" ]; then\n",
    "    echo \"PLINK2 installed successfully.\"\n",
    "    \"$plink2_binary\" --version\n",
    "else\n",
    "    echo \"Error: PLINK2 installation failed. Binary not found or not executable.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Define RFMix2 installation directory\n",
    "rfmix2_dir=\"${UTILS_DIRECTORY}/rfmix2\"\n",
    "\n",
    "# Install required tools (if missing)\n",
    "for tool in autoconf make gcc; do\n",
    "    if ! command -v $tool &> /dev/null; then\n",
    "        echo \"$tool not found. Installing...\"\n",
    "        sudo apt-get install -y $tool || {\n",
    "            echo \"Failed to install $tool. Exiting.\"\n",
    "            exit 1\n",
    "        }\n",
    "    else\n",
    "        echo \"$tool is already installed.\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "# Clone RFMix2 repository\n",
    "rfmix_dir=\"${UTILS_DIRECTORY}/rfmix2\"\n",
    "if [ ! -d \"$rfmix_dir\" ]; then\n",
    "    echo \"Cloning RFMix2 repository...\"\n",
    "    git clone https://github.com/slowkoni/rfmix.git \"$rfmix_dir\" || {\n",
    "        echo \"Failed to clone RFMix2 repository. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # Navigate to RFMix2 directory\n",
    "    if [ -d \"$rfmix_dir\" ]; then\n",
    "        cd \"$rfmix_dir\" || { echo \"Failed to enter $rfmix_dir. Exiting.\"; exit 1; }\n",
    "    else\n",
    "        echo \"Error: RFMix2 directory not found. Exiting.\"\n",
    "        exit 1\n",
    "    fi\n",
    "\n",
    "    # Step-by-step generation of configuration files\n",
    "    echo \"Generating build files the long way...\"\n",
    "\n",
    "    # 1. Create aclocal.m4\n",
    "    echo \"Running aclocal...\"\n",
    "    aclocal || {\n",
    "        echo \"Error running aclocal. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 2. Create config.h.in\n",
    "    echo \"Running autoheader...\"\n",
    "    autoheader || {\n",
    "        echo \"Error running autoheader. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 3. Create configure script\n",
    "    echo \"Running autoconf...\"\n",
    "    autoconf || {\n",
    "        echo \"Error running autoconf. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 4. Create Makefile.in\n",
    "    echo \"Running automake with --add-missing...\"\n",
    "    automake --add-missing || {\n",
    "        echo \"Error running automake. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 5. Configure the build system\n",
    "    echo \"Running ./configure...\"\n",
    "    ./configure || {\n",
    "        echo \"Error running configure. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 6. Compile the program\n",
    "    echo \"Compiling RFMix2...\"\n",
    "    make || {\n",
    "        echo \"Error running make. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "    \n",
    "else\n",
    "    echo \"RFMix2 repository already exists at $rfmix_dir\"\n",
    "fi\n",
    "\n",
    "# Verify RFMix2 build\n",
    "if [ -f \"$rfmix_dir/rfmix\" ]; then\n",
    "    echo \"RFMix2 built successfully and is ready to use.\"\n",
    "else\n",
    "    echo \"Error: RFMix2 binary not found. Build failed.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting a Jupyter Notebook to PDF with Poetry\n",
    "\n",
    "This guide explains how to **export a Jupyter Notebook (`.ipynb`) to a PDF** using Poetry’s virtual environment.\n",
    "\n",
    "## **Running the Conversion in the Terminal**\n",
    "To convert a Jupyter Notebook to PDF, run the following command in the terminal:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf path/to/notebook.ipynb\n",
    "```\n",
    "\n",
    "### **Example:**\n",
    "If your notebook is named `Lab0_Code_Environment.ipynb` and is stored in the `instructions/` directory, run:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb\n",
    "```\n",
    "\n",
    "### **Saving the PDF to a Specific Path**\n",
    "By default, the PDF will be saved in the **same directory as the input notebook**. To save the output in a different location, use the `--output-dir` option:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf path/to/notebook.ipynb --output-dir=path/to/save/\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "To save the PDF in the `results/` directory:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb --output-dir=results/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **What Happens If We Run This Inside a Jupyter Notebook?**\n",
    "If you attempt to run `!poetry run jupyter nbconvert --to pdf ...` inside a Jupyter Notebook cell, you may encounter issues because **Notebook-specific variables (such as inline plots) might not be preserved.**\n",
    "\n",
    "### **Workaround**\n",
    "You can run the conversion within a Jupyter Notebook cell if you don't think that is an issue in the notebook you're using. The commnad to convert the notebook to PDF is (also in cell below)\n",
    "```\n",
    "!poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb\n",
    "```\n",
    "However, **it is recommended to run this in the terminal instead** for better stability.\n",
    "\n",
    "---\n",
    "By following these steps, you can successfully convert Jupyter Notebooks into PDFs while managing dependencies with Poetry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell here in Jupyter Notebook. To get the PDF, go outside of Ubuntu (e.g., Windows), open file explorer, enter `\\\\wsl$` in the navigation bar, select Ubuntu, then navigate to the file starting with `home` and `username`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🚀 Start Your Labs in the Fully Configured Environment!**\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Setup Completed! Your Environment is Ready.**\n",
    "Your system has been successfully configured with:\n",
    "\n",
    "- 📁 **Project directory structure set up**\n",
    "- 📦 **System packages updated**\n",
    "- 🛠️ **`~/.local/bin` added to PATH**\n",
    "- 🔧 **System dependencies installed**\n",
    "- 🏗 **Poetry installed and configured**\n",
    "- 🐍 **Project dependencies installed**\n",
    "- 📚 **Python kernel installed for Jupyter Notebooks**\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Your environment is fully set up. Get started on your next lab now!** 🚀\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
