{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 21: Bonsai - Real-World Applications\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the previous lab, we explored various optimization algorithms for reconstructing pedigrees using the Bonsai framework. Now, we'll examine how these techniques can be applied to real-world genetic genealogy datasets.\n",
    "\n",
    "Real-world applications of pedigree reconstruction present unique challenges not encountered in controlled simulations, including:\n",
    "\n",
    "- Incomplete or missing data\n",
    "- Genotyping and IBD detection errors\n",
    "- Complex genetic structures (endogamy, multiple family lines, etc.)\n",
    "- Computational efficiency requirements for large datasets\n",
    "- Privacy and ethical considerations\n",
    "\n",
    "This lab will demonstrate how to address these challenges using Bonsai's optimization frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stats\n",
    "from IPython.display import display, HTML\n",
    "from typing import List, Dict, Tuple, Set, Optional\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('ggplot')\n",
    "sns.set_context('notebook')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also import our Bonsai framework components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bonsai components from previous labs\n",
    "# Note: In a real application, these would be properly packaged modules\n",
    "\n",
    "# Pedigree data structures\n",
    "class Individual:\n",
    "    \"\"\"Represents an individual in a pedigree.\"\"\"\n",
    "    def __init__(self, id_str, father_id=None, mother_id=None, sex=None):\n",
    "        self.id = id_str\n",
    "        self.father_id = father_id\n",
    "        self.mother_id = mother_id\n",
    "        self.sex = sex  # 'M' or 'F'\n",
    "        self.ibd_segments = []  # List of IBD segments with other individuals\n",
    "\n",
    "class Pedigree:\n",
    "    \"\"\"Represents a pedigree as a collection of individuals.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.individuals = {}  # Dictionary mapping IDs to Individual objects\n",
    "        self.graph = nx.DiGraph()  # Directed graph representing the pedigree\n",
    "\n",
    "    def add_individual(self, individual):\n",
    "        \"\"\"Add an individual to the pedigree.\"\"\"\n",
    "        self.individuals[individual.id] = individual\n",
    "        self.graph.add_node(individual.id)\n",
    "        # Add edges for parental relationships if they exist\n",
    "        if individual.father_id and individual.father_id in self.individuals:\n",
    "            self.graph.add_edge(individual.father_id, individual.id)\n",
    "        if individual.mother_id and individual.mother_id in self.individuals:\n",
    "            self.graph.add_edge(individual.mother_id, individual.id)\n",
    "\n",
    "    def visualize(self, figsize=(12, 8)):\n",
    "        \"\"\"Visualize the pedigree graph.\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        pos = nx.nx_agraph.graphviz_layout(self.graph, prog='dot')\n",
    "        nx.draw(self.graph, pos, with_labels=True, node_color='lightblue', \n",
    "                node_size=2000, arrowsize=20, font_size=10)\n",
    "        plt.title(\"Pedigree Graph\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working with Real Genetic Genealogy Datasets\n",
    "\n",
    "Real genetic genealogy datasets differ from simulations in several important ways. Let's explore how to load, clean, and prepare real-world data for pedigree reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ibd_segments(file_path):\n",
    "    \"\"\"Load IBD segments from a real dataset file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the IBD segments file (e.g., from IBIS, hap-IBD, etc.)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing IBD segments\n",
    "    \"\"\"\n",
    "    # In practice, this would handle various file formats from IBD detection tools\n",
    "    # For this lab, we'll use a simplified format\n",
    "    \n",
    "    # Example: Reading from a CSV or similar format\n",
    "    try:\n",
    "        ibd_df = pd.read_csv(file_path)\n",
    "        # Ensure required columns exist\n",
    "        required_cols = ['id1', 'id2', 'chromosome', 'start_position', 'end_position', 'cM_length']\n",
    "        for col in required_cols:\n",
    "            if col not in ibd_df.columns:\n",
    "                print(f\"Warning: Missing required column {col}\")\n",
    "        return ibd_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading IBD data: {e}\")\n",
    "        # Create a sample dataframe for demonstration\n",
    "        return pd.DataFrame({\n",
    "            'id1': ['sample1', 'sample1', 'sample2'],\n",
    "            'id2': ['sample2', 'sample3', 'sample3'],\n",
    "            'chromosome': [1, 2, 1],\n",
    "            'start_position': [1000000, 2000000, 1500000],\n",
    "            'end_position': [2000000, 3000000, 2500000],\n",
    "            'cM_length': [10.5, 15.2, 8.7]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this lab, we'll use the ped_sim data as a realistic example\n",
    "# In a real application, you would replace this with your actual data path\n",
    "sample_ibd_file = \"../data/class_data/ped_sim_run2.seg\"\n",
    "\n",
    "# Check if the file exists, otherwise use sample data\n",
    "if os.path.exists(sample_ibd_file):\n",
    "    # Load the real data\n",
    "    print(f\"Loading real IBD segments from {sample_ibd_file}\")\n",
    "    raw_ibd_segments = pd.read_csv(sample_ibd_file, sep='\\t')\n",
    "    # Display the first few rows and the column names\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(raw_ibd_segments.columns.tolist())\n",
    "    display(raw_ibd_segments.head())\n",
    "else:\n",
    "    print(f\"File {sample_ibd_file} not found. Using synthetic data for demonstration.\")\n",
    "    # Create synthetic data for demonstration\n",
    "    raw_ibd_segments = load_ibd_segments(\"dummy_path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Cleaning and Preprocessing\n",
    "\n",
    "Real-world data often contains errors, inconsistencies, and missing values. Let's implement some common preprocessing steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ibd_data(ibd_df, min_cm_length=7.0, max_cm_length=None, remove_duplicates=True):\n",
    "    \"\"\"Clean and preprocess IBD segment data.\n",
    "    \n",
    "    Args:\n",
    "        ibd_df: DataFrame containing IBD segments\n",
    "        min_cm_length: Minimum centiMorgan length to keep (filter out short segments)\n",
    "        max_cm_length: Maximum centiMorgan length to keep (filter out potential errors)\n",
    "        remove_duplicates: Whether to remove duplicate segments\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = ibd_df.copy()\n",
    "    \n",
    "    # Initial row count\n",
    "    initial_count = len(df)\n",
    "    print(f\"Initial IBD segment count: {initial_count}\")\n",
    "    \n",
    "    # Standardize column names if needed\n",
    "    column_mapping = {\n",
    "        # Map various possible column names to standardized names\n",
    "        # Example: 'ID1': 'id1', 'sample1': 'id1', etc.\n",
    "    }\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    \n",
    "    # Handle missing values\n",
    "    print(f\"Missing values before cleaning:\\n{df.isnull().sum()}\")\n",
    "    df = df.dropna(subset=['id1', 'id2', 'cM_length'])  # Drop rows with missing critical data\n",
    "    print(f\"Rows after dropping missing values: {len(df)}\")\n",
    "    \n",
    "    # Filter by segment length\n",
    "    if min_cm_length is not None:\n",
    "        df = df[df['cM_length'] >= min_cm_length]\n",
    "        print(f\"Rows after filtering segments < {min_cm_length} cM: {len(df)}\")\n",
    "    \n",
    "    if max_cm_length is not None:\n",
    "        df = df[df['cM_length'] <= max_cm_length]\n",
    "        print(f\"Rows after filtering segments > {max_cm_length} cM: {len(df)}\")\n",
    "    \n",
    "    # Remove duplicate segments\n",
    "    if remove_duplicates:\n",
    "        # Define what constitutes a duplicate (e.g., same individuals, chromosome, and positions)\n",
    "        dup_cols = ['id1', 'id2', 'chromosome', 'start_position', 'end_position']\n",
    "        # Sort id1 and id2 to treat (A,B) and (B,A) as the same pair\n",
    "        df['sorted_id1'] = df.apply(lambda x: min(x['id1'], x['id2']), axis=1)\n",
    "        df['sorted_id2'] = df.apply(lambda x: max(x['id1'], x['id2']), axis=1)\n",
    "        # Check for duplicates using sorted IDs\n",
    "        dupe_mask = df.duplicated(subset=['sorted_id1', 'sorted_id2', 'chromosome', 'start_position', 'end_position'], keep='first')\n",
    "        print(f\"Duplicate segments found: {dupe_mask.sum()}\")\n",
    "        df = df[~dupe_mask]\n",
    "        # Remove the temporary sorting columns\n",
    "        df = df.drop(columns=['sorted_id1', 'sorted_id2'])\n",
    "    \n",
    "    # Calculate reduction percentage\n",
    "    final_count = len(df)\n",
    "    reduction = (initial_count - final_count) / initial_count * 100 if initial_count > 0 else 0\n",
    "    print(f\"Final IBD segment count: {final_count} ({reduction:.1f}% reduction)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to our IBD data\n",
    "# Let's adapt the function to match the column names in our actual data\n",
    "if 'cM_length' not in raw_ibd_segments.columns and 'seg_cm' in raw_ibd_segments.columns:\n",
    "    raw_ibd_segments = raw_ibd_segments.rename(columns={'seg_cm': 'cM_length'})\n",
    "if 'id1' not in raw_ibd_segments.columns and 'indiv1' in raw_ibd_segments.columns:\n",
    "    raw_ibd_segments = raw_ibd_segments.rename(columns={'indiv1': 'id1', 'indiv2': 'id2'})\n",
    "\n",
    "# Process IBD data with appropriate thresholds for real-world analysis\n",
    "cleaned_ibd_segments = preprocess_ibd_data(\n",
    "    raw_ibd_segments,\n",
    "    min_cm_length=7.0,         # Standard threshold for meaningful IBD segments\n",
    "    max_cm_length=300.0,       # Filter out extremely long segments that might be errors\n",
    "    remove_duplicates=True\n",
    ")\n",
    "\n",
    "# Display the cleaned data\n",
    "display(cleaned_ibd_segments.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 IBD Segment Statistics and Quality Assessment\n",
    "\n",
    "Let's analyze the distribution of IBD segments to assess data quality and identify potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ibd_distribution(ibd_df):\n",
    "    \"\"\"Analyze the distribution of IBD segments to identify potential issues.\n",
    "    \n",
    "    Args:\n",
    "        ibd_df: DataFrame containing cleaned IBD segments\n",
    "    \"\"\"\n",
    "    # Create a figure with multiple subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Distribution of segment lengths\n",
    "    ax1 = axes[0, 0]\n",
    "    sns.histplot(ibd_df['cM_length'], bins=50, kde=True, ax=ax1)\n",
    "    ax1.set_title('Distribution of IBD Segment Lengths')\n",
    "    ax1.set_xlabel('Length (cM)')\n",
    "    ax1.set_ylabel('Count')\n",
    "    \n",
    "    # 2. Distribution by chromosome\n",
    "    ax2 = axes[0, 1]\n",
    "    if 'chromosome' in ibd_df.columns:\n",
    "        chr_counts = ibd_df['chromosome'].value_counts().sort_index()\n",
    "        chr_counts.plot(kind='bar', ax=ax2)\n",
    "        ax2.set_title('IBD Segments by Chromosome')\n",
    "        ax2.set_xlabel('Chromosome')\n",
    "        ax2.set_ylabel('Count')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Chromosome data not available', ha='center', va='center')\n",
    "    \n",
    "    # 3. Number of segments per individual\n",
    "    ax3 = axes[1, 0]\n",
    "    # Combine id1 and id2 to count segments per individual\n",
    "    all_ids = pd.concat([ibd_df['id1'], ibd_df['id2']])\n",
    "    id_counts = all_ids.value_counts()\n",
    "    sns.histplot(id_counts, bins=30, kde=True, ax=ax3)\n",
    "    ax3.set_title('Distribution of IBD Segments per Individual')\n",
    "    ax3.set_xlabel('Number of IBD Segments')\n",
    "    ax3.set_ylabel('Count of Individuals')\n",
    "    \n",
    "    # 4. Average segment length by individual\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Create a dictionary to store segments for each individual\n",
    "    individual_segments = defaultdict(list)\n",
    "    \n",
    "    # Populate the dictionary with segment lengths\n",
    "    for _, row in ibd_df.iterrows():\n",
    "        individual_segments[row['id1']].append(row['cM_length'])\n",
    "        individual_segments[row['id2']].append(row['cM_length'])\n",
    "    \n",
    "    # Calculate average segment length for each individual\n",
    "    avg_lengths = {ind: np.mean(lengths) for ind, lengths in individual_segments.items()}\n",
    "    \n",
    "    # Plot the distribution of average segment lengths\n",
    "    sns.histplot(list(avg_lengths.values()), bins=30, kde=True, ax=ax4)\n",
    "    ax4.set_title('Average IBD Segment Length per Individual')\n",
    "    ax4.set_xlabel('Average Length (cM)')\n",
    "    ax4.set_ylabel('Count of Individuals')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(f\"Total IBD segments: {len(ibd_df)}\")\n",
    "    print(f\"Unique individuals: {len(set(all_ids))}\")\n",
    "    print(f\"Average segments per individual: {all_ids.value_counts().mean():.2f}\")\n",
    "    print(f\"Average segment length: {ibd_df['cM_length'].mean():.2f} cM\")\n",
    "    print(f\"Median segment length: {ibd_df['cM_length'].median():.2f} cM\")\n",
    "    print(f\"Longest segment: {ibd_df['cM_length'].max():.2f} cM\")\n",
    "    \n",
    "    # Identify potential outliers or data quality issues\n",
    "    print(\"\\nPotential Data Quality Issues:\")\n",
    "    \n",
    "    # Very long segments (potential errors or close relationships)\n",
    "    long_threshold = ibd_df['cM_length'].quantile(0.99)\n",
    "    long_segments = ibd_df[ibd_df['cM_length'] > long_threshold]\n",
    "    print(f\"Unusually long segments (>{long_threshold:.2f} cM): {len(long_segments)}\")\n",
    "    \n",
    "    # Individuals with unusually many segments (potential quality issues or highly connected)\n",
    "    many_segments_threshold = id_counts.quantile(0.95)\n",
    "    individuals_many_segments = id_counts[id_counts > many_segments_threshold]\n",
    "    print(f\"Individuals with unusually many segments (>{many_segments_threshold:.0f}): {len(individuals_many_segments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the distribution of IBD segments\n",
    "analyze_ibd_distribution(cleaned_ibd_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Adapting Bonsai for Real-World Challenges\n",
    "\n",
    "Now that we've explored the characteristics of real-world IBD data, let's adapt our Bonsai framework to handle common challenges:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Handling Incomplete Data\n",
    "\n",
    "Real-world datasets often have incomplete data. Let's implement strategies to handle missing or incomplete information during pedigree reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustPedigreeReconstructor:\n",
    "    \"\"\"A pedigree reconstructor designed to handle incomplete or noisy data.\"\"\"\n",
    "    \n",
    "    def __init__(self, ibd_segments, min_confidence=0.7):\n",
    "        \"\"\"Initialize the reconstructor.\n",
    "        \n",
    "        Args:\n",
    "            ibd_segments: DataFrame of IBD segments\n",
    "            min_confidence: Minimum confidence threshold for making relationship inferences\n",
    "        \"\"\"\n",
    "        self.ibd_segments = ibd_segments\n",
    "        self.min_confidence = min_confidence\n",
    "        self.pedigree = Pedigree()\n",
    "        self.relationship_confidences = defaultdict(float)  # Store confidence for each inferred relationship\n",
    "        \n",
    "    def calculate_relationship_likelihood(self, ind1, ind2):\n",
    "        \"\"\"Calculate likelihood of different relationships based on IBD patterns.\n",
    "        \n",
    "        Args:\n",
    "            ind1, ind2: IDs of the two individuals\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping relationship types to confidence scores\n",
    "        \"\"\"\n",
    "        # Filter segments between these two individuals\n",
    "        segments = self.ibd_segments[\n",
    "            ((self.ibd_segments['id1'] == ind1) & (self.ibd_segments['id2'] == ind2)) |\n",
    "            ((self.ibd_segments['id1'] == ind2) & (self.ibd_segments['id2'] == ind1))\n",
    "        ]\n",
    "        \n",
    "        if len(segments) == 0:\n",
    "            return {'no_relationship': 1.0}\n",
    "        \n",
    "        # Calculate key metrics\n",
    "        total_cm = segments['cM_length'].sum()\n",
    "        segment_count = len(segments)\n",
    "        longest_segment = segments['cM_length'].max() if not segments.empty else 0\n",
    "        \n",
    "        # Simple heuristic rules for relationship inference\n",
    "        # In a real implementation, this would use more sophisticated statistical models\n",
    "        # trained on real data distributions for different relationship types\n",
    "        \n",
    "        likelihoods = {\n",
    "            'parent-child': 0.0,\n",
    "            'sibling': 0.0,\n",
    "            'half-sibling': 0.0,\n",
    "            'first-cousin': 0.0,\n",
    "            'second-cousin': 0.0,\n",
    "            'distant': 0.0,\n",
    "            'no_relationship': 0.0\n",
    "        }\n",
    "        \n",
    "        # Parent-child: typically share ~3400-3800 cM, few long segments spanning entire chromosomes\n",
    "        if total_cm > 3300 and longest_segment > 180:\n",
    "            likelihoods['parent-child'] = 0.95\n",
    "        \n",
    "        # Siblings: typically share ~2400-2800 cM, many segments of varied lengths\n",
    "        elif total_cm > 2300 and segment_count > 30:\n",
    "            likelihoods['sibling'] = 0.90\n",
    "        \n",
    "        # Half-siblings: typically share ~1700-2200 cM\n",
    "        elif total_cm > 1600 and total_cm < 2300:\n",
    "            likelihoods['half-sibling'] = 0.85\n",
    "        \n",
    "        # First cousins: typically share ~800-1300 cM\n",
    "        elif total_cm > 700 and total_cm < 1400:\n",
    "            likelihoods['first-cousin'] = 0.80\n",
    "        \n",
    "        # Second cousins: typically share ~200-600 cM\n",
    "        elif total_cm > 180 and total_cm < 700:\n",
    "            likelihoods['second-cousin'] = 0.75\n",
    "        \n",
    "        # Distant relationships\n",
    "        elif total_cm > 40:\n",
    "            likelihoods['distant'] = 0.70\n",
    "        \n",
    "        # No clear relationship\n",
    "        else:\n",
    "            likelihoods['no_relationship'] = 0.60\n",
    "        \n",
    "        # Normalize so highest confidence relationship is 1.0\n",
    "        max_likelihood = max(likelihoods.values())\n",
    "        if max_likelihood > 0:\n",
    "            likelihoods = {rel: val/max_likelihood for rel, val in likelihoods.items()}\n",
    "        \n",
    "        return likelihoods\n",
    "    \n",
    "    def infer_relationships(self):\n",
    "        \"\"\"Infer relationships between all pairs of individuals.\"\"\"\n",
    "        # Get unique individuals\n",
    "        all_individuals = set(self.ibd_segments['id1']).union(set(self.ibd_segments['id2']))\n",
    "        print(f\"Inferring relationships among {len(all_individuals)} individuals\")\n",
    "        \n",
    "        # Initialize progress tracking\n",
    "        total_pairs = len(all_individuals) * (len(all_individuals) - 1) // 2\n",
    "        processed = 0\n",
    "        \n",
    "        # Store inferred relationships\n",
    "        self.inferred_relationships = []\n",
    "        \n",
    "        # Iterate through all pairs\n",
    "        for ind1, ind2 in itertools.combinations(all_individuals, 2):\n",
    "            # Calculate relationship likelihoods\n",
    "            likelihoods = self.calculate_relationship_likelihood(ind1, ind2)\n",
    "            \n",
    "            # Get most likely relationship\n",
    "            most_likely_rel = max(likelihoods.items(), key=lambda x: x[1])\n",
    "            relationship, confidence = most_likely_rel\n",
    "            \n",
    "            # Store if confidence exceeds threshold and it's not 'no_relationship'\n",
    "            if confidence >= self.min_confidence and relationship != 'no_relationship':\n",
    "                self.inferred_relationships.append({\n",
    "                    'id1': ind1,\n",
    "                    'id2': ind2,\n",
    "                    'relationship': relationship,\n",
    "                    'confidence': confidence\n",
    "                })\n",
    "            \n",
    "            # Update progress (in a real implementation, use a proper progress bar)\n",
    "            processed += 1\n",
    "            if processed % 1000 == 0 or processed == total_pairs:\n",
    "                print(f\"Processed {processed}/{total_pairs} pairs ({(processed/total_pairs*100):.1f}%)\")\n",
    "        \n",
    "        # Convert to DataFrame for easier analysis\n",
    "        self.relationship_df = pd.DataFrame(self.inferred_relationships)\n",
    "        print(f\"Inferred {len(self.relationship_df)} relationships with confidence >= {self.min_confidence}\")\n",
    "        \n",
    "        return self.relationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reduced dataset for faster demonstration\n",
    "# In a real application, you would use the full dataset\n",
    "if len(cleaned_ibd_segments) > 1000:\n",
    "    # Get the top 100 individuals with the most IBD segments for a meaningful subset\n",
    "    top_individuals = pd.concat([cleaned_ibd_segments['id1'], cleaned_ibd_segments['id2']])\\\n",
    "                        .value_counts().head(20).index.tolist()\n",
    "    \n",
    "    # Filter segments to only include these individuals\n",
    "    demo_segments = cleaned_ibd_segments[\n",
    "        (cleaned_ibd_segments['id1'].isin(top_individuals)) & \n",
    "        (cleaned_ibd_segments['id2'].isin(top_individuals))\n",
    "    ]\n",
    "    print(f\"Created demonstration dataset with {len(demo_segments)} segments among {len(top_individuals)} individuals\")\n",
    "else:\n",
    "    demo_segments = cleaned_ibd_segments\n",
    "    print(f\"Using full dataset with {len(demo_segments)} segments\")\n",
    "\n",
    "# Create and run the robust reconstructor\n",
    "reconstructor = RobustPedigreeReconstructor(demo_segments, min_confidence=0.7)\n",
    "relationship_df = reconstructor.infer_relationships()\n",
    "\n",
    "# Display the inferred relationships\n",
    "if not relationship_df.empty:\n",
    "    display(relationship_df.sort_values('confidence', ascending=False).head(10))\n",
    "else:\n",
    "    print(\"No relationships were inferred with sufficient confidence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dealing with Conflicting Evidence\n",
    "\n",
    "In real-world data, we often encounter conflicting evidence about relationships. Let's implement a strategy to resolve conflicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_relationship_conflicts(relationship_df):\n",
    "    \"\"\"Resolve conflicts in inferred relationships.\n",
    "    \n",
    "    Args:\n",
    "        relationship_df: DataFrame of inferred relationships\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with conflicts resolved\n",
    "    \"\"\"\n",
    "    if relationship_df.empty:\n",
    "        return relationship_df\n",
    "    \n",
    "    print(\"Checking for conflicts in relationship inferences...\")\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    resolved_df = relationship_df.copy()\n",
    "    \n",
    "    # Get unique individuals\n",
    "    all_individuals = set(relationship_df['id1']).union(set(relationship_df['id2']))\n",
    "    \n",
    "    # Dictionary to track relationship conflicts\n",
    "    conflicts = []\n",
    "    \n",
    "    # Check for logical inconsistencies\n",
    "    for ind in all_individuals:\n",
    "        # Get all relationships involving this individual\n",
    "        ind_rels = relationship_df[\n",
    "            (relationship_df['id1'] == ind) | (relationship_df['id2'] == ind)\n",
    "        ]\n",
    "        \n",
    "        if len(ind_rels) < 2:\n",
    "            continue  # Need at least 2 relationships to have a conflict\n",
    "        \n",
    "        # Check for parent-child relationship conflicts\n",
    "        parent_child_rels = ind_rels[ind_rels['relationship'] == 'parent-child']\n",
    "        \n",
    "        # Example conflict: person has more than 2 parents\n",
    "        if len(parent_child_rels) > 2:\n",
    "            print(f\"Conflict detected: Individual {ind} has more than 2 parent-child relationships\")\n",
    "            \n",
    "            # Resolve by keeping the 2 highest-confidence relationships\n",
    "            sorted_rels = parent_child_rels.sort_values('confidence', ascending=False)\n",
    "            to_keep = sorted_rels.iloc[:2].index\n",
    "            to_remove = sorted_rels.iloc[2:].index\n",
    "            \n",
    "            # Log conflicts\n",
    "            for idx in to_remove:\n",
    "                conflicts.append({\n",
    "                    'individual': ind, \n",
    "                    'relationship_index': idx,\n",
    "                    'conflict_type': 'too_many_parents',\n",
    "                    'resolution': 'removed_lower_confidence'\n",
    "                })\n",
    "            \n",
    "            # Update the resolved dataframe\n",
    "            resolved_df.loc[to_remove, 'relationship'] = 'conflicted_removed'\n",
    "    \n",
    "    # Check for sibling relationship conflicts\n",
    "    # Similar conflict resolution logic would be implemented here\n",
    "    \n",
    "    # Check for generational conflicts (e.g., someone can't be both your sibling and your grandparent)\n",
    "    # Complex conflict resolution logic would be implemented here\n",
    "    \n",
    "    # Remove conflicted relationships\n",
    "    resolved_df = resolved_df[resolved_df['relationship'] != 'conflicted_removed']\n",
    "    \n",
    "    # Report conflicts\n",
    "    conflicts_df = pd.DataFrame(conflicts) if conflicts else pd.DataFrame()\n",
    "    print(f\"Resolved {len(conflicts)} conflicts\")\n",
    "    \n",
    "    return resolved_df, conflicts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve conflicts in our inferred relationships\n",
    "if not relationship_df.empty:\n",
    "    resolved_relationships, conflicts = resolve_relationship_conflicts(relationship_df)\n",
    "    \n",
    "    print(f\"\\nRelationships after conflict resolution: {len(resolved_relationships)}\")\n",
    "    display(resolved_relationships.head())\n",
    "    \n",
    "    # Display conflicts if any\n",
    "    if not conflicts.empty:\n",
    "        print(\"\\nConflicts detected and resolved:\")\n",
    "        display(conflicts)\n",
    "else:\n",
    "    print(\"No relationships to check for conflicts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Pedigrees from Real-World Data\n",
    "\n",
    "Now let's apply our robust framework to construct pedigrees from real-world IBD data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealWorldPedigreeBuilder:\n",
    "    \"\"\"Builds pedigrees from real-world relationship inferences.\"\"\"\n",
    "    \n",
    "    def __init__(self, relationship_df):\n",
    "        \"\"\"Initialize the pedigree builder.\n",
    "        \n",
    "        Args:\n",
    "            relationship_df: DataFrame of inferred relationships\n",
    "        \"\"\"\n",
    "        self.relationship_df = relationship_df\n",
    "        self.pedigree = Pedigree()\n",
    "    \n",
    "    def build_pedigree(self, method='greedy'):\n",
    "        \"\"\"Build a pedigree using the specified method.\n",
    "        \n",
    "        Args:\n",
    "            method: Reconstruction method to use ('greedy', 'simulated_annealing', etc.)\n",
    "            \n",
    "        Returns:\n",
    "            Constructed Pedigree object\n",
    "        \"\"\"\n",
    "        if self.relationship_df.empty:\n",
    "            print(\"No relationships provided. Cannot build pedigree.\")\n",
    "            return self.pedigree\n",
    "        \n",
    "        print(f\"Building pedigree using {method} method...\")\n",
    "        \n",
    "        # Get all individuals\n",
    "        all_individuals = set(self.relationship_df['id1']).union(set(self.relationship_df['id2']))\n",
    "        print(f\"Creating pedigree with {len(all_individuals)} individuals\")\n",
    "        \n",
    "        # Add all individuals to the pedigree\n",
    "        for ind_id in all_individuals:\n",
    "            individual = Individual(id_str=ind_id)\n",
    "            self.pedigree.add_individual(individual)\n",
    "        \n",
    "        # Sort relationships by confidence (highest first)\n",
    "        sorted_rels = self.relationship_df.sort_values('confidence', ascending=False)\n",
    "        \n",
    "        if method == 'greedy':\n",
    "            self._greedy_reconstruction(sorted_rels)\n",
    "        elif method == 'simulated_annealing':\n",
    "            self._simulated_annealing_reconstruction(sorted_rels)\n",
    "        else:\n",
    "            print(f\"Method {method} not implemented. Using greedy reconstruction.\")\n",
    "            self._greedy_reconstruction(sorted_rels)\n",
    "        \n",
    "        print(f\"Pedigree construction complete. Added {len(self.pedigree.graph.edges)} relationships.\")\n",
    "        return self.pedigree\n",
    "    \n",
    "    def _greedy_reconstruction(self, sorted_rels):\n",
    "        \"\"\"Greedily add relationships to the pedigree based on confidence.\"\"\"\n",
    "        # Track used relationships to avoid conflicts\n",
    "        used_relationships = set()\n",
    "        \n",
    "        # Keep track of parents for each individual\n",
    "        parents = {ind_id: [] for ind_id in self.pedigree.individuals}\n",
    "        \n",
    "        # Process relationships in order of confidence\n",
    "        for _, rel in sorted_rels.iterrows():\n",
    "            id1, id2 = rel['id1'], rel['id2']\n",
    "            relationship = rel['relationship']\n",
    "            \n",
    "            # Skip if either individual is already in a used relationship\n",
    "            if (id1, id2) in used_relationships or (id2, id1) in used_relationships:\n",
    "                continue\n",
    "            \n",
    "            # Handle parent-child relationships\n",
    "            if relationship == 'parent-child':\n",
    "                # Determine which is parent and which is child\n",
    "                # In a real implementation, this would use additional evidence like age\n",
    "                # For demo, we'll just assign id1 as parent and id2 as child\n",
    "                parent_id, child_id = id1, id2\n",
    "                \n",
    "                # Check if child already has 2 parents\n",
    "                if len(parents[child_id]) >= 2:\n",
    "                    continue\n",
    "                \n",
    "                # Add parent-child relationship\n",
    "                parents[child_id].append(parent_id)\n",
    "                \n",
    "                # Update individual objects and graph\n",
    "                individual = self.pedigree.individuals[child_id]\n",
    "                \n",
    "                # If this is the first parent, assign as father (in real world would use evidence)\n",
    "                if len(parents[child_id]) == 1:\n",
    "                    individual.father_id = parent_id\n",
    "                    individual.sex = 'M'  # Assume father for simplicity\n",
    "                # If this is the second parent, assign as mother\n",
    "                else:\n",
    "                    individual.mother_id = parent_id\n",
    "                    # Update the sex of the parent (for simplicity)\n",
    "                    parent_individual = self.pedigree.individuals[parent_id]\n",
    "                    parent_individual.sex = 'F'  # Assume mother for simplicity\n",
    "                \n",
    "                # Add edge to the graph\n",
    "                self.pedigree.graph.add_edge(parent_id, child_id)\n",
    "                \n",
    "                # Mark as used\n",
    "                used_relationships.add((id1, id2))\n",
    "            \n",
    "            # Handle sibling relationships\n",
    "            elif relationship == 'sibling':\n",
    "                # In a real implementation, would ensure both share parents\n",
    "                # For simplicity, just note the sibling relationship without modifying the graph\n",
    "                used_relationships.add((id1, id2))\n",
    "            \n",
    "            # Other relationship types would have specific handling here\n",
    "    \n",
    "    def _simulated_annealing_reconstruction(self, sorted_rels):\n",
    "        \"\"\"Use simulated annealing to find optimal pedigree structure.\"\"\"\n",
    "        # In a real implementation, this would use a more sophisticated approach\n",
    "        # For this lab, we'll use a simplified placeholder implementation\n",
    "        print(\"Simulated annealing reconstruction (simplified version)\")\n",
    "        self._greedy_reconstruction(sorted_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pedigree from our resolved relationships\n",
    "if 'resolved_relationships' in locals() and not resolved_relationships.empty:\n",
    "    # Create the pedigree builder\n",
    "    pedigree_builder = RealWorldPedigreeBuilder(resolved_relationships)\n",
    "    \n",
    "    # Build the pedigree using greedy reconstruction\n",
    "    pedigree = pedigree_builder.build_pedigree(method='greedy')\n",
    "    \n",
    "    # Visualize the resulting pedigree\n",
    "    try:\n",
    "        pedigree.visualize(figsize=(15, 10))\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing pedigree: {e}\")\n",
    "        print(\"Pedigree structure:\")\n",
    "        print(f\"- Individuals: {len(pedigree.individuals)}\")\n",
    "        print(f\"- Relationships: {len(pedigree.graph.edges)}\")\n",
    "        \n",
    "        # Show the first few relationships as text\n",
    "        print(\"\\nSample relationships:\")\n",
    "        for i, edge in enumerate(list(pedigree.graph.edges())[:10]):\n",
    "            print(f\"{edge[0]} -> {edge[1]}\")\n",
    "else:\n",
    "    print(\"No resolved relationships available for building a pedigree.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating Real-World Pedigree Reconstruction\n",
    "\n",
    "In real-world applications, we often don't have the ground truth to evaluate our reconstructed pedigrees. Let's explore methods for evaluating reconstruction quality without ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pedigree_without_ground_truth(pedigree, ibd_segments):\n",
    "    \"\"\"Evaluate a reconstructed pedigree without access to ground truth.\n",
    "    \n",
    "    Args:\n",
    "        pedigree: Reconstructed Pedigree object\n",
    "        ibd_segments: DataFrame of IBD segments used for reconstruction\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Initialize metrics dictionary\n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Structural metrics\n",
    "    graph = pedigree.graph\n",
    "    metrics['node_count'] = len(graph.nodes)\n",
    "    metrics['edge_count'] = len(graph.edges)\n",
    "    metrics['connected_components'] = nx.number_connected_components(graph.to_undirected())\n",
    "    \n",
    "    # Calculate density as ratio of actual edges to maximum possible edges\n",
    "    n = metrics['node_count']\n",
    "    metrics['density'] = metrics['edge_count'] / (n * (n - 1) / 2) if n > 1 else 0\n",
    "    \n",
    "    # Check for cycles, which shouldn't exist in a valid pedigree\n",
    "    try:\n",
    "        cycles = list(nx.simple_cycles(graph))\n",
    "        metrics['has_cycles'] = len(cycles) > 0\n",
    "        metrics['cycle_count'] = len(cycles)\n",
    "    except:\n",
    "        metrics['has_cycles'] = \"Error checking cycles\"\n",
    "        metrics['cycle_count'] = \"Unknown\"\n",
    "    \n",
    "    # 2. IBD consistency metrics\n",
    "    # Check if the pedigree structure is consistent with IBD patterns\n",
    "    \n",
    "    # Count relationships in the pedigree that are supported by IBD segments\n",
    "    ibd_consistent = 0\n",
    "    ibd_inconsistent = 0\n",
    "    \n",
    "    # Get unique pairs of individuals with IBD segments\n",
    "    ibd_pairs = set()\n",
    "    for _, row in ibd_segments.iterrows():\n",
    "        id1, id2 = row['id1'], row['id2']\n",
    "        ibd_pairs.add((id1, id2) if id1 < id2 else (id2, id1))\n",
    "    \n",
    "    # Check if related individuals in the pedigree share IBD segments\n",
    "    for edge in graph.edges:\n",
    "        parent, child = edge\n",
    "        edge_pair = (parent, child) if parent < child else (child, parent)\n",
    "        \n",
    "        if edge_pair in ibd_pairs:\n",
    "            ibd_consistent += 1\n",
    "        else:\n",
    "            ibd_inconsistent += 1\n",
    "    \n",
    "    metrics['ibd_consistent_relationships'] = ibd_consistent\n",
    "    metrics['ibd_inconsistent_relationships'] = ibd_inconsistent\n",
    "    metrics['ibd_consistency_ratio'] = ibd_consistent / len(graph.edges) if len(graph.edges) > 0 else 0\n",
    "    \n",
    "    # 3. Biological plausibility metrics\n",
    "    \n",
    "    # Check if each individual has at most two parents\n",
    "    invalid_parent_count = 0\n",
    "    for node in graph.nodes:\n",
    "        # Count incoming edges (parents)\n",
    "        parent_count = len(list(graph.predecessors(node)))\n",
    "        if parent_count > 2:\n",
    "            invalid_parent_count += 1\n",
    "    \n",
    "    metrics['invalid_parent_count'] = invalid_parent_count\n",
    "    \n",
    "    # 4. Cross-validation\n",
    "    # In a real implementation, would include methods to:  \n",
    "    # - Split IBD data\n",
    "    # - Reconstruct on partial data\n",
    "    # - Validate consistency across reconstructions\n",
    "    \n",
    "    # Return evaluation metrics\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the reconstructed pedigree\n",
    "if 'pedigree' in locals() and 'demo_segments' in locals():\n",
    "    evaluation_metrics = evaluate_pedigree_without_ground_truth(pedigree, demo_segments)\n",
    "    \n",
    "    # Display metrics\n",
    "    print(\"Pedigree Evaluation Metrics:\")\n",
    "    for metric, value in evaluation_metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "    \n",
    "    # Visualize key metrics\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Select numeric metrics for visualization\n",
    "    numeric_metrics = {k: v for k, v in evaluation_metrics.items() \n",
    "                      if isinstance(v, (int, float)) and k != 'node_count' and k != 'edge_count'}\n",
    "    \n",
    "    # Bar chart\n",
    "    bars = ax.bar(numeric_metrics.keys(), numeric_metrics.values())\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}' if isinstance(height, float) else f'{height}',\n",
    "                ha='center', va='bottom', rotation=0)\n",
    "    \n",
    "    ax.set_title('Pedigree Evaluation Metrics')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_xticklabels(numeric_metrics.keys(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No pedigree or IBD segments available for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Case Study: Success Stories and Challenges\n",
    "\n",
    "Let's examine a few real-world scenarios where pedigree reconstruction has been successful or challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Success Story: Identifying Unknown Relationships\n",
    "\n",
    "One common application of computational genetic genealogy is identifying unknown biological relationships. Let's consider a simplified case study:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Study: Locating Biological Family\n",
    "\n",
    "In this scenario, an adoptee is searching for biological family members. They have:\n",
    "- Their own DNA test results\n",
    "- Access to a database of genetic matches\n",
    "- No prior knowledge of their biological family\n",
    "\n",
    "The approach would typically involve:\n",
    "1. Identifying close genetic matches through IBD detection\n",
    "2. Using the Bonsai algorithm to reconstruct a plausible pedigree\n",
    "3. Combining the genetic evidence with available non-genetic information (age, location, etc.)\n",
    "\n",
    "Success factors in such cases include:\n",
    "- Multiple close relatives in the database (2nd cousins or closer)\n",
    "- High-quality IBD detection with minimal errors\n",
    "- Robust pedigree reconstruction that handles missing individuals\n",
    "- Integration of non-genetic data to resolve ambiguities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Challenge: Endogamy and Complex Pedigrees\n",
    "\n",
    "One of the most significant challenges in genetic genealogy is handling endogamy, where individuals marry within a closed community over generations, leading to complex and interrelated pedigrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge: Reconstructing Endogamous Pedigrees\n",
    "\n",
    "In endogamous populations, the standard assumptions about IBD sharing break down because:\n",
    "- Individuals share multiple recent common ancestors\n",
    "- IBD segments may come from multiple ancestral paths\n",
    "- Relationship predictions are often overestimated\n",
    "\n",
    "Approaches to address endogamy include:\n",
    "1. Adjusting IBD thresholds based on population-specific models\n",
    "2. Using more sophisticated likelihood models that account for endogamy\n",
    "3. Incorporating historical records and documentary evidence alongside genetics\n",
    "4. Focusing on identifying specific branches rather than the entire pedigree\n",
    "\n",
    "Recent advances in the field have shown promise in handling endogamy by:\n",
    "- Developing population-specific genetic models\n",
    "- Using graph theory to identify and handle complex pedigree structures\n",
    "- Incorporating statistical methods that account for endogamy in relationship prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Future Directions and Ethical Considerations\n",
    "\n",
    "As computational genetic genealogy continues to advance, several important future directions and ethical considerations emerge:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Future Directions\n",
    "\n",
    "1. **Integration with other data types:**\n",
    "   - Combining genetic data with documentary evidence (census, vital records)\n",
    "   - Incorporating epigenetic data for age estimation\n",
    "   - Using demographic and historical context to improve reconstructions\n",
    "\n",
    "2. **Scalability improvements:**\n",
    "   - Algorithms that can handle millions of individuals\n",
    "   - Distributed computing approaches for large-scale pedigree reconstruction\n",
    "   - Efficient data structures for very large pedigrees\n",
    "\n",
    "3. **Advanced statistical models:**\n",
    "   - Better modeling of recombination and genetic inheritance\n",
    "   - Population-specific IBD distribution models\n",
    "   - Machine learning approaches for relationship prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Ethical Considerations\n",
    "\n",
    "1. **Privacy concerns:**\n",
    "   - Reconstructed pedigrees can reveal relationships that individuals may not be aware of\n",
    "   - Genetic privacy extends beyond the tested individual to biological relatives\n",
    "   - Need for clear consent processes and privacy protections\n",
    "\n",
    "2. **Unexpected findings:**\n",
    "   - Misattributed parentage\n",
    "   - Previously unknown siblings or other close relatives\n",
    "   - Medical information that could impact family members\n",
    "\n",
    "3. **Equity and representation:**\n",
    "   - Most genetic databases have limited diversity\n",
    "   - Algorithms may perform differently across population groups\n",
    "   - Need for inclusive approaches that work for all ancestries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab, we've explored the real-world applications of the Bonsai algorithm for pedigree reconstruction. We've seen how to:\n",
    "\n",
    "1. Process and clean real genetic genealogy datasets\n",
    "2. Adapt our algorithms to handle incomplete and noisy data\n",
    "3. Resolve conflicts in relationship evidence\n",
    "4. Build and evaluate pedigrees without ground truth\n",
    "5. Consider success stories, challenges, and ethical implications\n",
    "\n",
    "As computational methods continue to improve, the field of genetic genealogy will increasingly rely on sophisticated algorithms like Bonsai to make sense of complex genetic relationships. By combining these computational approaches with traditional genealogical research and ethical considerations, we can advance our understanding of human relationships while respecting privacy and promoting equity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Data Quality Assessment:**\n",
    "   - Modify the `preprocess_ibd_data` function to include additional quality checks specific to real-world data.\n",
    "   - Implement a visualization to identify potential errors in IBD segments.\n",
    "\n",
    "2. **Relationship Inference Improvements:**\n",
    "   - Enhance the `calculate_relationship_likelihood` function to use more sophisticated criteria for relationship classification.\n",
    "   - Implement a confusion matrix to evaluate the accuracy of relationship predictions.\n",
    "\n",
    "3. **Advanced Pedigree Reconstruction:**\n",
    "   - Implement a more sophisticated version of simulated annealing for pedigree reconstruction.\n",
    "   - Add support for incorporating known relationships from documentary sources.\n",
    "\n",
    "4. **Case Study Development:**\n",
    "   - Choose a specific genealogical scenario and develop a detailed approach using the Bonsai algorithm.\n",
    "   - Document the challenges and proposed solutions for your chosen scenario.\n",
    "\n",
    "5. **Ethical Framework:**\n",
    "   - Develop a set of ethical guidelines for the application of computational genealogy.\n",
    "   - Create a privacy-preserving version of the Bonsai algorithm that minimizes exposure of sensitive relationship information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}