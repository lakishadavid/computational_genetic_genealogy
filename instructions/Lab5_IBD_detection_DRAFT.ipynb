{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from: /home/lakishadavid/computational_genetic_genealogy/.env\n"
     ]
    }
   ],
   "source": [
    "def find_comp_gen_dir():\n",
    "    \"\"\"Find the computational_genetic_genealogy directory by searching up from current directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Search up through parent directories\n",
    "    while current != current.parent:\n",
    "        # Check if target directory exists in current path\n",
    "        target = current / 'computational_genetic_genealogy'\n",
    "        if target.is_dir():\n",
    "            return target\n",
    "        # Move up one directory\n",
    "        current = current.parent\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find computational_genetic_genealogy directory\")\n",
    "\n",
    "def load_env_file():\n",
    "    \"\"\"Find and load the .env file from the computational_genetic_genealogy directory.\"\"\"\n",
    "    try:\n",
    "        # Find the computational_genetic_genealogy directory\n",
    "        comp_gen_dir = find_comp_gen_dir()\n",
    "        \n",
    "        # Look for .env file\n",
    "        env_path = comp_gen_dir / '.env'\n",
    "        if not env_path.exists():\n",
    "            print(f\"Warning: No .env file found in {comp_gen_dir}\")\n",
    "            return None\n",
    "        \n",
    "        # Load the .env file\n",
    "        load_dotenv(env_path, override=True)\n",
    "        print(f\"Loaded environment variables from: {env_path}\")\n",
    "        return env_path\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use the function\n",
    "env_path = load_env_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /home/lakishadavid/computational_genetic_genealogy\n",
      "Data Directory: /home/lakishadavid/computational_genetic_genealogy/data\n",
      "References Directory: /home/lakishadavid/computational_genetic_genealogy/references\n",
      "Results Directory: /home/lakishadavid/computational_genetic_genealogy/results\n",
      "Utils Directory: /home/lakishadavid/computational_genetic_genealogy/utils\n",
      "The current directory is /home/lakishadavid/computational_genetic_genealogy\n"
     ]
    }
   ],
   "source": [
    "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
    "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
    "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
    "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
    "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
    "\n",
    "print(f\"Working Directory: {working_directory}\")\n",
    "print(f\"Data Directory: {data_directory}\")\n",
    "print(f\"References Directory: {references_directory}\")\n",
    "print(f\"Results Directory: {results_directory}\")\n",
    "print(f\"Utils Directory: {utils_directory}\")\n",
    "\n",
    "os.chdir(working_directory)\n",
    "print(f\"The current directory is {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\"):\n",
    "    \"\"\"\n",
    "    Configure logging for both file and console handlers.\n",
    "\n",
    "    Args:\n",
    "        log_filename (str): Path to the log file where logs will be written.\n",
    "        log_file_debug_level (str): Logging level for the file handler.\n",
    "        console_debug_level (str): Logging level for the console handler.\n",
    "    \"\"\"\n",
    "    # Create a root logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)  # Capture all messages at the root level\n",
    "\n",
    "    # Convert level names to numeric levels\n",
    "    file_level = getattr(logging, log_file_debug_level.upper(), logging.INFO)\n",
    "    console_level = getattr(logging, console_debug_level.upper(), logging.INFO)\n",
    "\n",
    "    # File handler: Logs messages at file_level and above to the file\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(file_level)\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "\n",
    "    # Console handler: Logs messages at console_level and above to the console\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(console_level)\n",
    "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "\n",
    "    # Add handlers to the root logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "def clear_logger():\n",
    "    \"\"\"Remove all handlers from the root logger.\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_filename = os.path.join(results_directory, \"lab6.log\")\n",
    "print(f\"The Lab 6 log file is located at {log_filename}.\")\n",
    "\n",
    "# Ensure the results_directory exists\n",
    "if not os.path.exists(results_directory):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "# Check if the file exists; if not, create it\n",
    "if not os.path.exists(log_filename):\n",
    "    with open(log_filename, 'w') as file:\n",
    "        pass  # The file is now created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_logger() # Clear the logger before reconfiguring it\n",
    "configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is a demo notebook from the developers: https://github.com/AI-sandbox/gnomix/blob/main/demo.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the supervised machine learning model can learn the distinctive allele frequency patterns and linkage structures characteristic of each population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is /home/lakishadavid/computational_genetic_genealogy/instructions\n",
      "The project root directory is /home/lakishadavid/computational_genetic_genealogy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "script_dir = os.getcwd()\n",
    "print(f\"The current working directory is {script_dir}\")\n",
    "\n",
    "# find computational_genetic_genealogy direcotory\n",
    "project_root = os.path.dirname(script_dir)\n",
    "print(f\"The project root directory is {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ibis_map(self, assembly, output_dir):\n",
    "    \"\"\"\n",
    "    Converts Beagle genetic map files to IBIS format by rearranging columns\n",
    "    and replacing '.' with '0'.\n",
    "    Rearrange the columns: \n",
    "    1. Chromosome (as is)\n",
    "    2. Physical position (currently in the 4th column)\n",
    "    3. Placeholder or recombination rate (currently in the 2nd column)\n",
    "    4. Genetic position (currently in the 3rd column)\n",
    "    \"\"\"\n",
    "    beagle_map_dir = os.path.join(references_directory, \"genetic_maps/beagle_genetic_maps\")\n",
    "    ibis_map_dir = os.path.join(references_directory, \"genetic_maps/ibis_genetic_maps\")\n",
    "    os.makedirs(ibis_map_dir, exist_ok=True)\n",
    "    \n",
    "    for map_file in os.listdir(beagle_map_dir):\n",
    "        if map_file.endswith(\".map\"):\n",
    "            beagle_map_filename = os.path.join(beagle_map_dir, map_file)\n",
    "            ibis_map_filename = os.path.join(ibis_map_dir, map_file)\n",
    "            print(f\"Processing {beagle_map_filename} to create IBIS map...\")\n",
    "            command = f\"awk '{{print $1, $4, ($2 == \\\".\\\" ? 0 : $2), $3}}' {beagle_map_filename} > {ibis_map_filename}\"\n",
    "            subprocess.run(command, shell=True, check=True)\n",
    "    print(\"All Beagle genetic maps converted to IBIS format.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up output directories\n",
    "genetic_maps_dir = os.path.join(references_directory, \"genetic_maps\")\n",
    "os.makedirs(genetic_maps_dir, exist_ok=True)\n",
    "\n",
    "ibis_genetic_maps = os.path.join(genetic_maps_dir, \"ibis_genetic_maps\")\n",
    "os.makedirs(ibis_genetic_maps, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$references_directory\"\n",
    "\n",
    "references_directory=\"$1\"\n",
    "\n",
    "# Define the URL for the plink2 genetic map files in build 38\n",
    "plink2_genetic_map_url=\"https://alkesgroup.broadinstitute.org/Eagle/downloads/tables/genetic_map_hg38_withX.txt.gz\"\n",
    "# download to references directory\n",
    "cd $references_directory\n",
    "# Download the genetic map file\n",
    "wget https://alkesgroup.broadinstitute.org/Eagle/downloads/tables/genetic_map_hg38_withX.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$project_root\"\n",
    "\n",
    "project_root=\"$1\"\n",
    "\n",
    "cd ${project_root}\n",
    "\n",
    "poetry run python scripts_work/run_ibd_detection.py --algorithm IBIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_all_vcfs_to_plink(phased_samples_dir, utils_directory):\n",
    "    \"\"\"\n",
    "    Iterates through all phased VCF files in the directory and converts them to PLINK binary files.\n",
    "    \"\"\"\n",
    "    plink2_executable = os.path.join(utils_directory, \"plink2\")\n",
    "    \n",
    "    # Ensure the PLINK2 executable exists\n",
    "    if not os.path.isfile(plink2_executable):\n",
    "        raise FileNotFoundError(f\"PLINK2 executable not found: {plink2_executable}\")\n",
    "\n",
    "    # Ensure the phased samples directory exists\n",
    "    if not os.path.isdir(phased_samples_dir):\n",
    "        raise NotADirectoryError(f\"Phased samples directory not found: {phased_samples_dir}\")\n",
    "\n",
    "    # Iterate over all VCF files in the directory\n",
    "    for vcf_file in os.listdir(phased_samples_dir):\n",
    "        if vcf_file.startswith(\"opensnps_phased_\") and vcf_file.endswith(\".vcf.gz\"):  # Only process compressed VCF files\n",
    "            vcf_path = os.path.join(phased_samples_dir, vcf_file)\n",
    "            output_prefix = vcf_path.split(\".\")[0]\n",
    "\n",
    "            # Construct the PLINK2 command\n",
    "            command = [\n",
    "                plink2_executable,\n",
    "                \"--vcf\", vcf_path,\n",
    "                \"--autosome\",\n",
    "                \"--make-bed\",\n",
    "                \"--out\", output_prefix\n",
    "            ]\n",
    "\n",
    "            try:\n",
    "                # Execute the command\n",
    "                subprocess.run(command, check=True)\n",
    "                print(f\"PLINK2 successfully processed: {vcf_file}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Error processing {vcf_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_all_vcfs_to_plink(phased_samples_dir, utils_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_genetic_map_to_all_bim(phased_samples_dir, references_directory, utils_directory):\n",
    "    \"\"\"\n",
    "    Iterates through all BIM files in the phased samples directory and adds a genetic map\n",
    "    for IBIS and Beagle compatibility.\n",
    "    \"\"\"\n",
    "    add_map_script = os.path.join(utils_directory, \"ibis/add-map-plink.pl\")\n",
    "\n",
    "    # Ensure the add-map script exists\n",
    "    if not os.path.isfile(add_map_script):\n",
    "        raise FileNotFoundError(f\"Add-map script not found: {add_map_script}\")\n",
    "\n",
    "    # Ensure the phased samples directory exists\n",
    "    if not os.path.isdir(phased_samples_dir):\n",
    "        raise NotADirectoryError(f\"Phased samples directory not found: {phased_samples_dir}\")\n",
    "\n",
    "    # Iterate over all BIM files in the directory\n",
    "    for bim_file in os.listdir(phased_samples_dir):\n",
    "        if bim_file.endswith(\".bim\"):\n",
    "            bim_path = os.path.join(phased_samples_dir, bim_file)\n",
    "            output_bim = bim_path.replace(\".bim\", \"_gm.bim\")\n",
    "            \n",
    "            # Extract chromosome number from the filename\n",
    "            chrom_number = bim_file.split(\"_\")[-1].replace(\".bim\", \"\").replace(\"chr\", \"\")\n",
    "            map_file = os.path.join(references_directory, f\"genetic_maps/ibis_genetic_maps/plink.chr{chrom_number}.GRCh38.map\")\n",
    "\n",
    "            # Ensure required files exist\n",
    "            if not os.path.isfile(bim_path):\n",
    "                print(f\"Skipping {bim_file}: BIM file not found.\")\n",
    "                continue\n",
    "            if not os.path.isfile(map_file):\n",
    "                print(f\"Skipping {bim_file}: Genetic map file not found for chromosome {chrom_number}.\")\n",
    "                continue\n",
    "\n",
    "            # Construct and execute the command\n",
    "            command = f\"{add_map_script} {bim_path} {map_file} > {output_bim}\"\n",
    "            try:\n",
    "                subprocess.run(command, shell=True, check=True)\n",
    "                print(f\"Genetic map added to: {bim_file}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Error processing {bim_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_genetic_map_to_all_bim(phased_samples_dir, references_directory, utils_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ibis(phased_samples_dir, results_directory, utils_directory):\n",
    "    \"\"\"\n",
    "    Runs IBIS IBD detection for all chromosome-specific files in the phased samples directory.\n",
    "    \"\"\"\n",
    "    ibis_executable = os.path.join(utils_directory, \"ibis/ibis\")\n",
    "    \n",
    "    # Ensure the IBIS executable exists\n",
    "    if not os.path.isfile(ibis_executable):\n",
    "        raise FileNotFoundError(f\"IBIS executable not found: {ibis_executable}\")\n",
    "\n",
    "    # Ensure the phased samples directory exists\n",
    "    if not os.path.isdir(phased_samples_dir):\n",
    "        raise NotADirectoryError(f\"Phased samples directory not found: {phased_samples_dir}\")\n",
    "\n",
    "    # Ensure the results directory exists or create it\n",
    "    os.makedirs(results_directory, exist_ok=True)\n",
    "\n",
    "    # Iterate over all chromosome-specific BIM files in the phased samples directory\n",
    "    for bim_file in os.listdir(phased_samples_dir):\n",
    "        if bim_file.endswith(\"_gm.bim\"):  # Process files with the genetic map suffix\n",
    "            chrom_prefix = bim_file.replace(\"_gm.bim\", \"\")\n",
    "            bed_file = os.path.join(phased_samples_dir, chrom_prefix + \".bed\")\n",
    "            fam_file = os.path.join(phased_samples_dir, chrom_prefix + \".fam\")\n",
    "            bim_path = os.path.join(phased_samples_dir, bim_file)\n",
    "            output_prefix = os.path.join(results_directory, chrom_prefix + \"_ibis\")\n",
    "\n",
    "            # Ensure required files exist\n",
    "            if not os.path.isfile(bed_file):\n",
    "                print(f\"Skipping {chrom_prefix}: BED file not found.\")\n",
    "                continue\n",
    "            if not os.path.isfile(fam_file):\n",
    "                print(f\"Skipping {chrom_prefix}: FAM file not found.\")\n",
    "                continue\n",
    "\n",
    "            # Construct the IBIS command\n",
    "            command = [\n",
    "                ibis_executable,\n",
    "                bed_file,\n",
    "                bim_path,\n",
    "                fam_file,\n",
    "                \"-ibd2\",\n",
    "                \"-min_l\", \"7\", \"-mt\", \"436\", \"-er\", \".004\",\n",
    "                \"-min_l2\", \"2\", \"-mt2\", \"186\", \"-er2\", \".008\",\n",
    "                \"-o\", output_prefix,\n",
    "                \"-printCoef\", \"-noFamID\"\n",
    "            ]\n",
    "\n",
    "            try:\n",
    "                # Execute the command\n",
    "                subprocess.run(command, check=True)\n",
    "                print(f\"IBIS IBD detection completed for: {chrom_prefix}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Error running IBIS for {chrom_prefix}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ibis(phased_samples_dir, results_directory, utils_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    # IBIS: sample1 sample2 chrom phys_start_pos phys_end_pos IBD_type genetic_start_pos genetic_end_pos genetic_seg_length marker_count error_count error_density\n",
    "    # Coef: sample1 sample2 kinship_coefficient IBD2_fraction segment_count degree_of_relatedness\n",
    "    # IBD2: Useful in sibling cases where a pair have matching haplotypes at a locus, having inherited from both parents/sides of the family\n",
    "    # HBD: ROH, matching haplotypes within the one person, not a comparison with another person\n",
    "    # HBD: sample_id chrom phys_start_pos phys_end_pos HBD_type genetic_start_pos genetic_end_pos genetic_seg_length marker_count error_count error_density\n",
    "    # Incoef: sample_id inbreeding_coefficient segment_count\n",
    "\n",
    "    # IBIS:\n",
    "    # This file contains detailed information about identity-by-descent (IBD) segments shared between pairs of individuals.\n",
    "    # Columns:\n",
    "    # - sample1, sample2: IDs of the two individuals being compared for shared genetic segments.\n",
    "    # - chrom: Chromosome number where the IBD segment is located.\n",
    "    # - phys_start_pos, phys_end_pos: Start and end positions of the IBD segment in base pairs (physical positions).\n",
    "    # - IBD_type: Type of IBD segment (e.g., IBD1 for sharing one parental haplotype or IBD2 for sharing both parental haplotypes).\n",
    "    # - genetic_start_pos, genetic_end_pos: Start and end positions of the segment in genetic map units (centiMorgans).\n",
    "    # - genetic_seg_length: Length of the IBD segment in centiMorgans (genetic distance).\n",
    "    # - marker_count: Number of genetic markers (SNPs) within the segment.\n",
    "    # - error_count: Total number of mismatches or genotyping errors detected in the segment.\n",
    "    # - error_density: Average error rate per marker in the segment (error_count divided by marker_count).\n",
    "\n",
    "    # Coef:\n",
    "    # This file provides information about pairwise kinship coefficients and degrees of relatedness.\n",
    "    # Columns:\n",
    "    # - sample1, sample2: IDs of the two individuals being compared.\n",
    "    # - kinship_coefficient: A measure of genetic similarity between the individuals, ranging from 0 (no relation) to higher values for close relatives.\n",
    "    # - IBD2_fraction: Proportion of the genome where both parental haplotypes are shared between the individuals.\n",
    "    # - segment_count: Total number of IBD segments identified between the individuals.\n",
    "    # - degree_of_relatedness: Classification of the relationship based on kinship (e.g., siblings, cousins).\n",
    "\n",
    "    # IBD2:\n",
    "    # Represents segments where two individuals share both parental haplotypes. \n",
    "    # IBD2 is particularly useful in identifying siblings or individuals with close familial ties, as these segments indicate inheritance from both sides of the family.\n",
    "\n",
    "    # HBD (Runs of Homozygosity):\n",
    "    # Indicates segments where an individual has matching haplotypes on both chromosomes, likely due to inheritance from a common ancestor.\n",
    "    # This is a measure of inbreeding or autozygosity (when an individual inherits identical haplotypes from both parents).\n",
    "    # Columns:\n",
    "    # - sample_id: ID of the individual being analyzed for HBD segments.\n",
    "    # - chrom: Chromosome number where the HBD segment is located.\n",
    "    # - phys_start_pos, phys_end_pos: Start and end positions of the HBD segment in base pairs.\n",
    "    # - HBD_type: Type or classification of the HBD segment.\n",
    "    # - genetic_start_pos, genetic_end_pos: Start and end positions of the segment in genetic map units (centiMorgans).\n",
    "    # - genetic_seg_length: Length of the HBD segment in centiMorgans.\n",
    "    # - marker_count: Number of genetic markers (SNPs) in the segment.\n",
    "    # - error_count: Total number of mismatches or genotyping errors detected in the segment.\n",
    "    # - error_density: Average error rate per marker in the segment.\n",
    "\n",
    "    # Incoef:\n",
    "    # Provides inbreeding coefficients for individuals, based on HBD analysis.\n",
    "    # Columns:\n",
    "    # - sample_id: ID of the individual being analyzed.\n",
    "    # - inbreeding_coefficient: A measure of inbreeding for the individual, reflecting the proportion of the genome covered by HBD segments.\n",
    "    # - segment_count: Total number of HBD segments identified in the individual's genome.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_sort_ibis_outputs(results_dir):\n",
    "    \"\"\"\n",
    "    Combines all chromosome-specific IBIS .coef and .seg files, and saves sorted results in the results directory.\n",
    "\n",
    "    Parameters:\n",
    "        phased_samples_dir (str): Directory containing chromosome-specific IBIS outputs.\n",
    "        results_dir (str): Directory to save the combined output files.\n",
    "    \"\"\"\n",
    "    combined_coef_path = os.path.join(results_dir, \"ibis_MergedSamples.coef\")\n",
    "    combined_seg_path = os.path.join(results_dir, \"ibis_MergedSamples.seg\")\n",
    "\n",
    "    coef_files = []\n",
    "    seg_files = []\n",
    "\n",
    "    # Collect .coef and .seg files\n",
    "    for chrom in range(1, 23):\n",
    "        coef_file = os.path.join(results_dir, f\"opensnps_phased_chr{chrom}_ibis.coef\")\n",
    "        seg_file = os.path.join(results_dir, f\"opensnps_phased_chr{chrom}_ibis.seg\")\n",
    "\n",
    "        if os.path.isfile(coef_file):\n",
    "            coef_files.append(coef_file)\n",
    "        else:\n",
    "            print(f\"Missing .coef file for chromosome {chrom}. Skipping.\")\n",
    "        \n",
    "        if os.path.isfile(seg_file):\n",
    "            seg_files.append(seg_file)\n",
    "        else:\n",
    "            print(f\"Missing .seg file for chromosome {chrom}. Skipping.\")\n",
    "\n",
    "    if not coef_files and not seg_files:\n",
    "        print(\"No .coef or .seg files found. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # Combine .coef files\n",
    "    if coef_files:\n",
    "        with open(combined_coef_path, \"w\") as outfile:\n",
    "            for i, coef_file in enumerate(coef_files):\n",
    "                with open(coef_file, \"r\") as infile:\n",
    "                    if i == 0:\n",
    "                        # Write the header from the first file\n",
    "                        outfile.write(infile.read())\n",
    "                    else:\n",
    "                        # Skip the header for subsequent files\n",
    "                        next(infile)  # Skip the header line\n",
    "                        outfile.write(infile.read())\n",
    "        print(f\"Combined .coef files saved to: {combined_coef_path}\")\n",
    "    else:\n",
    "        print(\"No .coef files to combine.\")\n",
    "\n",
    "    # Combine and sort .seg files\n",
    "    if seg_files:\n",
    "        combined_seg_data = []\n",
    "        for seg_file in seg_files:\n",
    "            seg_data = pd.read_csv(seg_file, sep=\"\\t\", header=None)\n",
    "            combined_seg_data.append(seg_data)\n",
    "\n",
    "        if combined_seg_data:\n",
    "            combined_seg_df = pd.concat(combined_seg_data, ignore_index=True)\n",
    "            combined_seg_df.columns = [\n",
    "                \"sample1\", \"sample2\", \n",
    "                \"chrom\", \n",
    "                \"phys_start_pos\", \"phys_end_pos\", \n",
    "                \"IBD_type\", \"genetic_start_pos\", \n",
    "                \"genetic_end_pos\", \"genetic_seg_length\", \n",
    "                \"marker_count\", \"error_count\", \"error_density\"\n",
    "            ]\n",
    "            sorted_seg_df = combined_seg_df.sort_values(\n",
    "                by=[\"chrom\", \"phys_start_pos\", \"phys_end_pos\", \"IBD_type\"],\n",
    "                ascending=[True, True, True, True]\n",
    "            )\n",
    "            sorted_seg_df.to_csv(combined_seg_path, sep=\"\\t\", index=False, header=False)\n",
    "            print(f\"Combined and sorted .seg file saved to: {combined_seg_path}\")\n",
    "        else:\n",
    "            print(\"No valid .seg data to combine.\")\n",
    "    else:\n",
    "        print(\"No .seg files to combine.\")\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibis_completion = combine_and_sort_ibis_outputs(results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_coefficients(results_directory, filename=\"ibis_MergedSamples.coef\", focus_on_related=True, save_plots=True, output_subdir=\"segments\"):\n",
    "    \"\"\"\n",
    "    Reads and explores the coefficients file from the results directory.\n",
    "    Includes handling for missing values and options to focus on related individuals.\n",
    "    \n",
    "    Parameters:\n",
    "        results_directory (str): Directory containing the result files.\n",
    "        filename (str): Filename of the coefficients file.\n",
    "        focus_on_related (bool): If True, focuses analysis on related individuals (Degree > 0).\n",
    "        save_plots (bool): If True, saves plots to the specified output directory.\n",
    "        output_dir (str): Directory to save plots.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed coefficients DataFrame for further analysis.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Ensure output directory exists\n",
    "    output_dir = os.path.join(results_directory, output_subdir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Step 1: Read the coefficients file\n",
    "    file_path = os.path.join(results_directory, filename)\n",
    "    coefficients = pd.read_csv(file_path, sep=\"\\t\", low_memory=False)\n",
    "\n",
    "    # Save both full and filtered data if focus_on_related is True\n",
    "    full_data = coefficients.copy()\n",
    "    filtered_data = None\n",
    "\n",
    "    if focus_on_related:\n",
    "        print(\"\\nFocusing on related individuals (Degree > 0).\")\n",
    "        filtered_data = full_data[full_data['Degree'] > 0]\n",
    "        print(f\"Filtered DataFrame Info (Degree > 0):\")\n",
    "        filtered_data.info()\n",
    "        print(\"\\n=== Descriptive Statistics (Filtered) ===\")\n",
    "        print(filtered_data.describe())\n",
    "        print(\"\\n\")\n",
    "        filtered_file_path = os.path.join(output_dir, \"filtered_coefficients.csv\")\n",
    "        filtered_data.to_csv(filtered_file_path, index=False)\n",
    "        print(f\"Filtered coefficients saved to: {filtered_file_path}\")\n",
    "\n",
    "    # Save and print the full data\n",
    "    print(\"\\nFull DataFrame Info:\")\n",
    "    full_data.info()\n",
    "    print(\"\\n=== Descriptive Statistics (Full) ===\")\n",
    "    print(full_data.describe())\n",
    "    print(\"\\n\")\n",
    "    full_file_path = os.path.join(output_dir, \"full_coefficients.csv\")\n",
    "    full_data.to_csv(full_file_path, index=False)\n",
    "    print(f\"Full coefficients saved to: {full_file_path}\")\n",
    "\n",
    "    # Analyze both datasets\n",
    "    datasets = {\"Full\": full_data, \"Filtered\": filtered_data} if focus_on_related else {\"Full\": full_data}\n",
    "\n",
    "    for name, data in datasets.items():\n",
    "        if data is not None:\n",
    "            print(f\"\\n=== Analyzing {name} Data ===\")\n",
    "            \n",
    "            # Counts by Degree\n",
    "            degree_grouped_counts = data['Degree'].value_counts().sort_index()\n",
    "            degree_grouped_counts_df = degree_grouped_counts.reset_index(name='Count')\n",
    "            degree_grouped_counts_df.columns = ['Degree', 'Count']\n",
    "            print(f\"=== Counts by Degree ({name}) ===\")\n",
    "            print(degree_grouped_counts_df)\n",
    "            \n",
    "            # Save HTML table\n",
    "            # html_table = degree_grouped_counts_df.to_html(index=False)\n",
    "            # html_file_path = os.path.join(output_dir, f\"{name.lower()}_degree_counts.html\")\n",
    "            # with open(html_file_path, \"w\") as f:\n",
    "            #     f.write(html_table)\n",
    "            # print(f\"HTML table for {name} data saved to: {html_file_path}\")\n",
    "\n",
    "            # # Display in Jupyter if available\n",
    "            # if hasattr(IPython, 'get_ipython') and IPython.get_ipython() is not None:\n",
    "            #     display(HTML(html_table))\n",
    "\n",
    "            # # Visualizations\n",
    "            # def save_or_show_plot(fig, filename):\n",
    "            #     if save_plots:\n",
    "            #         fig.savefig(os.path.join(output_dir, f\"{name.lower()}_{filename}\"))\n",
    "            #     plt.close(fig)\n",
    "\n",
    "            # # Degree distribution\n",
    "            # fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            # sns.histplot(data['Degree'], bins=10, kde=False, ax=ax)\n",
    "            # ax.set_title(f'Degree Distribution ({name})')\n",
    "            # ax.set_xlabel('Degree')\n",
    "            # ax.set_ylabel('Frequency')\n",
    "            # save_or_show_plot(fig, \"degree_distribution.png\")\n",
    "\n",
    "            # # Other plots\n",
    "            # if 'Kinship_Coefficient' in data.columns:\n",
    "            #     fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            #     sns.histplot(data['Kinship_Coefficient'], bins=30, kde=True, ax=ax)\n",
    "            #     ax.set_title(f'Kinship Coefficient Distribution ({name})')\n",
    "            #     ax.set_xlabel('Kinship Coefficient')\n",
    "            #     ax.set_ylabel('Frequency')\n",
    "            #     save_or_show_plot(fig, \"kinship_coefficient_distribution.png\")\n",
    "\n",
    "            # if 'IBD2_Fraction' in data.columns:\n",
    "            #     fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            #     sns.histplot(data['IBD2_Fraction'], bins=30, kde=True, ax=ax)\n",
    "            #     ax.set_title(f'IBD2 Fraction Distribution ({name})')\n",
    "            #     ax.set_xlabel('IBD2 Fraction')\n",
    "            #     ax.set_ylabel('Frequency')\n",
    "            #     save_or_show_plot(fig, \"ibd2_fraction_distribution.png\")\n",
    "\n",
    "            # if all(col in data.columns for col in ['Kinship_Coefficient', 'IBD2_Fraction']):\n",
    "            #     fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            #     sns.scatterplot(\n",
    "            #         data=data,\n",
    "            #         x='Kinship_Coefficient',\n",
    "            #         y='IBD2_Fraction',\n",
    "            #         hue='Degree', palette='viridis', ax=ax\n",
    "            #     )\n",
    "            #     ax.set_title(f'Kinship vs. IBD2 Fraction ({name})')\n",
    "            #     ax.set_xlabel('Kinship Coefficient')\n",
    "            #     ax.set_ylabel('IBD2 Fraction')\n",
    "            #     plt.legend(title='Degree')\n",
    "            #     save_or_show_plot(fig, \"kinship_vs_ibd2_fraction.png\")\n",
    "\n",
    "            # # Correlation matrix\n",
    "            # numeric_cols = ['Kinship_Coefficient', 'IBD2_Fraction', 'Segment_Count']\n",
    "            # existing_cols = [col for col in numeric_cols if col in data.columns]\n",
    "            # if existing_cols:\n",
    "            #     fig, ax = plt.subplots(figsize=(6, 5))\n",
    "            #     corr = data[existing_cols].corr()\n",
    "            #     sns.heatmap(corr, annot=True, cmap='Blues', square=True, ax=ax)\n",
    "            #     ax.set_title(f'Correlation Matrix ({name})')\n",
    "            #     save_or_show_plot(fig, \"correlation_matrix.png\")\n",
    "\n",
    "    print(\"\\nAnalysis completed.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_segments_ibis(\n",
    "        results_directory, \n",
    "        filename=\"ibis_MergedSamples.seg\",\n",
    "        min_length=7, \n",
    "        min_markers=436, \n",
    "        max_error_density=0.004,\n",
    "        save_plots=True, \n",
    "        output_subdir=\"segments\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Explores and optionally filters the segments DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        results_directory (str): Directory containing the segments file.\n",
    "        filename (str): Filename of the segments file.\n",
    "        min_length (float): Minimum genetic length threshold for filtering.\n",
    "        min_markers (int): Minimum marker count threshold for filtering.\n",
    "        max_error_density (float): Maximum error density threshold for filtering.\n",
    "        filter_segments_enabled (bool): If True, apply filtering to the segments.\n",
    "        save_plots (bool): If True, save plots to the specified directory.\n",
    "        output_dir (str): Directory to save outputs and plots.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The segments DataFrame (filtered or unfiltered based on input).\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    output_dir = os.path.join(results_directory, output_subdir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Step 1: Read the segments file\n",
    "    file_path = os.path.join(results_directory, filename)\n",
    "    segments = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
    "    segments.columns = [\n",
    "        \"id1\", \"id2\", \"chromosome\", \"physical_position_start\", \n",
    "        \"physical_position_end\", \"IBD_type\", \"genetic_position_start\", \n",
    "        \"genetic_position_end\", \"genetic_length\", \"marker_count\", \n",
    "        \"error_count\", \"error_density\"\n",
    "    ]\n",
    "\n",
    "    # Ensure numeric columns are properly parsed\n",
    "    numeric_columns = [\"genetic_length\", \"marker_count\", \"error_density\", \"chromosome\"]\n",
    "    for col in numeric_columns:\n",
    "        if col in segments.columns:\n",
    "            segments[col] = pd.to_numeric(segments[col], errors='coerce')\n",
    "\n",
    "    # Drop rows with NaN values in numeric columns\n",
    "    nan_rows = segments[segments[numeric_columns].isnull().any(axis=1)]\n",
    "    if not nan_rows.empty:\n",
    "        nan_file_path = os.path.join(output_dir, \"nan_segments_ibis.csv\")\n",
    "        nan_rows.to_csv(nan_file_path, sep=\"\\t\", index=False)\n",
    "        print(f\"Rows with NaN values saved to: {nan_file_path}\")\n",
    "    segments = segments.dropna(subset=numeric_columns).reset_index(drop=True)\n",
    "\n",
    "    # Step 2: Basic info and descriptive statistics\n",
    "    print(\"=== Segments DataFrame Info ===\")\n",
    "    segments.info()\n",
    "    print(\"\\n=== Descriptive Statistics ===\")\n",
    "    print(segments[['genetic_length', 'marker_count', 'error_density']].describe())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Save the unfiltered data\n",
    "    unfiltered_file_path = os.path.join(output_dir, \"unfiltered_segments_ibis.csv\")\n",
    "    segments.to_csv(unfiltered_file_path, sep=\"\\t\", index=False)\n",
    "    print(f\"Unfiltered segments saved to: {unfiltered_file_path}\")\n",
    "    print()\n",
    "\n",
    "    filtered_segments = segments[\n",
    "        (segments['genetic_length'] >= min_length) &\n",
    "        (segments['marker_count'] >= min_markers) &\n",
    "        (segments['error_density'] <= max_error_density)\n",
    "    ].copy()\n",
    "    \n",
    "    print(\"=== Filtered Segments Info ===\")\n",
    "    filtered_segments.info()\n",
    "    print(\"\\n=== Descriptive Statistics (Filtered) ===\")\n",
    "    print(filtered_segments[['genetic_length', 'marker_count', 'error_density']].describe())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Save filtered segments to a new file\n",
    "    filtered_filename = \"filtered_segments_ibis.csv\"\n",
    "    filtered_file_path = os.path.join(output_dir, filtered_filename)\n",
    "    filtered_segments.to_csv(filtered_file_path, sep=\"\\t\", index=False)\n",
    "    print(f\"Filtered segments saved to: {filtered_file_path}\")\n",
    "\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total segments: {len(segments)}\")\n",
    "    print(f\"Filtered segments: {len(filtered_segments)}\")\n",
    "    if not nan_rows.empty:\n",
    "        print(f\"Rows with NaN values: {len(nan_rows)} (saved to: {nan_file_path})\")\n",
    "\n",
    "\n",
    "    # # Step 4: Visualizations\n",
    "    # def save_or_show_plot(fig, filename):\n",
    "    #     if save_plots:\n",
    "    #         fig.savefig(os.path.join(output_dir, filename))\n",
    "    #     plt.close(fig)\n",
    "\n",
    "    # def plot_distribution(data, column, title, xlabel, ylabel, filename, bins=30, kde=True):\n",
    "    #     fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    #     sns.histplot(data[column], bins=bins, kde=kde, ax=ax)\n",
    "    #     ax.set_title(title)\n",
    "    #     ax.set_xlabel(xlabel)\n",
    "    #     ax.set_ylabel(ylabel)\n",
    "    #     save_or_show_plot(fig, filename)\n",
    "\n",
    "    # # Visualize genetic_length distribution\n",
    "    # plot_distribution(\n",
    "    #     segments, \"genetic_length\", \"Distribution of Genetic Length\", \n",
    "    #     \"Genetic Length (cM)\", \"Frequency\", \"genetic_length_distribution_unfiltered.png\"\n",
    "    # )\n",
    "\n",
    "    # plot_distribution(\n",
    "    #     filtered_segments, \"genetic_length\", \"Distribution of Genetic Length (Filtered)\", \n",
    "    #     \"Genetic Length (cM)\", \"Frequency\", \"genetic_length_distribution_filtered.png\"\n",
    "    # )\n",
    "\n",
    "    # # Visualize marker_count distribution\n",
    "    # plot_distribution(\n",
    "    #     segments, \"marker_count\", \"Distribution of Marker Count\", \n",
    "    #     \"Marker Count\", \"Frequency\", \"marker_count_distribution_unfiltered.png\"\n",
    "    # )\n",
    "    # plot_distribution(\n",
    "    #     filtered_segments, \"marker_count\", \"Distribution of Marker Count (Filtered)\", \n",
    "    #     \"Marker Count\", \"Frequency\", \"marker_count_distribution_filtered.png\"\n",
    "    # )\n",
    "\n",
    "    # # Boxplot of genetic_length by chromosome\n",
    "    # def plot_boxplot(data, x_col, y_col, title, xlabel, ylabel, filename):\n",
    "    #     fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    #     sns.boxplot(x=x_col, y=y_col, data=data, ax=ax)\n",
    "    #     ax.set_title(title)\n",
    "    #     ax.set_xlabel(xlabel)\n",
    "    #     ax.set_ylabel(ylabel)\n",
    "    #     plt.xticks(rotation=45)\n",
    "    #     plt.tight_layout()\n",
    "    #     save_or_show_plot(fig, filename)\n",
    "\n",
    "    # plot_boxplot(\n",
    "    #     segments, \"chromosome\", \"genetic_length\", \n",
    "    #     \"Distribution of Genetic Length by Chromosome\", \n",
    "    #     \"Chromosome\", \"Genetic Length (cM)\", \"genetic_length_by_chromosome_unfiltered.png\"\n",
    "    # )\n",
    "    # plot_boxplot(\n",
    "    #     filtered_segments, \"chromosome\", \"genetic_length\", \n",
    "    #     \"Distribution of Genetic Length by Chromosome (Filtered)\", \n",
    "    #     \"Chromosome\", \"Genetic Length (cM)\", \"genetic_length_by_chromosome_filtered.png\"\n",
    "    # )\n",
    "\n",
    "    print(\"\\nAnalysis completed.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if ibis_completion == True:\n",
    "            explore_coefficients(results_directory, filename=\"ibis_MergedSamples.coef\", focus_on_related=True)\n",
    "            \n",
    "            explore_segments_ibis(\n",
    "                results_directory, \n",
    "                filename=\"ibis_MergedSamples.seg\",\n",
    "                min_length=7, \n",
    "                min_markers=436, \n",
    "                max_error_density=0.004,\n",
    "                save_plots=True, \n",
    "                output_subdir=\"segments\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
