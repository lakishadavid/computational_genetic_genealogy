{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9a43fe",
   "metadata": {},
   "source": [
    "Bonsai: Robust Pedigree Reconstruction Exploration\n",
    "\n",
    "This notebook provides a comprehensive exploration of the Bonsai algorithm\n",
    "\n",
    "for reconstructing pedigrees from genetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from matplotlib.colors import to_rgba\n",
    "import matplotlib.patches as mpatches\n",
    "import sys\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Assuming utils.bonsaitree.bonsaitree.v3 is properly installed\n",
    "from utils.bonsaitree.bonsaitree.v3 import bonsai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c020c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# 1. Data Preparation #\n",
    "#######################\n",
    "\n",
    "def load_genetic_data(seg_file, fam_file, dict_file=None):\n",
    "    \"\"\"\n",
    "    Load and prepare genetic data from .seg, .fam, and optional dict files.\n",
    "    \n",
    "    Args:\n",
    "        seg_file: Path to the .seg file\n",
    "        fam_file: Path to the .fam file\n",
    "        dict_file: Path to the ID mapping file (optional)\n",
    "    \n",
    "    Returns:\n",
    "        seg_df: DataFrame with segment data\n",
    "        individuals: Dictionary of individual metadata\n",
    "        individual_to_bonsai: Mapping from original IDs to Bonsai IDs\n",
    "    \"\"\"\n",
    "    # Load the ID mapping if provided\n",
    "    individual_to_bonsai = {}\n",
    "    if dict_file and os.path.exists(dict_file):\n",
    "        print(f\"Loading ID mapping from {dict_file}\")\n",
    "        try:\n",
    "            with open(dict_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    if len(parts) == 2:\n",
    "                        individual_id, bonsai_id = parts\n",
    "                        individual_to_bonsai[individual_id] = int(bonsai_id)\n",
    "            print(f\"Loaded {len(individual_to_bonsai)} ID mappings\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading ID mapping: {e}\")\n",
    "    \n",
    "    # Read the seg file\n",
    "    seg_df = pd.read_csv(seg_file, sep=\"\\t\", header=None)\n",
    "    if len(seg_df.columns) == 9:\n",
    "        seg_df.columns = [\"sample1\", \"sample2\", \"chrom\", \"phys_start\", \"phys_end\", \n",
    "                          \"ibd_type\", \"gen_start\", \"gen_end\", \"gen_seg_len\"]\n",
    "    else:\n",
    "        print(f\"Warning: Unexpected number of columns in seg file: {len(seg_df.columns)}\")\n",
    "        print(\"Columns found:\", seg_df.columns)\n",
    "        return None, None, None\n",
    "    \n",
    "    # Extract unique individuals from seg file\n",
    "    unique_individuals_from_seg = set(seg_df[\"sample1\"]).union(set(seg_df[\"sample2\"]))\n",
    "    print(f\"Number of unique individuals in seg file: {len(unique_individuals_from_seg)}\")\n",
    "    \n",
    "    # Read the fam file to get individual metadata\n",
    "    individuals = {}\n",
    "    try:\n",
    "        with open(fam_file, 'r') as file:\n",
    "            fam_lines = file.readlines()\n",
    "        \n",
    "        # Process each line in the fam file\n",
    "        for line in fam_lines:\n",
    "            fields = line.strip().split()\n",
    "            if len(fields) < 6:\n",
    "                continue\n",
    "                \n",
    "            family_id = fields[0]\n",
    "            individual_id = fields[1]\n",
    "            \n",
    "            # Skip individuals not present in the ID mapping if using a mapping\n",
    "            if individual_to_bonsai and individual_id not in individual_to_bonsai:\n",
    "                continue\n",
    "                \n",
    "            father_id = fields[2]\n",
    "            mother_id = fields[3]\n",
    "            sex = 'M' if fields[4] == '1' else 'F'\n",
    "            \n",
    "            # Extract generation using regex\n",
    "            match = re.search(r'g(\\d+)-', individual_id)\n",
    "            generation = int(match.group(1)) if match else None\n",
    "            \n",
    "            # Store the individual information\n",
    "            individuals[individual_id] = {\n",
    "                'family_id': family_id,\n",
    "                'father_id': father_id,\n",
    "                'mother_id': mother_id,\n",
    "                'sex': sex,\n",
    "                'generation': generation\n",
    "            }\n",
    "        \n",
    "        print(f\"Loaded metadata for {len(individuals)} individuals from FAM file\")\n",
    "        \n",
    "        # Print a sample of the individuals dictionary\n",
    "        sample_keys = list(individuals.keys())[:3]\n",
    "        print(\"\\nSample of individuals data:\")\n",
    "        for key in sample_keys:\n",
    "            print(f\"{key}: {individuals[key]}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        generations = {}\n",
    "        for ind_id, info in individuals.items():\n",
    "            gen = info.get('generation')\n",
    "            if gen:\n",
    "                generations[gen] = generations.get(gen, 0) + 1\n",
    "        \n",
    "        print(\"\\nIndividuals by generation:\")\n",
    "        for gen, count in sorted(generations.items()):\n",
    "            print(f\"Generation {gen}: {count} individuals\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading FAM file: {e}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    return seg_df, individuals, individual_to_bonsai\n",
    "\n",
    "def create_bioinfo(individuals, individual_to_bonsai):\n",
    "    \"\"\"\n",
    "    Create bioinfo list for Bonsai with ages assigned based on generation.\n",
    "    \n",
    "    Args:\n",
    "        individuals: Dictionary of individual metadata\n",
    "        individual_to_bonsai: Mapping of original IDs to Bonsai IDs\n",
    "    \n",
    "    Returns:\n",
    "        bioinfo: List of dictionaries with individual metadata for Bonsai\n",
    "    \"\"\"\n",
    "    # Check if we have generation information\n",
    "    has_generation_info = any('generation' in info and info['generation'] is not None \n",
    "                             for info in individuals.values())\n",
    "    \n",
    "    if not has_generation_info:\n",
    "        print(\"Warning: No generation information found in individuals data\")\n",
    "        return []\n",
    "    \n",
    "    # Get generation range\n",
    "    generations = [info['generation'] for info in individuals.values() \n",
    "                  if 'generation' in info and info['generation'] is not None]\n",
    "    \n",
    "    if not generations:\n",
    "        print(\"Warning: No valid generation values found\")\n",
    "        return []\n",
    "    \n",
    "    latest_generation = max(generations)\n",
    "    earliest_generation = min(generations)\n",
    "    print(f\"Generation range: {earliest_generation} to {latest_generation}\")\n",
    "    \n",
    "    # Assign ages based on generation\n",
    "    for individual_id, info in individuals.items():\n",
    "        generation = info.get('generation')\n",
    "        if generation is None:\n",
    "            # Skip individuals without generation info\n",
    "            continue\n",
    "            \n",
    "        if generation == latest_generation:\n",
    "            # Latest generation: ages 18-40\n",
    "            info['age'] = random.randint(18, 40)\n",
    "        else:\n",
    "            # Earlier generations: older based on generation gap\n",
    "            gen_gap = latest_generation - generation\n",
    "            min_age = 25 + (gen_gap * 20)\n",
    "            max_age = 40 + (gen_gap * 20)\n",
    "            info['age'] = random.randint(min_age, max_age)\n",
    "    \n",
    "    # Create bioinfo list for Bonsai\n",
    "    bioinfo = []\n",
    "    for individual_id, info in individuals.items():\n",
    "        if 'generation' in info and info['generation'] is not None:\n",
    "            if individual_id in individual_to_bonsai:\n",
    "                bonsai_id = individual_to_bonsai[individual_id]\n",
    "                age = info.get('age', 30)  # Default age if not calculated\n",
    "                sex = info.get('sex', 'U')  # Default sex if not available\n",
    "                bioinfo.append({'genotype_id': bonsai_id, 'age': age, 'sex': sex})\n",
    "    \n",
    "    return bioinfo\n",
    "\n",
    "def create_ibd_segment_list(seg_df):\n",
    "    \"\"\"Create an unphased IBD segment list for Bonsai from the segment dataframe.\"\"\"\n",
    "    unphased_ibd_seg_list = []\n",
    "    \n",
    "    for _, row in seg_df.iterrows():\n",
    "        try:\n",
    "            id1 = int(row['sample1'])\n",
    "            id2 = int(row['sample2'])\n",
    "            chrom = str(row['chrom'])\n",
    "            start_bp = float(row['phys_start'])\n",
    "            end_bp = float(row['phys_end'])\n",
    "            is_full = row['ibd_type'] == 2  # Assuming IBD2 indicates \"full\" sharing\n",
    "            len_cm = float(row['gen_seg_len'])\n",
    "            \n",
    "            unphased_ibd_seg_list.append([id1, id2, chrom, start_bp, end_bp, is_full, len_cm])\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing segment: {e}\")\n",
    "    \n",
    "    return unphased_ibd_seg_list\n",
    "\n",
    "##########################\n",
    "# 2. Community Detection #\n",
    "##########################\n",
    "\n",
    "def detect_communities(ibd_seg_list, bioinfo, resolution=1.0, min_community_size=10):\n",
    "    \"\"\"\n",
    "    Detect communities using Louvain algorithm to divide the dataset.\n",
    "    \n",
    "    Args:\n",
    "        ibd_seg_list: List of IBD segments\n",
    "        bioinfo: List of individual metadata\n",
    "        resolution: Resolution parameter for Louvain (higher = smaller communities)\n",
    "        min_community_size: Minimum community size to keep\n",
    "    \n",
    "    Returns:\n",
    "        communities: List of detected communities (sets of individual IDs)\n",
    "    \"\"\"\n",
    "    # Create a graph from IBD segments\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes for all individuals in bioinfo\n",
    "    genotype_ids = [info['genotype_id'] for info in bioinfo]\n",
    "    G.add_nodes_from(genotype_ids)\n",
    "    \n",
    "    # Add edges weighted by IBD sharing\n",
    "    edge_weights = defaultdict(float)\n",
    "    for segment in ibd_seg_list:\n",
    "        id1, id2 = segment[0], segment[1]\n",
    "        cm_length = segment[6]  # Length in centiMorgans\n",
    "        edge_weights[(id1, id2)] += cm_length\n",
    "    \n",
    "    # Add all edges to the graph\n",
    "    for (id1, id2), weight in edge_weights.items():\n",
    "        G.add_edge(id1, id2, weight=weight)\n",
    "    \n",
    "    # Find communities using Louvain\n",
    "    try:\n",
    "        communities = list(nx.community.louvain_communities(G, resolution=resolution, weight='weight'))\n",
    "        \n",
    "        # Filter out communities that are too small\n",
    "        communities = [comm for comm in communities if len(comm) >= min_community_size]\n",
    "        \n",
    "        print(f\"Detected {len(communities)} communities\")\n",
    "        for i, community in enumerate(communities):\n",
    "            print(f\"Community {i+1}: {len(community)} members\")\n",
    "        \n",
    "        return communities\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting communities: {e}\")\n",
    "        # If community detection fails, return a single community with all individuals\n",
    "        print(\"Falling back to using all individuals as one community\")\n",
    "        return [set(genotype_ids)]\n",
    "\n",
    "def filter_for_community(community, bioinfo, ibd_seg_list):\n",
    "    \"\"\"Filter bioinfo and IBD segments for a specific community.\"\"\"\n",
    "    # Filter bioinfo\n",
    "    community_bioinfo = [info for info in bioinfo if info['genotype_id'] in community]\n",
    "    \n",
    "    # Filter IBD segments\n",
    "    community_ibd = []\n",
    "    for seg in ibd_seg_list:\n",
    "        id1, id2 = seg[0], seg[1]\n",
    "        if id1 in community and id2 in community:\n",
    "            community_ibd.append(seg)\n",
    "    \n",
    "    return community_bioinfo, community_ibd\n",
    "\n",
    "def visualize_communities(G, communities, output_file=None, figsize=(12, 12)):\n",
    "    \"\"\"Visualize communities in a graph.\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Create a colormap for communities\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(communities)))\n",
    "    \n",
    "    # Assign community colors to nodes\n",
    "    node_colors = []\n",
    "    for node in G.nodes():\n",
    "        for i, community in enumerate(communities):\n",
    "            if node in community:\n",
    "                node_colors.append(colors[i])\n",
    "                break\n",
    "        else:\n",
    "            # If node isn't in any community\n",
    "            node_colors.append((0.7, 0.7, 0.7, 0.5))\n",
    "    \n",
    "    # Create color patches for legend\n",
    "    patches = []\n",
    "    for i, color in enumerate(colors):\n",
    "        patches.append(mpatches.Patch(color=color, label=f'Community {i+1}'))\n",
    "    \n",
    "    # Apply layout - try different options depending on graph size\n",
    "    if len(G.nodes()) > 500:\n",
    "        print(\"Using sfdp layout for large graph...\")\n",
    "        try:\n",
    "            pos = nx.nx_agraph.graphviz_layout(G, prog='sfdp')\n",
    "        except:\n",
    "            print(\"Graphviz sfdp layout failed, falling back to spring layout\")\n",
    "            pos = nx.spring_layout(G, k=0.3, iterations=50, seed=42)\n",
    "    else:\n",
    "        try:\n",
    "            # For smaller graphs try neato first\n",
    "            pos = nx.nx_agraph.graphviz_layout(G, prog='neato')\n",
    "        except:\n",
    "            print(\"Graphviz layout failed, falling back to spring layout\")\n",
    "            pos = nx.spring_layout(G, k=0.3, iterations=50, seed=42)\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=50, alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos, width=0.5, alpha=0.3)\n",
    "    \n",
    "    plt.title(\"IBD Network Communities\", fontsize=16)\n",
    "    plt.legend(handles=patches, loc='upper right')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Network visualization saved to {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "##########################\n",
    "# 3. Running Bonsai      #\n",
    "##########################\n",
    "\n",
    "def run_bonsai(bioinfo, ibd_seg_list, min_seg_len=3, restrict_connections=False, \n",
    "               verbose=True):\n",
    "    \"\"\"Run Bonsai with the given parameters.\"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Running Bonsai with {len(bioinfo)} individuals, {len(ibd_seg_list)} segments\")\n",
    "        print(f\"Min segment length: {min_seg_len} cM\")\n",
    "        print(f\"Restrict connections: {restrict_connections}\")\n",
    "    \n",
    "    try:\n",
    "        up_dict_log_like_list = bonsai.build_pedigree(\n",
    "            bio_info=bioinfo,\n",
    "            unphased_ibd_seg_list=ibd_seg_list,\n",
    "            min_seg_len=min_seg_len,\n",
    "            restrict_connection_points=restrict_connections\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Bonsai generated {len(up_dict_log_like_list)} pedigrees\")\n",
    "        \n",
    "        return up_dict_log_like_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error running Bonsai: {e}\")\n",
    "        return []\n",
    "\n",
    "##########################\n",
    "# 4. Pedigree Analysis   #\n",
    "##########################\n",
    "\n",
    "def visualize_pedigree(pedigree, bioinfo, output_file=None, figsize=(15, 10)):\n",
    "    \"\"\"Visualize a pedigree as a directed graph.\"\"\"\n",
    "    # Create directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Create sex lookup\n",
    "    sex_lookup = {info['genotype_id']: info['sex'] for info in bioinfo}\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for child, parents in pedigree.items():\n",
    "        # Add child node\n",
    "        is_real = isinstance(child, int) and child > 0\n",
    "        G.add_node(child, is_real=is_real)\n",
    "        \n",
    "        for parent in parents:\n",
    "            G.add_node(parent, is_real=isinstance(parent, int) and parent > 0)\n",
    "            G.add_edge(parent, child)  # Parent to child direction\n",
    "    \n",
    "    # Set node colors and shapes\n",
    "    node_colors = []\n",
    "    node_shapes = []\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        if G.nodes[node]['is_real']:\n",
    "            # Real individual: green\n",
    "            node_colors.append('green')\n",
    "        else:\n",
    "            # Inferred ancestor: white\n",
    "            node_colors.append('white')\n",
    "        \n",
    "        # Use shapes based on sex\n",
    "        if node in sex_lookup:\n",
    "            if sex_lookup[node] == 'M':\n",
    "                node_shapes.append('s')  # Square for male\n",
    "            elif sex_lookup[node] == 'F':\n",
    "                node_shapes.append('o')  # Circle for female\n",
    "            else:\n",
    "                node_shapes.append('d')  # Diamond for unknown\n",
    "        else:\n",
    "            node_shapes.append('d')  # Diamond for inferred ancestors\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Calculate layout (hierarchical)\n",
    "    try:\n",
    "        pos = nx.nx_agraph.graphviz_layout(G, prog='dot')\n",
    "    except:\n",
    "        # Fallback to spring layout if graphviz not available\n",
    "        print(\"Graphviz not available, using spring layout instead\")\n",
    "        pos = nx.spring_layout(G, scale=2)\n",
    "    \n",
    "    # Draw the graph\n",
    "    for shape in set(node_shapes):\n",
    "        nodes = [node for i, node in enumerate(G.nodes()) if node_shapes[i] == shape]\n",
    "        colors = [color for i, color in enumerate(node_colors) if node_shapes[i] == shape]\n",
    "        \n",
    "        if shape == 's':  # Square (male)\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=nodes, node_color=colors, \n",
    "                                  node_shape='s', node_size=500)\n",
    "        elif shape == 'o':  # Circle (female)\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=nodes, node_color=colors, \n",
    "                                  node_shape='o', node_size=500)\n",
    "        else:  # Diamond (unknown)\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=nodes, node_color=colors, \n",
    "                                  node_shape='d', node_size=500)\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, arrows=True)\n",
    "    \n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(G, pos)\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10, label='Real (female)'),\n",
    "        plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='green', markersize=10, label='Real (male)'),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='white', markersize=10, label='Inferred (female)'),\n",
    "        plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='white', markersize=10, label='Inferred (male)'),\n",
    "        plt.Line2D([0], [0], marker='d', color='w', markerfacecolor='white', markersize=10, label='Unknown sex')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.title(\"Reconstructed Pedigree\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Pedigree visualization saved to {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def pedigree_statistics(pedigree, bioinfo):\n",
    "    \"\"\"Calculate and display statistics about a pedigree.\"\"\"\n",
    "    # Count individuals by type\n",
    "    real_individuals = [node for node in pedigree.keys() if isinstance(node, int) and node > 0]\n",
    "    inferred_ancestors = [node for node in pedigree.keys() if isinstance(node, int) and node < 0]\n",
    "    \n",
    "    print(f\"Pedigree has {len(real_individuals)} real individuals\")\n",
    "    print(f\"Pedigree has {len(inferred_ancestors)} inferred ancestors\")\n",
    "    \n",
    "    # Analyze pedigree depth (maximum generations)\n",
    "    max_depth = 0\n",
    "    for node in real_individuals:\n",
    "        depth = 0\n",
    "        current = node\n",
    "        visited = set()  # To avoid infinite loops in case of cycles\n",
    "        while current in pedigree and pedigree[current] and current not in visited:\n",
    "            visited.add(current)\n",
    "            # Get first parent\n",
    "            parent = list(pedigree[current].keys())[0]\n",
    "            current = parent\n",
    "            depth += 1\n",
    "        max_depth = max(max_depth, depth)\n",
    "    \n",
    "    print(f\"Maximum depth in the pedigree: {max_depth} generations\")\n",
    "    \n",
    "    # Find sibling groups\n",
    "    siblings = {}\n",
    "    for child, parents in pedigree.items():\n",
    "        if not parents:  # Skip nodes with no parents\n",
    "            continue\n",
    "        \n",
    "        # Convert parents to a hashable key\n",
    "        parent_key = frozenset(parents.keys())\n",
    "        if parent_key not in siblings:\n",
    "            siblings[parent_key] = []\n",
    "        siblings[parent_key].append(child)\n",
    "    \n",
    "    # Count sibling groups with at least 2 siblings\n",
    "    sibling_groups = [children for children in siblings.values() if len(children) >= 2]\n",
    "    print(f\"Found {len(sibling_groups)} sibling groups\")\n",
    "    \n",
    "    real_sibling_groups = []\n",
    "    for group in sibling_groups:\n",
    "        real_siblings = [s for s in group if isinstance(s, int) and s > 0]\n",
    "        if len(real_siblings) >= 2:\n",
    "            real_sibling_groups.append(real_siblings)\n",
    "    \n",
    "    print(f\"Found {len(real_sibling_groups)} real sibling groups\")\n",
    "    \n",
    "    return {\n",
    "        \"real_individuals\": len(real_individuals),\n",
    "        \"inferred_ancestors\": len(inferred_ancestors),\n",
    "        \"max_depth\": max_depth,\n",
    "        \"sibling_groups\": len(sibling_groups),\n",
    "        \"real_sibling_groups\": len(real_sibling_groups)\n",
    "    }\n",
    "\n",
    "###########################\n",
    "# 5. Main Analysis Flow   #\n",
    "###########################\n",
    "\n",
    "def run_bonsai_analysis(seg_file, fam_file, dict_file=None, output_dir=\"bonsai_results\", \n",
    "                        community_index=0, resolution=1.0):\n",
    "    \"\"\"\n",
    "    Run a complete Bonsai analysis pipeline.\n",
    "    \n",
    "    Args:\n",
    "        seg_file: Path to the .seg file\n",
    "        fam_file: Path to the .fam file\n",
    "        dict_file: Path to the ID mapping file (optional)\n",
    "        output_dir: Directory to save results\n",
    "        community_index: Index of community to analyze (0-based)\n",
    "        resolution: Resolution parameter for community detection\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"1. Loading genetic data...\")\n",
    "    seg_df, individuals, individual_to_bonsai = load_genetic_data(seg_file, fam_file, dict_file)\n",
    "    if seg_df is None or individuals is None:\n",
    "        print(\"Error loading data. Exiting.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n2. Creating bioinfo...\")\n",
    "    bioinfo = create_bioinfo(individuals, individual_to_bonsai)\n",
    "    print(f\"Created bioinfo for {len(bioinfo)} individuals\")\n",
    "    \n",
    "    if len(bioinfo) == 0:\n",
    "        print(\"Error: No valid bioinfo created. Check your FAM file format.\")\n",
    "        return None\n",
    "    \n",
    "    # Sample of the bioinfo data\n",
    "    print(\"\\nSample of bioinfo data:\")\n",
    "    for i in range(min(3, len(bioinfo))):\n",
    "        print(bioinfo[i])\n",
    "    \n",
    "    print(\"\\n3. Creating IBD segment list...\")\n",
    "    ibd_seg_list = create_ibd_segment_list(seg_df)\n",
    "    print(f\"Created {len(ibd_seg_list)} IBD segments\")\n",
    "    \n",
    "    # Sample of IBD segment list\n",
    "    print(\"\\nSample of IBD segments:\")\n",
    "    for i in range(min(3, len(ibd_seg_list))):\n",
    "        print(ibd_seg_list[i])\n",
    "    \n",
    "    print(\"\\n4. Detecting communities...\")\n",
    "    communities = detect_communities(ibd_seg_list, bioinfo, resolution=resolution)\n",
    "    \n",
    "    if not communities:\n",
    "        print(\"No communities detected. Using all individuals as one community.\")\n",
    "        genotype_ids = [info['genotype_id'] for info in bioinfo]\n",
    "        communities = [set(genotype_ids)]\n",
    "    \n",
    "    # Visualize communities\n",
    "    print(\"\\n5. Visualizing communities...\")\n",
    "    # Create graph for visualization\n",
    "    G = nx.Graph()\n",
    "    for segment in ibd_seg_list:\n",
    "        id1, id2 = segment[0], segment[1]\n",
    "        cm_length = segment[6]  # Length in centiMorgans\n",
    "        if G.has_edge(id1, id2):\n",
    "            G[id1][id2]['weight'] += cm_length\n",
    "        else:\n",
    "            G.add_edge(id1, id2, weight=cm_length)\n",
    "\n",
    "    visualize_communities(G, communities, \n",
    "                         output_file=os.path.join(output_dir, \"communities.png\"))\n",
    "    \n",
    "    # Select a community to analyze\n",
    "    if community_index >= len(communities):\n",
    "        print(f\"Warning: Community index {community_index} out of range. Using first community.\")\n",
    "        community_index = 0\n",
    "    \n",
    "    selected_community = communities[community_index]\n",
    "    print(f\"\\n6. Selected community {community_index + 1} with {len(selected_community)} individuals\")\n",
    "    \n",
    "    # Filter data for the selected community\n",
    "    community_bioinfo, community_ibd = filter_for_community(selected_community, bioinfo, ibd_seg_list)\n",
    "    \n",
    "    print(\"\\n7. Running Bonsai on selected community...\")\n",
    "    up_dict_log_like_list = run_bonsai(community_bioinfo, community_ibd)\n",
    "    \n",
    "    if up_dict_log_like_list:\n",
    "        # Analyze the best pedigree\n",
    "        best_pedigree = up_dict_log_like_list[0][0]\n",
    "        best_likelihood = up_dict_log_like_list[0][1]\n",
    "        \n",
    "        print(f\"\\n8. Analyzing best pedigree (Log-likelihood: {best_likelihood:.2f})...\")\n",
    "        stats = pedigree_statistics(best_pedigree, community_bioinfo)\n",
    "        \n",
    "        # Visualize the pedigree\n",
    "        visualize_pedigree(best_pedigree, community_bioinfo, \n",
    "                          output_file=os.path.join(output_dir, \"best_pedigree.png\"))\n",
    "        \n",
    "        # Try variations for comparison\n",
    "        print(\"\\n9. Trying different parameters...\")\n",
    "        \n",
    "        # With higher min_seg_len\n",
    "        print(\"\\nRunning with min_seg_len=7...\")\n",
    "        up_dict_log_like_list_7cm = run_bonsai(\n",
    "            community_bioinfo, community_ibd, min_seg_len=7, verbose=False\n",
    "        )\n",
    "        \n",
    "        # With restricted connections\n",
    "        print(\"\\nRunning with restricted connections...\")\n",
    "        up_dict_log_like_list_restricted = run_bonsai(\n",
    "            community_bioinfo, community_ibd, restrict_connections=True, verbose=False\n",
    "        )\n",
    "        \n",
    "        print(\"\\nResults comparison:\")\n",
    "        print(f\"Default settings: {len(up_dict_log_like_list)} pedigrees\")\n",
    "        print(f\"Min segment 7cM: {len(up_dict_log_like_list_7cm)} pedigrees\")\n",
    "        print(f\"Restricted connections: {len(up_dict_log_like_list_restricted)} pedigrees\")\n",
    "        \n",
    "        # Save the best pedigree\n",
    "        pedigree_file = os.path.join(output_dir, \"best_pedigree.json\")\n",
    "        with open(pedigree_file, 'w') as f:\n",
    "            # Convert any non-string keys to strings for JSON\n",
    "            str_pedigree = {}\n",
    "            for key, value in best_pedigree.items():\n",
    "                str_key = str(key)\n",
    "                str_value = {}\n",
    "                for sub_key, sub_value in value.items():\n",
    "                    str_value[str(sub_key)] = sub_value\n",
    "                str_pedigree[str_key] = str_value\n",
    "            \n",
    "            json.dump(str_pedigree, f, indent=2)\n",
    "            print(f\"\\nSaved best pedigree to {pedigree_file}\")\n",
    "        \n",
    "        return {\n",
    "            \"bioinfo\": bioinfo,\n",
    "            \"community_bioinfo\": community_bioinfo,\n",
    "            \"ibd_seg_list\": ibd_seg_list,\n",
    "            \"community_ibd\": community_ibd,\n",
    "            \"communities\": communities,\n",
    "            \"best_pedigree\": best_pedigree,\n",
    "            \"best_likelihood\": best_likelihood\n",
    "        }\n",
    "    else:\n",
    "        print(\"No pedigrees were generated by Bonsai.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7fddb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading genetic data...\n",
      "Loading ID mapping from ../data/class_data/ped_sim_run2.seg_dict.txt\n",
      "Loaded 520 ID mappings\n",
      "Number of unique individuals in seg file: 520\n",
      "Loaded metadata for 520 individuals from FAM file\n",
      "\n",
      "Sample of individuals data:\n",
      "FAM1_g1-b1-s1: {'family_id': 'FAM1', 'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 1}\n",
      "FAM1_g1-b1-i1: {'family_id': 'FAM1', 'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 1}\n",
      "FAM1_g2-b1-s1: {'family_id': 'FAM1', 'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 2}\n",
      "\n",
      "Individuals by generation:\n",
      "Generation 1: 20 individuals\n",
      "Generation 2: 40 individuals\n",
      "Generation 3: 80 individuals\n",
      "Generation 4: 120 individuals\n",
      "Generation 5: 160 individuals\n",
      "Generation 6: 100 individuals\n",
      "\n",
      "2. Creating bioinfo...\n",
      "Generation range: 1 to 6\n",
      "Created bioinfo for 520 individuals\n",
      "\n",
      "Sample of bioinfo data:\n",
      "{'genotype_id': 1000, 'age': 131, 'sex': 'F'}\n",
      "{'genotype_id': 1001, 'age': 126, 'sex': 'M'}\n",
      "{'genotype_id': 1002, 'age': 111, 'sex': 'F'}\n",
      "\n",
      "3. Creating IBD segment list...\n",
      "Created 183061 IBD segments\n",
      "\n",
      "Sample of IBD segments:\n",
      "[1000, 1003, '1', 817341.0, 44617788.0, False, 68.343071]\n",
      "[1000, 1003, '1', 44617789.0, 205983275.0, False, 131.810042]\n",
      "[1000, 1003, '1', 205983276.0, 242249428.0, False, 50.427756]\n",
      "\n",
      "4. Detecting communities...\n",
      "Detected 10 communities\n",
      "Community 1: 52 members\n",
      "Community 2: 52 members\n",
      "Community 3: 52 members\n",
      "Community 4: 52 members\n",
      "Community 5: 52 members\n",
      "Community 6: 52 members\n",
      "Community 7: 52 members\n",
      "Community 8: 52 members\n",
      "Community 9: 52 members\n",
      "Community 10: 52 members\n",
      "\n",
      "5. Selected community 1 with 52 individuals\n",
      "\n",
      "6. Running Bonsai on selected community...\n",
      "Running Bonsai with 52 individuals, 17819 segments\n",
      "Min segment length: 3 cM\n",
      "Restrict connections: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lakishadavid/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/druid.py:221: RuntimeWarning: divide by zero encountered in log\n",
      "  log_term = np.log(1 - np.exp(-np.exp(log_mu_amt)))\n",
      "/home/lakishadavid/computational_genetic_genealogy/.venv/lib/python3.12/site-packages/scipy/stats/_distn_infrastructure.py:2068: RuntimeWarning: divide by zero encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "/home/lakishadavid/computational_genetic_genealogy/.venv/lib/python3.12/site-packages/scipy/stats/_distn_infrastructure.py:2068: RuntimeWarning: invalid value encountered in divide\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dict_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/class_data/ped_sim_run2.seg_dict.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run the analysis on the first community\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_bonsai_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfam_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommunity_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 505\u001b[0m, in \u001b[0;36mrun_bonsai_analysis\u001b[0;34m(seg_file, fam_file, dict_file, output_dir, community_index, resolution)\u001b[0m\n\u001b[1;32m    502\u001b[0m community_bioinfo, community_ibd \u001b[38;5;241m=\u001b[39m filter_for_community(selected_community, bioinfo, ibd_seg_list)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m6. Running Bonsai on selected community...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 505\u001b[0m up_dict_log_like_list \u001b[38;5;241m=\u001b[39m \u001b[43mrun_bonsai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommunity_bioinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommunity_ibd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m up_dict_log_like_list:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;66;03m# Analyze the best pedigree\u001b[39;00m\n\u001b[1;32m    509\u001b[0m     best_pedigree \u001b[38;5;241m=\u001b[39m up_dict_log_like_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[10], line 269\u001b[0m, in \u001b[0;36mrun_bonsai\u001b[0;34m(bioinfo, ibd_seg_list, min_seg_len, restrict_connections, verbose)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestrict connections: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrestrict_connections\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     up_dict_log_like_list \u001b[38;5;241m=\u001b[39m \u001b[43mbonsai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_pedigree\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbio_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbioinfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43munphased_ibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_seg_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrict_connections\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBonsai generated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(up_dict_log_like_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pedigrees\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/bonsai.py:182\u001b[0m, in \u001b[0;36mbuild_pedigree\u001b[0;34m(bio_info, unphased_ibd_seg_list, phased_ibd_seg_list, condition_pair_set, min_seg_len, max_con_pts, restrict_connection_points, connect_up_only, max_peds, max_start_peds, db_fig_base_dir, true_ped, mean_bgd_num, mean_bgd_len)\u001b[0m\n\u001b[1;32m    179\u001b[0m condition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# build the pedigrees\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_up_dicts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx_to_up_dict_ll_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midx_to_up_dict_ll_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_to_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mid_to_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx_to_id_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midx_to_id_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphased_ibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpw_ll_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpw_ll_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_peds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_peds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_start_peds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_start_peds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_con_pts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_con_pts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnect_up_only\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconnect_up_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdb_fig_base_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdb_fig_base_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrue_ped\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrue_ped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# get the index of the pedigree that was built\u001b[39;00m\n\u001b[1;32m    200\u001b[0m idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39mresult][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/connections.py:1905\u001b[0m, in \u001b[0;36mcombine_up_dicts\u001b[0;34m(idx_to_up_dict_ll_list, id_to_idx, idx_to_id_set, ibd_seg_list, pw_ll_cls, condition, max_peds, max_start_peds, max_con_pts, min_seg_len, restrict_connection_points, connect_up_only, db_fig_base_dir, true_ped)\u001b[0m\n\u001b[1;32m   1902\u001b[0m     filled_up_dct1 \u001b[38;5;241m=\u001b[39m fill_in_partners(up_dct\u001b[38;5;241m=\u001b[39mup_dct1)\n\u001b[1;32m   1903\u001b[0m     filled_up_dct2 \u001b[38;5;241m=\u001b[39m fill_in_partners(up_dct\u001b[38;5;241m=\u001b[39mup_dct2)\n\u001b[0;32m-> 1905\u001b[0m     this_up_dct_ll_list \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_pedigrees\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mup_dct1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilled_up_dct1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mup_dct2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilled_up_dct2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpw_ll_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpw_ll_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_peds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_peds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_con_pts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_con_pts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_seg_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnect_up_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnect_up_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfig_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfig_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m     up_dct_ll_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m this_up_dct_ll_list\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# sort from most to least likely\u001b[39;00m\n",
      "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/connections.py:1646\u001b[0m, in \u001b[0;36mcombine_pedigrees\u001b[0;34m(up_dct1, up_dct2, pw_ll_cls, ibd_seg_list, condition, max_peds, max_con_pts, min_seg_len, restrict_connection_points, connect_up_only, fig_dir)\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;124;03mCombine pedigrees up_dct1 and up_dct2 through the top most likely\u001b[39;00m\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;124;03mdegrees and common ancestor pairs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;124;03m                   {node: {parent1 : deg1, parent2 : deg2}, ..}\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;66;03m# get a list of the form [[point1, point2, deg1, deg2, num_common_ancs, log_like], ...]\u001b[39;00m\n\u001b[0;32m-> 1646\u001b[0m anc_deg_log_like_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_connecting_points_degs_and_log_likes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mup_dct1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mup_dct2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpw_ll_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpw_ll_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_seg_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_con_pts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_con_pts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnect_up_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnect_up_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1658\u001b[0m ped_log_like_list : \u001b[38;5;28mlist\u001b[39m[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m   1659\u001b[0m ped_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/connections.py:1001\u001b[0m, in \u001b[0;36mget_connecting_points_degs_and_log_likes\u001b[0;34m(up_dct1, up_dct2, pw_ll_cls, ibd_seg_list, condition, min_seg_len, max_con_pts, restrict_connection_points, connect_up_only)\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m point1 \u001b[38;5;129;01min\u001b[39;00m con_pt_set1:\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m point2 \u001b[38;5;129;01min\u001b[39;00m con_pt_set2:\n\u001b[0;32m-> 1001\u001b[0m         connection_log_like_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_connection_degs_and_log_likes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpoint1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoint1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpoint2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoint2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m            \u001b[49m\u001b[43mup_dct1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m            \u001b[49m\u001b[43mup_dct2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpw_ll_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpw_ll_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m            \u001b[49m\u001b[43mphased_ibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIN_SEG_LEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m         info_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m con, log_like \u001b[38;5;129;01min\u001b[39;00m connection_log_like_list:\n",
      "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/connections.py:586\u001b[0m, in \u001b[0;36mget_connection_degs_and_log_likes\u001b[0;34m(point1, point2, up_dct1, up_dct2, pw_ll_cls, phased_ibd_seg_list, condition, min_seg_len, deg_range_delta)\u001b[0m\n\u001b[1;32m    582\u001b[0m     deg_range \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;66;03m# TODO: memoize the following call.\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;66;03m# TODO: This does not currently account for background IBD (mean_bgd_num and mean_bgd_len)\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m     est_deg, L_est \u001b[38;5;241m=\u001b[39m \u001b[43minfer_degree_generalized_druid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43manc_id1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manc_id1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43manc_id2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manc_id2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartner_id1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartner_id1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartner_id2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartner_id2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdir1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdir2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mup_dct1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mup_dct2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphased_ibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIN_SEG_LEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m     deg_range \u001b[38;5;241m=\u001b[39m get_deg_range(\n\u001b[1;32m    600\u001b[0m         deg\u001b[38;5;241m=\u001b[39mest_deg,\n\u001b[1;32m    601\u001b[0m         delta\u001b[38;5;241m=\u001b[39mdeg_range_delta,\n\u001b[1;32m    602\u001b[0m     )\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# get the relationships between each proximally-related\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# genotyped ID and anc_id1 and anc_id2.\u001b[39;00m\n",
      "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/druid.py:588\u001b[0m, in \u001b[0;36minfer_degree_generalized_druid\u001b[0;34m(anc_id1, anc_id2, partner_id1, partner_id2, dir1, dir2, up_dct1, up_dct2, ibd_seg_list, condition, min_seg_len)\u001b[0m\n\u001b[1;32m    545\u001b[0m id_set2 \u001b[38;5;241m=\u001b[39m id_set2 \u001b[38;5;241m|\u001b[39m p_id_set2\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# FIXFIX: [EDITED 2024-03-30] this has been fixed perhaps\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m#         as much as it is possible to fix it by merging\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m#         segments on the correct haplogytpe if id_set1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m#       satisfy A IBD to C and B IBD to D so the phase does matter and\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m#       we can't just squash the segment in A with the segment in B.\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m L_union \u001b[38;5;241m=\u001b[39m \u001b[43mget_total_ibd_between_id_sets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_set1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_set1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_set2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_set2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;66;03m# find the fraction of anc_id1's genome (or anc_id1 + partner_id1 if it has a partner)\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;66;03m# that is shared with its most proximal genotyped relatives\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;66;03m# The shared fraction is 1 - Pr(S^c), where S^c is the event that a given allele is not shared\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# so\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m#   Pr(S) = 1 - [(1-Pr(S|A)) + (1-Pr(S|B))]/2\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m partner_id1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/ibd.py:523\u001b[0m, in \u001b[0;36mget_total_ibd_between_id_sets\u001b[0;34m(id_set1, id_set2, ibd_seg_list)\u001b[0m\n\u001b[1;32m    521\u001b[0m     L_tot \u001b[38;5;241m=\u001b[39m L_tot0 \u001b[38;5;241m+\u001b[39m L_tot1\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 523\u001b[0m     merged_regions \u001b[38;5;241m=\u001b[39m \u001b[43mget_merged_regions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg_subset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     L_tot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([e\u001b[38;5;241m-\u001b[39ms \u001b[38;5;28;01mfor\u001b[39;00m c,s,e \u001b[38;5;129;01min\u001b[39;00m merged_regions])\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m L_tot\n",
      "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/ibd.py:424\u001b[0m, in \u001b[0;36mget_merged_regions\u001b[0;34m(ibd_seg_list)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ibd_seg_list \u001b[38;5;241m==\u001b[39m []:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m--> 424\u001b[0m ibd_seg_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m start_seg \u001b[38;5;241m=\u001b[39m ibd_seg_list[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    426\u001b[0m prev_chrom, prev_start, prev_end \u001b[38;5;241m=\u001b[39m start_seg[\u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m7\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    seg_file = \"../data/class_data/ped_sim_run2.seg\"\n",
    "    fam_file = \"../data/class_data/ped_sim_run2-everyone.fam\"\n",
    "    dict_file = \"../data/class_data/ped_sim_run2.seg_dict.txt\"\n",
    "    \n",
    "    # Run the analysis on the first community\n",
    "    results = run_bonsai_analysis(seg_file, fam_file, dict_file, community_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854fc006",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run jupyter nbconvert --to pdf Lab15_Explore_Bonsai.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
