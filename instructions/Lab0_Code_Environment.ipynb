{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 0: Code Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Code Environments\n",
    "\n",
    "## What is a Code Environment?\n",
    "\n",
    "A **code environment** is the structured setup in which software applications run, including dependencies, libraries, and configurations necessary for execution. Code environments ensure that software behaves consistently across different machines and operating systems, preventing issues related to dependency conflicts and system inconsistencies.\n",
    "\n",
    "### Why Do Code Environments Matter?\n",
    "\n",
    "- **Reproducibility** – Ensures that code runs the same way across different systems, facilitating collaboration and research reproducibility.\n",
    "- **Dependency Management** – Prevents conflicts between different software packages by isolating dependencies.\n",
    "- **System Stability** – Protects the main operating system from unnecessary installations and modifications.\n",
    "- **Scalability** – Makes it easier to scale applications across multiple machines, cloud environments, or containerized deployments.\n",
    "\n",
    "## Virtual Environments with Poetry\n",
    "\n",
    "Our class is using **Poetry**, a modern dependency management tool for Python that simplifies package installation, versioning, and virtual environment creation. Poetry offers an elegant solution by combining dependency management and virtual environment creation into a single workflow.\n",
    "\n",
    "### Why Use Poetry?\n",
    "\n",
    "- **Automated Virtual Environments** – Poetry automatically creates and manages virtual environments for projects.\n",
    "- **Simplified Dependency Management** – Uses a `pyproject.toml` file instead of a `requirements.txt`, making package tracking more structured.\n",
    "- **Reproducibility** – The `poetry.lock` file ensures that everyone working on the project installs the exact same package versions.\n",
    "- **Seamless Package Publishing** – Poetry simplifies the process of building and publishing Python packages.\n",
    "\n",
    "### Key Poetry Commands\n",
    "\n",
    "| Command | Description |\n",
    "|---------|-------------|\n",
    "| `poetry new my_project` | Creates a new Poetry project with a `pyproject.toml` file |\n",
    "| `poetry install` | Installs dependencies and sets up the virtual environment |\n",
    "| `poetry add <package>` | Adds a new package to the project |\n",
    "| `poetry remove <package>` | Removes a package from the project |\n",
    "| `poetry shell` | Activates the project's virtual environment |\n",
    "| `poetry run <command>` | Runs a command inside the virtual environment |\n",
    "| `poetry lock` | Locks the dependencies to exact versions for consistency |\n",
    "\n",
    "## Docker: Containerized Code Environments\n",
    "\n",
    "While Poetry helps manage dependencies within Python projects, **Docker** provides an alternative approach by encapsulating an entire system environment, including the OS, into a container. Unlike virtual environments, which only manage dependencies at the application level, Docker offers a complete solution for deploying applications across different systems.\n",
    "\n",
    "### Key Features of Docker:\n",
    "- **Portability** – Containers run identically on any system with Docker installed.\n",
    "- **Isolation** – Each container runs independently, preventing dependency conflicts.\n",
    "- **Scalability** – Facilitates cloud-based and microservices architectures.\n",
    "\n",
    "### When to Use Poetry vs. Docker:\n",
    "\n",
    "| Feature            | Poetry (Virtual Environment) | Docker (Containerization) |\n",
    "|--------------------|---------------------------|--------------------------|\n",
    "| **Scope**         | Manages Python dependencies within a project | Encapsulates the entire OS and software stack |\n",
    "| **Reproducibility** | Ensures consistent package versions | Provides full OS-level consistency |\n",
    "| **Portability**   | Works across Python projects on the same system | Runs across different machines and cloud platforms |\n",
    "| **Resource Usage** | Lightweight | Slightly heavier due to system overhead |\n",
    "| **Best Use Case** | Managing dependencies for Python projects | Deploying applications in diverse environments |\n",
    "\n",
    "## Docker Environment: Ubuntu 22.04\n",
    "\n",
    "In our Docker setup, we are using **Ubuntu 22.04 (Jammy Jellyfish)** as the base environment. This ensures consistency across different systems and provides a stable, long-term support (LTS) release with security updates and package support until **April 2027**. \n",
    "\n",
    "### Why Use Ubuntu 22.04?\n",
    "\n",
    "- **Long-Term Support (LTS)** – Ubuntu 22.04 is an LTS release, ensuring reliability and security updates for an extended period.\n",
    "- **Stability and Compatibility** – It is widely used in cloud computing, machine learning, and development environments, making it an ideal choice for reproducible research and software deployment.\n",
    "- **Lightweight and Efficient** – The minimal Ubuntu image is optimized for running applications in containers without unnecessary overhead.\n",
    "- **Extensive Package Support** – Ubuntu provides access to a vast software ecosystem, ensuring compatibility with necessary tools and dependencies.\n",
    "\n",
    "By using **Ubuntu 22.04** within Docker, we establish a controlled environment that minimizes discrepancies between development, testing, and production systems, ensuring consistency and reproducibility in our work.\n",
    "\n",
    "## Ensuring You Are Using the Latest Docker Image\n",
    "\n",
    "To maintain consistency and take advantage of the most up-to-date dependencies and security patches, it is important to ensure you are running the latest version of the **Ubuntu 22.04**-based Docker image. This prevents issues caused by outdated packages and ensures alignment with the current development environment.\n",
    "\n",
    "### Pulling the Latest Image\n",
    "\n",
    "Before running a container, always pull the latest version of the image by executing:\n",
    "\n",
    "```\n",
    "docker pull lakishadavid/cgg_image:latest\n",
    "```\n",
    "\n",
    "This command fetches the most recent version of the **cgg_image**, ensuring you are using the most up-to-date environment.\n",
    "\n",
    "### Running the Docker Container\n",
    "\n",
    "Once you have pulled the latest image, start a container interactively with:\n",
    "\n",
    "```\n",
    "docker run -it lakishadavid/cgg_image:latest bash\n",
    "```\n",
    "\n",
    "This command:\n",
    "- **Runs** a new container from the latest image.\n",
    "- **Opens an interactive terminal (`-it`)** to allow direct interaction with the container.\n",
    "- **Launches a Bash shell** so you can execute commands within the container.\n",
    "\n",
    "By following these steps, you ensure that your development environment is always using the most recent and properly configured version of the image.\n",
    "\n",
    "## Exiting the Docker Container\n",
    "\n",
    "Once you have finished working inside the Docker container, you will need to exit properly. There are multiple ways to leave the container depending on whether you want to stop it entirely or keep it running in the background.\n",
    "\n",
    "### Exit and Stop the Container\n",
    "\n",
    "The most common way to exit a Docker container is by using the `exit` command:\n",
    "\n",
    "```\n",
    "exit\n",
    "```\n",
    "\n",
    "This will terminate the container and return you to your local terminal.\n",
    "\n",
    "### When Should You Stop a Container?\n",
    "\n",
    "Stopping a container is necessary when:\n",
    "- You **no longer need** the application or environment running.\n",
    "- You want to **free up system resources** being used by the container.\n",
    "- You need to **apply updates** or modifications before restarting the container.\n",
    "- You want to **preserve changes** made inside the container so they are available the next time you start it.\n",
    "\n",
    "If the container is still running in the background, you can stop it from your terminal using:\n",
    "\n",
    "```\n",
    "docker stop <container_id>\n",
    "```\n",
    "\n",
    "To ensure a clean development workflow, it is good practice to stop containers when they are no longer needed, rather than letting them consume system resources indefinitely.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "A well-structured code environment is essential for ensuring software **stability**, **reproducibility**, and **efficiency**. In our setup:\n",
    "- **Poetry** simplifies dependency and virtual environment management, ensuring consistency across Python projects.\n",
    "- **Docker** provides an isolated, reproducible system environment, making it ideal for deploying applications across different machines.\n",
    "\n",
    "Understanding when to use each tool helps streamline development workflows. **Poetry** is best suited for managing dependencies within a Python project, while **Docker** ensures complete system encapsulation for broader deployment and portability needs. By combining both tools effectively, we create an environment that supports seamless collaboration, minimal dependency conflicts, and efficient software deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responsibility for the Code Environment\n",
    "\n",
    "While I will maintain the **Docker environment**, the focus of this class is on **running and understanding the genomic analysis code itself**. The Docker image provides a controlled and reproducible environment, ensuring that all necessary dependencies are pre-installed and configured correctly. By using Docker, you eliminate potential compatibility issues and can focus on the **analysis and interpretation of genomic data**.\n",
    "\n",
    "### Choosing How to Maintain Your Code Environment\n",
    "\n",
    "Students have two options for managing their code environment:\n",
    "\n",
    "1. **Use the Provided Docker Image**  \n",
    "   - I will maintain and update the Docker image to ensure compatibility and reproducibility.\n",
    "   - If you encounter any issues while using Docker, I will troubleshoot and resolve the problem.\n",
    "   - Using the Docker environment ensures that you are working in the exact same setup as me and others using the image.\n",
    "\n",
    "2. **Maintain Your Own Code Environment**  \n",
    "   - If you choose **not to use Docker**, you are responsible for setting up and maintaining your own code environment.\n",
    "   - You must ensure that all dependencies are correctly installed and compatible with the provided code.\n",
    "   - If issues arise due to your custom environment, I will offer support, but it is ultimately your responsibility to resolve them.\n",
    "\n",
    "### Required Setup for Non-Docker Users\n",
    "\n",
    "If you choose to work **outside of Docker**, you must manually install the required dependencies. The following code blocks have already been completed **within the Docker image**, meaning Docker users **do not need to run them**. However, **non-Docker users must run the following setup commands themselves** to ensure their environment is configured correctly.\n",
    "\n",
    "#### Important Notes:\n",
    "- The provided code blocks assume you are running **Ubuntu 22.04**.\n",
    "- If you are using a different system, you must adapt the installation steps accordingly.\n",
    "- While I can answer general questions about dependencies, my responsibility is to **maintain the code base within the Docker image**. Your responsibility is to effectively use that image—**either by running it directly or by correctly configuring your own system.**\n",
    "\n",
    "Below are the commands that **non-Docker Ubuntu users must run** to set up their environment properly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to get your username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Detect current user\n",
    "USER_ID=$(id -u)\n",
    "USER_NAME=$(whoami)\n",
    "\n",
    "# Print environment debugging info\n",
    "echo \"🔹 Running as user: $USER_NAME (UID: $USER_ID)\"\n",
    "\n",
    "# # Always add user to sudo and plugdev groups\n",
    "# sudo usermod -aG sudo,plugdev $USER_NAME\n",
    "\n",
    "# # Check if the docker group exists before adding the user\n",
    "# if grep -q \"^docker:\" /etc/group; then\n",
    "#     sudo usermod -aG docker $USER_NAME\n",
    "#     echo \"✅ Added $USER_NAME to the docker group.\"\n",
    "# else\n",
    "#     echo \"⚠️ Docker is not installed. Skipping docker group.\"\n",
    "# fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Enable Passwordless sudo apt-get for Jupyter Notebook**\n",
    "\n",
    "To run `sudo apt-get` commands in Jupyter Notebook **without being prompted for a password**, follow these steps.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Find Your Username**\n",
    "Before proceeding, you need to determine your Linux username. To do this, run the following in your terminal window:\n",
    "\n",
    "```\n",
    "whoami\n",
    "```\n",
    "\n",
    "This will return your username. **Example Output:**\n",
    "```\n",
    "failingbird\n",
    "```\n",
    "\n",
    "In this example, the username is `failingbird`. The user would see `$HOME` defined as `/home/failingbird`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Add the Rule**\n",
    "Copy and paste the following command into your terminal:\n",
    "\n",
    "```\n",
    "echo \"$(whoami) ALL=(ALL) NOPASSWD: /usr/bin/apt-get, /usr/bin/dpkg, /usr/bin/apt, /bin/rm\" | sudo tee -a /etc/sudoers.d/$(whoami)\n",
    "```\n",
    "\n",
    "### **Example for Username `failingbird`**\n",
    "If your username was `failingbird`, you would run:\n",
    "\n",
    "```\n",
    "echo \"failingbird ALL=(ALL) NOPASSWD: /usr/bin/apt-get, /usr/bin/dpkg, /usr/bin/apt, /bin/rm\" | sudo tee -a /etc/sudoers.d/failingbird\n",
    "```\n",
    "\n",
    "This command adds a rule to allow **your user** to execute `sudo apt-get` and `sudo rm` commands without entering a password.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3: Verify the Change**\n",
    "Run the following command to confirm the rule was added successfully:\n",
    "\n",
    "```\n",
    "sudo cat /etc/sudoers.d/$(whoami)\n",
    "```\n",
    "\n",
    "### **Example for Username `failingbird`**\n",
    "```\n",
    "sudo cat /etc/sudoers.d/failingbird\n",
    "```\n",
    "\n",
    "If the output includes:\n",
    "\n",
    "```\n",
    "failingbird ALL=(ALL) NOPASSWD: /usr/bin/apt-get, /usr/bin/dpkg, /usr/bin/apt, /bin/rm\n",
    "```\n",
    "\n",
    "then the setup is correct.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 4: (Optional) Remove the Rule**\n",
    "If you ever need to **undo** this change and restore the default behavior (where a password is required for `sudo apt-get` and `sudo rm`), run:\n",
    "\n",
    "```\n",
    "sudo rm /etc/sudoers.d/$(whoami)\n",
    "```\n",
    "\n",
    "### **Example for Username `failingbird`**\n",
    "```\n",
    "sudo rm /etc/sudoers.d/failingbird\n",
    "```\n",
    "\n",
    "This will remove the rule and require a password for future `sudo apt-get` and `sudo rm` commands.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **You can now run system updates in Jupyter Notebook without entering a password!** 🚀\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required System Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update system packages\n",
    "\n",
    "!sudo apt-get update -y\n",
    "\n",
    "!sudo apt-get install -y --no-install-recommends \\\n",
    "    build-essential \\\n",
    "    g++ \\\n",
    "    gcc \\\n",
    "    make \\\n",
    "    python3 \\\n",
    "    python3-pip \\\n",
    "    python3-dev \\\n",
    "    graphviz \\\n",
    "    libfreetype-dev \\\n",
    "    pkg-config \\\n",
    "    libpng-dev \\\n",
    "    zlib1g-dev \\\n",
    "    libbz2-dev \\\n",
    "    libharfbuzz-dev \\\n",
    "    libcurl4-openssl-dev \\\n",
    "    libssl-dev \\\n",
    "    libxml2-dev \\\n",
    "    wget \\\n",
    "    curl \\\n",
    "    git \\\n",
    "    unzip \\\n",
    "    default-jre \\\n",
    "    gawk \\\n",
    "    libboost-all-dev \\\n",
    "    texlive-xetex \\\n",
    "    texlive-fonts-recommended \\\n",
    "    texlive-plain-generic \\\n",
    "    pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get clean\n",
    "!sudo rm -rf /var/lib/apt/lists/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ensure `~/.local/bin` is in Your PATH**\n",
    "\n",
    "Add `~/.local/bin` to your system `PATH` so that installed executables in this directory can be run from anywhere by running the following code block. This text explains what the following code block is doing:\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Ensure `~/.local` Exists**\n",
    "The following script ensures that the `~/.local` directory exists, creating it if necessary:\n",
    "\n",
    "```\n",
    "if [ ! -d \"$HOME/.local\" ]; then\n",
    "    mkdir -p \"$HOME/.local\"\n",
    "fi\n",
    "```\n",
    "\n",
    "This ensures that any tools installed to `~/.local/bin` have a proper location.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Add `~/.local/bin` to PATH**\n",
    "The script then checks if `~/.local/bin` is already in your `PATH`. If not, it appends the necessary export command to `~/.profile` and `~/.bashrc`:\n",
    "\n",
    "```\n",
    "if ! grep -q 'export PATH=\"$HOME/.local/bin:$PATH\"' \"$HOME/.profile\"; then\n",
    "    echo 'export PATH=\"$HOME/.local/bin:$PATH\"' >> \"$HOME/.profile\"\n",
    "    echo \"Added ~/.local/bin to PATH in ~/.profile\"\n",
    "fi\n",
    "\n",
    "if ! grep -q 'export PATH=\"$HOME/.local/bin:$PATH\"' \"$HOME/.bashrc\"; then\n",
    "    echo 'export PATH=\"$HOME/.local/bin:$PATH\"' >> \"$HOME/.bashrc\"\n",
    "    echo \"Added ~/.local/bin to PATH in ~/.bashrc\"\n",
    "fi\n",
    "```\n",
    "\n",
    "- `~/.profile` is updated to ensure `PATH` is modified for **login shells**.\n",
    "- `~/.bashrc` is updated to ensure `PATH` is modified for **interactive shells**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3: Apply Changes Immediately**\n",
    "After updating the files, the script applies the `PATH` update immediately for the current session:\n",
    "\n",
    "```\n",
    "export PATH=\"$HOME/.local/bin:$PATH\"\n",
    "```\n",
    "\n",
    "This ensures that any executables in `~/.local/bin` are immediately available **without requiring a logout or restart**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 4: Fix Ownership of `~/.local`**\n",
    "If the `~/.local` directory is owned by another user (which can happen due to certain installations), the script corrects its ownership:\n",
    "\n",
    "```\n",
    "CURRENT_USER=$(whoami)\n",
    "if [ \"$(stat -c '%U' \"$HOME/.local\")\" != \"$CURRENT_USER\" ]; then\n",
    "    echo \"Fixing ownership of $HOME/.local...\"\n",
    "    sudo chown -R \"$CURRENT_USER:$CURRENT_USER\" \"$HOME/.local\"\n",
    "fi\n",
    "```\n",
    "\n",
    "This ensures the current user has full permissions to modify the directory.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 5: Apply Changes Without Logging Out**\n",
    "To ensure changes take effect **immediately**, run:\n",
    "\n",
    "```\n",
    "source ~/.profile\n",
    "source ~/.bashrc\n",
    "```\n",
    "\n",
    "This reloads the profile and applies the new `PATH` settings without requiring a system restart.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Your system is now set up to use executables in `~/.local/bin` without manually specifying the full path!** 🚀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Ensure ~/.local exists\n",
    "if [ ! -d \"$HOME/.local\" ]; then\n",
    "    mkdir -p \"$HOME/.local\"\n",
    "fi\n",
    "\n",
    "# Define the export command\n",
    "EXPORT_CMD='export PATH=\"$HOME/.local/bin:$PATH\"'\n",
    "\n",
    "# Function to add PATH modification if it's not already present\n",
    "add_path_if_missing() {\n",
    "    local FILE=$1\n",
    "    if [ -f \"$FILE\" ] && ! grep -q 'export PATH=\"\\$HOME/.local/bin:' \"$FILE\"; then\n",
    "        echo \"$EXPORT_CMD\" >> \"$FILE\"\n",
    "        echo \"✅ Added ~/.local/bin to PATH in $FILE\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Modify necessary shell startup files\n",
    "add_path_if_missing \"$HOME/.profile\"\n",
    "add_path_if_missing \"$HOME/.bashrc\"\n",
    "add_path_if_missing \"$HOME/.bash_profile\"\n",
    "add_path_if_missing \"$HOME/.bash_login\"\n",
    "\n",
    "# Apply changes immediately in the current session\n",
    "export PATH=\"$HOME/.local/bin:$PATH\"\n",
    "\n",
    "# Fix ownership of ~/.local if needed\n",
    "CURRENT_USER=$(whoami)\n",
    "if [ \"$(stat -c '%U' \"$HOME/.local\")\" != \"$CURRENT_USER\" ]; then\n",
    "    echo \"🔧 Fixing ownership of $HOME/.local...\"\n",
    "    sudo chown -R \"$CURRENT_USER:$CURRENT_USER\" \"$HOME/.local\"\n",
    "fi\n",
    "\n",
    "# Display a reminder to restart the terminal\n",
    "echo \"🚀 Please restart your terminal or run:\"\n",
    "echo \"    source ~/.profile && source ~/.bashrc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook assumes you are running this from *computational_genetic_genealogy/instructions. It also assumes that `$HOME` is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pwd\n",
    "echo \"$HOME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install or Upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Ensure pip is installed before upgrading\n",
    "if ! command -v pip &>/dev/null; then\n",
    "    echo \"⚠️ pip not found. Installing pip...\"\n",
    "    python3 -m ensurepip --default-pip\n",
    "fi\n",
    "\n",
    "# Upgrade pip\n",
    "python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Poetry and Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we check if the Python package manager Poetry is installed. If it's not, we install peortry.\n",
    "\n",
    "Then we install all of the Python packages and their dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Check if Poetry is already installed\n",
    "if command -v poetry &>/dev/null; then\n",
    "    echo \"✅ Poetry is already installed at $(which poetry)\"\n",
    "else\n",
    "    # Ensure curl is installed\n",
    "    if ! command -v curl &>/dev/null; then\n",
    "        echo \"❌ curl is required but not installed. Installing it now...\"\n",
    "        sudo apt-get update -y && sudo apt-get install -y curl\n",
    "    fi\n",
    "\n",
    "    # Remove conflicting symlink if it exists\n",
    "    if [ -L \"/usr/local/bin/poetry\" ]; then\n",
    "        echo \"🔧 Removing conflicting Poetry symlink...\"\n",
    "        sudo rm /usr/local/bin/poetry\n",
    "    fi\n",
    "\n",
    "    # Install Poetry in user space\n",
    "    curl -sSL https://install.python-poetry.org | python3 -\n",
    "\n",
    "    # Ensure ~/.local/bin is in PATH persistently\n",
    "    if ! grep -q 'export PATH=\"$HOME/.local/bin:$PATH\"' \"$HOME/.profile\"; then\n",
    "        echo 'export PATH=\"$HOME/.local/bin:$PATH\"' >> \"$HOME/.profile\"\n",
    "    fi\n",
    "    if ! grep -q 'export PATH=\"$HOME/.local/bin:$PATH\"' \"$HOME/.bashrc\"; then\n",
    "        echo 'export PATH=\"$HOME/.local/bin:$PATH\"' >> \"$HOME/.bashrc\"\n",
    "    fi\n",
    "\n",
    "    # Apply changes **for this session only**\n",
    "    export PATH=\"$HOME/.local/bin:$PATH\"\n",
    "fi\n",
    "\n",
    "# Verify installation\n",
    "if ! command -v poetry &>/dev/null; then\n",
    "    echo \"❌ Poetry installation failed or is not in PATH.\" >&2\n",
    "    exit 1\n",
    "else\n",
    "    echo \"🎉 Poetry installed successfully at $(which poetry)\"\n",
    "fi\n",
    "\n",
    "# Display instructions for users to source their profile\n",
    "echo \"🚀 To apply changes permanently, run this in a new cell or terminal:\"\n",
    "echo \"    source ~/.profile && source ~/.bashrc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Configure Poetry\n",
    "poetry config virtualenvs.create true\n",
    "poetry config virtualenvs.in-project true\n",
    "\n",
    "# Fix Poetry cache permissions\n",
    "if [ -d \"$HOME/.cache/poetry\" ] && [ \"$(stat -c '%U' \"$HOME/.cache/poetry\")\" != \"$USER\" ]; then\n",
    "    echo \"Fixing Poetry cache ownership...\"\n",
    "    sudo_cmd chown -R \"$USER:$USER\" \"$HOME/.cache/poetry\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Install project dependencies\n",
    "if [ -f \"../pyproject.toml\" ] && [ -f \"../poetry.lock\" ]; then\n",
    "    poetry install --no-root\n",
    "else\n",
    "    echo \"Warning: pyproject.toml or poetry.lock not found in $(pwd)\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run the Directory Setup Script**\n",
    "\n",
    "Follow these steps to execute the `directory_setup.py` script.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Open Your Terminal Window**\n",
    "- **Linux/macOS**: Open **Terminal**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Navigate to the `computational_genetic_genealogy` Directory**\n",
    "In your terminal, run the following command:\n",
    "\n",
    "```\n",
    "cd ~/computational_genetic_genealogy\n",
    "```\n",
    "\n",
    "If your project is in a different location, replace `~/computational_genetic_genealogy` with the actual path.\n",
    "\n",
    "To confirm you are in the correct directory, run:\n",
    "\n",
    "```\n",
    "pwd\n",
    "```\n",
    "\n",
    "The output should show the full path to `computational_genetic_genealogy`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3: Run the Setup Script**\n",
    "Now, execute the following command:\n",
    "\n",
    "```\n",
    "python scripts_env/directory_setup.py\n",
    "```\n",
    "\n",
    "This will:\n",
    "- **Run the script to set up required directories.**\n",
    "- **Ensure your environment is properly structured.**\n",
    "\n",
    "---\n",
    "\n",
    "✅ **You have successfully executed `directory_setup.py`!** 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get directory variables\n",
    "\n",
    "Now that you ran `directory_setup.py`, you should see your .env file in your file explorer. Let's make sure the notebook can see the file. Run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "env_path = os.path.join(project_root, '.env')\n",
    "load_dotenv(env_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
    "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
    "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
    "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
    "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
    "\n",
    "print(f\"Working Directory: {working_directory}\")\n",
    "print(f\"Data Directory: {data_directory}\")\n",
    "print(f\"References Directory: {references_directory}\")\n",
    "print(f\"Results Directory: {results_directory}\")\n",
    "print(f\"Utils Directory: {utils_directory}\")\n",
    "\n",
    "os.chdir(working_directory)\n",
    "print(f\"The current directory is {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Utils Directory to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Add ~/computational_genetic_genealogy/utils to PATH persistently\n",
    "if ! grep -q 'export PATH=\"$HOME/computational_genetic_genealogy/utils:$PATH\"' \"$HOME/.profile\"; then\n",
    "    echo 'export PATH=\"$HOME/computational_genetic_genealogy/utils:$PATH\"' | tee -a ~/.profile ~/.bashrc\n",
    "    echo \"✅ Added ~/computational_genetic_genealogy/utils to PATH\"\n",
    "fi\n",
    "\n",
    "# Apply changes immediately in the current session\n",
    "export PATH=\"$HOME/computational_genetic_genealogy/utils:$PATH\"\n",
    "\n",
    "# Verify PATH update\n",
    "echo \"🔍 Current PATH: $PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install bcftools, samtools, and tabix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install -y --no-install-recommends \\\n",
    "    libbz2-dev \\\n",
    "    liblzma-dev \\\n",
    "    zlib1g-dev \\\n",
    "    libgsl-dev \\\n",
    "    libcurl4-openssl-dev\n",
    "\n",
    "!sudo apt-get install -y bcftools samtools tabix\n",
    "!bcftools --version\n",
    "!samtools --version\n",
    "!tabix --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if command -v java &> /dev/null; then\n",
    "    echo \"Java is already installed. Version: $(java -version 2>&1 | head -n 1)\"\n",
    "    exit 0\n",
    "fi\n",
    "\n",
    "sudo apt-get install -y default-jdk\n",
    "\n",
    "# Verify installation\n",
    "if command -v java &> /dev/null; then\n",
    "    echo \"Java installation successful. Version: $(java -version 2>&1 | head -n 1)\"\n",
    "else\n",
    "    echo \"Java installation failed. Please check the log at $LOGFILE for details.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Verify Java Home\n",
    "JAVA_HOME=$(readlink -f /usr/bin/java | sed \"s:/bin/java::\")\n",
    "if [ -n \"$JAVA_HOME\" ]; then\n",
    "    echo \"JAVA_HOME detected: $JAVA_HOME\"\n",
    "    if ! grep -q \"export JAVA_HOME=$JAVA_HOME\" \"$HOME/.bashrc\"; then\n",
    "        echo \"Adding JAVA_HOME to .bashrc...\"\n",
    "        echo \"export JAVA_HOME=$JAVA_HOME\" >> \"$HOME/.bashrc\"\n",
    "        echo \"export PATH=\\$JAVA_HOME/bin:\\$PATH\" >> \"$HOME/.bashrc\"\n",
    "        source \"$HOME/.bashrc\"\n",
    "    else\n",
    "        echo \"JAVA_HOME already set in .bashrc.\"\n",
    "    fi\n",
    "else\n",
    "    echo \"Failed to detect JAVA_HOME. Please set it manually if required.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install beagle, bref, and unbref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "BEAGLE_VERSION=\"17Dec24.224\"\n",
    "BEAGLE_JAR=\"beagle.${BEAGLE_VERSION}.jar\"\n",
    "BREF3_JAR=\"bref3.${BEAGLE_VERSION}.jar\"\n",
    "UNBREF3_JAR=\"unbref3.${BEAGLE_VERSION}.jar\"\n",
    "BEAGLE_URL=\"https://faculty.washington.edu/browning/beagle/${BEAGLE_JAR}\"\n",
    "BREF3_URL=\"https://faculty.washington.edu/browning/beagle/${BREF3_JAR}\"\n",
    "UNBREF3_URL=\"https://faculty.washington.edu/browning/beagle/${UNBREF3_JAR}\"\n",
    "\n",
    "# Function to download a file only if it does not exist\n",
    "download_if_missing() {\n",
    "    local file_path=\"$utils_directory/$1\"\n",
    "    local file_url=\"$2\"\n",
    "\n",
    "    if [ -f \"$file_path\" ]; then\n",
    "        echo \"✅ File already exists: $file_path. Skipping download.\"\n",
    "    else\n",
    "        echo \"⬇️ Downloading $file_url...\"\n",
    "        wget -P \"$utils_directory\" \"$file_url\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Check and download each required file\n",
    "download_if_missing \"$UNBREF3_JAR\" \"$UNBREF3_URL\"\n",
    "download_if_missing \"$BREF3_JAR\" \"$BREF3_URL\"\n",
    "download_if_missing \"$BEAGLE_JAR\" \"$BEAGLE_URL\"\n",
    "\n",
    "# Test Beagle installation\n",
    "echo \"🔍 Testing Beagle installation...\"\n",
    "java -jar \"$utils_directory/$BEAGLE_JAR\" 2>&1\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"❌ Beagle test run failed.\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"✅ Beagle installed successfully.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install bonsaitree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "bash $PROJECT_WORKING_DIR/scripts_env/install_bonsaitree.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Hap-IBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "# Define variables\n",
    "HAP_IBD_URL=\"https://faculty.washington.edu/browning/hap-ibd.jar\"\n",
    "HAP_IBD_JAR=\"hap-ibd.jar\"\n",
    "\n",
    "# Function to download a file only if it does not exist\n",
    "download_if_missing() {\n",
    "    local file_path=\"$utils_directory/$1\"\n",
    "    local file_url=\"$2\"\n",
    "\n",
    "    if [ -f \"$file_path\" ]; then\n",
    "        echo \"✅ File already exists: $file_path. Skipping download.\"\n",
    "    else\n",
    "        echo \"⬇️ Downloading $file_url...\"\n",
    "        wget -P \"$utils_directory\" \"$file_url\"\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Check and download each required file\n",
    "download_if_missing \"$HAP_IBD_JAR\" \"$HAP_IBD_URL\"\n",
    "\n",
    "# Test installation\n",
    "echo \"Testing installation...\"\n",
    "java -jar \"$utils_directory/$HAP_IBD_JAR\" 2>&1\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"Test run failed.\"\n",
    "    exit 1\n",
    "else\n",
    "    echo \"Installed successfully.\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install IBIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "IBIS_REPO=\"https://github.com/williamslab/ibis.git\"\n",
    "IBIS_DIR=\"$utils_directory/ibis\"\n",
    "\n",
    "# Handle existing IBIS directory\n",
    "if [ -d \"$IBIS_DIR\" ]; then\n",
    "    echo \"📂 IBIS directory already exists at $IBIS_DIR.\"\n",
    "    \n",
    "    # Check if it is a valid Git repo\n",
    "    if [ -d \"$IBIS_DIR/.git\" ]; then\n",
    "        echo \"🔄 Updating IBIS repository...\"\n",
    "        cd \"$IBIS_DIR\" || { echo \"❌ Failed to navigate to IBIS directory.\"; exit 1; }\n",
    "        git pull origin master\n",
    "    else\n",
    "        echo \"⚠️ Directory exists but is not a Git repository. Consider removing it manually.\"\n",
    "        exit 1  # Stop execution\n",
    "    fi\n",
    "else\n",
    "    # Clone IBIS repository\n",
    "    echo \"⬇️ Cloning IBIS repository...\"\n",
    "    git clone --recurse-submodules \"$IBIS_REPO\" \"$IBIS_DIR\" || { echo \"❌ Git clone failed.\"; exit 1; }\n",
    "    \n",
    "    # Navigate to IBIS directory and build\n",
    "    cd \"$IBIS_DIR\" || { echo \"❌ Failed to navigate to $IBIS_DIR.\"; exit 1; }\n",
    "    echo \"🔨 Building IBIS using make...\"\n",
    "    make || { echo \"❌ Build failed.\"; exit 1; }\n",
    "fi\n",
    "\n",
    "# Verify IBIS installation\n",
    "if [ -x \"./ibis\" ]; then\n",
    "    echo \"✅ IBIS installed successfully.\"\n",
    "else\n",
    "    echo \"❌ IBIS executable not found. Build might have failed.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "sudo apt-get install -y libboost-all-dev make\n",
    "\n",
    "PED_SIM_REPO=\"https://github.com/williamslab/ped-sim.git\"\n",
    "PED_SIM_DIR=\"$utils_directory/ped-sim\"\n",
    "\n",
    "# Handle existing IBIS directory\n",
    "if [ -d \"$PED_SIM_DIR\" ]; then\n",
    "    echo \"📂 Ped-Sim directory already exists at $PED_SIM_DIR.\"\n",
    "    \n",
    "    # Check if it is a valid Git repo\n",
    "    if [ -d \"$PED_SIM_DIR/.git\" ]; then\n",
    "        echo \"🔄 Updating IBIS repository...\"\n",
    "        cd \"$PED_SIM_DIR\" || { echo \"❌ Failed to navigate to Ped-Sim directory.\"; exit 1; }\n",
    "        git pull origin master\n",
    "    else\n",
    "        echo \"⚠️ Directory exists but is not a Git repository. Consider removing it manually.\"\n",
    "        exit 1  # Stop execution\n",
    "    fi\n",
    "else\n",
    "    # Clone Ped-Sim repository\n",
    "    echo \"⬇️ Cloning Ped-Sim repository...\"\n",
    "    git clone --recurse-submodules \"$PED_SIM_REPO\" \"$PED_SIM_DIR\" || { echo \"❌ Git clone failed.\"; exit 1; }\n",
    "    \n",
    "    # Navigate to Ped-Sim directory and build\n",
    "    cd \"$PED_SIM_DIR\" || { echo \"❌ Failed to navigate to $PED_SIM_DIR.\"; exit 1; }\n",
    "    echo \"🔨 Building Ped-Sim using make...\"\n",
    "    make || { echo \"❌ Build failed.\"; exit 1; }\n",
    "fi\n",
    "\n",
    "chmod +x ./ped-sim\n",
    "\n",
    "# Verify Ped-Sim installation\n",
    "if [ -x \"./ped-sim\" ]; then\n",
    "    echo \"✅ Ped-Sim installed successfully.\"\n",
    "else\n",
    "    echo \"❌ Ped-Sim executable not found. Build might have failed.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "# Define PLINK2 download URL and file\n",
    "plink2_file_url=\"https://s3.amazonaws.com/plink2-assets/alpha6/plink2_linux_x86_64_20241206.zip\"\n",
    "plink2_zip_file=\"$utils_directory/plink2_linux_x86_64_20241206.zip\"\n",
    "plink2_binary=\"$utils_directory/plink2\"\n",
    "\n",
    "# Download and unzip PLINK2 if not already present\n",
    "if [ ! -f \"$plink2_binary\" ]; then\n",
    "    echo\n",
    "    echo \"Downloading PLINK2...\"\n",
    "    echo\n",
    "    wget --progress=bar:force:noscroll \"$plink2_file_url\" -P \"$utils_directory\"\n",
    "    \n",
    "    # Ensure the file is downloaded before unzipping\n",
    "    while [ ! -f \"$plink2_zip_file\" ]; do\n",
    "        sleep 1\n",
    "    done\n",
    "\n",
    "    echo\n",
    "    echo \"Unzipping PLINK2...\"\n",
    "    echo\n",
    "    unzip \"$plink2_zip_file\" -d \"$utils_directory\"\n",
    "\n",
    "    # Remove the zip file after extraction\n",
    "    rm \"$plink2_zip_file\"\n",
    "fi\n",
    "\n",
    "# Check if the PLINK2 binary was installed correctly\n",
    "if [ -f \"$plink2_binary\" ] && [ -x \"$plink2_binary\" ]; then\n",
    "    echo \"PLINK2 installed successfully.\"\n",
    "    \"$plink2_binary\" --version\n",
    "else\n",
    "    echo \"Error: PLINK2 installation failed. Binary not found or not executable.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "utils_directory=$1\n",
    "\n",
    "# Define RFMix2 installation directory\n",
    "rfmix2_dir=\"$utils_directory/rfmix2\"\n",
    "\n",
    "# Install required tools (if missing)\n",
    "for tool in autoconf make gcc; do\n",
    "    if ! command -v $tool &> /dev/null; then\n",
    "        echo \"$tool not found. Installing...\"\n",
    "        sudo apt-get install -y $tool || {\n",
    "            echo \"Failed to install $tool. Exiting.\"\n",
    "            exit 1\n",
    "        }\n",
    "    else\n",
    "        echo \"$tool is already installed.\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "# Clone RFMix2 repository\n",
    "rfmix_dir=\"$utils_directory/rfmix2\"\n",
    "if [ ! -d \"$rfmix_dir\" ]; then\n",
    "    echo \"Cloning RFMix2 repository...\"\n",
    "    git clone https://github.com/slowkoni/rfmix.git \"$rfmix_dir\" || {\n",
    "        echo \"Failed to clone RFMix2 repository. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # Navigate to RFMix2 directory\n",
    "    if [ -d \"$rfmix_dir\" ]; then\n",
    "        cd \"$rfmix_dir\" || { echo \"Failed to enter $rfmix_dir. Exiting.\"; exit 1; }\n",
    "    else\n",
    "        echo \"Error: RFMix2 directory not found. Exiting.\"\n",
    "        exit 1\n",
    "    fi\n",
    "\n",
    "    # Step-by-step generation of configuration files\n",
    "    echo \"Generating build files the long way...\"\n",
    "\n",
    "    # 1. Create aclocal.m4\n",
    "    echo \"Running aclocal...\"\n",
    "    aclocal || {\n",
    "        echo \"Error running aclocal. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 2. Create config.h.in\n",
    "    echo \"Running autoheader...\"\n",
    "    autoheader || {\n",
    "        echo \"Error running autoheader. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 3. Create configure script\n",
    "    echo \"Running autoconf...\"\n",
    "    autoconf || {\n",
    "        echo \"Error running autoconf. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 4. Create Makefile.in\n",
    "    echo \"Running automake with --add-missing...\"\n",
    "    automake --add-missing || {\n",
    "        echo \"Error running automake. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 5. Configure the build system\n",
    "    echo \"Running ./configure...\"\n",
    "    ./configure || {\n",
    "        echo \"Error running configure. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "\n",
    "    # 6. Compile the program\n",
    "    echo \"Compiling RFMix2...\"\n",
    "    make || {\n",
    "        echo \"Error running make. Exiting.\"\n",
    "        exit 1\n",
    "    }\n",
    "    \n",
    "else\n",
    "    echo \"RFMix2 repository already exists at $rfmix_dir\"\n",
    "fi\n",
    "\n",
    "# Verify RFMix2 build\n",
    "if [ -f \"$rfmix_dir/rfmix\" ]; then\n",
    "    echo \"RFMix2 built successfully and is ready to use.\"\n",
    "else\n",
    "    echo \"Error: RFMix2 binary not found. Build failed.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$utils_directory\"\n",
    "\n",
    "bash $PROJECT_WORKING_DIR/scripts_env/install_yhaplo.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting a Jupyter Notebook to PDF with Poetry\n",
    "\n",
    "This guide explains how to **export a Jupyter Notebook (`.ipynb`) to a PDF** using Poetry’s virtual environment.\n",
    "\n",
    "## **Running the Conversion in the Terminal**\n",
    "To convert a Jupyter Notebook to PDF, run the following command in the terminal:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf path/to/notebook.ipynb\n",
    "```\n",
    "\n",
    "### **Example:**\n",
    "If your notebook is named `Lab0_Code_Environment.ipynb` and is stored in the `instructions/` directory, run:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb\n",
    "```\n",
    "\n",
    "### **Saving the PDF to a Specific Path**\n",
    "By default, the PDF will be saved in the **same directory as the input notebook**. To save the output in a different location, use the `--output-dir` option:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf path/to/notebook.ipynb --output-dir=path/to/save/\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "To save the PDF in the `results/` directory:\n",
    "\n",
    "```\n",
    "poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb --output-dir=results/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **What Happens If We Run This Inside a Jupyter Notebook?**\n",
    "If you attempt to run `!poetry run jupyter nbconvert --to pdf ...` inside a Jupyter Notebook cell, you may encounter issues because **Notebook-specific variables (such as inline plots) might not be preserved.**\n",
    "\n",
    "### **Workaround**\n",
    "You can run the conversion within a Jupyter Notebook cell if you don't think that is an issue in the notebook you're using. The commnad to convert the notebook to PDF is (also in cell below)\n",
    "```\n",
    "!poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb\n",
    "```\n",
    "However, **it is recommended to run this in the terminal instead** for better stability.\n",
    "\n",
    "---\n",
    "By following these steps, you can successfully convert Jupyter Notebooks into PDFs while managing dependencies with Poetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run jupyter nbconvert --to pdf instructions/Lab0_Code_Environment.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🚀 Start Your Lab in the Fully Configured Environment!**\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ **Setup Completed! Your Environment is Ready.**\n",
    "Your system has been successfully configured with:\n",
    "\n",
    "- 📁 **Project directory structure set up**\n",
    "- 📦 **System packages updated**\n",
    "- 🛠️ **`~/.local/bin` added to PATH**\n",
    "- 🔧 **System dependencies installed**\n",
    "- 🏗 **Poetry installed and configured**\n",
    "- 🐍 **Project dependencies installed**\n",
    "- 📚 **Python kernel installed for Jupyter Notebooks**\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Your environment is fully set up. Get started on your next lab now!** 🚀\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
