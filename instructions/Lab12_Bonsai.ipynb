{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyrnlNJ2hiso"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZmLfSJqg2uR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "import logging\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "import IPython\n",
        "import pandas as pd\n",
        "import boto3\n",
        "import importlib.util\n",
        "import ast\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from scipy.stats import poisson\n",
        "import json\n",
        "\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nduw3nmhg5kV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded environment variables from: /home/lakishadavid/computational_genetic_genealogy/.env\n",
            "Working Directory: /home/lakishadavid/computational_genetic_genealogy\n",
            "Data Directory: /home/lakishadavid/computational_genetic_genealogy/data\n",
            "References Directory: /home/lakishadavid/computational_genetic_genealogy/references\n",
            "Results Directory: /home/lakishadavid/computational_genetic_genealogy/results\n",
            "Utils Directory: /home/lakishadavid/computational_genetic_genealogy/utils\n",
            "The current directory is /home/lakishadavid/computational_genetic_genealogy\n"
          ]
        }
      ],
      "source": [
        "def find_comp_gen_dir():\n",
        "    \"\"\"Find the computational_genetic_genealogy directory by searching up from current directory.\"\"\"\n",
        "    current = Path.cwd()\n",
        "    \n",
        "    # Search up through parent directories\n",
        "    while current != current.parent:\n",
        "        # Check if target directory exists in current path\n",
        "        target = current / 'computational_genetic_genealogy'\n",
        "        if target.is_dir():\n",
        "            return target\n",
        "        # Move up one directory\n",
        "        current = current.parent\n",
        "    \n",
        "    raise FileNotFoundError(\"Could not find computational_genetic_genealogy directory\")\n",
        "\n",
        "def load_env_file():\n",
        "    \"\"\"Find and load the .env file from the computational_genetic_genealogy directory.\"\"\"\n",
        "    try:\n",
        "        # Find the computational_genetic_genealogy directory\n",
        "        comp_gen_dir = find_comp_gen_dir()\n",
        "        \n",
        "        # Look for .env file\n",
        "        env_path = comp_gen_dir / '.env'\n",
        "        if not env_path.exists():\n",
        "            print(f\"Warning: No .env file found in {comp_gen_dir}\")\n",
        "            return None\n",
        "        \n",
        "        # Load the .env file\n",
        "        load_dotenv(env_path, override=True)\n",
        "        print(f\"Loaded environment variables from: {env_path}\")\n",
        "        return env_path\n",
        "        \n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Use the function\n",
        "env_path = load_env_file()\n",
        "\n",
        "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
        "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
        "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
        "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
        "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
        "\n",
        "os.environ[\"WORKING_DIRECTORY\"] = working_directory\n",
        "os.environ[\"DATA_DIRECTORY\"] = data_directory\n",
        "os.environ[\"REFERENCES_DIRECTORY\"] = references_directory\n",
        "os.environ[\"RESULTS_DIRECTORY\"] = results_directory\n",
        "os.environ[\"UTILS_DIRECTORY\"] = utils_directory\n",
        "\n",
        "print(f\"Working Directory: {working_directory}\")\n",
        "print(f\"Data Directory: {data_directory}\")\n",
        "print(f\"References Directory: {references_directory}\")\n",
        "print(f\"Results Directory: {results_directory}\")\n",
        "print(f\"Utils Directory: {utils_directory}\")\n",
        "\n",
        "os.chdir(working_directory)\n",
        "print(f\"The current directory is {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7GlSu-GWsDS"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onCavOg0NoQt"
      },
      "source": [
        "Bonsai requires data on the age and sex of each individual. However, when we simulated data, we did not get an age. Bonsai also requires the the individual name to be an integer, which is not how our simulated data outputs names. This section of code will assign a random integer ID and age based on certain parameters and output this bioinfo variable as needed for Bonsai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "IYJRzLyBXzmh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of individuals: 520\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Read the seg file and extract unique individual IDs\n",
        "seg_file = os.path.join(data_directory, \"class_data/ped_sim_run2.seg\")\n",
        "seg_df = pd.read_csv(seg_file, sep=\"\\t\", header=None)\n",
        "seg_df.columns = [\"sample1\", \"sample2\", \"chrom\", \"phys_start\", \"phys_end\", \"ibd_type\", \"gen_start\", \"gen_end\", \"gen_seg_len\"]\n",
        "unique_individuals = set(seg_df[\"sample1\"]).union(set(seg_df[\"sample2\"]))\n",
        "unique_individuals = sorted(list(unique_individuals))\n",
        "print(\"Number of individuals:\", len(unique_individuals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "TOdu2C-WYLpJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 individuals:\n",
            "{'FAM1_g1-b1-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 1}, 'FAM1_g1-b1-i1': {'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 1}, 'FAM1_g2-b1-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 2}, 'FAM1_g2-b1-i1': {'father_id': 'FAM1_g1-b1-i1', 'mother_id': 'FAM1_g1-b1-s1', 'sex': 'M', 'generation': 2}, 'FAM1_g2-b2-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 2}, 'FAM1_g2-b2-i1': {'father_id': 'FAM1_g1-b1-i1', 'mother_id': 'FAM1_g1-b1-s1', 'sex': 'F', 'generation': 2}, 'FAM1_g3-b1-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 3}, 'FAM1_g3-b1-i1': {'father_id': 'FAM1_g2-b1-i1', 'mother_id': 'FAM1_g2-b1-s1', 'sex': 'F', 'generation': 3}, 'FAM1_g3-b2-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 3}, 'FAM1_g3-b2-i1': {'father_id': 'FAM1_g2-b1-i1', 'mother_id': 'FAM1_g2-b1-s1', 'sex': 'M', 'generation': 3}}\n"
          ]
        }
      ],
      "source": [
        "# Read the fam file\n",
        "with open(os.path.join(data_directory, \"class_data/ped_sim_run2-everyone.fam\"), 'r') as file:\n",
        "    fam_lines = file.readlines()\n",
        "\n",
        "# Create a dictionary to store individual information and Bonsai IDs\n",
        "individuals = {}\n",
        "bonsai_ids = {}\n",
        "\n",
        "# Process each line in the fam file\n",
        "for line in fam_lines:\n",
        "    fields = line.strip().split()\n",
        "    individual_id = fields[1]\n",
        "\n",
        "    # Skip individuals not present in the seg file\n",
        "    if individual_id not in unique_individuals:\n",
        "        continue\n",
        "\n",
        "    father_id = fields[2]\n",
        "    mother_id = fields[3]\n",
        "    sex = 'M' if fields[4] == '1' else 'F'\n",
        "\n",
        "    # Extract the generation number from the individual ID\n",
        "    generation = int(individual_id.split('-')[0].split('_')[-1][1:])\n",
        "\n",
        "    # Store the individual information in the dictionary\n",
        "    individuals[individual_id] = {\n",
        "        'father_id': father_id,\n",
        "        'mother_id': mother_id,\n",
        "        'sex': sex,\n",
        "        'generation': generation\n",
        "    }\n",
        "    \n",
        "print(\"First 10 individuals:\")\n",
        "print({k: v for k, v in list(individuals.items())[:10]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8M707kiIZLxg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Earliest generation: 1, Latest generation: 6\n"
          ]
        }
      ],
      "source": [
        "# Get the earliest and latest generation numbers\n",
        "generation_numbers = [info['generation'] for info in individuals.values()]\n",
        "earliest_generation = min(generation_numbers)\n",
        "latest_generation = max(generation_numbers)\n",
        "print(f\"Earliest generation: {earliest_generation}, Latest generation: {latest_generation}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlTPOT_wZQKO"
      },
      "source": [
        "This code block retrieves the earliest and latest generation numbers from the `individuals` dictionary. It creates a list comprehension to extract the 'generation' values from the dictionary values. The `min` and `max` functions are used to find the earliest and latest generation numbers, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7Ff8O_32Zike"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 individuals with ages:\n",
            "{'FAM1_g1-b1-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 1, 'age': 151}, 'FAM1_g1-b1-i1': {'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 1, 'age': 170}, 'FAM1_g2-b1-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 2, 'age': 127}, 'FAM1_g2-b1-i1': {'father_id': 'FAM1_g1-b1-i1', 'mother_id': 'FAM1_g1-b1-s1', 'sex': 'M', 'generation': 2, 'age': 150}, 'FAM1_g2-b2-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 2, 'age': 117}, 'FAM1_g2-b2-i1': {'father_id': 'FAM1_g1-b1-i1', 'mother_id': 'FAM1_g1-b1-s1', 'sex': 'F', 'generation': 2, 'age': 132}, 'FAM1_g3-b1-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 3, 'age': 106}, 'FAM1_g3-b1-i1': {'father_id': 'FAM1_g2-b1-i1', 'mother_id': 'FAM1_g2-b1-s1', 'sex': 'F', 'generation': 3, 'age': 116}, 'FAM1_g3-b2-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 3, 'age': 120}, 'FAM1_g3-b2-i1': {'father_id': 'FAM1_g2-b1-i1', 'mother_id': 'FAM1_g2-b1-s1', 'sex': 'M', 'generation': 3, 'age': 112}}\n",
            "\n",
            "\n",
            "The age range is: 18 - 170\n"
          ]
        }
      ],
      "source": [
        "# Assign ages to individuals based on their generation\n",
        "for generation in range(latest_generation, earliest_generation - 1, -1):\n",
        "    for individual_id, info in individuals.items():\n",
        "        if info['generation'] == generation:\n",
        "            if generation == latest_generation:\n",
        "                # Assign ages between 18 and 40 for the latest generation\n",
        "                age = random.randint(18, 40)\n",
        "            else:\n",
        "                # Assign ages based on the descendants' ages\n",
        "                child_ages = []\n",
        "                for child_id, child_info in individuals.items():\n",
        "                    if child_info['father_id'] == individual_id or child_info['mother_id'] == individual_id:\n",
        "                        child_ages.append(child_info['age'])\n",
        "\n",
        "                if child_ages:\n",
        "                    min_child_age = min(child_ages)\n",
        "                    age = min_child_age + random.randint(12, 40)\n",
        "                else:\n",
        "                    # If no child information is available, assign a random age based on the generation gap\n",
        "                    age_gap = (latest_generation - generation) * random.randint(12, 40)\n",
        "                    age = random.randint(18, 40) + age_gap\n",
        "\n",
        "            individuals[individual_id]['age'] = age\n",
        "            \n",
        "\n",
        "print(\"First 10 individuals with ages:\")\n",
        "print({k: v for k, v in list(individuals.items())[:10]})\n",
        "print(\"\\n\")\n",
        "print(\"The age range is:\", min([info['age'] for info in individuals.values()]), \"-\", max([info['age'] for info in individuals.values()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9-RXmLYZjk-"
      },
      "source": [
        "This code block assigns ages to individuals based on their generation. It iterates over the generations in reverse order, starting from the latest generation and going backward to the earliest generation.\n",
        "\n",
        "For each generation:\n",
        "\n",
        "* If it's the latest generation, ages between 18 and 40 are randomly assigned using random.randint(18, 40).\n",
        "* For earlier generations, ages are assigned based on the descendants' ages. It iterates over the individuals and checks if the current individual is the father or mother of any other individual. If so, the age of the child is appended to the child_ages list.\n",
        "  * If the child_ages list is not empty, the minimum age among the children is found using min(child_ages), and the individual's age is assigned by adding a random value between 12 and 40 to the minimum child age.\n",
        "  * If the child_ages list is empty (i.e., the individual has no children), a random age is assigned based on the generation gap. The generation gap is calculated by subtracting the current generation from the latest generation, and then multiplying it by a random value between 12 and 40. The individual's age is then assigned by adding this age gap to a base age range of 18 to 40.\n",
        "* The assigned age is stored in the individuals dictionary under the 'age' key for each individual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Nut1Oy6naLFJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 individuals with Genotype IDs:\n",
            "{'FAM1_g1-b1-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 1, 'age': 151, 'genotype_id': '1000'}, 'FAM1_g1-b1-i1': {'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 1, 'age': 170, 'genotype_id': '1001'}, 'FAM1_g2-b1-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 2, 'age': 127, 'genotype_id': '1002'}, 'FAM1_g2-b1-i1': {'father_id': 'FAM1_g1-b1-i1', 'mother_id': 'FAM1_g1-b1-s1', 'sex': 'M', 'generation': 2, 'age': 150, 'genotype_id': '1003'}, 'FAM1_g2-b2-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 2, 'age': 117, 'genotype_id': '1004'}, 'FAM1_g2-b2-i1': {'father_id': 'FAM1_g1-b1-i1', 'mother_id': 'FAM1_g1-b1-s1', 'sex': 'F', 'generation': 2, 'age': 132, 'genotype_id': '1005'}, 'FAM1_g3-b1-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'M', 'generation': 3, 'age': 106, 'genotype_id': '1006'}, 'FAM1_g3-b1-i1': {'father_id': 'FAM1_g2-b1-i1', 'mother_id': 'FAM1_g2-b1-s1', 'sex': 'F', 'generation': 3, 'age': 116, 'genotype_id': '1007'}, 'FAM1_g3-b2-s1': {'father_id': '0', 'mother_id': '0', 'sex': 'F', 'generation': 3, 'age': 120, 'genotype_id': '1008'}, 'FAM1_g3-b2-i1': {'father_id': 'FAM1_g2-b1-i1', 'mother_id': 'FAM1_g2-b1-s1', 'sex': 'M', 'generation': 3, 'age': 112, 'genotype_id': '1009'}}\n"
          ]
        }
      ],
      "source": [
        "# Create Genotype IDs for individuals\n",
        "for index, individual_id in enumerate(individuals.keys(), start=1000):\n",
        "    bonsai_id = str(index)\n",
        "    individuals[individual_id]['genotype_id'] = bonsai_id\n",
        "    \n",
        "print(\"First 10 individuals with Genotype IDs:\")\n",
        "print({k: v for k, v in list(individuals.items())[:10]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgzd1POsaI_U"
      },
      "source": [
        "This code block creates Bonsai IDs for each individual. It uses the enumerate function to iterate over the keys of the individuals dictionary, starting the index from 1000. For each individual ID, a corresponding Bonsai ID is created by converting the index to a string. The Bonsai ID is then stored in the bonsai_ids dictionary using the individual ID as the key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "UHywg178aRDh"
      },
      "outputs": [],
      "source": [
        "# Write the individual information to a new file\n",
        "with open(os.path.join(results_directory, 'individual_info.txt'), 'w') as file:\n",
        "    file.write(\"Individual ID\\tBonsai ID\\tAge\\tSex\\n\")\n",
        "    for individual_id, info in individuals.items():\n",
        "        genotype_id = info['genotype_id']\n",
        "        age = info['age']\n",
        "        sex = info['sex']\n",
        "        file.write(f\"{individual_id}\\t{genotype_id}\\t{age}\\t{sex}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTvuQ78eaR2w"
      },
      "source": [
        "This code block writes the individual information to a new file named \"individual_info.txt\" in the results_directory. It opens the file in write mode ('w').\n",
        "\n",
        "The header line `\"Individual ID\\tBonsai ID\\tAge\\tSex\\n\"` is written to the file first.\n",
        "\n",
        "Then, it iterates over the `individuals` dictionary items. For each individual:\n",
        "\n",
        "* The corresponding Bonsai ID is retrieved from the `bonsai_ids` dictionary using the individual ID as the key.\n",
        "* The age and sex information is retrieved from the `individuals` dictionary.\n",
        "* The individual information is written to the file in the format `\"Individual ID\\tBonsai ID\\tAge\\tSex\\n\"` using an f-string.\n",
        "\n",
        "Take a look at the `individual_info.txt` file in your results directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ESFCtYDGaq9o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The first 10 bioinfo values:\n",
            "{'genotype_id': 1000, 'age': 151, 'sex': 'F'}\n",
            "{'genotype_id': 1001, 'age': 170, 'sex': 'M'}\n",
            "{'genotype_id': 1002, 'age': 127, 'sex': 'F'}\n",
            "{'genotype_id': 1003, 'age': 150, 'sex': 'M'}\n",
            "{'genotype_id': 1004, 'age': 117, 'sex': 'M'}\n",
            "{'genotype_id': 1005, 'age': 132, 'sex': 'F'}\n",
            "{'genotype_id': 1006, 'age': 106, 'sex': 'M'}\n",
            "{'genotype_id': 1007, 'age': 116, 'sex': 'F'}\n",
            "{'genotype_id': 1008, 'age': 120, 'sex': 'F'}\n",
            "{'genotype_id': 1009, 'age': 112, 'sex': 'M'}\n"
          ]
        }
      ],
      "source": [
        "# Create the bioinfo value in the desired format\n",
        "bioinfo = []\n",
        "for individual_id, info in individuals.items():\n",
        "    genotype_id = int(info['genotype_id'])\n",
        "    age = info['age']\n",
        "    sex = info['sex']\n",
        "    bioinfo.append({'genotype_id': genotype_id, 'age': age, 'sex': sex})\n",
        "    \n",
        "print(\"The first 10 bioinfo values:\")\n",
        "for i in range(10):\n",
        "    print(bioinfo[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzvNI8WAaubK"
      },
      "source": [
        "This code block creates the bioinfo value in the desired format. It initializes an empty list called `bioinfo`.\n",
        "\n",
        "It iterates over the `individuals` dictionary items. For each individual:\n",
        "\n",
        "* The corresponding Bonsai ID is retrieved from the `bonsai_ids` dictionary using the individual ID as the key.\n",
        "* The Bonsai ID is converted to an integer and assigned to the `genotype_id` variable.\n",
        "* The age and sex information is retrieved from the `individuals` dictionary.\n",
        "* A dictionary containing the `genotype_id`, `age`, and `sex` is appended to the `bioinfo` list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzxQ_H0UXDvr"
      },
      "source": [
        "Remember that Bonsai is designed to read the individal names as integers. We already assigned integer IDs for each individual in our segments file in the earlier code. Let's use those assignments to update our segments file by replacing the individual names with their integer IDs.\n",
        "\n",
        "**NOTE: The following code block can't run more than once unless you change the existing .seg_orig to .seg**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApvfuVGgddXY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segments and dictionary saved successfully.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample1</th>\n",
              "      <th>sample2</th>\n",
              "      <th>chrom</th>\n",
              "      <th>phys_start</th>\n",
              "      <th>phys_end</th>\n",
              "      <th>ibd_type</th>\n",
              "      <th>gen_start</th>\n",
              "      <th>gen_end</th>\n",
              "      <th>gen_seg_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>1003</td>\n",
              "      <td>1</td>\n",
              "      <td>817341</td>\n",
              "      <td>44617788</td>\n",
              "      <td>IBD1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>68.343071</td>\n",
              "      <td>68.343071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000</td>\n",
              "      <td>1003</td>\n",
              "      <td>1</td>\n",
              "      <td>44617789</td>\n",
              "      <td>205983275</td>\n",
              "      <td>IBD1</td>\n",
              "      <td>68.343113</td>\n",
              "      <td>200.153155</td>\n",
              "      <td>131.810042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000</td>\n",
              "      <td>1003</td>\n",
              "      <td>1</td>\n",
              "      <td>205983276</td>\n",
              "      <td>242249428</td>\n",
              "      <td>IBD1</td>\n",
              "      <td>200.153157</td>\n",
              "      <td>250.580913</td>\n",
              "      <td>50.427756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1003</td>\n",
              "      <td>1</td>\n",
              "      <td>242249429</td>\n",
              "      <td>248876512</td>\n",
              "      <td>IBD1</td>\n",
              "      <td>250.580914</td>\n",
              "      <td>261.713366</td>\n",
              "      <td>11.132452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000</td>\n",
              "      <td>1003</td>\n",
              "      <td>2</td>\n",
              "      <td>118913</td>\n",
              "      <td>4929466</td>\n",
              "      <td>IBD1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.741841</td>\n",
              "      <td>8.741841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample1  sample2  chrom  phys_start   phys_end ibd_type   gen_start  \\\n",
              "0     1000     1003      1      817341   44617788     IBD1    0.000000   \n",
              "1     1000     1003      1    44617789  205983275     IBD1   68.343113   \n",
              "2     1000     1003      1   205983276  242249428     IBD1  200.153157   \n",
              "3     1000     1003      1   242249429  248876512     IBD1  250.580914   \n",
              "4     1000     1003      2      118913    4929466     IBD1    0.000000   \n",
              "\n",
              "      gen_end  gen_seg_len  \n",
              "0   68.343071    68.343071  \n",
              "1  200.153155   131.810042  \n",
              "2  250.580913    50.427756  \n",
              "3  261.713366    11.132452  \n",
              "4    8.741841     8.741841  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "seg_file_orig = seg_file + \"_orig\"\n",
        "\n",
        "# Check for .seg_orig and .seg files in the results directory\n",
        "if os.path.exists(seg_file_orig) and os.path.exists(seg_file):\n",
        "    os.remove(seg_file)\n",
        "    os.rename(seg_file_orig, seg_file)\n",
        "elif os.path.exists(seg_file_orig):\n",
        "    os.rename(seg_file_orig, seg_file)\n",
        "    \n",
        "segments = seg_df.copy()\n",
        "\n",
        "# New file paths\n",
        "seg_file_new = seg_file\n",
        "dict_file = seg_file + \"_dict.txt\"\n",
        "\n",
        "# Read the individual_info.txt file\n",
        "individual_info = pd.read_csv(os.path.join(results_directory, 'individual_info.txt'), sep='\\t')\n",
        "\n",
        "# Create a dictionary to map individual IDs to Bonsai IDs\n",
        "individual_to_bonsai = dict(zip(individual_info['Individual ID'], individual_info['Bonsai ID']))\n",
        "\n",
        "# Replace sample names with their corresponding Bonsai IDs\n",
        "segments['sample1'] = segments['sample1'].map(individual_to_bonsai)\n",
        "segments['sample2'] = segments['sample2'].map(individual_to_bonsai)\n",
        "\n",
        "# Save the modified segments as .seg\n",
        "segments.to_csv(seg_file_new, sep='\\t', index=False, header=False)\n",
        "\n",
        "# Save the dictionary\n",
        "with open(dict_file, 'w') as f:\n",
        "    for individual, bonsai_id in individual_to_bonsai.items():\n",
        "        f.write(f\"{individual}\\t{bonsai_id}\\n\")\n",
        "\n",
        "print(\"Segments and dictionary saved successfully.\")\n",
        "display(segments.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the segment list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 unphased IBD segments:\n",
            "[1000, 1003, '1', 817341.0, 44617788.0, False, 68.343071]\n",
            "[1000, 1003, '1', 44617789.0, 205983275.0, False, 131.810042]\n",
            "[1000, 1003, '1', 205983276.0, 242249428.0, False, 50.427756]\n",
            "[1000, 1003, '1', 242249429.0, 248876512.0, False, 11.132452]\n",
            "[1000, 1003, '2', 118913.0, 4929466.0, False, 8.741841]\n",
            "[1000, 1003, '2', 4929467.0, 67922741.0, False, 77.365229]\n",
            "[1000, 1003, '2', 67922742.0, 242101808.0, False, 162.599718]\n",
            "[1000, 1003, '3', 66543.0, 42375917.0, False, 63.832452]\n",
            "[1000, 1003, '3', 42375918.0, 198073373.0, False, 153.016539]\n",
            "[1000, 1003, '4', 173807.0, 108049728.0, False, 107.960655]\n"
          ]
        }
      ],
      "source": [
        "def create_unphased_ibd_seg_list(segments):\n",
        "    \"\"\"\n",
        "    Creates an unphased IBD segment list from the given DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        segments_ibd (pd.DataFrame): DataFrame containing the IBD segments with columns:\n",
        "                                     ['id1', 'id2', 'chromosome', 'physical_position_start',\n",
        "                                      'physical_position_end', 'IBD_type', 'genetic_length'].\n",
        "        numeric_ids (dict): Mapping of sample IDs (str) to numeric IDs (int).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of unphased IBD segments in the specified format:\n",
        "              [[id1, id2, chrom, start_bp, end_bp, is_full, len_cm], ...].\n",
        "    \"\"\"\n",
        "    unphased_ibd_seg_list = []\n",
        "\n",
        "    for _, row in segments.iterrows():\n",
        "        try:\n",
        "            id1 = int(row['sample1'])\n",
        "            id2 = int(row['sample2'])\n",
        "            chrom = str(row['chrom'])  # Convert chromosome to string if necessary\n",
        "            start_bp = float(row['phys_start'])\n",
        "            end_bp = float(row['phys_end'])\n",
        "            is_full = row['ibd_type'] == 2  # Assuming IBD2 indicates \"full\"\n",
        "            len_cm = float(row['gen_seg_len'])\n",
        "\n",
        "            unphased_ibd_seg_list.append([id1, id2, chrom, start_bp, end_bp, is_full, len_cm])\n",
        "        except KeyError as e:\n",
        "            print(f\"Error mapping ID: {e}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error converting row data: {e}\")\n",
        "\n",
        "    return unphased_ibd_seg_list\n",
        "\n",
        "unphased_ibd_seg_list = create_unphased_ibd_seg_list(segments)\n",
        "\n",
        "print(\"First 10 unphased IBD segments:\")\n",
        "for i in range(10):\n",
        "    print(unphased_ibd_seg_list[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh--6OMseIgp"
      },
      "source": [
        "## Run Bonsai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "DcLLLzrFVn_R"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lakishadavid/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/druid.py:221: RuntimeWarning: divide by zero encountered in log\n",
            "  log_term = np.log(1 - np.exp(-np.exp(log_mu_amt)))\n",
            "/home/lakishadavid/computational_genetic_genealogy/.venv/lib/python3.12/site-packages/scipy/stats/_distn_infrastructure.py:2068: RuntimeWarning: divide by zero encountered in divide\n",
            "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
            "/home/lakishadavid/computational_genetic_genealogy/.venv/lib/python3.12/site-packages/scipy/stats/_distn_infrastructure.py:2068: RuntimeWarning: invalid value encountered in divide\n",
            "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbonsaitree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbonsaitree\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bonsai\n\u001b[0;32m----> 3\u001b[0m up_dict_log_like_list \u001b[38;5;241m=\u001b[39m \u001b[43mbonsai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_pedigree\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbio_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbioinfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43munphased_ibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munphased_ibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/bonsai.py:182\u001b[0m, in \u001b[0;36mbuild_pedigree\u001b[0;34m(bio_info, unphased_ibd_seg_list, phased_ibd_seg_list, condition_pair_set, min_seg_len, max_con_pts, restrict_connection_points, connect_up_only, max_peds, max_start_peds, db_fig_base_dir, true_ped, mean_bgd_num, mean_bgd_len)\u001b[0m\n\u001b[1;32m    179\u001b[0m condition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# build the pedigrees\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_up_dicts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx_to_up_dict_ll_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midx_to_up_dict_ll_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_to_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mid_to_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx_to_id_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midx_to_id_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphased_ibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpw_ll_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpw_ll_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_peds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_peds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_start_peds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_start_peds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_con_pts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_con_pts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnect_up_only\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconnect_up_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdb_fig_base_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdb_fig_base_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrue_ped\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrue_ped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# get the index of the pedigree that was built\u001b[39;00m\n\u001b[1;32m    200\u001b[0m idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39mresult][\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/connections.py:1905\u001b[0m, in \u001b[0;36mcombine_up_dicts\u001b[0;34m(idx_to_up_dict_ll_list, id_to_idx, idx_to_id_set, ibd_seg_list, pw_ll_cls, condition, max_peds, max_start_peds, max_con_pts, min_seg_len, restrict_connection_points, connect_up_only, db_fig_base_dir, true_ped)\u001b[0m\n\u001b[1;32m   1902\u001b[0m     filled_up_dct1 \u001b[38;5;241m=\u001b[39m fill_in_partners(up_dct\u001b[38;5;241m=\u001b[39mup_dct1)\n\u001b[1;32m   1903\u001b[0m     filled_up_dct2 \u001b[38;5;241m=\u001b[39m fill_in_partners(up_dct\u001b[38;5;241m=\u001b[39mup_dct2)\n\u001b[0;32m-> 1905\u001b[0m     this_up_dct_ll_list \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_pedigrees\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mup_dct1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilled_up_dct1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mup_dct2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilled_up_dct2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpw_ll_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpw_ll_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_peds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_peds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_con_pts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_con_pts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_seg_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnect_up_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnect_up_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfig_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfig_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1918\u001b[0m     up_dct_ll_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m this_up_dct_ll_list\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# sort from most to least likely\u001b[39;00m\n",
            "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/connections.py:1646\u001b[0m, in \u001b[0;36mcombine_pedigrees\u001b[0;34m(up_dct1, up_dct2, pw_ll_cls, ibd_seg_list, condition, max_peds, max_con_pts, min_seg_len, restrict_connection_points, connect_up_only, fig_dir)\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;124;03mCombine pedigrees up_dct1 and up_dct2 through the top most likely\u001b[39;00m\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;124;03mdegrees and common ancestor pairs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;124;03m                   {node: {parent1 : deg1, parent2 : deg2}, ..}\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;66;03m# get a list of the form [[point1, point2, deg1, deg2, num_common_ancs, log_like], ...]\u001b[39;00m\n\u001b[0;32m-> 1646\u001b[0m anc_deg_log_like_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_connecting_points_degs_and_log_likes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mup_dct1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mup_dct2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpw_ll_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpw_ll_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_seg_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_con_pts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_con_pts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestrict_connection_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnect_up_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnect_up_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1658\u001b[0m ped_log_like_list : \u001b[38;5;28mlist\u001b[39m[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m   1659\u001b[0m ped_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/connections.py:1001\u001b[0m, in \u001b[0;36mget_connecting_points_degs_and_log_likes\u001b[0;34m(up_dct1, up_dct2, pw_ll_cls, ibd_seg_list, condition, min_seg_len, max_con_pts, restrict_connection_points, connect_up_only)\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m point1 \u001b[38;5;129;01min\u001b[39;00m con_pt_set1:\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m point2 \u001b[38;5;129;01min\u001b[39;00m con_pt_set2:\n\u001b[0;32m-> 1001\u001b[0m         connection_log_like_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_connection_degs_and_log_likes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpoint1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoint1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpoint2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoint2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m            \u001b[49m\u001b[43mup_dct1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m            \u001b[49m\u001b[43mup_dct2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpw_ll_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpw_ll_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m            \u001b[49m\u001b[43mphased_ibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIN_SEG_LEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m         info_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m con, log_like \u001b[38;5;129;01min\u001b[39;00m connection_log_like_list:\n",
            "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/connections.py:586\u001b[0m, in \u001b[0;36mget_connection_degs_and_log_likes\u001b[0;34m(point1, point2, up_dct1, up_dct2, pw_ll_cls, phased_ibd_seg_list, condition, min_seg_len, deg_range_delta)\u001b[0m\n\u001b[1;32m    582\u001b[0m     deg_range \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;66;03m# TODO: memoize the following call.\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;66;03m# TODO: This does not currently account for background IBD (mean_bgd_num and mean_bgd_len)\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m     est_deg, L_est \u001b[38;5;241m=\u001b[39m \u001b[43minfer_degree_generalized_druid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43manc_id1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manc_id1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43manc_id2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manc_id2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartner_id1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartner_id1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartner_id2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartner_id2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdir1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdir2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mup_dct1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mup_dct2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mup_dct2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphased_ibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_seg_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIN_SEG_LEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m     deg_range \u001b[38;5;241m=\u001b[39m get_deg_range(\n\u001b[1;32m    600\u001b[0m         deg\u001b[38;5;241m=\u001b[39mest_deg,\n\u001b[1;32m    601\u001b[0m         delta\u001b[38;5;241m=\u001b[39mdeg_range_delta,\n\u001b[1;32m    602\u001b[0m     )\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# get the relationships between each proximally-related\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# genotyped ID and anc_id1 and anc_id2.\u001b[39;00m\n",
            "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/druid.py:588\u001b[0m, in \u001b[0;36minfer_degree_generalized_druid\u001b[0;34m(anc_id1, anc_id2, partner_id1, partner_id2, dir1, dir2, up_dct1, up_dct2, ibd_seg_list, condition, min_seg_len)\u001b[0m\n\u001b[1;32m    545\u001b[0m id_set2 \u001b[38;5;241m=\u001b[39m id_set2 \u001b[38;5;241m|\u001b[39m p_id_set2\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# FIXFIX: [EDITED 2024-03-30] this has been fixed perhaps\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m#         as much as it is possible to fix it by merging\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m#         segments on the correct haplogytpe if id_set1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m#       satisfy A IBD to C and B IBD to D so the phase does matter and\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m#       we can't just squash the segment in A with the segment in B.\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m L_union \u001b[38;5;241m=\u001b[39m \u001b[43mget_total_ibd_between_id_sets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_set1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_set1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mid_set2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_set2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;66;03m# find the fraction of anc_id1's genome (or anc_id1 + partner_id1 if it has a partner)\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;66;03m# that is shared with its most proximal genotyped relatives\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;66;03m# The shared fraction is 1 - Pr(S^c), where S^c is the event that a given allele is not shared\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# so\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m#   Pr(S) = 1 - [(1-Pr(S|A)) + (1-Pr(S|B))]/2\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m partner_id1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/ibd.py:494\u001b[0m, in \u001b[0;36mget_total_ibd_between_id_sets\u001b[0;34m(id_set1, id_set2, ibd_seg_list)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_total_ibd_between_id_sets\u001b[39m(\n\u001b[1;32m    444\u001b[0m     id_set1: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    445\u001b[0m     id_set2: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    446\u001b[0m     ibd_seg_list: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]],\n\u001b[1;32m    447\u001b[0m ):\n\u001b[1;32m    448\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m    Get the total amount of IBD shared between two sets of IDs\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m \n\u001b[1;32m    493\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m     seg_subset \u001b[38;5;241m=\u001b[39m \u001b[43mget_segs_between_sets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mid_set1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_set1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mid_set2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_set2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mibd_seg_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mibd_seg_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# if id_set1 or id_set2 contains just one ID, then we should\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# merge the segments on the left and right haplotypes separately\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(id_set1) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/computational_genetic_genealogy/utils/bonsaitree/bonsaitree/v3/ibd.py:365\u001b[0m, in \u001b[0;36mget_segs_between_sets\u001b[0;34m(id_set1, id_set2, ibd_seg_list)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_segs_between_sets\u001b[39m(\n\u001b[1;32m    347\u001b[0m     id_set1: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    348\u001b[0m     id_set2: \u001b[38;5;28mset\u001b[39m[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    349\u001b[0m     ibd_seg_list: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]],\n\u001b[1;32m    350\u001b[0m ):\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Get all segments between two sets of IDs\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m                  ID in id_set2\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 365\u001b[0m         s\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m ibd_seg_list\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (s[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m id_set1 \u001b[38;5;129;01mand\u001b[39;00m s[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m id_set2)\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (s[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m id_set1 \u001b[38;5;129;01mand\u001b[39;00m s[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m id_set2)\n\u001b[1;32m    369\u001b[0m     ]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from utils.bonsaitree.bonsaitree.v3 import bonsai\n",
        "\n",
        "up_dict_log_like_list = bonsai.build_pedigree(\n",
        "    bio_info=bioinfo,\n",
        "    unphased_ibd_seg_list=unphased_ibd_seg_list,\n",
        "    min_seg_len=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzp7Y7dKzo0o"
      },
      "source": [
        "## Louvain communities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR2eYQ_W7_t_"
      },
      "source": [
        "Louvain communities is a community detection algorithm that helps identify groups of nodes that are more densely connected to each other than to nodes in other groups. In the context of our problem, using Louvain communities allows us to partition the large network of individuals into smaller, more manageable communities.\n",
        "\n",
        "The Louvain algorithm is a hierarchical clustering algorithm that optimizes the modularity score of the network. Modularity is a measure of the strength of division of a network into communities. A high modularity score indicates that the nodes within a community have more connections among themselves than with nodes in other communities.\n",
        "\n",
        "By applying the Louvain algorithm to our network of individuals, we can identify communities of individuals that are more closely related to each other based on their shared IBD segments. This allows us to focus our analysis on smaller subsets of the data, reducing the computational burden and memory requirements.\n",
        "\n",
        "By leveraging Louvain communities, we can partition our large network into smaller communities and run Bonsai on each community separately. This approach enables us to work with larger datasets and overcome the memory limitations of the free version of Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "fLIHoAQgzsRP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding edges to the graph: 100%|██████████| 183061/183061 [00:05<00:00, 35775.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Create a graph from the hapibd_df DataFrame\n",
        "G = nx.Graph()\n",
        "\n",
        "with tqdm(total=len(segments), desc=\"Adding edges to the graph\") as pbar:\n",
        "    for _, row in segments.iterrows():\n",
        "        first_sample = row[\"sample1\"]\n",
        "        second_sample = row[\"sample2\"]\n",
        "        gen_seg_len = row[\"gen_seg_len\"]\n",
        "        G.add_edge(first_sample, second_sample, weight=gen_seg_len)\n",
        "        pbar.update(1)\n",
        "\n",
        "# Find Louvain communities\n",
        "communities = nx.community.louvain_communities(G, weight='weight')\n",
        "\n",
        "print(len(communities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "CJO4-Iwh6rZ7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Community 1:\n",
            "[1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023]\n",
            "\n",
            "Community 2:\n",
            "[1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103]\n",
            "\n",
            "Community 3:\n",
            "[1152, 1153, 1154, 1155, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151]\n",
            "\n",
            "Community 4:\n",
            "[1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207]\n",
            "\n",
            "Community 5:\n",
            "[1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the members of each community\n",
        "for i, community in enumerate(communities[:5], start=1):\n",
        "    print(f\"Community {i}:\")\n",
        "    print(list(community))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_vlJYp6k_qP"
      },
      "source": [
        "To make the Louvain communities smaller, you can adjust the `resolution` parameter in the `louvain_communities` function. The `resolution` parameter controls the size of the communities detected by the algorithm. By default, it is set to 1.0.\n",
        "\n",
        "* Decreasing the `resolution` parameter (e.g., setting it to a value less than 1.0) will result in larger communities. The algorithm will favor merging smaller communities into larger ones.\n",
        "* Increasing the `resolution` parameter (e.g., setting it to a value greater than 1.0) will result in smaller communities. The algorithm will favor splitting larger communities into smaller ones.\n",
        "\n",
        "Here's how you can modify the code to make the communities smaller:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "RSZVnG7PlPxV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding edges to the graph: 100%|██████████| 183061/183061 [00:04<00:00, 37638.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "358\n"
          ]
        }
      ],
      "source": [
        "with tqdm(total=len(segments), desc=\"Adding edges to the graph\") as pbar:\n",
        "    for _, row in segments.iterrows():\n",
        "        first_sample = row[\"sample1\"]\n",
        "        second_sample = row[\"sample2\"]\n",
        "        gen_seg_len = row[\"gen_seg_len\"]\n",
        "        G.add_edge(first_sample, second_sample, weight=gen_seg_len)\n",
        "        pbar.update(1)\n",
        "\n",
        "# Find Louvain communities with a smaller resolution value\n",
        "resolution = 100  # Adjust this value to control the size of the communities\n",
        "communities_v2 = nx.community.louvain_communities(G, resolution=resolution, weight='weight')\n",
        "print(len(communities_v2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "eG30P4OplbB7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Community 1:\n",
            "[1000]\n",
            "\n",
            "Community 2:\n",
            "[1003]\n",
            "\n",
            "Community 3:\n",
            "[1005]\n",
            "\n",
            "Community 4:\n",
            "[1007]\n",
            "\n",
            "Community 5:\n",
            "[1009]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print the members of each community\n",
        "for i, community in enumerate(communities_v2[:5], start=1):\n",
        "    print(f\"Community {i}:\")\n",
        "    print(list(community))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OezMpWaFnvGj"
      },
      "source": [
        "NOTE: It could be that you find Bonsai is more accurate for smaller, more related groups of individuals than for larger, more distantly related individuals. Bonsai has a `seed_pedigree_list` parameter that is an \"optional [list] of seed pedigrees to use as starting points for building the pedigree\". It also has a `validated_node_set_list` parameter where you can identify the nodes in the pedigrees in the `seed_pedigree_list` where you know the genealogical relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLXFu1nygNoc"
      },
      "source": [
        "# Run Bonsai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYYvmdK_l8g1"
      },
      "source": [
        "Rather than running Bonsai on our entire dataset, we can now run it on a Louvain community where we know there is relatedness among the members of the community. Because of this, we need to reduce our ibd_seg_list and bioinfo variables to only the inviduals in the community."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "WZxR8m1dJuM8"
      },
      "outputs": [],
      "source": [
        "# Choose the community you want to focus on (e.g., community 0)\n",
        "target_community = communities[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mdfJlW1qqM7u"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{1000,\n",
              " 1001,\n",
              " 1002,\n",
              " 1003,\n",
              " 1004,\n",
              " 1005,\n",
              " 1006,\n",
              " 1007,\n",
              " 1008,\n",
              " 1009,\n",
              " 1010,\n",
              " 1011,\n",
              " 1012,\n",
              " 1013,\n",
              " 1014,\n",
              " 1015,\n",
              " 1016,\n",
              " 1017,\n",
              " 1018,\n",
              " 1019,\n",
              " 1020,\n",
              " 1021,\n",
              " 1022,\n",
              " 1023,\n",
              " 1024,\n",
              " 1025,\n",
              " 1026,\n",
              " 1027,\n",
              " 1028,\n",
              " 1029,\n",
              " 1030,\n",
              " 1031,\n",
              " 1032,\n",
              " 1033,\n",
              " 1034,\n",
              " 1035,\n",
              " 1036,\n",
              " 1037,\n",
              " 1038,\n",
              " 1039,\n",
              " 1040,\n",
              " 1041,\n",
              " 1042,\n",
              " 1043,\n",
              " 1044,\n",
              " 1045,\n",
              " 1046,\n",
              " 1047,\n",
              " 1048,\n",
              " 1049,\n",
              " 1050,\n",
              " 1051}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "mSc_Ym0h8Yb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'genotype_id': 1000, 'age': 151, 'sex': 'F'},\n",
              " {'genotype_id': 1001, 'age': 170, 'sex': 'M'},\n",
              " {'genotype_id': 1002, 'age': 127, 'sex': 'F'},\n",
              " {'genotype_id': 1003, 'age': 150, 'sex': 'M'},\n",
              " {'genotype_id': 1004, 'age': 117, 'sex': 'M'},\n",
              " {'genotype_id': 1005, 'age': 132, 'sex': 'F'},\n",
              " {'genotype_id': 1006, 'age': 106, 'sex': 'M'},\n",
              " {'genotype_id': 1007, 'age': 116, 'sex': 'F'},\n",
              " {'genotype_id': 1008, 'age': 120, 'sex': 'F'},\n",
              " {'genotype_id': 1009, 'age': 112, 'sex': 'M'},\n",
              " {'genotype_id': 1010, 'age': 122, 'sex': 'F'},\n",
              " {'genotype_id': 1011, 'age': 108, 'sex': 'M'},\n",
              " {'genotype_id': 1012, 'age': 96, 'sex': 'F'},\n",
              " {'genotype_id': 1013, 'age': 100, 'sex': 'M'},\n",
              " {'genotype_id': 1014, 'age': 70, 'sex': 'F'},\n",
              " {'genotype_id': 1015, 'age': 90, 'sex': 'M'},\n",
              " {'genotype_id': 1016, 'age': 79, 'sex': 'F'},\n",
              " {'genotype_id': 1017, 'age': 85, 'sex': 'M'},\n",
              " {'genotype_id': 1018, 'age': 77, 'sex': 'M'},\n",
              " {'genotype_id': 1019, 'age': 95, 'sex': 'F'},\n",
              " {'genotype_id': 1020, 'age': 95, 'sex': 'M'},\n",
              " {'genotype_id': 1021, 'age': 88, 'sex': 'F'},\n",
              " {'genotype_id': 1022, 'age': 91, 'sex': 'M'},\n",
              " {'genotype_id': 1023, 'age': 93, 'sex': 'F'},\n",
              " {'genotype_id': 1024, 'age': 79, 'sex': 'M'},\n",
              " {'genotype_id': 1025, 'age': 69, 'sex': 'F'},\n",
              " {'genotype_id': 1026, 'age': 53, 'sex': 'M'},\n",
              " {'genotype_id': 1027, 'age': 68, 'sex': 'F'},\n",
              " {'genotype_id': 1028, 'age': 69, 'sex': 'F'},\n",
              " {'genotype_id': 1029, 'age': 53, 'sex': 'M'},\n",
              " {'genotype_id': 1030, 'age': 44, 'sex': 'F'},\n",
              " {'genotype_id': 1031, 'age': 51, 'sex': 'M'},\n",
              " {'genotype_id': 1032, 'age': 63, 'sex': 'F'},\n",
              " {'genotype_id': 1033, 'age': 61, 'sex': 'M'},\n",
              " {'genotype_id': 1034, 'age': 52, 'sex': 'M'},\n",
              " {'genotype_id': 1035, 'age': 66, 'sex': 'F'},\n",
              " {'genotype_id': 1036, 'age': 77, 'sex': 'F'},\n",
              " {'genotype_id': 1037, 'age': 68, 'sex': 'M'},\n",
              " {'genotype_id': 1038, 'age': 59, 'sex': 'F'},\n",
              " {'genotype_id': 1039, 'age': 65, 'sex': 'M'},\n",
              " {'genotype_id': 1040, 'age': 34, 'sex': 'M'},\n",
              " {'genotype_id': 1041, 'age': 44, 'sex': 'F'},\n",
              " {'genotype_id': 1042, 'age': 35, 'sex': 'F'},\n",
              " {'genotype_id': 1043, 'age': 37, 'sex': 'M'},\n",
              " {'genotype_id': 1044, 'age': 31, 'sex': 'F'},\n",
              " {'genotype_id': 1045, 'age': 24, 'sex': 'M'},\n",
              " {'genotype_id': 1046, 'age': 27, 'sex': 'M'},\n",
              " {'genotype_id': 1047, 'age': 26, 'sex': 'F'},\n",
              " {'genotype_id': 1048, 'age': 29, 'sex': 'M'},\n",
              " {'genotype_id': 1049, 'age': 39, 'sex': 'M'},\n",
              " {'genotype_id': 1050, 'age': 36, 'sex': 'F'},\n",
              " {'genotype_id': 1051, 'age': 22, 'sex': 'M'}]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def filter_ibd_seg_list(ibd_seg_list, community_ids, both_in_community=True):\n",
        "    if both_in_community:\n",
        "        filtered_ibd_seg_list = [\n",
        "            seg for seg in ibd_seg_list\n",
        "            if seg[0] in community_ids and seg[1] in community_ids\n",
        "        ]\n",
        "    # else:\n",
        "    #     filtered_ibd_seg_list = [\n",
        "    #         seg for seg in ibd_seg_list\n",
        "    #         if seg[0] in community_ids or seg[1] in community_ids\n",
        "    #     ]\n",
        "    return filtered_ibd_seg_list\n",
        "\n",
        "# Filter the ibd_seg_list based on the community IDs\n",
        "filtered_ibd_seg_list_v1 = filter_ibd_seg_list(unphased_ibd_seg_list, target_community, both_in_community=True)\n",
        "# filtered_ibd_seg_list_v2 = filter_ibd_seg_list(ibd_seg_list, target_community, both_in_community=False)\n",
        "\n",
        "# Filter the bioinfo based on the community IDs\n",
        "filtered_bioinfo = [info for info in bioinfo if info['genotype_id'] in target_community]\n",
        "filtered_bioinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QSOmfangdGs"
      },
      "source": [
        "### Option 1\n",
        "\n",
        "Run Bonsai without selecting a focal_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEe5Hjxxgmn0"
      },
      "outputs": [],
      "source": [
        "from utils.bonsaitree.bonsaitree.v3 import bonsai\n",
        "\n",
        "up_dict_log_like_list = bonsai.build_pedigree(\n",
        "    bio_info=filtered_bioinfo,\n",
        "    unphased_ibd_seg_list=filtered_ibd_seg_list_v1,\n",
        "    min_seg_len=3\n",
        ")\n",
        "\n",
        "# Takes about 5 mintues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pedigree {1050: {-2: 1, -5: 1}, -2: {-3: 1, -4: 1}, 1038: {-3: 1, -4: 1}, -5: {-6: 1, -7: 1}, 1049: {-10: 1, -13: 1}, -10: {-11: 1, -12: 1}, 1036: {-11: 1, -12: 1}, 1035: {-13: 1, -23: 1}, -13: {-6: 1, -18: 1}, 1020: {-18: 1, -22: 1}, 1037: {-18: 1, -6: 1}, 1048: {-26: 1, -33: 1}, -26: {-13: 1, -28: 1}, 1034: {-28: 1, -32: 1}, 1047: {-28: 1, -13: 1}, 1022: {-36: 1, -37: 1}, 1039: {-7: 1, -6: 1}, -7: {-36: 1, -37: 1}, 1025: {-44: 1, -47: 1}, -44: {-45: 1, -46: 1}, 1012: {-45: 1, -46: 1}, 1024: {-50: 1, -51: 1}, 1041: {-54: 1, -55: 1}, -54: {-50: 1, -51: 1}, 1040: {-58: 1, -59: 1}, 1051: {-58: 1, -60: 1}, -60: {-55: 1, -54: 1}, -55: {-47: 1, -44: 1}, 1017: {-63: 1, -64: 1}, 1033: {-67: 1, -68: 1}, 1018: {-67: 1, -69: 1}, -68: {-70: 1, -71: 1}, 1011: {-74: 1, -75: 1}, 1004: {-74: 1, -76: 1}, 1013: {-47: 1, -80: 1}, -47: {-75: 1, -74: 1}, 1028: {-83: 1, -84: 1}, 1044: {-87: 1, -88: 1}, -87: {-83: 1, -84: 1}, -88: {-89: 1, -90: 1}, 1026: {-93: 1, -94: 1}, 1043: {-93: 1, -90: 1}, 1042: {-98: 1, -99: 1}, -98: {-90: 1, -93: 1}, 1009: {-75: 1, -103: 1}, 1000: {-106: 1, -107: 1}, 1003: {-106: 1, 1001: 1}, 1001: {}, 1005: {-75: 1, -116: 1}, -75: {1001: 1, -106: 1}, 1029: {-90: 1, -89: 1}, 1027: {-64: 1, -63: 1}, 1014: {-90: 1, -128: 1}, -90: {-64: 1, -63: 1}, 1006: {-64: 1, -132: 1}, 1015: {-64: 1, -63: 1}, -63: {-75: 1, -103: 1}, 1002: {-103: 1, -139: 1}, 1007: {-103: 1, -75: 1}, 1008: {-142: 1, -143: 1}, 1019: {-71: 1, -70: 1}, -71: {-142: 1, -143: 1}, -70: {-103: 1, -75: 1}, 1010: {-150: 1, -151: 1}, 1023: {-150: 1, -47: 1}, 1021: {-6: 1, -18: 1}, -6: {-47: 1, -150: 1}, 1045: {-159: 1, -162: 1}, -159: {-160: 1, -161: 1}, 1030: {-160: 1, -161: 1}, -162: {-163: 1, -164: 1}, 1016: {-167: 1, -168: 1}, 1031: {-164: 1, -163: 1}, -164: {-167: 1, -168: 1}, -163: {-63: 1, -64: 1}, 1032: {-171: 1, -172: 1}, 1046: {-175: 1, -176: 1}, -175: {-171: 1, -172: 1}, -176: {-68: 1, -67: 1}}\n",
            "likelihood -16251.185047844805\n",
            "pedigree {1050: {-2: 1, -5: 1}, -2: {-3: 1, -4: 1}, 1038: {-3: 1, -4: 1}, -5: {-6: 1, -7: 1}, 1049: {-10: 1, -13: 1}, -10: {-11: 1, -12: 1}, 1036: {-11: 1, -12: 1}, 1035: {-13: 1, -23: 1}, -13: {-6: 1, -18: 1}, 1020: {-18: 1, -22: 1}, 1037: {-18: 1, -6: 1}, 1048: {-26: 1, -33: 1}, -26: {-13: 1, -28: 1}, 1034: {-28: 1, -32: 1}, 1047: {-28: 1, -13: 1}, 1022: {-36: 1, -37: 1}, 1039: {-7: 1, -6: 1}, -7: {-36: 1, -37: 1}, 1025: {-44: 1, -47: 1}, -44: {-45: 1, -46: 1}, 1012: {-45: 1, -46: 1}, 1024: {-50: 1, -51: 1}, 1041: {-54: 1, -55: 1}, -54: {-50: 1, -51: 1}, 1040: {-58: 1, -59: 1}, 1051: {-58: 1, -60: 1}, -60: {-55: 1, -54: 1}, -55: {-47: 1, -44: 1}, 1017: {-63: 1, -64: 1}, 1033: {-67: 1, -68: 1}, 1018: {-67: 1, -69: 1}, -68: {-70: 1, -71: 1}, 1011: {-74: 1, -75: 1}, 1004: {-74: 1, -76: 1}, 1013: {-47: 1, -80: 1}, -47: {-75: 1, -74: 1}, 1028: {-83: 1, -84: 1}, 1044: {-87: 1, -88: 1}, -87: {-83: 1, -84: 1}, -88: {-89: 1, -90: 1}, 1026: {-93: 1, -94: 1}, 1043: {-93: 1, -90: 1}, 1042: {-98: 1, -99: 1}, -98: {-90: 1, -93: 1}, 1009: {-75: 1, -103: 1}, 1000: {-106: 1, -107: 1}, 1003: {-106: 1, 1001: 1}, 1001: {}, 1005: {-75: 1, -116: 1}, -75: {1001: 1, -106: 1}, 1029: {-90: 1, -89: 1}, 1027: {-64: 1, -63: 1}, 1014: {-90: 1, -128: 1}, -90: {-64: 1, -63: 1}, 1006: {-64: 1, -132: 1}, 1015: {-64: 1, -63: 1}, -63: {-75: 1, -103: 1}, 1002: {-103: 1, -139: 1}, 1007: {-103: 1, -75: 1}, 1008: {-142: 1, -143: 1}, 1019: {-71: 1, -70: 1}, -71: {-142: 1, -143: 1}, -70: {-103: 1, -75: 1}, 1010: {-150: 1, -151: 1}, 1023: {-150: 1, -47: 1}, 1021: {-6: 1, -18: 1}, -6: {-47: 1, -150: 1}, 1045: {-159: 1, -162: 1}, -159: {-160: 1, -161: 1}, 1030: {-160: 1, -161: 1}, -162: {-163: 1, -164: 1}, 1016: {-167: 1, -168: 1}, 1031: {-164: 1, -163: 1}, -164: {-167: 1, -168: 1}, -163: {-63: 1, -64: 1}, 1032: {-171: 1, -172: 1}, 1046: {-175: 1, -176: 1}, -175: {-171: 1, -172: 1}, -176: {-68: 1, -67: 1}}\n",
            "likelihood -16251.185047844805\n",
            "pedigree {1050: {-2: 1, -5: 1}, -2: {-3: 1, -4: 1}, 1038: {-3: 1, -4: 1}, -5: {-6: 1, -7: 1}, 1049: {-10: 1, -13: 1}, -10: {-11: 1, -12: 1}, 1036: {-11: 1, -12: 1}, 1035: {-13: 1, -23: 1}, -13: {-6: 1, -18: 1}, 1020: {-18: 1, -22: 1}, 1037: {-18: 1, -6: 1}, 1048: {-26: 1, -33: 1}, -26: {-13: 1, -28: 1}, 1034: {-28: 1, -32: 1}, 1047: {-28: 1, -13: 1}, 1022: {-36: 1, -37: 1}, 1039: {-7: 1, -6: 1}, -7: {-36: 1, -37: 1}, 1025: {-44: 1, -47: 1}, -44: {-45: 1, -46: 1}, 1012: {-45: 1, -46: 1}, 1024: {-50: 1, -51: 1}, 1041: {-54: 1, -55: 1}, -54: {-50: 1, -51: 1}, 1040: {-58: 1, -59: 1}, 1051: {-58: 1, -60: 1}, -60: {-55: 1, -54: 1}, -55: {-47: 1, -44: 1}, 1017: {-63: 1, -64: 1}, 1033: {-67: 1, -68: 1}, 1018: {-67: 1, -69: 1}, -68: {-70: 1, -71: 1}, 1011: {-74: 1, -75: 1}, 1004: {-74: 1, -76: 1}, 1013: {-47: 1, -80: 1}, -47: {-75: 1, -74: 1}, 1028: {-83: 1, -84: 1}, 1044: {-87: 1, -88: 1}, -87: {-83: 1, -84: 1}, -88: {-89: 1, -90: 1}, 1026: {-93: 1, -94: 1}, 1043: {-93: 1, -90: 1}, 1042: {-98: 1, -99: 1}, -98: {-90: 1, -93: 1}, 1009: {-75: 1, -103: 1}, 1000: {-106: 1, -107: 1}, 1003: {-106: 1, 1001: 1}, 1001: {}, 1005: {-75: 1, -116: 1}, -75: {1001: 1, -106: 1}, 1029: {-90: 1, -89: 1}, 1027: {-64: 1, -63: 1}, 1014: {-90: 1, -128: 1}, -90: {-64: 1, -63: 1}, 1006: {-64: 1, -132: 1}, 1015: {-64: 1, -63: 1}, -63: {-75: 1, -103: 1}, 1002: {-103: 1, -139: 1}, 1007: {-103: 1, -75: 1}, 1008: {-142: 1, -143: 1}, 1019: {-71: 1, -70: 1}, -71: {-142: 1, -143: 1}, -70: {-103: 1, -75: 1}, 1010: {-150: 1, -151: 1}, 1023: {-150: 1, -47: 1}, 1021: {-6: 1, -18: 1}, -6: {-47: 1, -150: 1}, 1045: {-159: 1, -162: 1}, -159: {-160: 1, -161: 1}, 1030: {-160: 1, -161: 1}, -162: {-163: 1, -164: 1}, 1016: {-167: 1, -168: 1}, 1031: {-164: 1, -163: 1}, -164: {-167: 1, -168: 1}, -163: {-63: 1, -64: 1}, 1032: {-171: 1, -172: 1}, 1046: {-175: 1, -176: 1}, -175: {-171: 1, -172: 1}, -176: {-68: 1, -67: 1}}\n",
            "likelihood -16251.185047844805\n"
          ]
        }
      ],
      "source": [
        "for element in up_dict_log_like_list:\n",
        "    print(f\"pedigree {element[0]}\")\n",
        "    print(f\"likelihood {element[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T80gqeD4gRDN"
      },
      "source": [
        "### Option 2\n",
        "\n",
        "Run Bonsai looping through the sample where each sample becomes the focal_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZDwdgHtgTOI"
      },
      "outputs": [],
      "source": [
        "from utils.bonsaitree.bonsaitree.v3 import bonsai\n",
        "\n",
        "for id in list(target_community):\n",
        "    up_dict_log_like_list = bonsai.build_pedigree(\n",
        "        bio_info=filtered_bioinfo,\n",
        "        unphased_ibd_seg_list=filtered_ibd_seg_list_v1,\n",
        "        focal_id=id,\n",
        "        min_seg_len=3\n",
        "    )\n",
        "\n",
        "print(up_dict_log_like_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmJW_rn8gtk8"
      },
      "source": [
        "# Graph the Bonsai results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X3qY160g_zd"
      },
      "source": [
        "#### Create and Save the Graphs (without displaying)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkpAhZTOgsMi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import igraph as ig\n",
        "import pickle\n",
        "\n",
        "# Get a list of files that begins with 'bonsai_normed_pedigree'\n",
        "pedigree_files = glob.glob(os.path.join(results_directory, 'bonsai_normed_pedigree*.json'))\n",
        "\n",
        "for file_path in pedigree_files:\n",
        "    # Read the network file\n",
        "    with open(file_path, 'r') as file:\n",
        "        network = json.load(file)\n",
        "\n",
        "    # Create a new graph\n",
        "    g = ig.Graph(directed=True)\n",
        "\n",
        "    # Add vertices (i.e., nodes)\n",
        "    all_ids = set(map(str, network.keys())) | {str(item) for sublist in network.values() for item in sublist[1:]}\n",
        "    g.add_vertices(sorted(all_ids))\n",
        "\n",
        "    # Add edges and set child sex as a vertex attribute\n",
        "    for child_id, (sex, parent1, parent2) in network.items():\n",
        "        g.vs.find(name=str(child_id))['sex'] = sex\n",
        "        if parent1 is not None:\n",
        "            g.add_edge(str(parent1), str(child_id))\n",
        "        if parent2 is not None:\n",
        "            g.add_edge(str(parent2), str(child_id))\n",
        "\n",
        "    # Save graph in pickle format\n",
        "    pickle_filename = os.path.splitext(os.path.basename(file_path))[0] + '.pkl'\n",
        "    with open(os.path.join(results_directory, pickle_filename), 'wb') as pickle_file:\n",
        "        pickle.dump(g, pickle_file)\n",
        "\n",
        "print(\"Graphs saved in pickle format.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-D8apwzhMp1"
      },
      "source": [
        "#### Plot (visualize) the graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfBUUam2VuzR"
      },
      "outputs": [],
      "source": [
        "import pygraphviz as pgv\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "samples_str = [str(sample) for sample in list(target_community)]\n",
        "\n",
        "def create_graph_image_pygraphviz(name):\n",
        "    focus = name\n",
        "    loaded_graph = pickle.load(open(f\"{results_directory}/bonsai_normed_pedigree_{str(focus)}.pkl\", 'rb'))\n",
        "\n",
        "    # Create a new NetworkX graph\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Add nodes and edges\n",
        "    for vertex in loaded_graph.vs:\n",
        "        node_label = vertex[\"name\"]\n",
        "        G.add_node(node_label)\n",
        "\n",
        "    for edge in loaded_graph.es:\n",
        "        parent = loaded_graph.vs[edge.source][\"name\"]\n",
        "        child = loaded_graph.vs[edge.target][\"name\"]\n",
        "        G.add_edge(parent, child)\n",
        "\n",
        "    # Create a new PyGraphviz graph for visualization\n",
        "    A = nx.nx_agraph.to_agraph(G)\n",
        "\n",
        "    # Set node colors\n",
        "    for node in A.nodes():\n",
        "        check_focus = focus.split(\"_\")[0]\n",
        "        if node == check_focus:\n",
        "            node.attr['color'] = 'green'\n",
        "        elif node in samples_str:\n",
        "            node.attr['color'] = 'yellow'\n",
        "        else:\n",
        "            node.attr['color'] = 'white'\n",
        "\n",
        "    # Set Graphviz layout options\n",
        "    A.layout(prog='dot')\n",
        "\n",
        "    # Save and display the graph\n",
        "    graph_filename = f\"{results_directory}/bonsai_normed_pedigree_{focus}_dot.png\"\n",
        "    A.draw(graph_filename, format='png')\n",
        "\n",
        "    # Load and display the image\n",
        "    img = mpimg.imread(graph_filename)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3crFbD-fhvJ0"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "focus = \"1025_v1\"\n",
        "predicted_graph = create_graph_image_pygraphviz(focus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5Uvl1xJYHpT"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "focus = \"wo_focalid_v1\"\n",
        "predicted_graph = create_graph_image_pygraphviz(focus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WxC8Ejzrz2-"
      },
      "source": [
        "## Plot the true graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpmXIAwrr2rc"
      },
      "outputs": [],
      "source": [
        "# Creates the true graph (does not display)\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "# Load the fam file into a DataFrame\n",
        "fam_df = pd.read_csv(f\"{results_directory}/ped_sim_run-everyone.fam\", sep=\" \", header=None)\n",
        "fam_df.columns = [\"family_id\", \"individual_id\", \"father_id\", \"mother_id\", \"sex\", \"phenotype\"]\n",
        "\n",
        "# Load the seg_dict file into a DataFrame\n",
        "seg_dict_df = pd.read_csv(f\"{results_directory}/ped_sim_run.seg_dict.txt\", sep=\"\\t\", header=None)\n",
        "seg_dict_df.columns = [\"individual_id\", \"bonsai_id\"]\n",
        "\n",
        "# Create a dictionary to map individual_id to bonsai_id\n",
        "individual_to_bonsai = dict(zip(seg_dict_df[\"individual_id\"], seg_dict_df[\"bonsai_id\"]))\n",
        "\n",
        "# Create a graph using the fam data\n",
        "fam_graph = nx.DiGraph()\n",
        "for _, row in fam_df.iterrows():\n",
        "    individual_id = row[\"individual_id\"]\n",
        "    father_id = row[\"father_id\"]\n",
        "    mother_id = row[\"mother_id\"]\n",
        "\n",
        "    # Use Bonsai ID if available, otherwise use the original name\n",
        "    individual_node = individual_to_bonsai.get(individual_id, individual_id)\n",
        "    fam_graph.add_node(individual_node)\n",
        "\n",
        "    if father_id != \"0\":\n",
        "        father_node = individual_to_bonsai.get(father_id, father_id)\n",
        "        fam_graph.add_edge(father_node, individual_node)\n",
        "\n",
        "    if mother_id != \"0\":\n",
        "        mother_node = individual_to_bonsai.get(mother_id, mother_id)\n",
        "        fam_graph.add_edge(mother_node, individual_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy0buUYGr8nI"
      },
      "outputs": [],
      "source": [
        "# Check the number of nodes and edges in the graph\n",
        "print(\"Number of nodes:\", fam_graph.number_of_nodes())\n",
        "print(\"Number of edges:\", fam_graph.number_of_edges())\n",
        "\n",
        "# Print a few nodes\n",
        "print(\"\\nNodes:\")\n",
        "for node in list(fam_graph.nodes())[:5]:\n",
        "    print(node)\n",
        "\n",
        "# Print a few edges\n",
        "print(\"\\nEdges:\")\n",
        "for edge in list(fam_graph.edges())[:5]:\n",
        "    print(edge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMpkrcJNtI7J"
      },
      "outputs": [],
      "source": [
        "# Find the target community individuals\n",
        "target_community_individual_ids = [seg_dict_df.loc[seg_dict_df[\"bonsai_id\"] == int(bonsai_id), \"individual_id\"].values[0] for bonsai_id in target_community]\n",
        "\n",
        "# Find all connected individuals (relatives and ancestors) of the target community\n",
        "connected_individuals = set()\n",
        "for individual_id in target_community_individual_ids:\n",
        "    connected_individuals.update(nx.descendants(fam_graph, individual_to_bonsai.get(individual_id, individual_id)))\n",
        "    connected_individuals.update(nx.ancestors(fam_graph, individual_to_bonsai.get(individual_id, individual_id)))\n",
        "connected_individuals.update(target_community_individual_ids)\n",
        "\n",
        "# Create the true graph for the target community and their connected individuals\n",
        "true_graph = nx.subgraph(fam_graph, [individual_to_bonsai.get(individual_id, individual_id) for individual_id in connected_individuals])\n",
        "\n",
        "# Check the number of nodes and edges in the graph\n",
        "print(\"Number of nodes:\", true_graph.number_of_nodes())\n",
        "print(\"Number of edges:\", true_graph.number_of_edges())\n",
        "\n",
        "# Print a few nodes\n",
        "print(\"\\nNodes:\")\n",
        "for node in list(true_graph.nodes())[:5]:\n",
        "    print(node)\n",
        "\n",
        "# Print a few edges\n",
        "print(\"\\nEdges:\")\n",
        "for edge in list(true_graph.edges())[:5]:\n",
        "    print(edge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ_EBErc5BtX"
      },
      "outputs": [],
      "source": [
        "# Create a PyGraphviz graph\n",
        "A = pgv.AGraph(directed=True)\n",
        "\n",
        "# Add nodes and edges to the PyGraphviz graph\n",
        "for node in true_graph.nodes():\n",
        "    A.add_node(node)\n",
        "    if node in [individual_to_bonsai.get(individual_id, individual_id) for individual_id in target_community_individual_ids]:\n",
        "        A.get_node(node).attr['color'] = 'green'\n",
        "    else:\n",
        "        A.get_node(node).attr['color'] = 'white'\n",
        "\n",
        "for edge in true_graph.edges():\n",
        "    parent, child = edge\n",
        "    A.add_edge(parent, child)\n",
        "\n",
        "# Set Graphviz layout options\n",
        "A.layout(prog='dot')\n",
        "\n",
        "# Save and display the graph\n",
        "graph_filename = f\"{results_directory}/true_graph_target_community.png\"\n",
        "A.draw(graph_filename, format='png')\n",
        "\n",
        "# Load and display the image\n",
        "img = mpimg.imread(graph_filename)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OddqX4zY6H8O"
      },
      "source": [
        "## Exploring Bonsai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imgPUKl06JpA"
      },
      "outputs": [],
      "source": [
        "from use.bonsaitree import bonsai\n",
        "\n",
        "results_v1 = bonsai.build_pedigree(filtered_ibd_seg_list_v1, filtered_bioinfo)\n",
        "\n",
        "bonsai_normed_pedigree_wo_focalid_v1 = results_v1['normed_pedigree']\n",
        "\n",
        "with open(f\"{results_directory}/bonsai_normed_pedigree_wo_focalid_v1.json\", 'w') as results_file:\n",
        "    json.dump(bonsai_normed_pedigree_wo_focalid_v1, results_file)\n",
        "\n",
        "#***********************************************\n",
        "ped_obj_wo_focalid_v1 = results_v1['ped_obj']\n",
        "#***********************************************"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmgaueV49Qj9"
      },
      "outputs": [],
      "source": [
        "focus = \"wo_focalid_v1\"\n",
        "predicted_graph = create_graph_image_pygraphviz(focus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz3ZtpiA6X4l"
      },
      "outputs": [],
      "source": [
        "ped_obj_wo_focalid_v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0x0PXc16b4t"
      },
      "outputs": [],
      "source": [
        "# up_pedigree_dict: (dict) Stores the topology of the inferred pedigree.\n",
        "# Has the form {child_id : [child_sex, child_age, parent1_id, parent2_id]}.\n",
        "\n",
        "ped_obj_wo_focalid_v1.up_pedigree_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwo7dijK6mia"
      },
      "outputs": [],
      "source": [
        "# (dict) Stores the topology of the inferred pedigree.\n",
        "# Has the form {parent_id : [parent_sex, parent_age, child1_id, child2_id, ...]}\n",
        "\n",
        "ped_obj_wo_focalid_v1.down_pedigree_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLIoJjPK6_1t"
      },
      "outputs": [],
      "source": [
        "# all_ids: (list) List of all ids in the pedigree\n",
        "\n",
        "ped_obj_wo_focalid_v1.all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKYOsMAy7G3h"
      },
      "outputs": [],
      "source": [
        "# ibd_stats: (dict) Dict with keys of the form frozenset({id1, id2})\n",
        "# and values giving summary statistics of the ibd sharing between the pair.\n",
        "ped_obj_wo_focalid_v1.ibd_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5giV88l27S4Q"
      },
      "outputs": [],
      "source": [
        "# rel_dict: (dict) Dict of the form dict[id] = {'anc' : <Set of ancestor ids>, 'desc' : <Set of descendant ids>,\n",
        "# 'rel' : <Set of relatives who are neither direct descendants nor ancestors>}.\n",
        "\n",
        "ped_obj_wo_focalid_v1.rel_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI3z0K3d7l5A"
      },
      "outputs": [],
      "source": [
        "# rels: (dict) Nested dict of the form dict[id1][id2] = deg,\n",
        "# where deg is a three-element tuple representing the relationship between id1 and id2.\n",
        "# Deg is of the form deg = (num_up, num_down, num_anc), where num_up is the number of\n",
        "# meioses separating id1 from its common ancestor(s) with id2. num_down is the number of\n",
        "# meioses separating id2 from its common ancestor(s) with id1. num_anc is the number of\n",
        "# common ancestors shared between id1 and id2.\n",
        "\n",
        "ped_obj_wo_focalid_v1.rels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI3aTZBu77tj"
      },
      "outputs": [],
      "source": [
        "# pairwise_log_likelihoods: (dict) Nested dict of the form dict[id1][id1] = log_like,\n",
        "# where log_like is the pairwise log likelihood of the relationship between id and id2 based on IBD sharing and age.\n",
        "\n",
        "ped_obj_wo_focalid_v1.pairwise_log_likelihoods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8aIdTpv79C0"
      },
      "outputs": [],
      "source": [
        "# get_connecting_path_set: (method) Find all ancestors on the path connecting two related nodes (id1 and id2).\n",
        "# Usage: path_set = ped_obj.get_connecting_path_set(id1, id2).\n",
        "\n",
        "ped_obj_wo_focalid_v1.get_connecting_path_set(1024, 1028)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
