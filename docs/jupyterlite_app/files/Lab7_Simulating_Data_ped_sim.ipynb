{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import IPython\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_comp_gen_dir():\n",
    "    \"\"\"Find the computational_genetic_genealogy directory by searching up from current directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Search up through parent directories\n",
    "    while current != current.parent:\n",
    "        # Check if target directory exists in current path\n",
    "        target = current / 'computational_genetic_genealogy'\n",
    "        if target.is_dir():\n",
    "            return target\n",
    "        # Move up one directory\n",
    "        current = current.parent\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find computational_genetic_genealogy directory\")\n",
    "\n",
    "def load_env_file():\n",
    "    \"\"\"Find and load the .env file from the computational_genetic_genealogy directory.\"\"\"\n",
    "    try:\n",
    "        # Find the computational_genetic_genealogy directory\n",
    "        comp_gen_dir = find_comp_gen_dir()\n",
    "        \n",
    "        # Look for .env file\n",
    "        env_path = comp_gen_dir / '.env'\n",
    "        if not env_path.exists():\n",
    "            print(f\"Warning: No .env file found in {comp_gen_dir}\")\n",
    "            return None\n",
    "        \n",
    "        # Load the .env file\n",
    "        load_dotenv(env_path, override=True)\n",
    "        print(f\"Loaded environment variables from: {env_path}\")\n",
    "        return env_path\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use the function\n",
    "env_path = load_env_file()\n",
    "\n",
    "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
    "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
    "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
    "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
    "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
    "\n",
    "os.environ[\"WORKING_DIRECTORY\"] = working_directory\n",
    "os.environ[\"DATA_DIRECTORY\"] = data_directory\n",
    "os.environ[\"REFERENCES_DIRECTORY\"] = references_directory\n",
    "os.environ[\"RESULTS_DIRECTORY\"] = results_directory\n",
    "os.environ[\"UTILS_DIRECTORY\"] = utils_directory\n",
    "\n",
    "print(f\"Working Directory: {working_directory}\")\n",
    "print(f\"Data Directory: {data_directory}\")\n",
    "print(f\"References Directory: {references_directory}\")\n",
    "print(f\"Results Directory: {results_directory}\")\n",
    "print(f\"Utils Directory: {utils_directory}\")\n",
    "\n",
    "os.chdir(working_directory)\n",
    "print(f\"The current directory is {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\"):\n",
    "    \"\"\"\n",
    "    Configure logging for both file and console handlers.\n",
    "\n",
    "    Args:\n",
    "        log_filename (str): Path to the log file where logs will be written.\n",
    "        log_file_debug_level (str): Logging level for the file handler.\n",
    "        console_debug_level (str): Logging level for the console handler.\n",
    "    \"\"\"\n",
    "    # Create a root logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)  # Capture all messages at the root level\n",
    "\n",
    "    # Convert level names to numeric levels\n",
    "    file_level = getattr(logging, log_file_debug_level.upper(), logging.INFO)\n",
    "    console_level = getattr(logging, console_debug_level.upper(), logging.INFO)\n",
    "\n",
    "    # File handler: Logs messages at file_level and above to the file\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(file_level)\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "\n",
    "    # Console handler: Logs messages at console_level and above to the console\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(console_level)\n",
    "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "\n",
    "    # Add handlers to the root logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "def clear_logger():\n",
    "    \"\"\"Remove all handlers from the root logger.\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "        \n",
    "log_filename = os.path.join(results_directory, \"lab8.log\")\n",
    "print(f\"The Lab 8 log file is located at {log_filename}.\")\n",
    "\n",
    "# Ensure the results_directory exists\n",
    "if not os.path.exists(results_directory):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "# Check if the file exists; if not, create it\n",
    "if not os.path.exists(log_filename):\n",
    "    with open(log_filename, 'w') as file:\n",
    "        pass  # The file is now created.\n",
    "    \n",
    "clear_logger() # Clear the logger before reconfiguring it\n",
    "configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ped-sim method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pedigree Simulator (Ped-sim) is a powerful tool for simulating pedigree structures that use sex-specific genetic maps and considers sex of the individual. To get it up and running on your system, you'll need to download and compile it in your computing space if it is not already there.\n",
    "\n",
    "Here is the ped-sim GitHub page for your reference: [ped-sim](https://github.com/williamslab/ped-sim)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex-specific Genetic Map\n",
    "\n",
    "From [Map file](https://github.com/williamslab/ped-sim?tab=readme-ov-file#map-file-):\n",
    "\n",
    "\"The genetic map file contains three columns for a sex-averaged map and four columns if using male and female maps. The format of this file is:\n",
    "\n",
    "`[chromosome] [physical_position] [map_position0] <map_position1>`\n",
    "\n",
    "The chromosomes are expected to be listed in the same order as they are in any input VCF file, with the physical positions in increasing order. The chromosome names must also match the names in the input VCF file, and all chromosome names present in the map must also have corresponding records in the VCF.\n",
    "\n",
    "[map_position0] is genetic position in centiMorgans, and should either be the sex-averaged genetic position if using only one map, or should be the male genetic position if using two maps. When using only one map, the simulator samples all crossovers from that one map and does not distinguish male and female parents.\n",
    "\n",
    "<map_position1> is likewise a genetic position in centiMorgans and should correspond to the female genetic position if given.\n",
    "\n",
    "A high resolution human sex-specific genetic map is available [here](https://github.com/cbherer/Bherer_etal_SexualDimorphismRecombination), and is described in [BhÃ©rer et al. (2017)](https://www.nature.com/articles/ncomms14994). To generate an autosomal map file in the format the simulator requires with both male and female genetic positions, run the following bash commands:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$references_directory\"\n",
    "\n",
    "# Receive directory variables from Python\n",
    "references_directory=$1\n",
    "\n",
    "# genetic map for ped-sim\n",
    "\n",
    "wget https://github.com/cbherer/Bherer_etal_SexualDimorphismRecombination/raw/master/Refined_genetic_map_b37.tar.gz -P $references_directory\n",
    "tar xvzf $references_directory/Refined_genetic_map_b37.tar.gz -C $references_directory\n",
    "printf \"#chr\\tpos\\tmale_cM\\tfemale_cM\\n\" > $references_directory/refined_mf_b37.simmap\n",
    "\n",
    "# The paste command combines each line from the male chromosome file (male_chr$chr.txt)\n",
    "# with the corresponding line from the female chromosome file (female_chr$chr.txt).\n",
    "# They are combined side by side, separated by a tab.\n",
    "for chr in {1..22}; do\n",
    "  paste $references_directory/Refined_genetic_map_b37/male_chr$chr.txt $references_directory/Refined_genetic_map_b37/female_chr$chr.txt \\\n",
    "    | awk -v OFS=\"\\t\" 'NR > 1 && $2 == $6 {print $1,$2,$4,$8}' \\\n",
    "    | sed 's/^chr//' >> $references_directory/refined_mf_b37.simmap\n",
    "done\n",
    "\n",
    "rm $references_directory/Refined_genetic_map_b37.tar.gz\n",
    "rm -r $references_directory/Refined_genetic_map_b37\n",
    "\n",
    "# When you get the check mark indicating that the cell successfully completed its run,\n",
    "# go ahead and clear the cell output.\n",
    "\n",
    "# For the moment, you can igore:\n",
    "\n",
    "# tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
    "# tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
    "# tar: Ignoring unknown extended header keyword 'SCHILY.nlink'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have the `refined_mf_b37.simmap` file in your references directory. Manually take a look at the file. It is a text file so you can use Notepad++ or your build-in text editor to view it.\n",
    "\n",
    "The next two cells is used to convert the file from build 37 to build 38."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$references_directory\" \"$utils_directory\"\n",
    "\n",
    "# Receive directory variables from Python\n",
    "references_directory=$1\n",
    "utils_directory=$2\n",
    "\n",
    "# --- Convert the build 37 map to build 38 using liftOver ---\n",
    "\n",
    "# Create a BED file from the build 37 simmap.\n",
    "# The BED file requires 0-based start coordinates, so subtract 1 from the position.\n",
    "awk 'NR>1 {print \"chr\"$1, $2-1, $2, $3, $4}' OFS=\"\\t\" $references_directory/refined_mf_b37.simmap > $references_directory/refined_mf_b37.bed\n",
    "\n",
    "# Run liftOver to convert BED coordinates to build 38.\n",
    "liftOver $references_directory/refined_mf_b37.bed \\\n",
    "         $references_directory/hg19ToHg38.over.chain.gz \\\n",
    "         $references_directory/refined_mf_b38.bed \\\n",
    "         $references_directory/refined_mf_b38.unmapped\n",
    "\n",
    "# (Optional) Clean up temporary files\n",
    "rm $references_directory/refined_mf_b37.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the BED file\n",
    "bed_file = os.path.join(references_directory, \"refined_mf_b38.bed\")\n",
    "bed_data = pd.read_csv(bed_file, sep='\\t', header=None)\n",
    "\n",
    "# Rename columns for clarity\n",
    "bed_data.columns = ['chr', 'start', 'pos', 'male_cM', 'female_cM']\n",
    "\n",
    "# Clean chromosome names (remove 'chr' prefix)\n",
    "bed_data['chr'] = bed_data['chr'].str.replace('chr', '', regex=True)\n",
    "\n",
    "# Convert chromosome to numeric if possible\n",
    "bed_data['chr'] = pd.to_numeric(bed_data['chr'], errors='coerce')\n",
    "\n",
    "# Filter for chromosomes 1-22 and remove NaN values\n",
    "mask = (bed_data['chr'] >= 1) & (bed_data['chr'] <= 22) & (bed_data['chr'].notna())\n",
    "filtered_data = bed_data[mask].copy()  # Create a copy to avoid the warning\n",
    "\n",
    "# Convert chromosome to integer after filtering out NaN values\n",
    "filtered_data['chr'] = filtered_data['chr'].astype(int)\n",
    "\n",
    "# Sort by chromosome (numerically) and position\n",
    "sorted_data = filtered_data.sort_values(by=['chr', 'pos'])\n",
    "\n",
    "# Keep only necessary columns\n",
    "simmap_data = sorted_data[['chr', 'pos', 'male_cM', 'female_cM']]\n",
    "\n",
    "# Print sample of data to verify\n",
    "print(\"Sample of data to be saved:\")\n",
    "print(simmap_data.head())\n",
    "\n",
    "# Save to simmap file with header\n",
    "simmap_file = os.path.join(references_directory, \"refined_mf_b38.simmap\")\n",
    "with open(simmap_file, 'w') as f:\n",
    "    f.write(\"#chr\\tpos\\tmale_cM\\tfemale_cM\\n\")\n",
    "simmap_data.to_csv(simmap_file, sep='\\t', index=False, header=False, mode='a')\n",
    "\n",
    "print(\"Processing complete - chromosomes saved as integers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Ped-sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to run ped-sim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$references_directory\" \"$utils_directory\" \"$results_directory\"\n",
    "\n",
    "# Receive directory variables from Python\n",
    "references_directory=$1\n",
    "utils_directory=$2\n",
    "results_directory=$3\n",
    "pedigree_definition_file=\"pedigree.def\"\n",
    "ped_sim_filename=\"ped_sim_run\"\n",
    "\n",
    "# Run ped-sim with parameters:\n",
    "\n",
    "# -d: Specifies the path to the pedigree definition file.\n",
    "# -m: Specifies the path to the genetic map file.\n",
    "# -o: Specifies the prefix for the output files.\n",
    "# --intf: Uses the interference crossover model\n",
    "# --seed: Sets the random number generator seed to ensure reproducibility.\n",
    "# --fam: Outputs the simulated data in PLINK's .fam format.\n",
    "# --mrca: Outputs the most recent common ancestor (MRCA) of all sampled individuals.\n",
    "\n",
    "\n",
    "# Notice that this uses the human crossover interference parameters stored in pedsim/interfere directory\n",
    "\n",
    "${utils_directory}/ped-sim/ped-sim \\\n",
    "  -d $results_directory/$pedigree_definition_file \\\n",
    "  -m $references_directory/refined_mf_b38.simmap \\\n",
    "  -o $results_directory/$ped_sim_filename \\\n",
    "  --intf $utils_directory/ped-sim/interfere/nu_p_campbell.tsv \\\n",
    "  --seed 1234 \\\n",
    "  --fam \\\n",
    "  --mrca\n",
    "\n",
    "# # using --pois instead of --intf\n",
    "# # --pois: Uses the Poisson distribution to determine the number of crossovers.\n",
    "# ./pedsim/ped-sim \\\n",
    "#   -d $util_directory/$pedigree_definition_file \\\n",
    "#   -m $references_directory/combined_genetic_map_b38.txt \\\n",
    "#   -o $results_directory/$ped_sim_filename \\\n",
    "#   --pois \\\n",
    "#   --seed 1234 \\\n",
    "#   --fam \\\n",
    "#   --mrca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's take a look at the results.** \n",
    "\n",
    "Familiarize yourself with the different result files. Those are the ped_sim_run files in your results directory. Notice from the output of the above cell that if you wanted to simulate genotype data for this configuration, you would need to rerun the above cell with an input VCF with 220 founders (if you selected 10 pedigrees and the predefined pedigree). For now, we do not actually need the genotype itself. Using the IBD segment data (the .seg file) is sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing the results\n",
    "\n",
    "In this run, we will first define the graph function, then call the function to create our graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the graph function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "def graph_fam_file_simulated(filename, pedigree=None):\n",
    "    fam_file = pd.read_csv(os.path.join(results_directory, filename), sep=\" \", header=None)\n",
    "    fam_file.columns = [\"fam\", \"id\", \"parent0\", \"parent1\", \"sex\", \"phenotype\"]\n",
    "\n",
    "    if pedigree is not None:\n",
    "\n",
    "        # Extract pedigree number from the first element\n",
    "        fam_file['pedigree_num'] = fam_file['fam'].apply(lambda x: x.replace(\"FAM\", \"\"))\n",
    "        fam_file = fam_file[fam_file['pedigree_num'] == str(pedigree)]\n",
    "\n",
    "    fig = plt.figure(num=None, figsize=(250, 100), dpi=100)\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for index, row in fam_file.iterrows():\n",
    "        id = row['id']\n",
    "\n",
    "        values_id1 = id.split(\"_\")\n",
    "        \n",
    "        # Ensure the ID follows expected format\n",
    "        if len(values_id1) < 2:\n",
    "            raise ValueError(f\"Unexpected ID format: {id} -> {values_id1}\")\n",
    "        \n",
    "        subvalues_id1 = values_id1[1].split(\"-\")\n",
    "        gen_id1 = int(subvalues_id1[0].lstrip(\"g\"))\n",
    "\n",
    "        G.add_node(id, time=gen_id1)\n",
    "\n",
    "        for parent_column in ['parent0', 'parent1']:\n",
    "            if row[parent_column] != '0':\n",
    "                parent_id = row[parent_column]\n",
    "                values_parent = parent_id.split(\"_\")\n",
    "\n",
    "                if len(values_parent) < 2:\n",
    "                    raise ValueError(f\"Unexpected Parent format: {parent_id} -> {values_parent}\")\n",
    "\n",
    "                subvalues_parent = values_parent[1].split(\"-\")\n",
    "                gen_parent = int(subvalues_parent[0].lstrip(\"g\"))\n",
    "                G.add_node(parent_id, time=gen_parent)\n",
    "                G.add_edge(parent_id, id)\n",
    "\n",
    "    # Reverse the order of generations\n",
    "    max_gen = max(gen_id1 for _, gen_id1 in G.nodes(data='time'))\n",
    "    for node, data in G.nodes(data=True):\n",
    "        data['time'] = max_gen - data['time']\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Call the graph function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = graph_fam_file_simulated(\"ped_sim_run-everyone.fam\")\n",
    "pos = nx.multipartite_layout(G1, subset_key=\"time\", align=\"horizontal\", scale=50)\n",
    "nx.draw_networkx(G1, pos, node_size=3000, with_labels=True, arrows=False)\n",
    "ped_sim_plot_filename = f\"{results_directory}/diagram_ped_sim_pedigree.svg\"\n",
    "# plt.title(\"Ped-Sim Pedigree\")\n",
    "plt.savefig(ped_sim_plot_filename, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output, you will see a depiction of all 10 pedigrees (also saved in your results directory as a `diagram_ped_sim_pedigree.svg`). You should see five rows of blue dots. These are the six generations specified in the pedigree definition file. But perhaps it's a little difficult to see what's going on in the output. Let's take a look at just one of the pedigrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedigree_num = 1\n",
    "G2 = graph_fam_file_simulated(\"ped_sim_run-everyone.fam\", pedigree = pedigree_num)\n",
    "pos = nx.multipartite_layout(G2, subset_key=\"time\", align=\"horizontal\", scale=50)\n",
    "nx.draw_networkx(G2, pos, node_size=3000, with_labels=True, arrows=False)\n",
    "ped_sim_plot_filename = f\"{results_directory}/diagram_ped_sim_pedigree_{pedigree_num}.svg\"\n",
    "plt.savefig(ped_sim_plot_filename, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better. Now we can see what one of the pedigrees look like.\n",
    "\n",
    "Each node (blue circle) is a person. Each edge (line) represents one generation.\n",
    "\n",
    "Can you identify:\n",
    "- full siblings\n",
    "- first cousins\n",
    "- second cousins\n",
    "- third cousins\n",
    "- parents\n",
    "- grandparents\n",
    "- great grandparents\n",
    "- 2x great grandparents\n",
    "- aunt/uncle (avuncular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segments\n",
    "\n",
    "Now, let's look at the segment data and build our data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = pd.read_csv(os.path.join(results_directory, \"ped_sim_run2.seg\"), sep=\"\\t\", header = None)\n",
    "segments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the column headers are not very informative. Let's change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.columns = ([\"id1\", \"id2\", \"chromosome\", \"physical_position_start\", \"physical_position_end\", \"IBD_type\", \"genetic_position_start\", \"genetic_position_end\", \"genetic_length\"])\n",
    "segments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values\n",
    "segments['IBD_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments['chromosome'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data descriptives\n",
    "segments['genetic_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the DNA segment minimum genetic length\n",
    "\n",
    "min_segment_size = float(segments['genetic_length'].min())\n",
    "\n",
    "print(f\"The minimum segment size is {min_segment_size:.6f} cM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, we would not work with DNA segments smaller than what we can accurately detect. The IBD detection algorithms we use can accurately detect IBD segments at a minimum of 2 cM (e.g., Refined IBD). Let's conservatively filter the segment such that we use only the segments with a minimum of 3 cM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset your data.\n",
    "# Get only the segments with a genetic length of at least 3 cM.\n",
    "\n",
    "filtered_segments = segments[segments['genetic_length'] >= 3]\n",
    "filtered_segments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data descriptives\n",
    "filtered_segments['genetic_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the descriptive output of the full dataset and the subsetted dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use other filtering conditions if you want. For example, you could filter the segments between 10 and 50 cM inclusively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_segments_50_10 = segments[(segments['genetic_length'] >= 10) & (segments['genetic_length'] <= 50)]\n",
    "filtered_segments_50_10.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_segments_50_10['genetic_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a summary pandas dataframe called relationships based on the segment data. Instead of having a row for each segment, this dataframe will summarize the shared segments for each unique pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the relationships dataframe for simulated data\n",
    "\n",
    "def segment_position(x, position):\n",
    "    sorted_values = x.sort_values(ascending=False)\n",
    "    if len(sorted_values) < position:\n",
    "        return 0\n",
    "    return sorted_values.iloc[position - 1]\n",
    "\n",
    "relationships = filtered_segments.groupby(['id1', 'id2']).agg(\n",
    "    num_seg=('id1', 'size'),\n",
    "    total_shared=('genetic_length', 'sum'),\n",
    "    max_seg=('genetic_length', 'max'),\n",
    "    second_seg=('genetic_length', lambda x: segment_position(x, 2)),\n",
    "    third_seg=('genetic_length', lambda x: segment_position(x, 3)),\n",
    "    fourth_seg=('genetic_length', lambda x: segment_position(x, 4)),\n",
    ").reset_index()\n",
    "\n",
    "relationships.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_relationships = relationships.copy()  # Create a copy of the relationships DataFrame\n",
    "\n",
    "def get_relationships(row):\n",
    "    common_ancestors = nx.lowest_common_ancestor(G1, row['id1'], row['id2'])\n",
    "    path_lengths1 = nx.shortest_path_length(G1, source=common_ancestors, target=row['id1'])\n",
    "    path_lengths2 = nx.shortest_path_length(G1, source=common_ancestors, target=row['id2'])\n",
    "    return str((path_lengths1, path_lengths2))\n",
    "\n",
    "with tqdm(total=len(updated_relationships), desc=\"Processing relationships\") as progress_bar:\n",
    "    for index, row in updated_relationships.iterrows():\n",
    "        updated_relationships.loc[index, 'genealogical_relationship'] = get_relationships(row)\n",
    "        progress_bar.update()\n",
    "\n",
    "updated_relationships.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the updated relationships dataframe, each row represents an unique pair. It also has the total number of segments shared in the pair, total amount of DNA (minimum of 3 cM), and largest 4 segment (cM). You'll also see a genealogical_relationship column where the value is a tuple. In the tuple, the first value is the number of generations from id1 to the shared ancestor, and the second value is the number of generations from id2 and the shared ancestor. For example, (2, 1) means that there is 2 generations between id1 and the shared ancestor and 1 generation between id2 and the shared ancestor. A genealogical_relationship of (1, 1) is full siblings (i.e., siblings sharing both biological parents). A value of 0 means \"self\", indicating that self is the ancestor of the other person. For example, (0, 1) means that id1 is the parent of id2. In another example, (2, 0) means that id1 is the grandchild of id2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_relationships.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_relationships.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we will add column meiotic_distance. Meiotic distance is the number of meioses separating the members of the pair. It is calculated by summing the values in the genealogical_relationship tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "updated_relationships['genealogical_relationship'] = updated_relationships['genealogical_relationship'].apply(ast.literal_eval)\n",
    "updated_relationships['meiotic_distance'] = updated_relationships['genealogical_relationship'].apply(lambda x: sum(x) if isinstance(x, tuple) else \"\")\n",
    "\n",
    "updated_relationships.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_relationships.to_csv(os.path.join(results_directory, \"relationships.csv\"), sep=\"\\t\", index=False)\n",
    "\n",
    "# Manually confirm that your relationships.csv file is in your results directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_relationships.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_relationships['genealogical_relationship'].value_counts())\n",
    "print(\"\\n\")\n",
    "print(f\"There are {len(updated_relationships['genealogical_relationship'].unique())} different relationship groups among the sampled individuals in this pedigree.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore some descriptives of DNA sharing (min 3 cM segment) at the various relationship levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_relationships.drop([\n",
    "    \"id1\", \"id2\",\n",
    "    \"second_seg\", \"third_seg\",\n",
    "    \"meiotic_distance\"\n",
    "    ], axis=1).groupby(\"genealogical_relationship\").agg(['count', 'mean', 'std', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the saved csv file as a Pandas dataframe, replacing the previously saved `relationships` value.\n",
    "relationships = pd.read_csv(os.path.join(results_directory, \"relationships.csv\"), sep = \"\\t\")\n",
    "\n",
    "relationships.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=relationships, y='meiotic_distance', x='max_seg')\n",
    "plt.xlabel('Max Segment Length')\n",
    "plt.ylabel('Genealogical Distance')\n",
    "plt.title('Scatter Plot: Genealogical Distance vs Max Segment Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=relationships, y='meiotic_distance', x='num_seg')\n",
    "plt.xlabel('Number of Segments')\n",
    "plt.ylabel('Genealogical Distance')\n",
    "plt.title('Scatter Plot: Genealogical Distance vs Number of Segments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=relationships, x='max_seg', y='meiotic_distance', cmap='viridis', fill=True)\n",
    "plt.xlabel('Max Segment Length')\n",
    "plt.ylabel('Genealogical Distance (generations)')\n",
    "plt.title('Density Plot: Max Segment Length vs Genealogical Relationship')\n",
    "\n",
    "# Set the y-axis tick labels based on the range of meiotic_distance\n",
    "gg_distance_values = sorted(relationships['meiotic_distance'].unique())\n",
    "plt.yticks(gg_distance_values, gg_distance_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=relationships, x='num_seg', y='meiotic_distance', cmap='viridis', fill=True)\n",
    "plt.xlabel('Number of Segments')\n",
    "plt.ylabel('Genealogical Distance (generations)')\n",
    "plt.title('Density Plot: Number of Segments vs Genealogical Relationship')\n",
    "\n",
    "# Set the y-axis tick labels based on the range of meiotic_distance\n",
    "gg_distance_values = sorted(relationships['meiotic_distance'].unique())\n",
    "plt.yticks(gg_distance_values, gg_distance_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average segment size for each pair\n",
    "relationships[\"average_segment_size\"] = relationships[\"total_shared\"] / relationships[\"num_seg\"]\n",
    "\n",
    "relationships.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the average segment size for each meiotic distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships.groupby('meiotic_distance')['average_segment_size'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the average segment size decreases as the meiotic distance between members of a pair increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.kdeplot(\n",
    "    data=relationships,\n",
    "    x='average_segment_size',\n",
    "    y='meiotic_distance',\n",
    "    cmap='viridis',\n",
    "    fill=True\n",
    ")\n",
    "\n",
    "plt.xlabel('Average Segment Size')\n",
    "plt.ylabel('Genealogical Distance (generations)')\n",
    "plt.title('KDE Plot: Average Segment Size vs Genealogical Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice that overall, the methods we have used in our exploration is not a predictor of genetic genealogical relationships beyond 1 or 2 generations. For that, we turn to machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating Input VCF Files in Ped-Sim for Simulated Segments and Genotype Data\n",
    "\n",
    "Now, let's incorporate an input VCF file into **Ped-Sim** so that it can generate both **IBD segments** and **genotype data** for our simulated dataset. \n",
    "\n",
    "At this point, you might wonder:  \n",
    "*\"If we are already providing genotype data as input, why do we need Ped-Sim to generate simulated genotype data?\"*  \n",
    "\n",
    "This is an excellent question! The key reason lies in how **Ped-Sim** handles the simulation process. While we are indeed providing real genotype data as input, this data serves a very specific purpose:  \n",
    "\n",
    "- **Founder Selection**: Ped-Sim does not randomly generate all genotypes from scratch. Instead, it selects the **founders** (the first generation in the genetic family tree) **from the input genotype data**. These founders form the genetic starting point for the simulated family tree.  \n",
    "\n",
    "- **Genetic Inheritance Simulation**: Once the founders are selected, Ped-Sim simulates the inheritance of genetic material across generations, introducing **recombination and inheritance patterns** that mirror real biological processes. This step ensures that the offspring in the simulated dataset inherit realistic genotype segments, following expected Mendelian inheritance rules.\n",
    "\n",
    "- **Generating IBD Segments**: Ped-Sim tracks how segments of DNA are passed down through generations, allowing us to analyze patterns of **identical-by-descent (IBD) sharing** among related individuals. These IBD segments are crucial for applications such as reconstructing family trees, studying relatedness, and making inferences about historical demography.\n",
    "\n",
    "Thus, even though we already have genotype data as input, that data does not represent a pedigree or the inheritance of genetic material across generations. Ped-Sim constructs a multi-generational genetic family tree by simulating how genetic material is passed down, using the genotype data we provide for founders. Through this process, it applies recombination and transmission patterns to produce a dataset that reflects realistic genealogical relationships.\n",
    "\n",
    "Now that we understand the purpose of including an input VCF file, let's proceed with configuring Ped-Sim to use it effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the data:\n",
    "\n",
    "Make sure you are using a single VCF file with all chromosomes 1 - 22 (and X if needed). If you don't have this file already, go to Lab4 and run the `Concat the by-chromosome files` section. (You will need to run all the previous cells that this section depends on (e.g., importing packages, defining directory variables))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back up to the output for the first ped-sim run. Do you see the towards the end where it says:\n",
    "\n",
    "\"To simulate genetic data, must use an input VCF with [number] founders.\"\n",
    "\n",
    "This tells us the number of individuals that need to be in our input vcf file for ped-sim to simulate the genetic family tree(s) that we defined earlier. Let's check the sample size of our input VCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Define the input and output VCF files\n",
    "input_vcf=${RESULTS_DIRECTORY}/merged_opensnps_autosomes.vcf.gz\n",
    "\n",
    "echo \"Input sample size:\" $(bcftools query -l ${input_vcf} | wc -l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your sample size should equal or exceed the required number of founders for the simulation.\n",
    "\n",
    "If this is not the case, you can address this in a couple of ways.\n",
    "1. Revise your pedigree definition file such that you have an adequate sample size.\n",
    "\n",
    "   **or**\n",
    "\n",
    "2. Increase the sample size in your input VCF file. (This may require you downloading more data. You can use Lab0_Get_OpenSNP_data for that.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the Data is Essential for Ped-Sim Simulations\n",
    "\n",
    "Pruning the data is an important preprocessing step to ensure this, and hereâs why:\n",
    "\n",
    "### 1. Ensuring Independent Founders\n",
    "\n",
    "- **Selection of Distantly Related Founders**:  \n",
    "  Ped-Sim selects founders from the input genotype data to form the basis of the simulated pedigree. If the dataset includes close relatives, the chosen founders may share too much genetic material, which undermines the assumption that they are independent. Pruning helps remove these close relatives, ensuring that the founders represent distinct genetic backgrounds.\n",
    "\n",
    "### 2. Preserving Genetic Diversity\n",
    "\n",
    "- **Avoiding Redundancy**:  \n",
    "  Close relatives have overlapping haplotypes, and their presence can lead to over-representation of certain genetic segments. By pruning out closely related individuals, you maintain greater genetic diversity among the founders, which is critical for accurately simulating recombination and inheritance patterns over generations.\n",
    "\n",
    "### 3. Enhancing Simulation Accuracy\n",
    "\n",
    "- **Realistic Pedigree Structure**:  \n",
    "  Using a pruned dataset allows Ped-Sim to generate a more realistic simulation of genetic inheritance. The process of recombination and the resulting distribution of genetic segments are better modeled when the founders are not overly similar, resulting in more accurate downstream analyses (e.g., identity-by-descent mapping).\n",
    "\n",
    "### References\n",
    "\n",
    "1. **Ped-Sim Documentation**: Detailed explanation of the simulation process and the importance of high-quality input data.\n",
    "2. **Purcell, S., et al. (2007).** [PLINK: A tool set for whole-genome association and population-based linkage analyses.](https://doi.org/10.1086/519795)\n",
    "3. **Manichaikul, A., et al. (2010).** [Robust relationship inference in genome-wide association studies.](https://doi.org/10.1093/bioinformatics/btq559)\n",
    "4. **Weir, B. S. (1996).** *Genetic Data Analysis II: Methods for Discrete Population Genetic Data.*\n",
    "\n",
    "By pruning your input genotype data, you ensure that the founders selected for Ped-Sim are as independent as possible, leading to a more realistic and robust simulation of multi-generational genetic inheritance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Define the input and output VCF files\n",
    "input_vcf=${RESULTS_DIRECTORY}/merged_opensnps_autosomes.vcf.gz\n",
    "output_vcf=${RESULTS_DIRECTORY}/merged_opensnps_autosomes_pruned\n",
    "\n",
    "# Step 1: Convert the VCF file to PLINK binary format (BED/BIM/FAM)\n",
    "plink2 --vcf ${input_vcf} --make-bed --out dataset\n",
    "\n",
    "# Step 2: Remove close relatives using a KING cutoff of 0.125.\n",
    "# The threshold 0.125 corresponds roughly to the expected kinship coefficient for first cousins.\n",
    "plink2 --bfile dataset --king-cutoff 0.125 --make-bed --out dataset_unrelated\n",
    "\n",
    "# Step 3: Convert the filtered, unrelated dataset back to VCF format\n",
    "plink2 --bfile dataset_unrelated --export vcf --out ${output_vcf}\n",
    "\n",
    "# Step 4: Compress the VCF file using bgzip and index it using tabix\n",
    "bgzip -c ${output_vcf}.vcf > ${output_vcf}.vcf.gz\n",
    "tabix -p vcf ${output_vcf}.vcf.gz\n",
    "rm ${output_vcf}.vcf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "output_vcf=${RESULTS_DIRECTORY}/merged_opensnps_autosomes_pruned\n",
    "\n",
    "# Step 5: Use bcftools to report the sample size in both the output VCF files.\n",
    "echo \"Output sample size:\" $(bcftools query -l ${output_vcf}.vcf.gz | wc -l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, you want to make sure that your sample size equals or exceeds the number of founders needed for your pedigree definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sample_file=\"merged_opensnps\"\n",
    "\n",
    "INPUT_PRUNED_VCF=${RESULTS_DIRECTORY}/merged_opensnps_autosomes_pruned.vcf.gz\n",
    "\n",
    "for chr in {1..22}; do\n",
    "    \n",
    "    plink2 --vcf ${INPUT_PRUNED_VCF} \\\n",
    "           --chr ${chr} \\\n",
    "           --export vcf bgz \\\n",
    "           --out ${RESULTS_DIRECTORY}/unphased_samples/merged_opensnps_pruned_chr${chr}\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sample_file=\"merged_opensnps\"\n",
    "beagle=\"${UTILS_DIRECTORY}/beagle.17Dec24.224.jar\"\n",
    "\n",
    "# Phase chromosomes using Beagle\n",
    "for chr in {1..22}; do\n",
    "    echo \"Processing chromosome $chr\"\n",
    "\n",
    "    INPUT_VCF=\"${RESULTS_DIRECTORY}/unphased_samples/merged_opensnps_pruned_chr${chr}.vcf.gz\"\n",
    "    REF_VCF=\"${REFERENCES_DIRECTORY}/onethousandgenomes_genotype/onethousandgenomes_genotyped_phased.chr${chr}.vcf.gz\"\n",
    "    MAP_FILE=\"${REFERENCES_DIRECTORY}/genetic_maps/beagle_genetic_maps/plink.chr${chr}.GRCh38.map\"\n",
    "    OUTPUT_PREFIX=\"${RESULTS_DIRECTORY}/phased_samples/merged_opensnps_pruned_chr${chr}\"\n",
    "    PHASED_VCF=\"${OUTPUT_PREFIX}.vcf.gz\"\n",
    "    TEMP_VCF=\"${RESULTS_DIRECTORY}/phased_samples/temp_pruned_chr${chr}.vcf.gz\"\n",
    "    SORTED_VCF=\"${RESULTS_DIRECTORY}/phased_samples/merged_opensnps_pruned_phased_chr${chr}_sorted.vcf.gz\"\n",
    "\n",
    "    # Check if input VCF exists\n",
    "    if [ ! -f \"$INPUT_VCF\" ]; then\n",
    "        echo \"Input VCF file not found for chromosome $chr. Skipping.\"\n",
    "        echo \"$INPUT_VCF\"\n",
    "        continue\n",
    "    fi\n",
    "\n",
    "    # Run Beagle phasing\n",
    "    if [ -f \"$REF_VCF\" ]; then\n",
    "        echo \"Running Beagle with reference panel for chromosome $chr\"\n",
    "        java -jar ${beagle} \\\n",
    "            gt=\"$INPUT_VCF\" \\\n",
    "            ref=\"$REF_VCF\" \\\n",
    "            map=\"$MAP_FILE\" \\\n",
    "            out=\"$OUTPUT_PREFIX\" || {\n",
    "                echo \"Beagle failed for chromosome $chr. Skipping.\"\n",
    "                continue\n",
    "            }\n",
    "    else\n",
    "        echo \"Running Beagle without reference panel for chromosome $chr\"\n",
    "        java -jar ${beagle} \\\n",
    "            gt=\"$INPUT_VCF\" \\\n",
    "            map=\"$MAP_FILE\" \\\n",
    "            out=\"$OUTPUT_PREFIX\" || {\n",
    "                echo \"Beagle failed for chromosome $chr. Skipping.\"\n",
    "                continue\n",
    "            }\n",
    "    fi\n",
    "\n",
    "    if [ ! -f \"$PHASED_VCF\" ]; then\n",
    "        echo \"Phasing failed for chromosome $chr. Output file not found. Skipping.\"\n",
    "        continue\n",
    "    fi\n",
    "\n",
    "    # Index the file\n",
    "    tabix -f -p vcf \"$PHASED_VCF\"\n",
    "    \n",
    "    # Add INFO field definition and sort\n",
    "    echo \"Sorting VCF for chromosome $chr\"\n",
    "    bcftools annotate --header-lines <(echo '##INFO=<ID=END,Number=1,Type=Integer,Description=\"End position of the variant\">') \"$PHASED_VCF\" | \\\n",
    "    bcftools sort -Oz -o \"$SORTED_VCF\" || {\n",
    "        echo \"Sorting failed for chromosome $chr\"\n",
    "        continue\n",
    "    }\n",
    "\n",
    "    # Index the sorted file\n",
    "    tabix -f -p vcf \"$SORTED_VCF\"\n",
    "    \n",
    "    # If the sorted vcf and index exists, remove phased vcf and index\n",
    "    if [ -f \"$SORTED_VCF\" ] && [ -f \"$SORTED_VCF.tbi\" ]; then\n",
    "        rm -f \"$PHASED_VCF\"\n",
    "        rm -f \"$PHASED_VCF.tbi\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"Results Directory: $RESULTS_DIRECTORY\"\n",
    "\n",
    "phased_directory=\"${RESULTS_DIRECTORY}/phased_samples\"\n",
    "merged_vcf=\"${RESULTS_DIRECTORY}/merged_opensnps_autosomes_pruned.vcf.gz\"\n",
    "\n",
    "# List of sorted VCFs\n",
    "vcf_list=()\n",
    "for CHR in {1..22}; do\n",
    "    SORTED_VCF=\"${RESULTS_DIRECTORY}/phased_samples/merged_opensnps_pruned_phased_chr${CHR}_sorted.vcf.gz\"\n",
    "    if [ -f \"$SORTED_VCF\" ]; then\n",
    "        vcf_list+=(\"$SORTED_VCF\")\n",
    "    else\n",
    "        echo \"Missing sorted VCF for chromosome $CHR, skipping.\"\n",
    "        echo \"Missing $SORTED_VCF\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "# Merge all VCFs\n",
    "if [ ${#vcf_list[@]} -gt 0 ]; then\n",
    "    echo \"Merging phased VCFs into a single autosomal file...\"\n",
    "    bcftools concat -Oz -o \"$merged_vcf\" \"${vcf_list[@]}\" || { echo \"Merging failed.\"; exit 1; }\n",
    "\n",
    "    # Index the merged VCF\n",
    "    tabix -f -p vcf \"$merged_vcf\"\n",
    "    echo \"Merged VCF created at $merged_vcf\"\n",
    "else\n",
    "    echo \"No VCFs available for merging.\"\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ped-sim documentation: \n",
    "\n",
    "> When genetic data are needed, an input VCF is required to be provided with the -i option. Given such a VCF, Ped-sim randomly samples individuals from this data and uses them as founders. The VCF must contain phased data for all individuals, with no missing data for any site. As most phasers automatically impute missing data, the latter requirement should be to easy to meet.\n",
    "> The input VCF file can be gzipped, and if it is, Ped-sim prints the output VCF in gzipped format (but this output VCF is not bgzipped).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pedigree_definition_file=\"pedigree.def\"\n",
    "ped_sim_filename=\"ped_sim_run2\"\n",
    "\n",
    "${UTILS_DIRECTORY}/ped-sim/ped-sim \\\n",
    "    -d ${RESULTS_DIRECTORY}/$pedigree_definition_file \\\n",
    "    -m ${REFERENCES_DIRECTORY}/refined_mf_b38.simmap \\\n",
    "    -o ${RESULTS_DIRECTORY}/$ped_sim_filename \\\n",
    "    -i ${RESULTS_DIRECTORY}/merged_opensnps_autosomes_pruned.vcf.gz \\\n",
    "    --intf ${UTILS_DIRECTORY}/ped-sim/interfere/nu_p_campbell.tsv \\\n",
    "    --seed 1234 \\\n",
    "    --fam \\\n",
    "    --mrca\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the stats on our new VCF file with simulated genotype data from our defined pedigree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "phased_directory=\"${RESULTS_DIRECTORY}/phased_samples\"\n",
    "PHASED_VCF=\"${RESULTS_DIRECTORY}/ped_sim_run2.vcf.gz\"\n",
    "STATS_OUTPUT=\"${phased_directory}/ped_sim_run2_stats.vchk\"\n",
    "\n",
    "bcftools stats -s - \"$PHASED_VCF\" > \"$STATS_OUTPUT\"\n",
    "bcftools stats -s - \"$PHASED_VCF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have (1) the genetic family tree fam file, (2) the VCF file of the defined sample, and (3) the segment file for our defined genetic family tree, we can use this as a ground truth to test our genomic analysis tools or conduct full experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of by-chromosome files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Define the input VCF file\n",
    "input_vcf=\"${RESULTS_DIRECTORY}/ped_sim_run2.vcf.gz\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "mkdir -p ${RESULTS_DIRECTORY}/ped_sim_run2_autosomes/unphased_samples/\n",
    "\n",
    "# Loop through each chromosome and create separate files\n",
    "for chr in {1..22}; do\n",
    "    plink2 --vcf ${input_vcf} \\\n",
    "           --chr ${chr} \\\n",
    "           --export vcf bgz \\\n",
    "           --out ${RESULTS_DIRECTORY}/ped_sim_run2_autosomes/unphased_samples/ped_sim_run2_chr${chr}\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "def graph_fam_file_simulated(filename, pedigree=None):\n",
    "    fam_file = pd.read_csv(os.path.join(results_directory, filename), sep=\" \", header=None)\n",
    "    fam_file.columns = [\"fam\", \"id\", \"parent0\", \"parent1\", \"sex\", \"phenotype\"]\n",
    "\n",
    "    if pedigree is not None:\n",
    "        # Extract pedigree number from the first element\n",
    "        fam_file['pedigree_num'] = fam_file['fam'].apply(lambda x: x.replace(\"FAM\", \"\"))\n",
    "        fam_file = fam_file[fam_file['pedigree_num'] == str(pedigree)]\n",
    "\n",
    "    fig = plt.figure(num=None, figsize=(250, 100), dpi=100)\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for index, row in fam_file.iterrows():\n",
    "        id = row['id']\n",
    "\n",
    "        values_id1 = id.split(\"_\")\n",
    "        \n",
    "        # Ensure the ID follows expected format\n",
    "        if len(values_id1) < 2:\n",
    "            raise ValueError(f\"Unexpected ID format: {id} -> {values_id1}\")\n",
    "        \n",
    "        subvalues_id1 = values_id1[1].split(\"-\")\n",
    "        gen_id1 = int(subvalues_id1[0].lstrip(\"g\"))\n",
    "\n",
    "        G.add_node(id, time=gen_id1)\n",
    "\n",
    "        for parent_column in ['parent0', 'parent1']:\n",
    "            if row[parent_column] != '0':\n",
    "                parent_id = row[parent_column]\n",
    "                values_parent = parent_id.split(\"_\")\n",
    "\n",
    "                if len(values_parent) < 2:\n",
    "                    raise ValueError(f\"Unexpected Parent format: {parent_id} -> {values_parent}\")\n",
    "\n",
    "                subvalues_parent = values_parent[1].split(\"-\")\n",
    "                gen_parent = int(subvalues_parent[0].lstrip(\"g\"))\n",
    "                G.add_node(parent_id, time=gen_parent)\n",
    "                G.add_edge(parent_id, id)\n",
    "\n",
    "    # Reverse the order of generations\n",
    "    max_gen = max(gen_id1 for _, gen_id1 in G.nodes(data='time'))\n",
    "    for node, data in G.nodes(data=True):\n",
    "        data['time'] = max_gen - data['time']\n",
    "\n",
    "    return G\n",
    "\n",
    "def find_common_ancestors(G, person1, person2):\n",
    "    \"\"\"\n",
    "    Find all common ancestors between two individuals in a family tree.\n",
    "    Returns a set of common ancestors.\n",
    "    \"\"\"\n",
    "    # Create a new graph with edges reversed to trace ancestors\n",
    "    G_reversed = G.reverse()\n",
    "    \n",
    "    # Find all ancestors for each person (including the person themselves)\n",
    "    ancestors1 = set(nx.dfs_preorder_nodes(G_reversed, person1))\n",
    "    ancestors2 = set(nx.dfs_preorder_nodes(G_reversed, person2))\n",
    "    \n",
    "    # Find common ancestors\n",
    "    common_ancestors = ancestors1.intersection(ancestors2)\n",
    "    \n",
    "    return common_ancestors\n",
    "\n",
    "def find_most_recent_common_ancestor(G, person1, person2):\n",
    "    \"\"\"\n",
    "    Find the most recent common ancestor (MRCA) between two individuals.\n",
    "    Returns the MRCA and the generation distance to each person.\n",
    "    \"\"\"\n",
    "    common_ancestors = find_common_ancestors(G, person1, person2)\n",
    "    \n",
    "    if not common_ancestors:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Find the MRCA (the one with the highest generation number)\n",
    "    mrca = max(common_ancestors, key=lambda x: G.nodes[x]['time'])\n",
    "    \n",
    "    # Calculate genealogical distance (number of generations)\n",
    "    # We need to use the original graph direction for descendants\n",
    "    path_to_person1 = nx.shortest_path(G, source=mrca, target=person1)\n",
    "    path_to_person2 = nx.shortest_path(G, source=mrca, target=person2)\n",
    "    \n",
    "    return mrca, len(path_to_person1) - 1, len(path_to_person2) - 1\n",
    "\n",
    "def calculate_relationship_degree(G, person1, person2):\n",
    "    \"\"\"\n",
    "    Calculate the canonical genealogical relationship degree between two individuals.\n",
    "    \n",
    "    Returns:\n",
    "    - mrca: Most recent common ancestor\n",
    "    - degree1: Degrees from mrca to person1\n",
    "    - degree2: Degrees from mrca to person2\n",
    "    - total_degree: Sum of degrees (traditional 'degree of relationship')\n",
    "    - canonical_degree: Min(degree1, degree2) for same-generation relationships\n",
    "    - relationship_type: Description of the relationship\n",
    "    \"\"\"\n",
    "    # Special case for same person\n",
    "    if person1 == person2:\n",
    "        return {\n",
    "            'mrca': person1,\n",
    "            'degree1': 0,\n",
    "            'degree2': 0,\n",
    "            'total_degree': 0,\n",
    "            'canonical_degree': 0,\n",
    "            'relationship_type': 'self'}\n",
    "    \n",
    "    # Find MRCA and genealogical distances\n",
    "    mrca, degree1, degree2 = find_most_recent_common_ancestor(G, person1, person2)\n",
    "    \n",
    "    if mrca is None:\n",
    "        return {\n",
    "            'mrca': None,\n",
    "            'degree1': None,\n",
    "            'degree2': None,\n",
    "            'total_degree': None,\n",
    "            'canonical_degree': None,\n",
    "            'relationship_type': 'unrelated'}\n",
    "    \n",
    "    total_degree = degree1 + degree2\n",
    "    canonical_degree = min(degree1, degree2)\n",
    "    \n",
    "    # Determine relationship type\n",
    "    relationship_type = \"unknown\"\n",
    "    \n",
    "    # Direct lineage\n",
    "    if degree1 == 0 or degree2 == 0:\n",
    "        if degree1 == 0:  # person1 is ancestor of person2\n",
    "            if degree2 == 1:\n",
    "                relationship_type = \"parent-child\"\n",
    "            elif degree2 == 2:\n",
    "                relationship_type = \"grandparent-grandchild\"\n",
    "            else:\n",
    "                relationship_type = f\"{degree2-1}x great-grandparent/grandchild\"\n",
    "        else:  # person2 is ancestor of person1\n",
    "            if degree1 == 1:\n",
    "                relationship_type = \"parent-child\"\n",
    "            elif degree1 == 2:\n",
    "                relationship_type = \"grandparent-grandchild\"\n",
    "            else:\n",
    "                relationship_type = f\"{degree1-1}x great-grandparent/grandchild\"\n",
    "    \n",
    "    # Same generation (siblings, cousins)\n",
    "    elif degree1 == degree2:\n",
    "        if degree1 == 1:\n",
    "            relationship_type = \"siblings\"\n",
    "        else:\n",
    "            relationship_type = f\"{degree1-1}th cousins\"\n",
    "    \n",
    "    # Different generation but not direct lineage (uncle/aunt, etc.)\n",
    "    else:\n",
    "        min_degree = min(degree1, degree2)\n",
    "        diff = abs(degree1 - degree2)\n",
    "        \n",
    "        if min_degree == 1:\n",
    "            if diff == 1:\n",
    "                relationship_type = \"uncle/aunt - nephew/niece\"\n",
    "            else:\n",
    "                relationship_type = f\"{diff-1}x great-uncle/aunt - nephew/niece\"\n",
    "        else:\n",
    "            relationship_type = f\"{min_degree-1}th cousins {diff} times removed\"\n",
    "    \n",
    "    return {\n",
    "        'mrca': mrca,\n",
    "        'degree1': degree1,\n",
    "        'degree2': degree2,\n",
    "        'total_degree': total_degree,\n",
    "        'canonical_degree': canonical_degree,\n",
    "        'relationship_type': relationship_type}\n",
    "\n",
    "def analyze_family_relationships(G, root_person=None):\n",
    "    \"\"\"\n",
    "    Analyze all familial relationships in a family tree.\n",
    "    \n",
    "    Parameters:\n",
    "    - G: NetworkX DiGraph representing the family tree\n",
    "    - root_person: Optional focal person for the analysis\n",
    "    \n",
    "    Returns a dictionary of relationships\n",
    "    \"\"\"\n",
    "    if root_person is None:\n",
    "        # Find a person who might be a good central figure (has many connections)\n",
    "        root_person = max(G.nodes(), key=lambda x: G.degree(x))\n",
    "    \n",
    "    relationships = {}\n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    for i, person1 in enumerate(nodes):\n",
    "        if person1 == root_person:\n",
    "            continue\n",
    "            \n",
    "        relationship = calculate_relationship_degree(G, root_person, person1)\n",
    "        relationships[person1] = relationship\n",
    "    \n",
    "    return relationships, root_person\n",
    "\n",
    "def visualize_family_tree_with_relationships(G, root_person=None, output_file=None):\n",
    "    \"\"\"\n",
    "    Visualize a family tree with relationship information.\n",
    "    \"\"\"\n",
    "    # Analyze relationships\n",
    "    relationships, analyzed_root = analyze_family_relationships(G, root_person)\n",
    "    \n",
    "    # Set up the plot\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # Position nodes using a hierarchical layout based on generation time\n",
    "    pos = nx.multipartite_layout(G, subset_key='time', align='horizontal')\n",
    "    \n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=100)\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='black', arrows=True)\n",
    "    \n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "    \n",
    "    # Display relationship information\n",
    "    print(f\"Relationship analysis for person: {analyzed_root}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for person, rel in relationships.items():\n",
    "        if rel['mrca'] is not None:\n",
    "            print(f\"{person}: {rel['relationship_type']}\")\n",
    "            print(f\"  MRCA: {rel['mrca']}\")\n",
    "            print(f\"  Degrees from MRCA to {analyzed_root}: {rel['degree1']}\")\n",
    "            print(f\"  Degrees from MRCA to {person}: {rel['degree2']}\")\n",
    "            print(f\"  Total degree of relationship: {rel['total_degree']}\")\n",
    "            print(\"\")\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return relationships\n",
    "\n",
    "# Usage example:\n",
    "input_file = os.path.join(results_directory, 'ped_sim_run2-everyone.fam')\n",
    "output_file = os.path.join(results_directory, 'family_with_relationships.png')\n",
    "G = graph_fam_file_simulated(input_file, pedigree=1)\n",
    "relationships = visualize_family_tree_with_relationships(G, output_file=output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
