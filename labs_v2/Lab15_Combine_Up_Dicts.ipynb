{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 15: The combine_up_dicts() Algorithm\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this lab, we'll explore the `combine_up_dicts()` algorithm, which is at the heart of Bonsai v3's ability to scale from small pedigree structures to larger, more complex family networks. This algorithm systematically merges smaller pedigrees based on genetic evidence, using an iterative, likelihood-based approach to find the most plausible connections between family units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import inspect\n",
    "import importlib\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Cross-compatibility setup\n",
    "from scripts_support.lab_cross_compatibility import setup_environment, is_jupyterlite, save_results, save_plot\n",
    "\n",
    "# Set up environment-specific paths\n",
    "DATA_DIR, RESULTS_DIR = setup_environment()\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup Bonsai module paths\n",
    "if not is_jupyterlite():\n",
    "    # In local environment, add the utils directory to system path\n",
    "    utils_dir = os.getenv('PROJECT_UTILS_DIR', os.path.join(os.path.dirname(DATA_DIR), 'utils'))\n",
    "    bonsaitree_dir = os.path.join(utils_dir, 'bonsaitree')\n",
    "    \n",
    "    # Add to path if it exists and isn't already there\n",
    "    if os.path.exists(bonsaitree_dir) and bonsaitree_dir not in sys.path:\n",
    "        sys.path.append(bonsaitree_dir)\n",
    "        print(f\"Added {bonsaitree_dir} to sys.path\")\n",
    "else:\n",
    "    # In JupyterLite, use a simplified approach\n",
    "    print(\"⚠️ Running in JupyterLite: Some Bonsai functionality may be limited.\")\n",
    "    print(\"This notebook is primarily designed for local execution where the Bonsai codebase is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Helper functions for exploring modules\n",
    "def display_module_classes(module_name):\n",
    "    \"\"\"Display classes and their docstrings from a module\"\"\"\n",
    "    try:\n",
    "        # Import the module\n",
    "        module = importlib.import_module(module_name)\n",
    "        \n",
    "        # Find all classes\n",
    "        classes = inspect.getmembers(module, inspect.isclass)\n",
    "        \n",
    "        # Filter classes defined in this module (not imported)\n",
    "        classes = [(name, cls) for name, cls in classes if cls.__module__ == module_name]\n",
    "        \n",
    "        # Print info for each class\n",
    "        for name, cls in classes:\n",
    "            print(f\"\\n## {name}\")\n",
    "            \n",
    "            # Get docstring\n",
    "            doc = inspect.getdoc(cls)\n",
    "            if doc:\n",
    "                print(f\"Docstring: {doc}\")\n",
    "            else:\n",
    "                print(\"No docstring available\")\n",
    "            \n",
    "            # Get methods\n",
    "            methods = inspect.getmembers(cls, inspect.isfunction)\n",
    "            if methods:\n",
    "                print(\"\\nMethods:\")\n",
    "                for method_name, method in methods:\n",
    "                    if not method_name.startswith('_'):  # Skip private methods\n",
    "                        print(f\"- {method_name}\")\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing module {module_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing module {module_name}: {e}\")\n",
    "\n",
    "def display_module_functions(module_name):\n",
    "    \"\"\"Display functions and their docstrings from a module\"\"\"\n",
    "    try:\n",
    "        # Import the module\n",
    "        module = importlib.import_module(module_name)\n",
    "        \n",
    "        # Find all functions\n",
    "        functions = inspect.getmembers(module, inspect.isfunction)\n",
    "        \n",
    "        # Filter functions defined in this module (not imported)\n",
    "        functions = [(name, func) for name, func in functions if func.__module__ == module_name]\n",
    "        \n",
    "        # Print info for each function\n",
    "        for name, func in functions:\n",
    "            if name.startswith('_'):  # Skip private functions\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n## {name}\")\n",
    "            \n",
    "            # Get signature\n",
    "            sig = inspect.signature(func)\n",
    "            print(f\"Signature: {name}{sig}\")\n",
    "            \n",
    "            # Get docstring\n",
    "            doc = inspect.getdoc(func)\n",
    "            if doc:\n",
    "                print(f\"Docstring: {doc}\")\n",
    "            else:\n",
    "                print(\"No docstring available\")\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing module {module_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing module {module_name}: {e}\")\n",
    "\n",
    "def view_source(obj):\n",
    "    \"\"\"Display the source code of an object (function or class)\"\"\"\n",
    "    try:\n",
    "        source = inspect.getsource(obj)\n",
    "        display(Markdown(f\"```python\\n{source}\\n```\"))\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving source: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Bonsai Installation\n",
    "\n",
    "Let's verify that the Bonsai v3 module is available for import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "try:\n",
    "    from utils.bonsaitree.bonsaitree import v3\n",
    "    print(\"✅ Successfully imported Bonsai v3 module\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Failed to import Bonsai v3 module: {e}\")\n",
    "    print(\"This lab requires access to the Bonsai v3 codebase.\")\n",
    "    print(\"Make sure you've properly set up your environment with the Bonsai repository.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 15: The combine_up_dicts() Algorithm\n",
    "\n",
    "In this lab, we'll explore the `combine_up_dicts()` algorithm, which is the central mechanism in Bonsai v3 for scaling from small pedigree structures to larger, more complex family networks. This algorithm is essential for reconstructing large pedigrees that would be computationally infeasible to optimize directly.\n",
    "\n",
    "The `combine_up_dicts()` function implements a bottom-up, incremental approach to pedigree reconstruction, where:\n",
    "\n",
    "1. Small, high-confidence pedigree units (often single individuals or family units) are identified first\n",
    "2. These units are progressively merged based on genetic evidence, starting with the most closely related units\n",
    "3. Multiple alternative pedigree configurations are maintained and evaluated at each step\n",
    "4. The process continues until all units are connected or no more reliable connections can be made\n",
    "\n",
    "This approach addresses the combinatorial explosion challenge inherent in pedigree reconstruction while allowing for exploration of multiple hypotheses about how individuals are related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the combine_up_dicts() Function\n",
    "\n",
    "Let's start by examining the `combine_up_dicts()` function in the Bonsai v3 codebase. This function orchestrates the entire process of merging small pedigrees into larger structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import the combine_up_dicts function from Bonsai v3\n",
    "if not is_jupyterlite():\n",
    "    from utils.bonsaitree.bonsaitree.v3.connections import combine_up_dicts\n",
    "    \n",
    "    # Display the source code of the function\n",
    "    print(\"Source code for combine_up_dicts:\")\n",
    "    view_source(combine_up_dicts)\n",
    "else:\n",
    "    print(\"Cannot display source code in JupyterLite environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The Core Algorithm Structure\n",
    "\n",
    "The `combine_up_dicts()` function implements an iterative algorithm for incrementally combining pedigrees. Let's break down its key components:\n",
    "\n",
    "1. **Initialization**: Setting up data structures to track pedigrees and their relationships\n",
    "   - `idx_to_up_dict_ll_list`: Maps pedigree indices to lists of (pedigree, likelihood) pairs\n",
    "   - `id_to_idx`: Maps individual IDs to the pedigree they belong to\n",
    "   - `idx_to_id_set`: Maps pedigree indices to sets of individual IDs contained in each pedigree\n",
    "\n",
    "2. **Main Iteration Loop**: Repeatedly finding and merging the closest pedigrees until only one remains or no more merges are possible\n",
    "\n",
    "3. **Finding Closest Pedigrees**: Identifying which pedigrees share the most IBD and should be merged next\n",
    "\n",
    "4. **Merging Pedigrees**: Combining two pedigrees through their most likely connection points\n",
    "\n",
    "5. **Evaluating Combinations**: Calculating likelihoods for different ways of connecting pedigrees\n",
    "\n",
    "6. **Maintaining Multiple Hypotheses**: Keeping track of multiple candidate pedigrees at each step\n",
    "\n",
    "Let's implement a simplified version of this algorithm to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def simplified_combine_up_dicts(id_to_up_dct, id_to_shared_ibd, id_to_info=None, n_keep=3):\n",
    "    \"\"\"\n",
    "    Simplified implementation of combine_up_dicts algorithm.\n",
    "    \n",
    "    Args:\n",
    "        id_to_up_dct: Dict mapping IDs to their pedigrees (up-node dictionaries)\n",
    "        id_to_shared_ibd: Dict mapping ID pairs to their IBD segments\n",
    "        id_to_info: Dict mapping IDs to their demographic information\n",
    "        n_keep: Number of top pedigrees to keep at each step\n",
    "        \n",
    "    Returns:\n",
    "        List of (pedigree, likelihood) pairs for the final pedigrees\n",
    "    \"\"\"\n",
    "    id_to_info = id_to_info or {}\n",
    "    \n",
    "    # Initialize pedigree tracking structures\n",
    "    idx_to_up_dict_ll_list = {}  # Maps pedigree indices to (pedigree, likelihood) lists\n",
    "    id_to_idx = {}               # Maps individual IDs to their pedigree index\n",
    "    idx_to_id_set = {}           # Maps pedigree indices to sets of contained IDs\n",
    "    \n",
    "    # Initialize with individual pedigrees\n",
    "    for i, (id_val, up_dict) in enumerate(id_to_up_dct.items()):\n",
    "        idx_to_up_dict_ll_list[i] = [(up_dict, 0.0)]  # Initial likelihood = 0\n",
    "        id_to_idx[id_val] = i\n",
    "        idx_to_id_set[i] = {id_val}\n",
    "    \n",
    "    # Calculate total IBD sharing for each pair\n",
    "    id_pair_to_cm = {}\n",
    "    for (id1, id2), segments in id_to_shared_ibd.items():\n",
    "        total_cm = sum(seg.get('length_cm', 0) for seg in segments)\n",
    "        id_pair_to_cm[(id1, id2)] = total_cm\n",
    "    \n",
    "    # Main iteration loop\n",
    "    while len(idx_to_up_dict_ll_list) > 1:\n",
    "        # Find closest pedigrees to merge\n",
    "        closest_pair, max_ibd = find_closest_pedigrees(idx_to_id_set, id_pair_to_cm)\n",
    "        \n",
    "        if closest_pair is None or max_ibd < 20:  # Minimum IBD threshold\n",
    "            break  # No more pedigrees to merge\n",
    "            \n",
    "        idx1, idx2 = closest_pair\n",
    "        \n",
    "        # Get pedigrees to merge\n",
    "        ped_ll_list1 = idx_to_up_dict_ll_list[idx1]\n",
    "        ped_ll_list2 = idx_to_up_dict_ll_list[idx2]\n",
    "        \n",
    "        # Try all combinations of pedigrees\n",
    "        all_combined = []\n",
    "        for ped1, ll1 in ped_ll_list1:\n",
    "            for ped2, ll2 in ped_ll_list2:\n",
    "                # Find ways to combine these pedigrees\n",
    "                combined_peds = combine_pedigrees_simple(ped1, ped2, id_pair_to_cm)\n",
    "                \n",
    "                for combined_ped, new_ll in combined_peds:\n",
    "                    # Add the new pedigree with combined likelihood\n",
    "                    all_combined.append((combined_ped, ll1 + ll2 + new_ll))\n",
    "        \n",
    "        # Sort by likelihood and keep top n_keep\n",
    "        all_combined.sort(key=lambda x: x[1], reverse=True)\n",
    "        kept_combined = all_combined[:n_keep]\n",
    "        \n",
    "        # Create new index for merged pedigree\n",
    "        new_idx = max(idx_to_up_dict_ll_list.keys()) + 1\n",
    "        \n",
    "        # Store combined pedigrees under new index\n",
    "        idx_to_up_dict_ll_list[new_idx] = kept_combined\n",
    "        \n",
    "        # Update id_to_idx and idx_to_id_set\n",
    "        id_set1 = idx_to_id_set[idx1]\n",
    "        id_set2 = idx_to_id_set[idx2]\n",
    "        merged_id_set = id_set1.union(id_set2)\n",
    "        \n",
    "        for id_val in merged_id_set:\n",
    "            id_to_idx[id_val] = new_idx\n",
    "            \n",
    "        idx_to_id_set[new_idx] = merged_id_set\n",
    "        \n",
    "        # Remove old pedigree records\n",
    "        del idx_to_up_dict_ll_list[idx1]\n",
    "        del idx_to_up_dict_ll_list[idx2]\n",
    "        del idx_to_id_set[idx1]\n",
    "        del idx_to_id_set[idx2]\n",
    "    \n",
    "    # Return the final pedigree list\n",
    "    if idx_to_up_dict_ll_list:\n",
    "        final_idx = next(iter(idx_to_up_dict_ll_list.keys()))\n",
    "        return idx_to_up_dict_ll_list[final_idx]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def find_closest_pedigrees(idx_to_id_set, id_pair_to_cm):\n",
    "    \"\"\"\n",
    "    Find the pair of pedigrees that share the most IBD.\n",
    "    \n",
    "    Args:\n",
    "        idx_to_id_set: Dict mapping pedigree indices to sets of contained IDs\n",
    "        id_pair_to_cm: Dict mapping ID pairs to their total shared cM\n",
    "        \n",
    "    Returns:\n",
    "        closest_pair: Tuple of (idx1, idx2) for the closest pedigrees\n",
    "        max_ibd: Total IBD sharing between the closest pedigrees\n",
    "    \"\"\"\n",
    "    # Calculate IBD sharing between pedigrees\n",
    "    ped_pair_to_ibd = defaultdict(float)\n",
    "    \n",
    "    # For each pair of pedigrees\n",
    "    pedigree_indices = list(idx_to_id_set.keys())\n",
    "    for i in range(len(pedigree_indices)):\n",
    "        idx1 = pedigree_indices[i]\n",
    "        id_set1 = idx_to_id_set[idx1]\n",
    "        \n",
    "        for j in range(i + 1, len(pedigree_indices)):\n",
    "            idx2 = pedigree_indices[j]\n",
    "            id_set2 = idx_to_id_set[idx2]\n",
    "            \n",
    "            # Calculate total IBD between individuals in different pedigrees\n",
    "            for id1 in id_set1:\n",
    "                for id2 in id_set2:\n",
    "                    pair = (min(id1, id2), max(id1, id2))\n",
    "                    if pair in id_pair_to_cm:\n",
    "                        ped_pair_to_ibd[(idx1, idx2)] += id_pair_to_cm[pair]\n",
    "    \n",
    "    # Find the pair with maximum IBD\n",
    "    if not ped_pair_to_ibd:\n",
    "        return None, 0\n",
    "        \n",
    "    max_pair = max(ped_pair_to_ibd.items(), key=lambda x: x[1])\n",
    "    return max_pair[0], max_pair[1]\n",
    "\n",
    "def combine_pedigrees_simple(ped1, ped2, id_pair_to_cm):\n",
    "    \"\"\"\n",
    "    Simple implementation of pedigree combination.\n",
    "    \n",
    "    Args:\n",
    "        ped1, ped2: Pedigrees to combine (up-node dictionaries)\n",
    "        id_pair_to_cm: Dict mapping ID pairs to their total shared cM\n",
    "        \n",
    "    Returns:\n",
    "        List of (combined_pedigree, likelihood) pairs\n",
    "    \"\"\"\n",
    "    # Simplified implementation - just merge the pedigrees without proper connections\n",
    "    combined = copy.deepcopy(ped1)\n",
    "    \n",
    "    # Add all nodes from ped2 not already in combined\n",
    "    for node, parents in ped2.items():\n",
    "        if node not in combined:\n",
    "            combined[node] = parents.copy()\n",
    "        else:\n",
    "            # Merge parents\n",
    "            for parent, deg in parents.items():\n",
    "                combined[node][parent] = deg\n",
    "    \n",
    "    # Calculate a simple likelihood based on total IBD\n",
    "    ids1 = set(ped1.keys())\n",
    "    ids2 = set(ped2.keys())\n",
    "    \n",
    "    total_ibd = 0\n",
    "    for id1 in ids1:\n",
    "        for id2 in ids2:\n",
    "            pair = (min(id1, id2), max(id1, id2))\n",
    "            if pair in id_pair_to_cm:\n",
    "                total_ibd += id_pair_to_cm[pair]\n",
    "    \n",
    "    # Simple likelihood score based on total IBD\n",
    "    likelihood = math.log(1 + total_ibd)\n",
    "    \n",
    "    return [(combined, likelihood)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simplified implementation captures the essence of the `combine_up_dicts()` algorithm, but lacks many of the sophisticated features of the real Bonsai v3 implementation, such as:\n",
    "\n",
    "- Advanced likelihood calculations based on proper relationship inference\n",
    "- Sophisticated mechanisms for finding the optimal way to connect pedigrees\n",
    "- Age and sex constraint enforcement\n",
    "- Handling of genotyped vs. ungenotyped individuals\n",
    "- Comprehensive error handling\n",
    "\n",
    "Next, let's import the key functions that `combine_up_dicts()` relies on and examine how they work together in the real Bonsai implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import key functions used by combine_up_dicts\n",
    "if not is_jupyterlite():\n",
    "    try:\n",
    "        from utils.bonsaitree.bonsaitree.v3.connections import (\n",
    "            combine_pedigrees,\n",
    "            find_closest_pedigrees,\n",
    "            get_connecting_points_degs_and_log_likes\n",
    "        )\n",
    "        \n",
    "        # Display the source code of these functions\n",
    "        print(\"1. find_closest_pedigrees:\")\n",
    "        view_source(find_closest_pedigrees)\n",
    "        \n",
    "        print(\"\\n2. combine_pedigrees:\")\n",
    "        view_source(combine_pedigrees)\n",
    "        \n",
    "        print(\"\\n3. get_connecting_points_degs_and_log_likes:\")\n",
    "        view_source(get_connecting_points_degs_and_log_likes)\n",
    "    except (ImportError, AttributeError) as e:\n",
    "        print(f\"Could not import functions: {e}\")\n",
    "else:\n",
    "    print(\"Cannot display source code in JupyterLite environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tracking and Merging Pedigrees\n",
    "\n",
    "Now that we've examined the core algorithm, let's focus on two critical aspects of `combine_up_dicts()`:\n",
    "\n",
    "1. How it tracks and manages pedigrees during the merging process\n",
    "2. How it determines the optimal way to merge pedigrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pedigree Tracking Data Structures\n",
    "\n",
    "The `combine_up_dicts()` function uses several data structures to track pedigrees and their relationships during the merging process. Let's implement simplified versions of these data structures to see how they work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def initialize_pedigree_tracking(id_to_up_dct):\n",
    "    \"\"\"\n",
    "    Initialize pedigree tracking data structures.\n",
    "    \n",
    "    Args:\n",
    "        id_to_up_dct: Dict mapping IDs to their pedigrees\n",
    "        \n",
    "    Returns:\n",
    "        idx_to_up_dict_ll_list: Maps pedigree indices to (pedigree, likelihood) lists\n",
    "        id_to_idx: Maps individual IDs to their pedigree index\n",
    "        idx_to_id_set: Maps pedigree indices to sets of contained IDs\n",
    "    \"\"\"\n",
    "    idx_to_up_dict_ll_list = {}\n",
    "    id_to_idx = {}\n",
    "    idx_to_id_set = {}\n",
    "    \n",
    "    # Initialize with individual pedigrees\n",
    "    for i, (id_val, up_dict) in enumerate(id_to_up_dct.items()):\n",
    "        idx_to_up_dict_ll_list[i] = [(up_dict, 0.0)]  # Initial likelihood = 0\n",
    "        id_to_idx[id_val] = i\n",
    "        idx_to_id_set[i] = {id_val}\n",
    "    \n",
    "    return idx_to_up_dict_ll_list, id_to_idx, idx_to_id_set\n",
    "\n",
    "def update_pedigree_tracking(idx_to_up_dict_ll_list, id_to_idx, idx_to_id_set, \n",
    "                             idx1, idx2, kept_combined):\n",
    "    \"\"\"\n",
    "    Update pedigree tracking data structures after merging two pedigrees.\n",
    "    \n",
    "    Args:\n",
    "        idx_to_up_dict_ll_list: Maps pedigree indices to (pedigree, likelihood) lists\n",
    "        id_to_idx: Maps individual IDs to their pedigree index\n",
    "        idx_to_id_set: Maps pedigree indices to sets of contained IDs\n",
    "        idx1, idx2: Indices of the pedigrees being merged\n",
    "        kept_combined: List of (pedigree, likelihood) pairs for the merged pedigree\n",
    "        \n",
    "    Returns:\n",
    "        Updated tracking data structures\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the originals\n",
    "    idx_to_up_dict_ll_list = idx_to_up_dict_ll_list.copy()\n",
    "    id_to_idx = id_to_idx.copy()\n",
    "    idx_to_id_set = idx_to_id_set.copy()\n",
    "    \n",
    "    # Create new index for merged pedigree\n",
    "    new_idx = max(idx_to_up_dict_ll_list.keys()) + 1 if idx_to_up_dict_ll_list else 0\n",
    "    \n",
    "    # Store combined pedigrees under new index\n",
    "    idx_to_up_dict_ll_list[new_idx] = kept_combined\n",
    "    \n",
    "    # Update id_to_idx and idx_to_id_set\n",
    "    id_set1 = idx_to_id_set[idx1]\n",
    "    id_set2 = idx_to_id_set[idx2]\n",
    "    merged_id_set = id_set1.union(id_set2)\n",
    "    \n",
    "    for id_val in merged_id_set:\n",
    "        id_to_idx[id_val] = new_idx\n",
    "        \n",
    "    idx_to_id_set[new_idx] = merged_id_set\n",
    "    \n",
    "    # Remove old pedigree records\n",
    "    del idx_to_up_dict_ll_list[idx1]\n",
    "    del idx_to_up_dict_ll_list[idx2]\n",
    "    del idx_to_id_set[idx1]\n",
    "    del idx_to_id_set[idx2]\n",
    "    \n",
    "    return idx_to_up_dict_ll_list, id_to_idx, idx_to_id_set\n",
    "\n",
    "# Let's demonstrate how these functions work with a simple example\n",
    "def demonstrate_pedigree_tracking():\n",
    "    # Create some simple pedigrees\n",
    "    id_to_up_dct = {\n",
    "        1: {},  # Individual 1\n",
    "        2: {},  # Individual 2\n",
    "        3: {}   # Individual 3\n",
    "    }\n",
    "    \n",
    "    # Initialize tracking structures\n",
    "    idx_to_up_dict_ll_list, id_to_idx, idx_to_id_set = initialize_pedigree_tracking(id_to_up_dct)\n",
    "    \n",
    "    print(\"Initial tracking structures:\")\n",
    "    print(f\"id_to_idx: {id_to_idx}\")\n",
    "    print(f\"idx_to_id_set: {idx_to_id_set}\")\n",
    "    print(f\"idx_to_up_dict_ll_list keys: {list(idx_to_up_dict_ll_list.keys())}\")\n",
    "    \n",
    "    # Merge pedigrees 0 and 1\n",
    "    # In reality, this would be based on IBD sharing, but for simplicity we'll just merge them directly\n",
    "    merged_pedigree = {1: {}, 2: {}}\n",
    "    kept_combined = [(merged_pedigree, 10.0)]  # Merged pedigree with likelihood score\n",
    "    \n",
    "    # Update tracking structures\n",
    "    idx_to_up_dict_ll_list, id_to_idx, idx_to_id_set = update_pedigree_tracking(\n",
    "        idx_to_up_dict_ll_list, id_to_idx, idx_to_id_set, 0, 1, kept_combined)\n",
    "    \n",
    "    print(\"\\nTracking structures after merging pedigrees 0 and 1:\")\n",
    "    print(f\"id_to_idx: {id_to_idx}\")\n",
    "    print(f\"idx_to_id_set: {idx_to_id_set}\")\n",
    "    print(f\"idx_to_up_dict_ll_list keys: {list(idx_to_up_dict_ll_list.keys())}\")\n",
    "    \n",
    "    # Merge the combined pedigree with pedigree 2\n",
    "    final_pedigree = {1: {}, 2: {}, 3: {}}\n",
    "    final_combined = [(final_pedigree, 15.0)]\n",
    "    \n",
    "    # Update tracking structures again\n",
    "    idx_to_up_dict_ll_list, id_to_idx, idx_to_id_set = update_pedigree_tracking(\n",
    "        idx_to_up_dict_ll_list, id_to_idx, idx_to_id_set, 3, 2, final_combined)\n",
    "    \n",
    "    print(\"\\nTracking structures after merging all pedigrees:\")\n",
    "    print(f\"id_to_idx: {id_to_idx}\")\n",
    "    print(f\"idx_to_id_set: {idx_to_id_set}\")\n",
    "    print(f\"idx_to_up_dict_ll_list keys: {list(idx_to_up_dict_ll_list.keys())}\")\n",
    "    print(f\"Final pedigree likelihood: {idx_to_up_dict_ll_list[4][0][1]}\")\n",
    "\n",
    "# Run the demonstration\n",
    "demonstrate_pedigree_tracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Finding Optimal Ways to Merge Pedigrees\n",
    "\n",
    "A critical aspect of the `combine_up_dicts()` algorithm is determining the optimal way to merge pedigrees. This involves:\n",
    "\n",
    "1. Identifying which pedigrees should be merged next based on IBD sharing\n",
    "2. Finding potential connection points in each pedigree\n",
    "3. Evaluating different relationship configurations for connecting these points\n",
    "4. Selecting the connections that maximize the overall likelihood\n",
    "\n",
    "Let's implement simplified versions of these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def find_optimal_merge(ped1, ped2, id_pair_to_cm):\n",
    "    \"\"\"\n",
    "    Find the optimal way to merge two pedigrees based on IBD sharing.\n",
    "    \n",
    "    Args:\n",
    "        ped1, ped2: Pedigrees to merge (up-node dictionaries)\n",
    "        id_pair_to_cm: Dict mapping ID pairs to their total shared cM\n",
    "        \n",
    "    Returns:\n",
    "        best_merged: The best merged pedigree\n",
    "        likelihood: The likelihood of the merged pedigree\n",
    "    \"\"\"\n",
    "    # Get all IDs in each pedigree\n",
    "    ids1 = set(ped1.keys())\n",
    "    ids2 = set(ped2.keys())\n",
    "    \n",
    "    # Find pairs of individuals that share IBD across pedigrees\n",
    "    connecting_pairs = []\n",
    "    for id1 in ids1:\n",
    "        for id2 in ids2:\n",
    "            pair = (min(id1, id2), max(id1, id2))\n",
    "            if pair in id_pair_to_cm and id_pair_to_cm[pair] > 20:  # Minimum threshold\n",
    "                connecting_pairs.append((id1, id2, id_pair_to_cm[pair]))\n",
    "    \n",
    "    # Sort by amount of IBD sharing (descending)\n",
    "    connecting_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # If no connecting pairs, just merge without connections\n",
    "    if not connecting_pairs:\n",
    "        merged = merge_pedigrees_simple(ped1, ped2)\n",
    "        return merged, 0.0\n",
    "    \n",
    "    # Try different relationship configurations for the top connecting pair\n",
    "    id1, id2, shared_cm = connecting_pairs[0]\n",
    "    relationship_configs = [\n",
    "        (\"parent-child\", 0, 1, 1),    # id1 is parent of id2\n",
    "        (\"parent-child\", 1, 0, 1),    # id2 is parent of id1\n",
    "        (\"siblings\", 1, 1, 2),        # id1 and id2 are full siblings\n",
    "        (\"half-siblings\", 1, 1, 1),   # id1 and id2 are half siblings\n",
    "        (\"cousins\", 2, 2, 2),         # id1 and id2 are cousins\n",
    "        (\"unrelated\", None, None, None)  # No direct relationship\n",
    "    ]\n",
    "    \n",
    "    # Evaluate each relationship configuration\n",
    "    best_merged = None\n",
    "    best_likelihood = float('-inf')\n",
    "    \n",
    "    for name, up, down, num_ancs in relationship_configs:\n",
    "        # Skip relationship if it doesn't match the IBD amount\n",
    "        if not is_plausible_relationship(name, shared_cm):\n",
    "            continue\n",
    "            \n",
    "        # Merge the pedigrees with this relationship configuration\n",
    "        merged = merge_with_relationship(ped1, ped2, id1, id2, up, down, num_ancs)\n",
    "        \n",
    "        # Calculate likelihood of the merged pedigree\n",
    "        likelihood = calculate_merged_likelihood(merged, id_pair_to_cm)\n",
    "        \n",
    "        # Update best if this is better\n",
    "        if likelihood > best_likelihood:\n",
    "            best_merged = merged\n",
    "            best_likelihood = likelihood\n",
    "    \n",
    "    return best_merged, best_likelihood\n",
    "\n",
    "def is_plausible_relationship(relationship, shared_cm):\n",
    "    \"\"\"\n",
    "    Check if a relationship is plausible given the amount of shared DNA.\n",
    "    \n",
    "    Args:\n",
    "        relationship: String describing the relationship\n",
    "        shared_cm: Amount of shared DNA in centimorgans\n",
    "        \n",
    "    Returns:\n",
    "        is_plausible: Whether the relationship is plausible\n",
    "    \"\"\"\n",
    "    # Expected IBD ranges for different relationships\n",
    "    ranges = {\n",
    "        \"parent-child\": (1700, 3400),  # ~50% of genome\n",
    "        \"siblings\": (1700, 2800),      # ~50-75% of genome\n",
    "        \"half-siblings\": (700, 1800),  # ~25-50% of genome\n",
    "        \"cousins\": (200, 900),         # ~12.5-25% of genome\n",
    "        \"unrelated\": (0, 100)          # Very little sharing\n",
    "    }\n",
    "    \n",
    "    if relationship in ranges:\n",
    "        min_cm, max_cm = ranges[relationship]\n",
    "        return min_cm <= shared_cm <= max_cm\n",
    "    else:\n",
    "        return True  # Unknown relationship, assume plausible\n",
    "\n",
    "def merge_with_relationship(ped1, ped2, id1, id2, up, down, num_ancs):\n",
    "    \"\"\"\n",
    "    Merge pedigrees with a specific relationship between id1 and id2.\n",
    "    \n",
    "    Args:\n",
    "        ped1, ped2: Pedigrees to merge\n",
    "        id1, id2: IDs to connect\n",
    "        up, down, num_ancs: Relationship parameters\n",
    "        \n",
    "    Returns:\n",
    "        merged: Merged pedigree\n",
    "    \"\"\"\n",
    "    # Create copies to avoid modifying originals\n",
    "    ped1 = copy.deepcopy(ped1)\n",
    "    ped2 = copy.deepcopy(ped2)\n",
    "    \n",
    "    # Implement different relationship types\n",
    "    if up == 0 and down == 1:  # id1 is parent of id2\n",
    "        if id2 not in ped2:\n",
    "            ped2[id2] = {}\n",
    "        ped2[id2][id1] = 1  # Add id1 as parent of id2\n",
    "        \n",
    "    elif up == 1 and down == 0:  # id2 is parent of id1\n",
    "        if id1 not in ped1:\n",
    "            ped1[id1] = {}\n",
    "        ped1[id1][id2] = 1  # Add id2 as parent of id1\n",
    "        \n",
    "    elif up == 1 and down == 1:  # siblings or half-siblings\n",
    "        # Create a common parent\n",
    "        parent_id = -1  # Use negative ID for ungenotyped individual\n",
    "        \n",
    "        # Add parent to both individuals\n",
    "        if id1 not in ped1:\n",
    "            ped1[id1] = {}\n",
    "        ped1[id1][parent_id] = 1\n",
    "        \n",
    "        if id2 not in ped2:\n",
    "            ped2[id2] = {}\n",
    "        ped2[id2][parent_id] = 1\n",
    "        \n",
    "        # For full siblings, add a second parent\n",
    "        if num_ancs == 2:\n",
    "            parent2_id = -2\n",
    "            ped1[id1][parent2_id] = 1\n",
    "            ped2[id2][parent2_id] = 1\n",
    "    \n",
    "    # Merge the modified pedigrees\n",
    "    merged = merge_pedigrees_simple(ped1, ped2)\n",
    "    return merged\n",
    "\n",
    "def merge_pedigrees_simple(ped1, ped2):\n",
    "    \"\"\"\n",
    "    Merge two pedigrees without adding new relationships.\n",
    "    \n",
    "    Args:\n",
    "        ped1, ped2: Pedigrees to merge\n",
    "        \n",
    "    Returns:\n",
    "        merged: Merged pedigree\n",
    "    \"\"\"\n",
    "    merged = copy.deepcopy(ped1)\n",
    "    \n",
    "    # Add all nodes from ped2\n",
    "    for node, parents in ped2.items():\n",
    "        if node not in merged:\n",
    "            merged[node] = parents.copy()\n",
    "        else:\n",
    "            # Merge parents\n",
    "            for parent, deg in parents.items():\n",
    "                merged[node][parent] = deg\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def calculate_merged_likelihood(merged_ped, id_pair_to_cm):\n",
    "    \"\"\"\n",
    "    Calculate likelihood of a merged pedigree.\n",
    "    \n",
    "    Args:\n",
    "        merged_ped: Merged pedigree\n",
    "        id_pair_to_cm: Dict mapping ID pairs to their shared cM\n",
    "        \n",
    "    Returns:\n",
    "        likelihood: Log-likelihood of the pedigree\n",
    "    \"\"\"\n",
    "    # Simple implementation - just sum the log of shared IBD amounts\n",
    "    likelihood = 0.0\n",
    "    \n",
    "    # Get all pairs of IDs in the pedigree\n",
    "    ids = list(merged_ped.keys())\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i + 1, len(ids)):\n",
    "            id1, id2 = ids[i], ids[j]\n",
    "            pair = (min(id1, id2), max(id1, id2))\n",
    "            \n",
    "            if pair in id_pair_to_cm:\n",
    "                # Add contribution to likelihood\n",
    "                shared_cm = id_pair_to_cm[pair]\n",
    "                likelihood += math.log(1 + shared_cm)\n",
    "    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a small example to demonstrate how these functions work together to find the optimal way to merge pedigrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def demonstrate_optimal_merge():\n",
    "    # Create two simple pedigrees\n",
    "    ped1 = {1: {}}  # Individual 1\n",
    "    ped2 = {2: {}}  # Individual 2\n",
    "    \n",
    "    # Create IBD sharing data - simulate parent-child relationship\n",
    "    id_pair_to_cm = {(1, 2): 1800}  # ~50% of genome shared\n",
    "    \n",
    "    # Find the optimal way to merge these pedigrees\n",
    "    merged, likelihood = find_optimal_merge(ped1, ped2, id_pair_to_cm)\n",
    "    \n",
    "    print(\"Merge example 1: Parent-child relationship\")\n",
    "    print(f\"Pedigree 1: {ped1}\")\n",
    "    print(f\"Pedigree 2: {ped2}\")\n",
    "    print(f\"IBD sharing: {id_pair_to_cm}\")\n",
    "    print(f\"Merged pedigree: {merged}\")\n",
    "    print(f\"Likelihood: {likelihood}\")\n",
    "    \n",
    "    # Create another example with half-sibling relationship\n",
    "    ped3 = {3: {}}  # Individual 3\n",
    "    ped4 = {4: {}}  # Individual 4\n",
    "    \n",
    "    # Create IBD sharing data - simulate half-sibling relationship\n",
    "    id_pair_to_cm = {(3, 4): 900}  # ~25% of genome shared\n",
    "    \n",
    "    # Find the optimal way to merge these pedigrees\n",
    "    merged2, likelihood2 = find_optimal_merge(ped3, ped4, id_pair_to_cm)\n",
    "    \n",
    "    print(\"\\nMerge example 2: Half-sibling relationship\")\n",
    "    print(f\"Pedigree 3: {ped3}\")\n",
    "    print(f\"Pedigree 4: {ped4}\")\n",
    "    print(f\"IBD sharing: {id_pair_to_cm}\")\n",
    "    print(f\"Merged pedigree: {merged2}\")\n",
    "    print(f\"Likelihood: {likelihood2}\")\n",
    "\n",
    "# Run the demonstration\n",
    "demonstrate_optimal_merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Putting It All Together - The Incremental Process\n",
    "\n",
    "Now let's implement a simplified version of the full `combine_up_dicts()` algorithm that incorporates all the elements we've explored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def simulate_ibd_data(num_individuals=5, density=0.3):\n",
    "    \"\"\"\n",
    "    Simulate IBD data for a set of individuals.\n",
    "    \n",
    "    Args:\n",
    "        num_individuals: Number of individuals to simulate\n",
    "        density: Probability of IBD sharing between pairs\n",
    "        \n",
    "    Returns:\n",
    "        id_to_up_dct: Dict mapping IDs to their pedigrees\n",
    "        id_to_shared_ibd: Dict mapping ID pairs to their IBD segments\n",
    "    \"\"\"\n",
    "    # Create individual pedigrees\n",
    "    id_to_up_dct = {i: {} for i in range(1, num_individuals + 1)}\n",
    "    \n",
    "    # Simulate IBD sharing\n",
    "    id_to_shared_ibd = {}\n",
    "    for i in range(1, num_individuals + 1):\n",
    "        for j in range(i + 1, num_individuals + 1):\n",
    "            # Randomly decide if this pair shares IBD\n",
    "            if random.random() < density:\n",
    "                # Simulate amount of sharing (random value between 50 and 2000 cM)\n",
    "                shared_cm = random.uniform(50, 2000)\n",
    "                \n",
    "                # Create a dummy segment\n",
    "                segment = {\"start\": 0, \"end\": 100, \"length_cm\": shared_cm}\n",
    "                id_to_shared_ibd[(i, j)] = [segment]\n",
    "    \n",
    "    return id_to_up_dct, id_to_shared_ibd\n",
    "\n",
    "def visualize_pedigree(up_node_dict, title=\"Pedigree\"):\n",
    "    \"\"\"\n",
    "    Visualize a pedigree using networkx.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        title: Title for the visualization\n",
    "    \"\"\"\n",
    "    # Create a directed graph (edges point from child to parent)\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add all nodes to the graph\n",
    "    all_ids = set(up_node_dict.keys())\n",
    "    for parents in up_node_dict.values():\n",
    "        all_ids.update(parents.keys())\n",
    "    \n",
    "    # Add nodes with colors (blue for genotyped, gray for ungenotyped)\n",
    "    for node_id in all_ids:\n",
    "        if node_id > 0:  # Genotyped individuals have positive IDs\n",
    "            G.add_node(node_id, color='lightblue')\n",
    "        else:  # Ungenotyped individuals have negative IDs\n",
    "            G.add_node(node_id, color='lightgray')\n",
    "    \n",
    "    # Add edges (from child to parent)\n",
    "    for child, parents in up_node_dict.items():\n",
    "        for parent in parents:\n",
    "            G.add_edge(child, parent)\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Get node colors\n",
    "    node_colors = [G.nodes[n]['color'] for n in G.nodes]\n",
    "    \n",
    "    # Set layout (tree layout looks nice for pedigrees)\n",
    "    pos = nx.spring_layout(G, seed=42)  # For reproducibility\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, \n",
    "            node_size=800, font_weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def run_combine_up_dicts_demo():\n",
    "    # Generate simulated IBD data\n",
    "    id_to_up_dct, id_to_shared_ibd = simulate_ibd_data(num_individuals=5, density=0.3)\n",
    "    \n",
    "    # Display the IBD sharing data\n",
    "    print(\"Simulated IBD sharing:\")\n",
    "    for (id1, id2), segments in id_to_shared_ibd.items():\n",
    "        total_cm = sum(seg[\"length_cm\"] for seg in segments)\n",
    "        print(f\"Individuals {id1} and {id2} share {total_cm:.1f} cM\")\n",
    "    \n",
    "    # Run our simplified combine_up_dicts implementation\n",
    "    final_pedigrees = simplified_combine_up_dicts(id_to_up_dct, id_to_shared_ibd)\n",
    "    \n",
    "    if final_pedigrees:\n",
    "        best_pedigree, likelihood = final_pedigrees[0]\n",
    "        print(f\"\\nBest pedigree has likelihood {likelihood:.2f}\")\n",
    "        \n",
    "        # Visualize the pedigree\n",
    "        visualize_pedigree(best_pedigree, \"Final Merged Pedigree\")\n",
    "    else:\n",
    "        print(\"\\nNo valid pedigrees found\")\n",
    "\n",
    "# Run the demonstration\n",
    "np.random.seed(42)  # For reproducibility\n",
    "random.seed(42)\n",
    "run_combine_up_dicts_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Comparison with the Real Bonsai v3 Implementation\n",
    "\n",
    "Our simplified implementation captures the essence of the `combine_up_dicts()` algorithm, but the real Bonsai v3 implementation includes many sophisticated features that make it more accurate and robust. Some of the key differences include:\n",
    "\n",
    "1. **Advanced Relationship Inference**: The real implementation uses sophisticated statistical models to infer relationships from IBD data, considering not just the total amount of sharing but also the patterns of segment lengths and counts.\n",
    "\n",
    "2. **Comprehensive Likelihood Calculation**: The Bonsai v3 likelihood calculation integrates genetic evidence with biological constraints like age, sex, and generation gaps.\n",
    "\n",
    "3. **Multiple Hypothesis Tracking**: The real implementation maintains multiple alternative hypotheses about how individuals might be related, allowing it to recover from local optima.\n",
    "\n",
    "4. **Sophisticated Connection Point Selection**: Bonsai v3 uses advanced algorithms to identify the best points to connect pedigrees, considering both genetic evidence and structural constraints.\n",
    "\n",
    "5. **Error Handling and Edge Cases**: The production code includes robust handling of edge cases like conflicting evidence or incompatible pedigrees.\n",
    "\n",
    "Let's see if we can use the real Bonsai v3 implementation directly on our simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if not is_jupyterlite():\n",
    "    try:\n",
    "        # Import the real combine_up_dicts function\n",
    "        from utils.bonsaitree.bonsaitree.v3.connections import combine_up_dicts as real_combine_up_dicts\n",
    "        \n",
    "        # Generate simulated data\n",
    "        id_to_up_dct, id_to_shared_ibd = simulate_ibd_data(num_individuals=5, density=0.3)\n",
    "        \n",
    "        # Convert IBD data to Bonsai v3 format\n",
    "        unphased_ibd_seg_list = []\n",
    "        for (id1, id2), segments in id_to_shared_ibd.items():\n",
    "            for segment in segments:\n",
    "                # Create segment in Bonsai format\n",
    "                bonsai_segment = {\n",
    "                    \"id1\": id1,\n",
    "                    \"id2\": id2,\n",
    "                    \"chrom\": 1,  # Dummy chromosome\n",
    "                    \"start_cm\": 0,\n",
    "                    \"end_cm\": segment[\"length_cm\"],\n",
    "                    \"length_cm\": segment[\"length_cm\"]\n",
    "                }\n",
    "                unphased_ibd_seg_list.append(bonsai_segment)\n",
    "        \n",
    "        # Create biographical information\n",
    "        bio_info = []\n",
    "        for id_val in range(1, 6):\n",
    "            info = {\n",
    "                \"id\": id_val,\n",
    "                \"sex\": random.choice([\"M\", \"F\"]),\n",
    "                \"age\": random.randint(20, 80)\n",
    "            }\n",
    "            bio_info.append(info)\n",
    "        \n",
    "        # Try to run the real combine_up_dicts function\n",
    "        try:\n",
    "            from utils.bonsaitree.bonsaitree.v3.pw_log_like import PwLogLike\n",
    "            \n",
    "            # Create PwLogLike instance\n",
    "            pw_ll = PwLogLike(bio_info=bio_info, unphased_ibd_seg_list=unphased_ibd_seg_list)\n",
    "            \n",
    "            # Run the real combine_up_dicts function\n",
    "            result = real_combine_up_dicts(\n",
    "                unphased_ibd_seg_list=unphased_ibd_seg_list,\n",
    "                bio_info=bio_info,\n",
    "                pw_ll_cls=PwLogLike\n",
    "            )\n",
    "            \n",
    "            print(\"Successfully ran real Bonsai v3 combine_up_dicts function\")\n",
    "            print(f\"Result: {result}\")\n",
    "            \n",
    "            # Visualize the result if available\n",
    "            if result and len(result) > 0 and len(result[0]) > 0:\n",
    "                best_pedigree = result[0][0]\n",
    "                visualize_pedigree(best_pedigree, \"Bonsai v3 Result\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running real combine_up_dicts: {e}\")\n",
    "            print(\"Using simplified implementation instead\")\n",
    "            \n",
    "            # Run our simplified implementation\n",
    "            result = simplified_combine_up_dicts(id_to_up_dct, id_to_shared_ibd)\n",
    "            \n",
    "            if result:\n",
    "                best_pedigree, likelihood = result[0]\n",
    "                print(f\"Simplified result: {best_pedigree}\")\n",
    "                print(f\"Likelihood: {likelihood}\")\n",
    "                visualize_pedigree(best_pedigree, \"Simplified Result\")\n",
    "            \n",
    "    except ImportError as e:\n",
    "        print(f\"Could not import Bonsai v3 functions: {e}\")\n",
    "        print(\"Using simplified implementation instead\")\n",
    "        \n",
    "        # Run our simplified implementation\n",
    "        result = simplified_combine_up_dicts(id_to_up_dct, id_to_shared_ibd)\n",
    "        \n",
    "        if result:\n",
    "            best_pedigree, likelihood = result[0]\n",
    "            print(f\"Simplified result: {best_pedigree}\")\n",
    "            print(f\"Likelihood: {likelihood}\")\n",
    "            visualize_pedigree(best_pedigree, \"Simplified Result\")\n",
    "else:\n",
    "    print(\"Running in JupyterLite environment - skipping real Bonsai v3 implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we explored the `combine_up_dicts()` algorithm, which is at the heart of Bonsai v3's ability to scale from small pedigree structures to larger, more complex family networks. Key takeaways include:\n",
    "\n",
    "1. **Iterative Merge Approach**: The algorithm works by repeatedly finding and merging the most closely related pedigrees until all individuals are connected or no more reliable connections can be made.\n",
    "\n",
    "2. **Pedigree Tracking**: Sophisticated data structures track pedigrees, their likelihoods, and the individuals they contain throughout the merging process.\n",
    "\n",
    "3. **Finding Optimal Connections**: The algorithm systematically evaluates different ways to connect pedigrees, selecting the connections that maximize the overall likelihood.\n",
    "\n",
    "4. **Multiple Hypothesis Tracking**: By maintaining multiple alternative pedigree configurations at each step, the algorithm can explore different hypotheses about how individuals might be related.\n",
    "\n",
    "5. **Comprehensive Likelihood Calculation**: The likelihood calculation integrates genetic evidence with biological constraints to evaluate different pedigree configurations.\n",
    "\n",
    "This incremental, likelihood-based approach is what enables Bonsai v3 to reconstruct complex family networks from genetic data, even in the presence of noise, missing data, and ambiguous relationships. By dividing the reconstruction problem into smaller, more manageable pieces, the `combine_up_dicts()` algorithm makes it possible to scale to larger pedigrees while maintaining computational feasibility and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert this notebook to PDF using poetry\n",
    "!poetry run jupyter nbconvert --to pdf Lab15_Combine_Up_Dicts.ipynb\n",
    "\n",
    "# Note: PDF conversion requires LaTeX to be installed on your system\n",
    "# If you encounter errors, you may need to install it:\n",
    "# On Ubuntu/Debian: sudo apt-get install texlive-xetex\n",
    "# On macOS with Homebrew: brew install texlive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}