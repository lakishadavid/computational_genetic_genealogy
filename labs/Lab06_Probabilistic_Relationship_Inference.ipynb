{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Probabilistic Relationship Inference\n",
    "\n",
    "## Overview\n",
    "\n",
    "This lab explores the probabilistic models used in Bonsai v3 for relationship inference. We'll focus on how statistical moments of IBD distributions are used to calculate likelihoods for different possible relationships.\n",
    "\n",
    "Key topics include:\n",
    "\n",
    "1. The mathematical framework for relationship inference\n",
    "2. Computing statistical moments for IBD segment distributions\n",
    "3. Building likelihood functions for different relationship types\n",
    "4. Handling uncertainty and stochasticity in relationship inference\n",
    "5. Calibrating models with real-world data\n",
    "\n",
    "By the end of this lab, you'll understand how Bonsai v3 quantifies the probability of different relationships given observed IBD patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§¬ Google Colab Setup - Run this cell first!\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "def is_colab():\n",
    "    '''Check if running in Google Colab'''\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if is_colab():\n",
    "    print(\"ðŸ”¬ Setting up Google Colab environment...\")\n",
    "    \n",
    "    # Install dependencies\n",
    "    print(\"ðŸ“¦ Installing packages...\")\n",
    "    !pip install -q pysam biopython scikit-allel networkx pygraphviz seaborn plotly\n",
    "    !apt-get update -qq && apt-get install -qq samtools bcftools tabix graphviz-dev\n",
    "    \n",
    "    # Create directories\n",
    "    !mkdir -p /content/class_data /content/results\n",
    "    \n",
    "    # Download essential class data\n",
    "    print(\"ðŸ“¥ Downloading class data...\")\n",
    "    S3_BASE = \"https://computational-genetic-genealogy.s3.us-east-2.amazonaws.com/class_data/\"\n",
    "    data_files = [\n",
    "        \"pedigree.fam\", \"pedigree.def\", \n",
    "        \"merged_opensnps_autosomes_ped_sim.seg\",\n",
    "        \"merged_opensnps_autosomes_ped_sim-everyone.fam\",\n",
    "        \"ped_sim_run2.seg\", \"ped_sim_run2-everyone.fam\"\n",
    "    ]\n",
    "    \n",
    "    for file in data_files:\n",
    "        !wget -q -O /content/class_data/{file} {S3_BASE}{file}\n",
    "        print(f\"  âœ… {file}\")\n",
    "    \n",
    "    # Define utility functions\n",
    "    def setup_environment():\n",
    "        return \"/content/class_data\", \"/content/results\"\n",
    "    \n",
    "    def save_results(dataframe, filename, description=\"results\"):\n",
    "        os.makedirs(\"/content/results\", exist_ok=True)\n",
    "        full_path = f\"/content/results/{filename}\"\n",
    "        dataframe.to_csv(full_path, index=False)\n",
    "        display(HTML(f'''\n",
    "        <div style=\"padding: 10px; background-color: #e3f2fd; border-left: 4px solid #2196f3; margin: 10px 0;\">\n",
    "            <p><strong>ðŸ’¾ Results saved!</strong> To download: \n",
    "            <code>from google.colab import files; files.download('{full_path}')</code></p>\n",
    "        </div>\n",
    "        '''))\n",
    "        return full_path\n",
    "    \n",
    "    def save_plot(plt, filename, description=\"plot\"):\n",
    "        os.makedirs(\"/content/results\", exist_ok=True)\n",
    "        full_path = f\"/content/results/{filename}\"\n",
    "        plt.savefig(full_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        display(HTML(f'''\n",
    "        <div style=\"padding: 10px; background-color: #e8f5e8; border-left: 4px solid #4caf50; margin: 10px 0;\">\n",
    "            <p><strong>ðŸ“Š Plot saved!</strong> To download: \n",
    "            <code>from google.colab import files; files.download('{full_path}')</code></p>\n",
    "        </div>\n",
    "        '''))\n",
    "        return full_path\n",
    "    \n",
    "    print(\"âœ… Colab setup complete! Ready to explore genetic genealogy.\")\n",
    "    \n",
    "else:\n",
    "    print(\"ðŸ  Local environment detected\")\n",
    "    def setup_environment():\n",
    "        return \"class_data\", \"results\"\n",
    "    def save_results(df, filename, description=\"\"):\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        path = f\"results/{filename}\"\n",
    "        df.to_csv(path, index=False)\n",
    "        return path\n",
    "    def save_plot(plt, filename, description=\"\"):\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        path = f\"results/{filename}\"\n",
    "        plt.savefig(path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        return path\n",
    "\n",
    "# Set up paths and configure visualization\n",
    "DATA_DIR, RESULTS_DIR = setup_environment()\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Bonsai module paths\n",
    "if not is_jupyterlite():\n",
    "    # In local environment, add the utils directory to system path\n",
    "    utils_dir = os.getenv('PROJECT_UTILS_DIR', os.path.join(os.path.dirname(DATA_DIR), 'utils'))\n",
    "    bonsaitree_dir = os.path.join(utils_dir, 'bonsaitree')\n",
    "    \n",
    "    # Add to path if it exists and isn't already there\n",
    "    if os.path.exists(bonsaitree_dir) and bonsaitree_dir not in sys.path:\n",
    "        sys.path.append(bonsaitree_dir)\n",
    "        print(f\"Added {bonsaitree_dir} to sys.path\")\n",
    "else:\n",
    "    # In JupyterLite, use a simplified approach\n",
    "    print(\"âš ï¸ Running in JupyterLite: Some Bonsai functionality may be limited.\")\n",
    "    print(\"This notebook is primarily designed for local execution where the Bonsai codebase is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for exploring modules\n",
    "def view_function_source(module_name, function_name):\n",
    "    \"\"\"Display the source code of a function\"\"\"\n",
    "    try:\n",
    "        # Import the module\n",
    "        module = importlib.import_module(module_name)\n",
    "        \n",
    "        # Get the function\n",
    "        func = getattr(module, function_name)\n",
    "        \n",
    "        # Get the source code\n",
    "        source = inspect.getsource(func)\n",
    "        \n",
    "        # Print the source code\n",
    "        from IPython.display import display, Markdown\n",
    "        display(Markdown(f\"```python\\n{source}\\n```\"))\n",
    "    except ImportError as e:\n",
    "        print(f\"Error importing module {module_name}: {e}\")\n",
    "    except AttributeError:\n",
    "        print(f\"Function {function_name} not found in module {module_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing function {function_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Bonsai Installation\n",
    "\n",
    "Let's verify that the Bonsai v3 module is available for import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from utils.bonsaitree.bonsaitree import v3\n",
    "    print(\"âœ… Successfully imported Bonsai v3 module\")\n",
    "    \n",
    "    # Check if moments module is available\n",
    "    try:\n",
    "        from utils.bonsaitree.bonsaitree.v3 import moments, likelihoods\n",
    "        print(\"âœ… Successfully imported Bonsai v3 moments and likelihoods modules\")\n",
    "        \n",
    "        # Display available methods in modules\n",
    "        print(\"\\nAvailable functions in moments module:\")\n",
    "        for name in dir(moments):\n",
    "            if not name.startswith('_') and callable(getattr(moments, name)):\n",
    "                print(f\"- {name}\")\n",
    "                \n",
    "        print(\"\\nAvailable classes in likelihoods module:\")\n",
    "        for name in dir(likelihoods):\n",
    "            if not name.startswith('_') and inspect.isclass(getattr(likelihoods, name)):\n",
    "                print(f\"- {name}\")\n",
    "                \n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ Failed to import Bonsai v3 moments module: {e}\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Failed to import Bonsai v3 module: {e}\")\n",
    "    print(\"This lab requires access to the Bonsai v3 codebase.\")\n",
    "    print(\"Make sure you've properly set up your environment with the Bonsai repository.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Relationship Representation and Mathematical Framework\n",
    "\n",
    "Let's start by exploring how Bonsai v3 represents relationships and the mathematical framework it uses for relationship inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Relationship Representation\n",
    "\n",
    "Bonsai v3 uses a tuple representation for relationships. There are two equivalent formats used in different parts of the code:\n",
    "\n",
    "1. **Five-value tuple**: `(degree1, removal1, degree2, removal2, half)`\n",
    "   - `degree1`: Genealogical degree of person 1 (ancestors to common ancestor)\n",
    "   - `removal1`: Removal for person 1 (generational distance within degree)\n",
    "   - `degree2`: Genealogical degree of person 2 (ancestors to common ancestor)\n",
    "   - `removal2`: Removal for person 2 (generational distance within degree)\n",
    "   - `half`: 1 for half relationships (one common ancestor), 0 for full relationships (two common ancestors)\n",
    "\n",
    "2. **Three-value tuple**: `(up, down, num_ancs)`\n",
    "   - `up`: Generations from person 1 to common ancestor\n",
    "   - `down`: Generations from common ancestor to person 2\n",
    "   - `num_ancs`: Number of common ancestors (1 for half-relationships, 2 for full relationships)\n",
    "\n",
    "The three-value representation is more commonly used in the moments module. Let's create a function to map these tuples to familiar relationship terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_relationship(rel_tuple):\n",
    "    \"\"\"Convert a relationship tuple (up, down, num_ancs) to a human-readable description.\"\"\"\n",
    "    up, down, num_ancs = rel_tuple\n",
    "    \n",
    "    if up == 0 and down == 0 and num_ancs == 2:\n",
    "        return \"Self\"\n",
    "    elif up == 0 and down == 1 and num_ancs == 1:\n",
    "        return \"Parent\"\n",
    "    elif up == 1 and down == 0 and num_ancs == 1:\n",
    "        return \"Child\"\n",
    "    elif up == 1 and down == 1 and num_ancs == 2:\n",
    "        return \"Full Sibling\"\n",
    "    elif up == 1 and down == 1 and num_ancs == 1:\n",
    "        return \"Half Sibling\"\n",
    "    elif up == 0 and down == 2 and num_ancs == 1:\n",
    "        return \"Grandparent\"\n",
    "    elif up == 2 and down == 0 and num_ancs == 1:\n",
    "        return \"Grandchild\"\n",
    "    elif up == 1 and down == 2 and num_ancs == 1:\n",
    "        return \"Aunt/Uncle\"\n",
    "    elif up == 2 and down == 1 and num_ancs == 1:\n",
    "        return \"Niece/Nephew\"\n",
    "    elif up == 2 and down == 2 and num_ancs == 2:\n",
    "        return \"Full First Cousin\"\n",
    "    elif up == 2 and down == 2 and num_ancs == 1:\n",
    "        return \"Half First Cousin\"\n",
    "    elif up == 3 and down == 3 and num_ancs == 2:\n",
    "        return \"Full Second Cousin\"\n",
    "    elif up == 3 and down == 3 and num_ancs == 1:\n",
    "        return \"Half Second Cousin\"\n",
    "    elif up == 4 and down == 4 and num_ancs == 2:\n",
    "        return \"Full Third Cousin\"\n",
    "    elif up == 4 and down == 4 and num_ancs == 1:\n",
    "        return \"Half Third Cousin\"\n",
    "    elif up == 1 and down == 3 and num_ancs == 1:\n",
    "        return \"First Cousin Once Removed (Aunt/Uncle)\"\n",
    "    elif up == 3 and down == 1 and num_ancs == 1:\n",
    "        return \"First Cousin Once Removed (Niece/Nephew)\"\n",
    "    else:\n",
    "        return f\"Complex Relationship (up={up}, down={down}, num_ancs={num_ancs})\"\n",
    "\n",
    "# Create a table of common relationships and their tuple representations\n",
    "relationships = [\n",
    "    ((0, 0, 2), \"Self\"),\n",
    "    ((0, 1, 1), \"Parent\"),\n",
    "    ((1, 0, 1), \"Child\"),\n",
    "    ((1, 1, 2), \"Full Sibling\"),\n",
    "    ((1, 1, 1), \"Half Sibling\"),\n",
    "    ((0, 2, 1), \"Grandparent\"),\n",
    "    ((2, 0, 1), \"Grandchild\"),\n",
    "    ((1, 2, 1), \"Aunt/Uncle\"),\n",
    "    ((2, 1, 1), \"Niece/Nephew\"),\n",
    "    ((2, 2, 2), \"Full First Cousin\"),\n",
    "    ((2, 2, 1), \"Half First Cousin\"),\n",
    "    ((3, 3, 2), \"Full Second Cousin\"),\n",
    "    ((3, 3, 1), \"Half Second Cousin\"),\n",
    "    ((4, 4, 2), \"Full Third Cousin\"),\n",
    "    ((4, 4, 1), \"Half Third Cousin\")\n",
    "]\n",
    "\n",
    "# Create a DataFrame for easier viewing\n",
    "rel_df = pd.DataFrame([(rel[0][0], rel[0][1], rel[0][2], rel[1], rel[0][0] + rel[0][1]) \n",
    "                       for rel in relationships],\n",
    "                     columns=['Up', 'Down', 'Num Ancestors', 'Relationship', 'Meiotic Distance'])\n",
    "display(rel_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The Mathematical Framework for Relationship Inference\n",
    "\n",
    "The core mathematical framework for relationship inference in Bonsai v3 is Bayesian. For a pair of individuals with observed IBD data, we want to find the most likely relationship:\n",
    "\n",
    "$$P(R|D) = \\frac{P(D|R) \\cdot P(R)}{P(D)}$$\n",
    "\n",
    "Where:\n",
    "- $P(R|D)$ is the probability of relationship $R$ given the observed IBD data $D$\n",
    "- $P(D|R)$ is the likelihood of observing IBD data $D$ given relationship $R$\n",
    "- $P(R)$ is the prior probability of relationship $R$\n",
    "- $P(D)$ is the probability of the observed IBD data across all possible relationships\n",
    "\n",
    "Since we're comparing different possible relationships for the same IBD data, $P(D)$ is constant and we can focus on:\n",
    "\n",
    "$$P(R|D) \\propto P(D|R) \\cdot P(R)$$\n",
    "\n",
    "Often, we work in log space to avoid numerical issues with very small probabilities:\n",
    "\n",
    "$$\\log P(R|D) \\propto \\log P(D|R) + \\log P(R)$$\n",
    "\n",
    "Let's implement this framework in simplified form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(relationship_tuple):\n",
    "    \"\"\"Calculate the log prior probability of a relationship.\n",
    "    \n",
    "    Args:\n",
    "        relationship_tuple: (up, down, num_ancs) tuple\n",
    "        \n",
    "    Returns:\n",
    "        Log prior probability\n",
    "    \"\"\"\n",
    "    up, down, num_ancs = relationship_tuple\n",
    "    \n",
    "    # Calculate meiotic distance\n",
    "    m = up + down\n",
    "    \n",
    "    # Simple prior model: probability decreases exponentially with meiotic distance\n",
    "    # and is higher for full relationships than half relationships\n",
    "    if m == 0:  # Self\n",
    "        return -10  # Very low prior for self-comparisons\n",
    "    \n",
    "    # Base prior depends on meiotic distance\n",
    "    base_prior = -0.5 * m\n",
    "    \n",
    "    # Adjust for full vs half relationships\n",
    "    if num_ancs == 2:  # Full relationship\n",
    "        base_prior += 0.5  # Boost for full relationships\n",
    "    \n",
    "    # Penalize highly asymmetric relationships (large difference between up and down)\n",
    "    asymmetry_penalty = -0.2 * abs(up - down)\n",
    "    \n",
    "    return base_prior + asymmetry_penalty\n",
    "\n",
    "# Calculate log priors for common relationships\n",
    "priors = [(rel[0], rel[1], log_prior(rel[0])) for rel in relationships]\n",
    "\n",
    "# Convert to DataFrame for easier viewing\n",
    "prior_df = pd.DataFrame([(p[0][0], p[0][1], p[0][2], p[1], p[2], np.exp(p[2])) \n",
    "                         for p in priors],\n",
    "                      columns=['Up', 'Down', 'Num Ancestors', 'Relationship', 'Log Prior', 'Prior'])\n",
    "prior_df['Prior'] = prior_df['Prior'] / prior_df['Prior'].sum()  # Normalize\n",
    "display(prior_df.sort_values('Prior', ascending=False))\n",
    "\n",
    "# Visualize relationship priors\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(prior_df['Relationship'], prior_df['Prior'] * 100)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Prior Probability (%)')\n",
    "plt.title('Prior Probabilities for Different Relationships')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Statistical Moments for IBD Distributions\n",
    "\n",
    "The core of Bonsai's relationship inference algorithm lies in calculating statistical moments for IBD distributions. Let's explore the key moments and how they're calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Lambda Parameter (Segment Length Distribution)\n",
    "\n",
    "The lambda parameter controls the distribution of IBD segment lengths. For a relationship with meiotic distance $m$, the lambda parameter is approximately $\\frac{m}{100}$. This means:\n",
    "\n",
    "- The expected length of IBD segments is $\\frac{100}{m}$ cM\n",
    "- Segments follow an exponential distribution\n",
    "- The probability that a segment exceeds length $x$ is $e^{-\\lambda x} = e^{-\\frac{m}{100}x}$\n",
    "\n",
    "Let's implement a function to calculate lambda values for different relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lambda(relationship_tuple):\n",
    "    \"\"\"Calculate the lambda parameter for a relationship.\n",
    "    \n",
    "    Args:\n",
    "        relationship_tuple: (up, down, num_ancs) tuple\n",
    "        \n",
    "    Returns:\n",
    "        Lambda parameter for segment length distribution\n",
    "    \"\"\"\n",
    "    up, down, num_ancs = relationship_tuple\n",
    "    \n",
    "    # Calculate meiotic distance\n",
    "    m = up + down\n",
    "    \n",
    "    # Handle special case for self-comparison\n",
    "    if m == 0 and num_ancs == 2:  # Self\n",
    "        return 0  # No segments (all DNA is identical)\n",
    "    \n",
    "    # Lambda is meiotic distance / 100\n",
    "    return m / 100\n",
    "\n",
    "# Calculate lambda values for common relationships\n",
    "lambda_values = [(rel[0], rel[1], get_lambda(rel[0]), 100 / (rel[0][0] + rel[0][1]) if rel[0][0] + rel[0][1] > 0 else float('inf')) \n",
    "                 for rel in relationships]\n",
    "\n",
    "# Convert to DataFrame for easier viewing\n",
    "lambda_df = pd.DataFrame([(l[0][0], l[0][1], l[0][2], l[1], l[2], l[3]) \n",
    "                         for l in lambda_values],\n",
    "                       columns=['Up', 'Down', 'Num Ancestors', 'Relationship', 'Lambda', 'Mean Segment Length (cM)'])\n",
    "display(lambda_df)\n",
    "\n",
    "# Visualize lambda values and mean segment lengths\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "bars = plt.bar(lambda_df['Relationship'], lambda_df['Lambda'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Lambda Parameter')\n",
    "plt.title('Lambda Parameters for Different Relationships')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "# Filter out infinite values (self)\n",
    "filtered_df = lambda_df[lambda_df['Mean Segment Length (cM)'] < 1000]\n",
    "bars = plt.bar(filtered_df['Relationship'], filtered_df['Mean Segment Length (cM)'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Mean Segment Length (cM)')\n",
    "plt.title('Expected Mean Segment Lengths for Different Relationships')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Eta Parameter (Segment Count Distribution)\n",
    "\n",
    "The eta parameter controls the expected number of IBD segments for a relationship. It's calculated as:\n",
    "\n",
    "$$\\eta = \\frac{a(rm+c)}{2^{m-1}} \\cdot e^{-\\frac{m \\cdot t}{100}}$$\n",
    "\n",
    "Where:\n",
    "- $a$ is the number of common ancestors (1 for half-relationships, 2 for full relationships)\n",
    "- $r$ is the recombination rate (~34 crossovers per meiosis)\n",
    "- $m$ is the meiotic distance\n",
    "- $c$ is the number of chromosomes (22 autosomes)\n",
    "- $t$ is the minimum detectable segment length\n",
    "\n",
    "Let's implement a function to calculate eta values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eta(relationship_tuple, min_seg_len=7, genome_length=3400):\n",
    "    \"\"\"Calculate the eta parameter (expected number of segments) for a relationship.\n",
    "    \n",
    "    Args:\n",
    "        relationship_tuple: (up, down, num_ancs) tuple\n",
    "        min_seg_len: Minimum detectable segment length (cM)\n",
    "        genome_length: Total genome length (cM)\n",
    "        \n",
    "    Returns:\n",
    "        Eta parameter for segment count distribution\n",
    "    \"\"\"\n",
    "    up, down, num_ancs = relationship_tuple\n",
    "    \n",
    "    # Calculate meiotic distance\n",
    "    m = up + down\n",
    "    \n",
    "    # Number of common ancestors\n",
    "    a = num_ancs\n",
    "    \n",
    "    # Handle special case for self-comparison\n",
    "    if m == 0 and num_ancs == 2:  # Self\n",
    "        return 0  # No segments (all DNA is identical)\n",
    "    \n",
    "    # Parameters\n",
    "    r = genome_length / 100  # Number of recombinations per meiosis (~34)\n",
    "    c = 22  # Number of chromosomes\n",
    "    \n",
    "    # Calculate the base expected number of segments\n",
    "    # eta = a * (r*m + c) / (2^(m-1))\n",
    "    if m <= 1:\n",
    "        base_eta = a * (r * m + c)\n",
    "    else:\n",
    "        base_eta = a * (r * m + c) / (2 ** (m - 1))\n",
    "    \n",
    "    # Probability of a segment exceeding the minimum threshold\n",
    "    p_obs = np.exp(-m * min_seg_len / 100)\n",
    "    \n",
    "    # Final expected segment count\n",
    "    eta = base_eta * p_obs\n",
    "    \n",
    "    return eta\n",
    "\n",
    "# Calculate eta values for common relationships\n",
    "eta_values = [(rel[0], rel[1], get_eta(rel[0])) for rel in relationships]\n",
    "\n",
    "# Convert to DataFrame for easier viewing\n",
    "eta_df = pd.DataFrame([(e[0][0], e[0][1], e[0][2], e[1], e[2]) \n",
    "                      for e in eta_values],\n",
    "                     columns=['Up', 'Down', 'Num Ancestors', 'Relationship', 'Eta (Expected Segments)'])\n",
    "display(eta_df)\n",
    "\n",
    "# Visualize eta values\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(eta_df['Relationship'], eta_df['Eta (Expected Segments)'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Expected Number of Segments')\n",
    "plt.title('Expected Segment Counts for Different Relationships')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Total IBD Sharing\n",
    "\n",
    "The expected total IBD sharing for a relationship is calculated from the eta and lambda parameters. For a relationship with meiotic distance $m$ and expected segment count $\\eta$, the expected total IBD sharing is:\n",
    "\n",
    "$$E[\\text{Total IBD}] = \\eta \\cdot (\\frac{100}{m} + t)$$\n",
    "\n",
    "Where $t$ is the minimum detectable segment length. This formula accounts for the truncation of the exponential distribution at the minimum threshold.\n",
    "\n",
    "Let's implement a function to calculate expected total IBD sharing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_total_ibd(relationship_tuple, min_seg_len=7, genome_length=3400):\n",
    "    \"\"\"Calculate expected total IBD sharing for a relationship.\n",
    "    \n",
    "    Args:\n",
    "        relationship_tuple: (up, down, num_ancs) tuple\n",
    "        min_seg_len: Minimum detectable segment length (cM)\n",
    "        genome_length: Total genome length (cM)\n",
    "        \n",
    "    Returns:\n",
    "        Expected total IBD (cM)\n",
    "    \"\"\"\n",
    "    up, down, num_ancs = relationship_tuple\n",
    "    \n",
    "    # Calculate meiotic distance\n",
    "    m = up + down\n",
    "    \n",
    "    # Handle special case for self-comparison\n",
    "    if m == 0 and num_ancs == 2:  # Self\n",
    "        return genome_length  # All DNA is identical\n",
    "    \n",
    "    # Get expected segment count\n",
    "    eta = get_eta(relationship_tuple, min_seg_len, genome_length)\n",
    "    \n",
    "    # Calculate expected total IBD\n",
    "    # This formula accounts for the truncation of the exponential distribution\n",
    "    if m > 0:\n",
    "        expected_total = eta * (100 / m + min_seg_len)\n",
    "    else:\n",
    "        expected_total = eta * min_seg_len  # Fallback for m=0\n",
    "    \n",
    "    return expected_total\n",
    "\n",
    "# Calculate expected total IBD for common relationships\n",
    "total_ibd_values = [(rel[0], rel[1], get_expected_total_ibd(rel[0])) for rel in relationships]\n",
    "\n",
    "# Convert to DataFrame for easier viewing\n",
    "total_ibd_df = pd.DataFrame([(t[0][0], t[0][1], t[0][2], t[1], t[2], t[2]/3400*100) \n",
    "                           for t in total_ibd_values],\n",
    "                          columns=['Up', 'Down', 'Num Ancestors', 'Relationship', 'Expected Total IBD (cM)', 'Percent of Genome'])\n",
    "display(total_ibd_df.sort_values('Expected Total IBD (cM)', ascending=False))\n",
    "\n",
    "# Visualize expected total IBD\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.bar(total_ibd_df['Relationship'], total_ibd_df['Percent of Genome'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Expected IBD Sharing (% of Genome)')\n",
    "plt.title('Expected Total IBD Sharing for Different Relationships')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add a reference line for the genome length\n",
    "plt.axhline(100, color='red', linestyle='--', alpha=0.7, label='Total Genome')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building Likelihood Functions\n",
    "\n",
    "Now let's build likelihood functions that calculate the probability of observed IBD patterns given different relationships. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Likelihood Function for Segment Count\n",
    "\n",
    "The number of IBD segments follows a Poisson distribution with parameter $\\eta$. The probability of observing $k$ segments given relationship $R$ is:\n",
    "\n",
    "$$P(k|R) = \\frac{\\eta^k e^{-\\eta}}{k!}$$\n",
    "\n",
    "Let's implement this likelihood function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_count_likelihood(observed_count, relationship_tuple, min_seg_len=7, genome_length=3400):\n",
    "    \"\"\"Calculate the likelihood of observing a specific segment count given a relationship.\n",
    "    \n",
    "    Args:\n",
    "        observed_count: Number of observed IBD segments\n",
    "        relationship_tuple: (up, down, num_ancs) tuple\n",
    "        min_seg_len: Minimum detectable segment length (cM)\n",
    "        genome_length: Total genome length (cM)\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood of the observed count\n",
    "    \"\"\"\n",
    "    up, down, num_ancs = relationship_tuple\n",
    "    \n",
    "    # Special case for self-comparison\n",
    "    if up == 0 and down == 0 and num_ancs == 2:  # Self\n",
    "        return 0.0 if observed_count == 0 else float('-inf')\n",
    "    \n",
    "    # Get expected segment count (eta)\n",
    "    eta = get_eta(relationship_tuple, min_seg_len, genome_length)\n",
    "    \n",
    "    # Calculate log-likelihood using Poisson PMF\n",
    "    log_likelihood = stats.poisson.logpmf(observed_count, eta)\n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "# Test the likelihood function with different segment counts\n",
    "test_counts = [5, 10, 20, 30, 40, 50]\n",
    "test_relationships = [\n",
    "    ((0, 1, 1), \"Parent-Child\"),\n",
    "    ((1, 1, 2), \"Full Sibling\"),\n",
    "    ((1, 1, 1), \"Half Sibling\"),\n",
    "    ((2, 2, 2), \"Full First Cousin\")\n",
    "]\n",
    "\n",
    "# Calculate log-likelihoods for each combination\n",
    "likelihood_data = []\n",
    "\n",
    "for count in test_counts:\n",
    "    row_data = {'observed_count': count}\n",
    "    \n",
    "    for rel_tuple, rel_name in test_relationships:\n",
    "        log_ll = segment_count_likelihood(count, rel_tuple)\n",
    "        row_data[rel_name] = log_ll\n",
    "    \n",
    "    likelihood_data.append(row_data)\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "likelihood_df = pd.DataFrame(likelihood_data)\n",
    "display(likelihood_df)\n",
    "\n",
    "# Visualize the likelihood function\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "counts = np.arange(0, 100, 1)\n",
    "for rel_tuple, rel_name in test_relationships:\n",
    "    log_likelihoods = [segment_count_likelihood(c, rel_tuple) for c in counts]\n",
    "    \n",
    "    # Convert to regular likelihoods for better visualization\n",
    "    likelihoods = np.exp(log_likelihoods)\n",
    "    \n",
    "    plt.plot(counts, likelihoods, '-', linewidth=2, label=rel_name)\n",
    "\n",
    "plt.title(\"Likelihood of Observed Segment Counts by Relationship\")\n",
    "plt.xlabel(\"Number of Observed IBD Segments\")\n",
    "plt.ylabel(\"Likelihood\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlim(0, 75)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Likelihood Function for Segment Lengths\n",
    "\n",
    "The distribution of segment lengths provides additional information for relationship inference. For a relationship with meiotic distance $m$, the probability density function for a segment of length $x$ (given that it exceeds the minimum threshold $t$) is:\n",
    "\n",
    "$$f(x|R, x > t) = \\frac{m}{100} e^{-\\frac{m}{100}(x-t)}$$\n",
    "\n",
    "Let's implement this likelihood function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_length_likelihood(observed_lengths, relationship_tuple, min_seg_len=7):\n",
    "    \"\"\"Calculate the likelihood of observing specific segment lengths given a relationship.\n",
    "    \n",
    "    Args:\n",
    "        observed_lengths: List of observed segment lengths (cM)\n",
    "        relationship_tuple: (up, down, num_ancs) tuple\n",
    "        min_seg_len: Minimum detectable segment length (cM)\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood of the observed lengths\n",
    "    \"\"\"\n",
    "    up, down, num_ancs = relationship_tuple\n",
    "    \n",
    "    # Calculate meiotic distance\n",
    "    m = up + down\n",
    "    \n",
    "    # Special case for self-comparison\n",
    "    if m == 0 and num_ancs == 2:  # Self\n",
    "        return 0.0 if not observed_lengths else float('-inf')\n",
    "    \n",
    "    # Calculate rate parameter (lambda)\n",
    "    rate = m / 100\n",
    "    \n",
    "    # Calculate log-likelihood for each segment\n",
    "    log_likelihoods = []\n",
    "    for length in observed_lengths:\n",
    "        # For segments shorter than the minimum threshold, likelihood is zero\n",
    "        if length < min_seg_len:\n",
    "            continue\n",
    "            \n",
    "        # Log-likelihood for this segment using the truncated exponential distribution\n",
    "        log_lik = np.log(rate) - rate * (length - min_seg_len)\n",
    "        log_likelihoods.append(log_lik)\n",
    "    \n",
    "    # Sum log-likelihoods to get total log-likelihood\n",
    "    if log_likelihoods:\n",
    "        return sum(log_likelihoods)\n",
    "    else:\n",
    "        return 0.0  # No segments\n",
    "\n",
    "# Generate synthetic segment lengths for different relationships\n",
    "def generate_segments(relationship_tuple, num_segments=20, min_seg_len=7, seed=None):\n",
    "    \"\"\"Generate synthetic IBD segments for a relationship.\n",
    "    \n",
    "    Args:\n",
    "        relationship_tuple: (up, down, num_ancs) tuple\n",
    "        num_segments: Number of segments to generate\n",
    "        min_seg_len: Minimum segment length (cM)\n",
    "        seed: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        List of segment lengths (cM)\n",
    "    \"\"\"\n",
    "    up, down, num_ancs = relationship_tuple\n",
    "    \n",
    "    # Calculate meiotic distance\n",
    "    m = up + down\n",
    "    \n",
    "    # Set random seed if provided\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Handle special case for self-comparison\n",
    "    if m == 0 and num_ancs == 2:  # Self\n",
    "        return []  # No segments\n",
    "    \n",
    "    # Calculate rate parameter\n",
    "    rate = m / 100\n",
    "    \n",
    "    # Generate segment lengths using truncated exponential distribution\n",
    "    segments = []\n",
    "    for _ in range(num_segments):\n",
    "        # Generate from truncated exponential distribution\n",
    "        # First generate from standard exponential\n",
    "        u = np.random.exponential() / rate\n",
    "        # Then add the minimum threshold\n",
    "        length = u + min_seg_len\n",
    "        segments.append(length)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# Generate segments for different relationships\n",
    "segments_by_relationship = {}\n",
    "for rel_tuple, rel_name in test_relationships:\n",
    "    # Get expected segment count for this relationship\n",
    "    eta = get_eta(rel_tuple)\n",
    "    # Generate roughly the expected number of segments\n",
    "    num_segments = max(1, int(eta) + 1)\n",
    "    segments = generate_segments(rel_tuple, num_segments=num_segments, seed=42+len(segments_by_relationship))\n",
    "    segments_by_relationship[rel_name] = segments\n",
    "\n",
    "# Calculate log-likelihoods for each set of segments against each relationship\n",
    "length_likelihood_data = []\n",
    "\n",
    "for true_rel_name, segments in segments_by_relationship.items():\n",
    "    row_data = {'true_relationship': true_rel_name, 'num_segments': len(segments)}\n",
    "    \n",
    "    for eval_rel_tuple, eval_rel_name in test_relationships:\n",
    "        log_ll = segment_length_likelihood(segments, eval_rel_tuple)\n",
    "        row_data[eval_rel_name] = log_ll\n",
    "    \n",
    "    length_likelihood_data.append(row_data)\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "length_likelihood_df = pd.DataFrame(length_likelihood_data)\n",
    "display(length_likelihood_df)\n",
    "\n",
    "# Visualize the segment length distributions\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for rel_name, segments in segments_by_relationship.items():\n",
    "    if segments:  # Skip if no segments\n",
    "        sns.kdeplot(segments, label=rel_name)\n",
    "\n",
    "plt.title(\"Synthetic IBD Segment Length Distributions by Relationship\")\n",
    "plt.xlabel(\"Segment Length (cM)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlim(0, 200)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Combining Likelihoods: The Get_Log_Seg_PDF Function\n",
    "\n",
    "In Bonsai v3, the `get_log_seg_pdf` function in the moments module combines the likelihoods from segment count and segment lengths into a single likelihood score. Let's implement a simplified version of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_seg_pdf(segments, relationship_tuple, min_seg_len=7, genome_length=3400):\n",
    "    \"\"\"Calculate the log-likelihood of observing a set of segments given a relationship.\n",
    "    \n",
    "    Args:\n",
    "        segments: List of segment lengths (cM)\n",
    "        relationship_tuple: (up, down, num_ancs) tuple\n",
    "        min_seg_len: Minimum detectable segment length (cM)\n",
    "        genome_length: Total genome length (cM)\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood of the observed segments\n",
    "    \"\"\"\n",
    "    # Filter segments below threshold\n",
    "    segments = [s for s in segments if s >= min_seg_len]\n",
    "    \n",
    "    # Get segment count\n",
    "    observed_count = len(segments)\n",
    "    \n",
    "    # Calculate likelihood for segment count\n",
    "    count_log_likelihood = segment_count_likelihood(observed_count, relationship_tuple, min_seg_len, genome_length)\n",
    "    \n",
    "    # Calculate likelihood for segment lengths\n",
    "    length_log_likelihood = segment_length_likelihood(segments, relationship_tuple, min_seg_len)\n",
    "    \n",
    "    # Combine likelihoods\n",
    "    # In this simplified version, we give equal weight to count and length likelihoods\n",
    "    combined_log_likelihood = count_log_likelihood + length_log_likelihood\n",
    "    \n",
    "    return combined_log_likelihood\n",
    "\n",
    "# Calculate combined log-likelihoods for each set of segments against each relationship\n",
    "combined_likelihood_data = []\n",
    "\n",
    "for true_rel_name, segments in segments_by_relationship.items():\n",
    "    row_data = {'true_relationship': true_rel_name, 'num_segments': len(segments)}\n",
    "    \n",
    "    for eval_rel_tuple, eval_rel_name in test_relationships:\n",
    "        log_ll = get_log_seg_pdf(segments, eval_rel_tuple)\n",
    "        row_data[eval_rel_name] = log_ll\n",
    "    \n",
    "    combined_likelihood_data.append(row_data)\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "combined_likelihood_df = pd.DataFrame(combined_likelihood_data)\n",
    "display(combined_likelihood_df)\n",
    "\n",
    "# For each set of segments, highlight the most likely relationship\n",
    "for i, row in combined_likelihood_df.iterrows():\n",
    "    true_rel = row['true_relationship']\n",
    "    \n",
    "    # Extract log-likelihoods for each relationship\n",
    "    rel_log_lls = [(rel, row[rel]) for rel in [r[1] for r in test_relationships]]\n",
    "    \n",
    "    # Sort by log-likelihood (highest first)\n",
    "    rel_log_lls.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_rel, top_log_ll = rel_log_lls[0]\n",
    "    \n",
    "    print(f\"True relationship: {true_rel}\")\n",
    "    print(f\"Most likely relationship: {top_rel} (log-likelihood = {top_log_ll:.2f})\")\n",
    "    \n",
    "    # Calculate evidence ratio (Bayes factor) between top and second relationships\n",
    "    if len(rel_log_lls) > 1:\n",
    "        second_rel, second_log_ll = rel_log_lls[1]\n",
    "        evidence_ratio = np.exp(top_log_ll - second_log_ll)\n",
    "        print(f\"Evidence ratio vs. second-best ({second_rel}): {evidence_ratio:.2f}x\")\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Handling Uncertainty and Stochasticity\n",
    "\n",
    "One of the key challenges in genetic relationship inference is handling the inherent stochasticity of genetic inheritance. Let's explore how stochasticity affects relationship inference and how Bonsai v3 addresses this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Simulating IBD Segment Patterns\n",
    "\n",
    "Let's generate multiple simulations of IBD segment patterns for different relationships to understand the variability in IBD sharing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ibd_data(relationship_tuple, num_simulations=100, min_seg_len=7, genome_length=3400):\n",
    "    \"\"\"Simulate IBD segment data for a relationship.\n",
    "    \n",
    "    Args:\n",
    "        relationship_tuple: (up, down, num_ancs) tuple\n",
    "        num_simulations: Number of simulations to generate\n",
    "        min_seg_len: Minimum detectable segment length (cM)\n",
    "        genome_length: Total genome length (cM)\n",
    "        \n",
    "    Returns:\n",
    "        List of simulated segment sets\n",
    "    \"\"\"\n",
    "    # Calculate expected segment count (eta)\n",
    "    eta = get_eta(relationship_tuple, min_seg_len, genome_length)\n",
    "    \n",
    "    simulations = []\n",
    "    for i in range(num_simulations):\n",
    "        # Generate random segment count from Poisson distribution\n",
    "        segment_count = np.random.poisson(eta)\n",
    "        \n",
    "        # Generate segment lengths\n",
    "        segments = generate_segments(relationship_tuple, num_segments=segment_count, min_seg_len=min_seg_len, seed=i)\n",
    "        \n",
    "        simulations.append(segments)\n",
    "    \n",
    "    return simulations\n",
    "\n",
    "# Simulate IBD data for different relationships\n",
    "simulation_results = {}\n",
    "for rel_tuple, rel_name in test_relationships:\n",
    "    simulations = simulate_ibd_data(rel_tuple, num_simulations=100)\n",
    "    simulation_results[rel_name] = simulations\n",
    "\n",
    "# Calculate statistics for each set of simulations\n",
    "simulation_stats = []\n",
    "\n",
    "for rel_name, simulations in simulation_results.items():\n",
    "    # Calculate statistics across simulations\n",
    "    segment_counts = [len(sim) for sim in simulations]\n",
    "    total_lengths = [sum(sim) if sim else 0 for sim in simulations]\n",
    "    \n",
    "    simulation_stats.append({\n",
    "        'relationship': rel_name,\n",
    "        'mean_segment_count': np.mean(segment_counts),\n",
    "        'std_segment_count': np.std(segment_counts),\n",
    "        'mean_total_length': np.mean(total_lengths),\n",
    "        'std_total_length': np.std(total_lengths),\n",
    "        'cv_total_length': np.std(total_lengths) / np.mean(total_lengths) if np.mean(total_lengths) > 0 else 0\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "simulation_stats_df = pd.DataFrame(simulation_stats)\n",
    "display(simulation_stats_df)\n",
    "\n",
    "# Visualize the distribution of total IBD sharing\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for rel_name, simulations in simulation_results.items():\n",
    "    # Calculate total length for each simulation\n",
    "    total_lengths = [sum(sim) if sim else 0 for sim in simulations]\n",
    "    \n",
    "    # Plot distribution\n",
    "    sns.kdeplot(total_lengths, label=rel_name)\n",
    "\n",
    "plt.title(\"Distribution of Total IBD Sharing by Relationship\")\n",
    "plt.xlabel(\"Total IBD (cM)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Impact of Stochasticity on Relationship Inference\n",
    "\n",
    "Let's assess how often the correct relationship is inferred given the stochasticity of IBD sharing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_relationship(segments, relationship_options):\n",
    "    \"\"\"Infer the most likely relationship from a set of segments.\n",
    "    \n",
    "    Args:\n",
    "        segments: List of segment lengths (cM)\n",
    "        relationship_options: List of (tuple, name) pairs for possible relationships\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (most likely relationship tuple, relationship name, log-likelihood)\n",
    "    \"\"\"\n",
    "    # Calculate log-likelihood for each relationship\n",
    "    log_likelihoods = []\n",
    "    for rel_tuple, rel_name in relationship_options:\n",
    "        log_ll = get_log_seg_pdf(segments, rel_tuple)\n",
    "        log_likelihoods.append((rel_tuple, rel_name, log_ll))\n",
    "    \n",
    "    # Sort by log-likelihood (highest first)\n",
    "    log_likelihoods.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # Return the most likely relationship\n",
    "    return log_likelihoods[0]\n",
    "\n",
    "# Assess relationship inference accuracy\n",
    "accuracy_results = []\n",
    "\n",
    "for true_rel_tuple, true_rel_name in test_relationships:\n",
    "    # Get simulations for this relationship\n",
    "    simulations = simulation_results[true_rel_name]\n",
    "    \n",
    "    # Count correct inferences\n",
    "    correct_count = 0\n",
    "    confusion_counts = defaultdict(int)\n",
    "    \n",
    "    for segments in simulations:\n",
    "        # Infer relationship\n",
    "        inferred_tuple, inferred_name, log_ll = infer_relationship(segments, test_relationships)\n",
    "        \n",
    "        # Check if correct\n",
    "        if inferred_tuple == true_rel_tuple:\n",
    "            correct_count += 1\n",
    "        else:\n",
    "            confusion_counts[inferred_name] += 1\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_count / len(simulations)\n",
    "    \n",
    "    # Find the most common confusion\n",
    "    most_confused = max(confusion_counts.items(), key=lambda x: x[1]) if confusion_counts else (\"None\", 0)\n",
    "    \n",
    "    accuracy_results.append({\n",
    "        'true_relationship': true_rel_name,\n",
    "        'accuracy': accuracy,\n",
    "        'most_confused_with': most_confused[0],\n",
    "        'confusion_rate': most_confused[1] / len(simulations)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "accuracy_df = pd.DataFrame(accuracy_results)\n",
    "display(accuracy_df)\n",
    "\n",
    "# Visualize accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(accuracy_df['true_relationship'], accuracy_df['accuracy'] * 100)\n",
    "plt.xlabel('True Relationship')\n",
    "plt.ylabel('Inference Accuracy (%)')\n",
    "plt.title('Relationship Inference Accuracy')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add accuracy labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{height:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "# Add confusion information\n",
    "for i, row in accuracy_df.iterrows():\n",
    "    if row['confusion_rate'] > 0:\n",
    "        plt.text(i, row['accuracy'] * 100 / 2,\n",
    "                 f\"Confused with\\n{row['most_confused_with']}\\n({row['confusion_rate']*100:.1f}%)\",\n",
    "                 ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "plt.ylim(0, 105)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Strategies for Handling Uncertainty\n",
    "\n",
    "Given the stochasticity in IBD sharing, Bonsai v3 uses several strategies to handle uncertainty in relationship inference:\n",
    "\n",
    "1. **Likelihood Ratios**: Compare the likelihood of the top relationship to alternatives\n",
    "2. **Confidence Intervals**: Report uncertainty in relationship estimates\n",
    "3. **Integration with Age Data**: Use demographic information to resolve ambiguity\n",
    "4. **Multiple Relationship Paths**: Consider all possible ways individuals might be related\n",
    "\n",
    "Let's implement a simplified version of the likelihood ratio approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood_ratios(segments, relationship_options):\n",
    "    \"\"\"Calculate likelihood ratios for different relationships.\n",
    "    \n",
    "    Args:\n",
    "        segments: List of segment lengths (cM)\n",
    "        relationship_options: List of (tuple, name) pairs for possible relationships\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with likelihood ratios\n",
    "    \"\"\"\n",
    "    # Calculate log-likelihood for each relationship\n",
    "    log_likelihoods = []\n",
    "    for rel_tuple, rel_name in relationship_options:\n",
    "        log_ll = get_log_seg_pdf(segments, rel_tuple)\n",
    "        log_likelihoods.append((rel_tuple, rel_name, log_ll))\n",
    "    \n",
    "    # Sort by log-likelihood (highest first)\n",
    "    log_likelihoods.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # Calculate likelihood ratios\n",
    "    top_log_ll = log_likelihoods[0][2]\n",
    "    \n",
    "    likelihood_ratios = []\n",
    "    for rel_tuple, rel_name, log_ll in log_likelihoods:\n",
    "        # Calculate likelihood ratio vs. top relationship\n",
    "        likelihood_ratio = np.exp(log_ll - top_log_ll)\n",
    "        \n",
    "        likelihood_ratios.append({\n",
    "            'relationship': rel_name,\n",
    "            'log_likelihood': log_ll,\n",
    "            'likelihood_ratio': likelihood_ratio\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(likelihood_ratios)\n",
    "\n",
    "# Create a test case with ambiguous relationship\n",
    "# Generate segments from a half-sibling with a high number to create ambiguity\n",
    "ambiguous_segments = generate_segments((1, 1, 1), num_segments=40, seed=200)\n",
    "\n",
    "# Calculate likelihood ratios\n",
    "likelihood_ratios_df = calculate_likelihood_ratios(ambiguous_segments, test_relationships)\n",
    "display(likelihood_ratios_df)\n",
    "\n",
    "# Visualize likelihood ratios\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(likelihood_ratios_df['relationship'], likelihood_ratios_df['likelihood_ratio'])\n",
    "plt.xlabel('Relationship')\n",
    "plt.ylabel('Likelihood Ratio')\n",
    "plt.title('Likelihood Ratios for Possible Relationships')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add likelihood ratio labels\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we've explored the probabilistic relationship inference methods used in Bonsai v3. Key takeaways include:\n",
    "\n",
    "1. **Relationship Representation**: Bonsai v3 uses a tuple representation for relationships, which captures the genealogical structure, meiotic distance, and number of common ancestors.\n",
    "\n",
    "2. **Statistical Moments**: Three key parameters characterize IBD distributions for different relationships: lambda (segment length distribution), eta (expected segment count), and total IBD sharing.\n",
    "\n",
    "3. **Likelihood Functions**: Bonsai v3 builds likelihood functions to calculate the probability of observed IBD patterns given different relationships, combining evidence from segment counts and lengths.\n",
    "\n",
    "4. **Handling Stochasticity**: Due to the random nature of genetic inheritance, relationship inference includes quantifying uncertainty through likelihood ratios and confidence intervals.\n",
    "\n",
    "5. **Bayesian Framework**: The relationship inference process follows a Bayesian framework, combining likelihoods with priors to calculate posterior probabilities for different relationships.\n",
    "\n",
    "These probabilistic methods allow Bonsai v3 to make robust inferences about relationships from IBD data, providing the foundation for pedigree reconstruction even with incomplete and noisy genetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this notebook to PDF using poetry\n",
    "!poetry run jupyter nbconvert --to pdf Lab04_IBD_Statistics_Extraction.ipynb\n",
    "\n",
    "# Note: PDF conversion requires LaTeX to be installed on your system\n",
    "# If you encounter errors, you may need to install it:\n",
    "# On Ubuntu/Debian: sudo apt-get install texlive-xetex\n",
    "# On macOS with Homebrew: brew install texlive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}