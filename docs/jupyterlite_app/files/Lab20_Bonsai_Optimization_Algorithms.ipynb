{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 20: Optimization Algorithms in Bonsai\n",
    "\n",
    "In this lab, we'll explore the optimization algorithms and techniques that power Bonsai's pedigree reconstruction capabilities. Building on our understanding of Bonsai's architecture, data quality, and multi-sample inference from previous labs, we'll now focus on how Bonsai efficiently searches through the vast space of possible pedigree configurations to find optimal solutions.\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Pedigree reconstruction is fundamentally a complex optimization problem. The number of possible pedigree configurations grows exponentially with the number of individuals, making exhaustive search impossible for all but the simplest cases. Effective optimization techniques are therefore critical for:\n",
    "- Efficiently exploring the space of possible pedigrees\n",
    "- Avoiding getting stuck in local optima\n",
    "- Balancing multiple competing objectives and constraints\n",
    "- Scaling to large datasets with hundreds or thousands of individuals\n",
    "- Providing confidence estimates for the reconstructed relationships\n",
    "\n",
    "**Learning Objectives**:\n",
    "- Understand the optimization challenges in pedigree reconstruction\n",
    "- Implement key optimization algorithms used in Bonsai\n",
    "- Compare different search strategies for pedigree space exploration\n",
    "- Develop heuristics to guide the optimization process\n",
    "- Create visualization tools to track optimization progress\n",
    "- Apply these techniques to complex pedigree reconstruction problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install --no-root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "import sys\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy import stats\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup for cross-compatibility\n",
    "from scripts_support.lab_cross_compatibility import setup_environment, is_jupyterlite\n\n",
    "# Set up environment-specific paths\n",
    "DATA_DIR, RESULTS_DIR = setup_environment()\n\n",
    "# Now you can use DATA_DIR and RESULTS_DIR consistently across environments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the Optimization Challenge\n",
    "\n",
    "Before diving into specific algorithms, let's first understand the nature of the optimization problem in pedigree reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The Pedigree Reconstruction Search Space\n",
    "\n",
    "The search space for pedigree reconstruction is vast and complex:\n",
    "\n",
    "1. **Size of the search space**: For n individuals, there are 2^(n\u00b2) possible pedigree configurations if we consider only whether each pair has a parent-child relationship.\n",
    "\n",
    "2. **Multiple relationship types**: When we consider different relationship types (sibling, grandparent, cousin, etc.), the space grows even larger.\n",
    "\n",
    "3. **Constraints**: Valid pedigrees must satisfy numerous biological and logical constraints (e.g., no cycles, consistent birth years, etc.).\n",
    "\n",
    "4. **Uncertain data**: IBD segments have measurement errors and inference uncertainties that complicate the optimization.\n",
    "\n",
    "5. **Missing information**: Many real-world pedigrees have missing individuals or incomplete data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The Objective Function\n",
    "\n",
    "Bonsai uses a likelihood-based objective function to evaluate pedigree configurations:\n",
    "\n",
    "1. **IBD likelihood**: How well does the pedigree explain the observed IBD segment data?\n",
    "\n",
    "2. **Prior probabilities**: Incorporating demographic and historical information as priors.\n",
    "\n",
    "3. **Constraint penalties**: Penalties for violating biological or logical constraints.\n",
    "\n",
    "4. **Complexity penalty**: Preference for simpler pedigrees (Occam's razor).\n",
    "\n",
    "The overall objective is to maximize the posterior probability of the pedigree given the observed data, which balances these components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Optimization Challenges\n",
    "\n",
    "Several challenges make this optimization problem particularly difficult:\n",
    "\n",
    "1. **Non-convexity**: The objective function has many local optima.\n",
    "\n",
    "2. **Discrete variables**: The relationships are discrete (present/absent), not continuous.\n",
    "\n",
    "3. **High dimensionality**: Real-world problems involve many individuals and relationships.\n",
    "\n",
    "4. **Interdependence**: Changing one relationship affects many others.\n",
    "\n",
    "5. **Complex constraints**: The many constraints on valid pedigrees create a complex feasible region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the size of the search space\n",
    "def calculate_search_space_size(n_individuals, n_relationship_types=1):\n",
    "    \"\"\"Calculate the size of the pedigree search space.\n",
    "    \n",
    "    Args:\n",
    "        n_individuals: Number of individuals\n",
    "        n_relationship_types: Number of possible relationship types\n",
    "        \n",
    "    Returns:\n",
    "        Size of the search space\n",
    "    \"\"\"\n",
    "    # For each directed pair, we have n_relationship_types + 1 possibilities (including no relationship)\n",
    "    directed_pairs = n_individuals * (n_individuals - 1)\n",
    "    # The size is (n_relationship_types + 1) ^ directed_pairs\n",
    "    space_size = (n_relationship_types + 1) ** directed_pairs\n",
    "    return space_size\n",
    "\n",
    "# Calculate and display search space sizes for different numbers of individuals\n",
    "individuals_range = range(2, 11)\n",
    "space_sizes_1_rel = [calculate_search_space_size(n, 1) for n in individuals_range]\n",
    "space_sizes_3_rel = [calculate_search_space_size(n, 3) for n in individuals_range]\n",
    "\n",
    "# Create a table to display the results\n",
    "search_space_df = pd.DataFrame({\n",
    "    'Number of Individuals': list(individuals_range),\n",
    "    'Number of Directed Pairs': [n * (n - 1) for n in individuals_range],\n",
    "    'Search Space Size (1 relationship type)': space_sizes_1_rel,\n",
    "    'Search Space Size (3 relationship types)': space_sizes_3_rel\n",
    "})\n",
    "\n",
    "# Format large numbers\n",
    "search_space_df['Search Space Size (1 relationship type)'] = search_space_df['Search Space Size (1 relationship type)'].apply(\n",
    "    lambda x: f\"{x:.2e}\" if x > 1e10 else f\"{x:,}\"\n",
    ")\n",
    "search_space_df['Search Space Size (3 relationship types)'] = search_space_df['Search Space Size (3 relationship types)'].apply(\n",
    "    lambda x: f\"{x:.2e}\" if x > 1e10 else f\"{x:,}\"\n",
    ")\n",
    "\n",
    "# Display the table\n",
    "display(search_space_df)\n",
    "\n",
    "# Plot the search space size on a log scale\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(individuals_range, space_sizes_1_rel, 'o-', label='1 relationship type')\n",
    "plt.semilogy(individuals_range, space_sizes_3_rel, 's-', label='3 relationship types')\n",
    "plt.xlabel('Number of Individuals')\n",
    "plt.ylabel('Search Space Size (log scale)')\n",
    "plt.title('Exponential Growth of Pedigree Search Space')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.xticks(individuals_range)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate some reference points for context\n",
    "print(\"For comparison:\")\n",
    "print(f\"Number of atoms in the universe: ~10^80\")\n",
    "print(f\"Search space size for 10 individuals (3 relationship types): ~{space_sizes_3_rel[-1]:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Optimization Algorithms in Bonsai\n",
    "\n",
    "Bonsai employs several optimization algorithms to navigate the complex search space efficiently. Let's implement and explore these algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Greedy Incremental Construction\n",
    "\n",
    "One of the foundational approaches in Bonsai is greedy incremental construction, which builds the pedigree step by step, adding the most confident relationships first."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's first import the Pedigree class we developed in the previous lab\n# This is a simplified version for this notebook\n\nclass Pedigree:\n    \"\"\"A class to represent and manipulate pedigree structures.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize an empty pedigree.\"\"\"\n        # Use a directed graph to represent parent->child relationships\n        self.graph = nx.DiGraph()\n        \n        # Keep track of individuals by ID\n        self.individuals = {}\n        \n        # Dictionary to track added relationships for quick lookup\n        self.relationships = {}\n    \n    def add_individual(self, id, **attributes):\n        \"\"\"\n        Add an individual to the pedigree.\n        \n        Args:\n            id: Unique identifier for the individual\n            **attributes: Additional attributes (birth_year, sex, etc.)\n            \n        Returns:\n            bool: True if added successfully, False if individual already exists\n        \"\"\"\n        if id in self.individuals:\n            return False\n        \n        # Add to graph\n        self.graph.add_node(id, **attributes)\n        \n        # Store in individuals dictionary\n        self.individuals[id] = attributes\n        \n        return True\n    \n    def add_relationship(self, parent_id, child_id, certainty=1.0, **attributes):\n        \"\"\"\n        Add a parent-child relationship to the pedigree.\n        \n        Args:\n            parent_id: ID of the parent\n            child_id: ID of the child\n            certainty: Confidence score for this relationship (0.0 to 1.0)\n            **attributes: Additional attributes for the relationship\n            \n        Returns:\n            bool: True if added successfully, False otherwise\n        \"\"\"\n        # Check if both individuals exist\n        if parent_id not in self.individuals or child_id not in self.individuals:\n            return False\n        \n        # Check for impossible relationships (e.g., child as a parent)\n        if self.would_create_cycle(parent_id, child_id):\n            return False\n        \n        # Add relationship to graph\n        self.graph.add_edge(parent_id, child_id, certainty=certainty, **attributes)\n        \n        # Store relationship in dictionary for quick lookup\n        rel_key = (parent_id, child_id)\n        self.relationships[rel_key] = {'certainty': certainty, **attributes}\n        \n        return True\n    \n    def would_create_cycle(self, parent_id, child_id):\n        \"\"\"\n        Check if adding parent_id as a parent of child_id would create a cycle.\n        \n        Args:\n            parent_id: Proposed parent\n            child_id: Proposed child\n            \n        Returns:\n            bool: True if this would create a cycle, False otherwise\n        \"\"\"\n        # If child is already an ancestor of parent, this would create a cycle\n        try:\n            path = nx.shortest_path(self.graph, child_id, parent_id)\n            return len(path) > 0\n        except nx.NetworkXNoPath:\n            return False\n    \n    def is_consistent(self):\n        \"\"\"\n        Check if the pedigree is biologically and logically consistent.\n        \n        Returns:\n            bool: True if consistent, False otherwise\n        \"\"\"\n        # Check for cycles (impossible in a real pedigree)\n        if not nx.is_directed_acyclic_graph(self.graph):\n            return False\n        \n        # Check birth year consistency (parents should be older than children)\n        for parent, child in self.graph.edges():\n            if 'birth_year' in self.individuals[parent] and 'birth_year' in self.individuals[child]:\n                parent_birth = self.individuals[parent]['birth_year']\n                child_birth = self.individuals[child]['birth_year']\n                \n                if parent_birth >= child_birth:\n                    return False\n        \n        # All checks passed\n        return True\n    \n    def assign_generations(self):\n        \"\"\"\n        Assign generation numbers to all individuals in the pedigree.\n        \n        Generation 0 is assigned to roots (individuals without parents).\n        Children are assigned generation numbers incremented from their parents.\n        \n        Returns:\n            dict: Mapping of individual IDs to generation numbers\n        \"\"\"\n        # Find roots (individuals without parents)\n        roots = [node for node in self.graph.nodes() if self.graph.in_degree(node) == 0]\n        \n        generations = {}\n        \n        # Assign generation 0 to roots\n        for root in roots:\n            generations[root] = 0\n        \n        # Process all nodes in topological order (parents before children)\n        for node in nx.topological_sort(self.graph):\n            # If this node is a root, it's already assigned\n            if node in generations:\n                continue\n            \n            # Get parents' generations\n            parents = list(self.graph.predecessors(node))\n            if parents:\n                # Assign generation one more than the maximum parent generation\n                parent_generations = [generations.get(parent, 0) for parent in parents]\n                generations[node] = max(parent_generations) + 1\n            else:\n                # No parents (but not a root), assign generation 0\n                generations[node] = 0\n        \n        return generations\n    \n    def visualize(self, highlight_nodes=None, node_labels=True, figsize=(12, 8)):\n        \"\"\"\n        Visualize the pedigree.\n        \n        Args:\n            highlight_nodes: List of node IDs to highlight\n            node_labels: Whether to show node labels\n            figsize: Figure size tuple\n            \n        Returns:\n            matplotlib figure\n        \"\"\"\n        # Create figure\n        plt.figure(figsize=figsize)\n        \n        if not self.graph.nodes():\n            plt.text(0.5, 0.5, \"Empty Pedigree\", ha='center', va='center')\n            plt.axis('off')\n            return plt.gcf()\n        \n        # Assign generations\n        generations = self.assign_generations()\n        \n        # Create a position layout based on generations (older generations at the top)\n        pos = nx.spring_layout(self.graph, seed=42)\n        \n        # Adjust y position based on generation\n        max_gen = max(generations.values()) if generations else 0\n        for node in self.graph.nodes():\n            gen = generations.get(node, 0)\n            # Normalize to 0-1 range with oldest at the top\n            norm_gen = 1 - (gen / max(1, max_gen))\n            pos[node] = (pos[node][0], 0.8 * norm_gen + 0.1)\n        \n        # Node colors based on generation\n        num_generations = max_gen + 1\n        cmap = plt.cm.viridis\n        node_colors = [cmap(generations.get(node, 0) / max(1, max_gen)) for node in self.graph.nodes()]\n        \n        # Draw nodes\n        nx.draw_networkx_nodes(self.graph, pos, node_color=node_colors, \n                              node_size=500, alpha=0.8)\n        \n        # Highlight specific nodes if provided\n        if highlight_nodes:\n            highlight_nodes = [n for n in highlight_nodes if n in self.graph.nodes()]\n            if highlight_nodes:\n                nx.draw_networkx_nodes(self.graph.subgraph(highlight_nodes), pos, \n                                      node_color='red', node_size=600, alpha=0.8)\n        \n        # Draw edges with certainty-based alpha\n        edge_alphas = [self.relationships.get((u, v), {}).get('certainty', 1.0) for u, v in self.graph.edges()]\n        for i, (u, v) in enumerate(self.graph.edges()):\n            # Draw edges with alpha based on certainty\n            alpha = edge_alphas[i]\n            nx.draw_networkx_edges(self.graph, pos, edgelist=[(u, v)], \n                                 width=1.5, alpha=alpha, arrows=True, \n                                 arrowsize=20, arrowstyle='-|>')\n        \n        # Add labels\n        if node_labels:\n            labels = {}\n            for node in self.graph.nodes():\n                label_parts = [str(node)]\n                if 'birth_year' in self.individuals[node]:\n                    label_parts.append(f\"({self.individuals[node]['birth_year']})\")\n                labels[node] = \"\\n\".join(label_parts)\n            \n            nx.draw_networkx_labels(self.graph, pos, labels=labels, font_size=10)\n        \n        plt.title('Pedigree Visualization', size=15)\n        plt.axis('off')\n        plt.tight_layout()\n        \n        return plt.gcf()\n    \n    def copy(self):\n        \"\"\"Create a deep copy of this pedigree.\"\"\"\n        new_pedigree = Pedigree()\n        \n        # Copy individuals\n        for ind_id, attrs in self.individuals.items():\n            new_pedigree.add_individual(ind_id, **attrs.copy())\n        \n        # Copy relationships\n        for parent, child in self.graph.edges():\n            attrs = self.graph.edges[parent, child].copy()\n            certainty = attrs.pop('certainty', 1.0)\n            new_pedigree.add_relationship(parent, child, certainty=certainty, **attrs)\n        \n        return new_pedigree\n    \n    def __eq__(self, other):\n        \"\"\"Check if two pedigrees are equal.\"\"\"\n        if not isinstance(other, Pedigree):\n            return False\n        \n        # Check if they have the same individuals\n        if set(self.individuals.keys()) != set(other.individuals.keys()):\n            return False\n        \n        # Check if they have the same edges\n        if set(self.graph.edges()) != set(other.graph.edges()):\n            return False\n        \n        return True\n    \n    def score(self, ibd_data, missing_penalty=0.1, extra_penalty=0.2):\n        \"\"\"\n        Score the pedigree against IBD data.\n        \n        Args:\n            ibd_data: DataFrame with IBD segment data\n            missing_penalty: Penalty for missing relationships\n            extra_penalty: Penalty for extra relationships\n            \n        Returns:\n            float: Score (higher is better)\n        \"\"\"\n        # Extract pairs with IBD from data\n        ibd_pairs = set()\n        ibd_values = {}\n        \n        for _, row in ibd_data.iterrows():\n            pair = (row['sample1'], row['sample2'])\n            ibd_pairs.add(pair)\n            # Store total IBD by pair\n            if pair in ibd_values:\n                ibd_values[pair] += row['gen_seg_len']\n            else:\n                ibd_values[pair] = row['gen_seg_len']\n        \n        # Extract relationships from pedigree\n        pedigree_pairs = set()\n        for i in self.individuals:\n            for j in self.individuals:\n                if i == j:\n                    continue\n                # Check if there's a path from i to j\n                try:\n                    if nx.has_path(self.graph, i, j) or nx.has_path(self.graph, j, i):\n                        pedigree_pairs.add((i, j))\n                except:\n                    pass\n        \n        # Calculate score components\n        correct_pairs = ibd_pairs.intersection(pedigree_pairs)\n        missing_pairs = ibd_pairs - pedigree_pairs\n        extra_pairs = pedigree_pairs - ibd_pairs\n        \n        # Simple scoring model\n        score = len(correct_pairs) - missing_penalty * len(missing_pairs) - extra_penalty * len(extra_pairs)\n        \n        return score\n\n# Now, let's implement the greedy incremental construction algorithm\nclass GreedyPedigreeBuilder:\n    \"\"\"\n    A class for incrementally building pedigrees using a greedy approach.\n    \"\"\"\n    \n    def __init__(self, segments_df, individuals_metadata=None):\n        \"\"\"\n        Initialize the builder with IBD data.\n        \n        Args:\n            segments_df: DataFrame with IBD segments (must have columns: sample1, sample2, gen_seg_len)\n            individuals_metadata: Optional DataFrame with metadata about individuals\n        \"\"\"\n        self.segments_df = segments_df\n        self.individuals_metadata = individuals_metadata\n        self.pedigree = Pedigree()\n        \n        # Initialize by adding all individuals\n        self._add_individuals()\n        \n        # Calculate total IBD sharing between each pair\n        self.pair_sharing = self._calculate_pair_sharing()\n        \n        # Build relationship candidates\n        self.candidates = self._build_relationship_candidates()\n    \n    def _add_individuals(self):\n        \"\"\"Add all individuals from the segment data to the pedigree.\"\"\"\n        # Extract all unique individuals\n        all_individuals = set(self.segments_df['sample1']).union(set(self.segments_df['sample2']))\n        \n        for ind_id in all_individuals:\n            # Get metadata for this individual if available\n            metadata = {}\n            if self.individuals_metadata is not None:\n                match = self.individuals_metadata[self.individuals_metadata['id'] == ind_id]\n                if len(match) > 0:\n                    metadata = match.iloc[0].to_dict()\n            \n            # Add individual to pedigree\n            self.pedigree.add_individual(ind_id, **metadata)\n    \n    def _calculate_pair_sharing(self):\n        \"\"\"Calculate total IBD sharing for each pair.\"\"\"\n        # Group by pairs and sum segment lengths\n        pair_sharing = self.segments_df.groupby(['sample1', 'sample2'])['gen_seg_len'].agg(['sum', 'count']).reset_index()\n        return pair_sharing\n    \n    def _build_relationship_candidates(self):\n        \"\"\"\n        Build a list of potential relationship candidates.\n        \n        Returns:\n            list: List of (sample1, sample2, relationship_type, certainty) tuples\n        \"\"\"\n        candidates = []\n        \n        for _, row in self.pair_sharing.iterrows():\n            sample1 = row['sample1']\n            sample2 = row['sample2']\n            total_cm = row['sum']\n            \n            # Determine relationship type and certainty based on total_cm\n            # This is a simplified model and would be more sophisticated in a real implementation\n            \n            # Parent-child: ~3400 cM\n            if 3000 <= total_cm <= 3720:\n                rel_type = 'parent-child'\n                # Higher certainty for values closer to the expected mean\n                certainty = 1.0 - abs(3400 - total_cm) / 400\n                candidates.append((sample1, sample2, rel_type, certainty))\n            \n            # Full sibling: ~2550 cM\n            elif 2200 <= total_cm < 3000:\n                rel_type = 'full-sibling'\n                certainty = 1.0 - abs(2550 - total_cm) / 350\n                candidates.append((sample1, sample2, rel_type, certainty))\n            \n            # Half-sibling/grandparent/avuncular: ~1700 cM\n            elif 1450 <= total_cm < 2200:\n                # These are ambiguous without additional information\n                # We'll add all possibilities with different certainties\n                certainty_base = 1.0 - abs(1700 - total_cm) / 250\n                \n                # Try to disambiguate based on birth years if available\n                p1_birth = self.pedigree.individuals[sample1].get('birth_year')\n                p2_birth = self.pedigree.individuals[sample2].get('birth_year')\n                \n                if p1_birth is not None and p2_birth is not None:\n                    year_diff = abs(p1_birth - p2_birth)\n                    \n                    if year_diff < 15:\n                        # Likely half-siblings\n                        candidates.append((sample1, sample2, 'half-sibling', certainty_base * 0.9))\n                    elif 15 <= year_diff <= 30:\n                        # Could be avuncular (aunt/uncle - niece/nephew)\n                        candidates.append((sample1, sample2, 'avuncular', certainty_base * 0.8))\n                    elif year_diff > 30:\n                        # Likely grandparent-grandchild\n                        # Determine direction based on birth years\n                        if p1_birth < p2_birth:\n                            candidates.append((sample1, sample2, 'grandparent-grandchild', certainty_base * 0.9))\n                        else:\n                            candidates.append((sample2, sample1, 'grandparent-grandchild', certainty_base * 0.9))\n                else:\n                    # Without birth years, add all possibilities with lower certainty\n                    candidates.append((sample1, sample2, 'half-sibling', certainty_base * 0.6))\n                    candidates.append((sample1, sample2, 'avuncular', certainty_base * 0.5))\n                    candidates.append((sample1, sample2, 'grandparent-grandchild', certainty_base * 0.4))\n            \n            # First cousin: ~850 cM\n            elif 550 <= total_cm < 1450:\n                rel_type = 'first-cousin'\n                certainty = 1.0 - abs(850 - total_cm) / 300\n                candidates.append((sample1, sample2, rel_type, certainty))\n            \n            # More distant relationships with lower certainty\n            elif 200 <= total_cm < 550:\n                certainty = 0.5\n                candidates.append((sample1, sample2, 'distant', certainty))\n        \n        # Sort candidates by certainty (highest first)\n        candidates.sort(key=lambda x: x[3], reverse=True)\n        \n        return candidates\n    \n    def build_pedigree(self, max_iterations=None, min_certainty=0.3):\n        \"\"\"\n        Build the pedigree using a greedy approach.\n        \n        Args:\n            max_iterations: Maximum number of iterations (relationships to add)\n            min_certainty: Minimum certainty threshold for relationships\n            \n        Returns:\n            Pedigree: The constructed pedigree\n        \"\"\"\n        # Track metrics\n        metrics = {\n            'iterations': 0,\n            'attempted_relationships': 0,\n            'added_relationships': 0,\n            'rejected_relationships': 0,\n            'certainty_history': []\n        }\n        \n        # Iterate through candidates\n        for sample1, sample2, rel_type, certainty in self.candidates:\n            # Stop if we've reached the maximum iterations\n            if max_iterations is not None and metrics['iterations'] >= max_iterations:\n                break\n            \n            # Skip if certainty is too low\n            if certainty < min_certainty:\n                continue\n            \n            metrics['iterations'] += 1\n            metrics['attempted_relationships'] += 1\n            metrics['certainty_history'].append(certainty)\n            \n            # Process the relationship based on its type\n            if rel_type == 'parent-child':\n                # Try to determine which is the parent based on birth years\n                p1_birth = self.pedigree.individuals[sample1].get('birth_year')\n                p2_birth = self.pedigree.individuals[sample2].get('birth_year')\n                \n                if p1_birth is not None and p2_birth is not None:\n                    if p1_birth < p2_birth:\n                        parent, child = sample1, sample2\n                    else:\n                        parent, child = sample2, sample1\n                else:\n                    # Without birth years, we can't determine direction\n                    # For demonstration, we'll use lexicographic ordering as a placeholder\n                    if sample1 < sample2:\n                        parent, child = sample1, sample2\n                    else:\n                        parent, child = sample2, sample1\n                \n                # Try to add the relationship\n                success = self.pedigree.add_relationship(parent, child, certainty=certainty, rel_type=rel_type)\n                \n                if success:\n                    metrics['added_relationships'] += 1\n                else:\n                    metrics['rejected_relationships'] += 1\n            \n            elif rel_type == 'full-sibling' or rel_type == 'half-sibling':\n                # For siblings, we need to create or find common parents\n                # This is a simplified approach\n                phantom_parent_id = f\"phantom_parent_{sample1}_{sample2}\"\n                \n                # Add phantom parent\n                if phantom_parent_id not in self.pedigree.individuals:\n                    # Estimate birth year for phantom parent\n                    p1_birth = self.pedigree.individuals[sample1].get('birth_year')\n                    p2_birth = self.pedigree.individuals[sample2].get('birth_year')\n                    \n                    parent_birth = None\n                    if p1_birth is not None and p2_birth is not None:\n                        avg_birth = (p1_birth + p2_birth) // 2\n                        parent_birth = avg_birth - 25  # Approximate parent birth year\n                    \n                    if parent_birth:\n                        self.pedigree.add_individual(phantom_parent_id, birth_year=parent_birth, is_phantom=True)\n                    else:\n                        self.pedigree.add_individual(phantom_parent_id, is_phantom=True)\n                \n                # Add relationship from phantom parent to both siblings\n                success1 = self.pedigree.add_relationship(phantom_parent_id, sample1, certainty=certainty*0.9, rel_type='parent-child')\n                success2 = self.pedigree.add_relationship(phantom_parent_id, sample2, certainty=certainty*0.9, rel_type='parent-child')\n                \n                if success1 and success2:\n                    metrics['added_relationships'] += 2\n                else:\n                    metrics['rejected_relationships'] += 2 - (success1 + success2)\n                \n                # For full siblings, add a second phantom parent\n                if rel_type == 'full-sibling':\n                    phantom_parent2_id = f\"phantom_parent2_{sample1}_{sample2}\"\n                    \n                    # Add second phantom parent\n                    if phantom_parent2_id not in self.pedigree.individuals:\n                        # Use similar birth year to first phantom parent\n                        parent_birth = self.pedigree.individuals.get(phantom_parent_id, {}).get('birth_year')\n                        \n                        if parent_birth:\n                            self.pedigree.add_individual(phantom_parent2_id, birth_year=parent_birth+2, is_phantom=True)\n                        else:\n                            self.pedigree.add_individual(phantom_parent2_id, is_phantom=True)\n                    \n                    # Add relationships from second phantom parent\n                    success3 = self.pedigree.add_relationship(phantom_parent2_id, sample1, certainty=certainty*0.8, rel_type='parent-child')\n                    success4 = self.pedigree.add_relationship(phantom_parent2_id, sample2, certainty=certainty*0.8, rel_type='parent-child')\n                    \n                    if success3 and success4:\n                        metrics['added_relationships'] += 2\n                    else:\n                        metrics['rejected_relationships'] += 2 - (success3 + success4)\n            \n            elif rel_type == 'grandparent-grandchild':\n                # For grandparent relationships, we need a phantom parent in between\n                phantom_parent_id = f\"phantom_parent_{sample1}_{sample2}\"\n                \n                # Determine which is the grandparent based on birth years\n                p1_birth = self.pedigree.individuals[sample1].get('birth_year')\n                p2_birth = self.pedigree.individuals[sample2].get('birth_year')\n                \n                if p1_birth is not None and p2_birth is not None:\n                    if p1_birth < p2_birth:\n                        grandparent, grandchild = sample1, sample2\n                    else:\n                        grandparent, grandchild = sample2, sample1\n                else:\n                    # Without birth years, we'll use lexicographic ordering as a placeholder\n                    if sample1 < sample2:\n                        grandparent, grandchild = sample1, sample2\n                    else:\n                        grandparent, grandchild = sample2, sample1\n                \n                # Add phantom parent\n                if phantom_parent_id not in self.pedigree.individuals:\n                    # Estimate birth year for phantom parent\n                    gp_birth = self.pedigree.individuals[grandparent].get('birth_year')\n                    gc_birth = self.pedigree.individuals[grandchild].get('birth_year')\n                    \n                    parent_birth = None\n                    if gp_birth is not None and gc_birth is not None:\n                        parent_birth = (gp_birth + gc_birth) // 2\n                    \n                    if parent_birth:\n                        self.pedigree.add_individual(phantom_parent_id, birth_year=parent_birth, is_phantom=True)\n                    else:\n                        self.pedigree.add_individual(phantom_parent_id, is_phantom=True)\n                \n                # Add relationships\n                success1 = self.pedigree.add_relationship(grandparent, phantom_parent_id, certainty=certainty*0.9, rel_type='parent-child')\n                success2 = self.pedigree.add_relationship(phantom_parent_id, grandchild, certainty=certainty*0.9, rel_type='parent-child')\n                \n                if success1 and success2:\n                    metrics['added_relationships'] += 2\n                else:\n                    metrics['rejected_relationships'] += 2 - (success1 + success2)\n            \n            elif rel_type == 'avuncular':\n                # Avuncular relationships (aunt/uncle - niece/nephew) are complex\n                # We'll use a simplified approach with a phantom common ancestor\n                phantom_id = f\"phantom_ancestor_{sample1}_{sample2}\"\n                \n                # Add phantom ancestor\n                if phantom_id not in self.pedigree.individuals:\n                    # Estimate birth year\n                    p1_birth = self.pedigree.individuals[sample1].get('birth_year')\n                    p2_birth = self.pedigree.individuals[sample2].get('birth_year')\n                    \n                    ancestor_birth = None\n                    if p1_birth is not None and p2_birth is not None:\n                        min_birth = min(p1_birth, p2_birth)\n                        ancestor_birth = min_birth - 30\n                    \n                    if ancestor_birth:\n                        self.pedigree.add_individual(phantom_id, birth_year=ancestor_birth, is_phantom=True)\n                    else:\n                        self.pedigree.add_individual(phantom_id, is_phantom=True)\n                \n                # Determine likely direction\n                if p1_birth is not None and p2_birth is not None:\n                    if p1_birth < p2_birth:\n                        aunt_uncle, niece_nephew = sample1, sample2\n                    else:\n                        aunt_uncle, niece_nephew = sample2, sample1\n                else:\n                    # Without birth years, use lexicographic ordering\n                    if sample1 < sample2:\n                        aunt_uncle, niece_nephew = sample1, sample2\n                    else:\n                        aunt_uncle, niece_nephew = sample2, sample1\n                \n                # Add phantom parent for niece/nephew\n                phantom_parent_id = f\"phantom_parent_{niece_nephew}\"\n                \n                if phantom_parent_id not in self.pedigree.individuals:\n                    # Estimate birth year\n                    nn_birth = self.pedigree.individuals[niece_nephew].get('birth_year')\n                    anc_birth = self.pedigree.individuals[phantom_id].get('birth_year')\n                    \n                    parent_birth = None\n                    if nn_birth is not None and anc_birth is not None:\n                        parent_birth = nn_birth - 25\n                    \n                    if parent_birth:\n                        self.pedigree.add_individual(phantom_parent_id, birth_year=parent_birth, is_phantom=True)\n                    else:\n                        self.pedigree.add_individual(phantom_parent_id, is_phantom=True)\n                \n                # Add relationships\n                success1 = self.pedigree.add_relationship(phantom_id, aunt_uncle, certainty=certainty*0.8, rel_type='parent-child')\n                success2 = self.pedigree.add_relationship(phantom_id, phantom_parent_id, certainty=certainty*0.8, rel_type='parent-child')\n                success3 = self.pedigree.add_relationship(phantom_parent_id, niece_nephew, certainty=certainty*0.9, rel_type='parent-child')\n                \n                if success1 and success2 and success3:\n                    metrics['added_relationships'] += 3\n                else:\n                    metrics['rejected_relationships'] += 3 - (success1 + success2 + success3)\n            \n            # Other relationship types would be handled similarly\n            else:\n                # For more distant relationships, we'll skip for this simplified example\n                pass\n        \n        # Return the constructed pedigree\n        return self.pedigree, metrics\n\n# Let's create some synthetic IBD data for demonstration\ndef create_synthetic_ibd_data(num_individuals=15, num_relationships=30):\n    \"\"\"\n    Create synthetic IBD data for demonstration purposes.\n    \n    Args:\n        num_individuals: Number of individuals\n        num_relationships: Number of relationships to generate\n        \n    Returns:\n        tuple: (segments_df, individuals_df)\n    \"\"\"\n    # Create individuals with birth years\n    individuals = []\n    for i in range(num_individuals):\n        birth_year = 1920 + i * 5  # Spread birth years over time\n        individuals.append({\n            'id': f\"ind_{i}\",\n            'birth_year': birth_year,\n            'sex': 'F' if i % 2 == 0 else 'M'  # Alternate sexes\n        })\n    \n    # Create relationships\n    segments = []\n    for _ in range(num_relationships):\n        # Select two random individuals\n        i, j = np.random.choice(range(num_individuals), size=2, replace=False)\n        ind1, ind2 = f\"ind_{i}\", f\"ind_{j}\"\n        \n        # Determine birth year difference to inform relationship type\n        year_diff = abs(individuals[i]['birth_year'] - individuals[j]['birth_year'])\n        \n        # Assign a relationship type based on birth year difference\n        if year_diff > 20 and year_diff < 30:\n            # Potential parent-child\n            rel_type = 'parent-child'\n            target_cm = np.random.normal(3400, 100)\n            num_segments_to_generate = np.random.randint(35, 45)\n        elif year_diff < 15:\n            # Potential siblings or cousins\n            if np.random.random() < 0.3:\n                rel_type = 'full-sibling'\n                target_cm = np.random.normal(2550, 180)\n                num_segments_to_generate = np.random.randint(30, 40)\n            else:\n                rel_type = 'first-cousin'\n                target_cm = np.random.normal(850, 150)\n                num_segments_to_generate = np.random.randint(15, 25)\n        elif year_diff > 40 and year_diff < 60:\n            # Potential grandparent-grandchild\n            rel_type = 'grandparent-grandchild'\n            target_cm = np.random.normal(1700, 160)\n            num_segments_to_generate = np.random.randint(20, 30)\n        else:\n            # Distant relationship\n            rel_type = 'distant'\n            target_cm = np.random.normal(100, 50)\n            num_segments_to_generate = np.random.randint(3, 8)\n        \n        # Generate segments to approximately match the target cM\n        cm_per_segment = target_cm / num_segments_to_generate\n        \n        for s in range(num_segments_to_generate):\n            # Generate segment length (with some variation)\n            segment_cm = max(1, np.random.normal(cm_per_segment, cm_per_segment * 0.3))\n            \n            # Random chromosome\n            chrom = np.random.randint(1, 23)\n            \n            # Add the segment\n            segments.append({\n                'sample1': ind1,\n                'sample2': ind2,\n                'chrom': chrom,\n                'gen_start': np.random.uniform(0, 200),\n                'gen_end': np.random.uniform(0, 200),  # Placeholder\n                'gen_seg_len': segment_cm,\n                'true_relationship': rel_type  # For evaluation\n            })\n    \n    # Convert to DataFrames\n    segments_df = pd.DataFrame(segments)\n    individuals_df = pd.DataFrame(individuals)\n    \n    return segments_df, individuals_df\n\n# Create synthetic data\nnp.random.seed(42)\nsynthetic_segments, synthetic_individuals = create_synthetic_ibd_data(num_individuals=10, num_relationships=15)\n\n# Display summary of the data\nprint(f\"Generated {len(synthetic_segments)} segments for {len(synthetic_individuals)} individuals\")\n\n# Calculate total sharing per pair\npair_sharing = synthetic_segments.groupby(['sample1', 'sample2', 'true_relationship'])['gen_seg_len'].sum().reset_index()\nprint(\"\\nSample of total IBD sharing between pairs:\")\ndisplay(pair_sharing.head(10))\n\n# Now, let's apply the greedy incremental construction algorithm\nbuilder = GreedyPedigreeBuilder(synthetic_segments, synthetic_individuals)\n\n# Build the pedigree\nbuilt_pedigree, metrics = builder.build_pedigree(min_certainty=0.3)\n\n# Display metrics\nprint(\"\\nPedigree construction metrics:\")\nprint(f\"Iterations: {metrics['iterations']}\")\nprint(f\"Attempted relationships: {metrics['attempted_relationships']}\")\nprint(f\"Added relationships: {metrics['added_relationships']}\")\nprint(f\"Rejected relationships: {metrics['rejected_relationships']}\")\n\n# Visualize the pedigree\nbuilt_pedigree.visualize(figsize=(12, 8))\n\n# Plot the certainty history\nplt.figure(figsize=(10, 5))\nplt.plot(metrics['certainty_history'], 'o-')\nplt.xlabel('Iteration')\nplt.ylabel('Relationship Certainty')\nplt.title('Certainty of Relationships Added During Construction')\nplt.grid(True, alpha=0.3)\nplt.ylim(0, 1.05)\nplt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 2.2 Simulated Annealing for Pedigree Optimization\n\nWhile greedy incremental construction is fast, it can get stuck in local optima. Simulated annealing is a more sophisticated approach that allows for temporary \"worsening\" moves to escape local optima.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's implement the simulated annealing algorithm for pedigree optimization\nclass SimulatedAnnealingPedigreeOptimizer:\n    \"\"\"\n    A class for optimizing pedigrees using simulated annealing.\n    \n    Simulated annealing is a probabilistic technique that allows exploration of the search\n    space by accepting worse solutions with a probability that decreases over time. This\n    helps escape local optima and find better global solutions.\n    \"\"\"\n    \n    def __init__(self, initial_pedigree, ibd_data, individuals_metadata=None):\n        \"\"\"\n        Initialize the optimizer.\n        \n        Args:\n            initial_pedigree: Initial pedigree to start from (can be empty or from greedy construction)\n            ibd_data: DataFrame with IBD segments\n            individuals_metadata: Optional DataFrame with metadata about individuals\n        \"\"\"\n        self.current_pedigree = initial_pedigree.copy()\n        self.best_pedigree = initial_pedigree.copy()\n        self.ibd_data = ibd_data\n        self.individuals_metadata = individuals_metadata\n        \n        # Set initial scores\n        self.current_score = self._score_pedigree(self.current_pedigree)\n        self.best_score = self.current_score\n        \n        # Store all individuals\n        self.all_individuals = set(ibd_data['sample1']).union(set(ibd_data['sample2']))\n        \n        # Calculate IBD sharing between pairs for quick lookup\n        self.pair_sharing = self._calculate_pair_sharing()\n        \n        # Build possible moves\n        self.possible_moves = self._build_possible_moves()\n    \n    def _calculate_pair_sharing(self):\n        \"\"\"Calculate total IBD sharing for each pair.\"\"\"\n        # Group by pairs and sum segment lengths\n        return self.ibd_data.groupby(['sample1', 'sample2'])['gen_seg_len'].sum().to_dict()\n    \n    def _score_pedigree(self, pedigree):\n        \"\"\"\n        Calculate a score for the pedigree based on how well it explains the IBD data.\n        \n        Args:\n            pedigree: Pedigree object to score\n            \n        Returns:\n            float: Score (higher is better)\n        \"\"\"\n        # We'll use a more comprehensive scoring model for simulated annealing\n        \n        # 1. Calculate how well pedigree explains IBD segments\n        ibd_explanation_score = 0\n        \n        # Get all pairs in the pedigree with paths\n        pedigree_relationships = {}\n        for ind1 in pedigree.individuals:\n            for ind2 in pedigree.individuals:\n                if ind1 == ind2:\n                    continue\n                    \n                # Check if there's a path connecting them\n                try:\n                    path1 = nx.has_path(pedigree.graph, ind1, ind2)\n                    path2 = nx.has_path(pedigree.graph, ind2, ind1)\n                    if path1 or path2:\n                        # Try to determine relationship degree\n                        try:\n                            if path1:\n                                path_length = len(nx.shortest_path(pedigree.graph, ind1, ind2)) - 1\n                            else:\n                                path_length = len(nx.shortest_path(pedigree.graph, ind2, ind1)) - 1\n                            \n                            # Convert path length to expected cM\n                            # This is a simplified model; real model would be more sophisticated\n                            if path_length == 1:  # Parent-child\n                                expected_cm = 3400\n                            elif path_length == 2:  # Grandparent or avuncular\n                                expected_cm = 1700\n                            elif path_length == 3:  # First cousin or great-grandparent\n                                expected_cm = 850\n                            elif path_length == 4:\n                                expected_cm = 425\n                            elif path_length == 5:\n                                expected_cm = 212\n                            else:\n                                expected_cm = 850 * (0.5 ** (path_length - 3))\n                            \n                            pedigree_relationships[(ind1, ind2)] = {\n                                'path_length': path_length,\n                                'expected_cm': expected_cm\n                            }\n                        except:\n                            # If there's an error calculating the path, use a default\n                            pedigree_relationships[(ind1, ind2)] = {\n                                'path_length': 0,\n                                'expected_cm': 0\n                            }\n                except:\n                    pass\n        \n        # Compare pedigree relationships with observed IBD\n        for pair, expected in pedigree_relationships.items():\n            # Check if this pair has observed IBD\n            observed_cm = self.pair_sharing.get((pair[0], pair[1]), 0)\n            if observed_cm == 0:\n                observed_cm = self.pair_sharing.get((pair[1], pair[0]), 0)\n            \n            # Calculate score contribution (how well does pedigree explain this pair's IBD?)\n            # We're using a simple Gaussian model; real implementation would use more complex models\n            expected_cm = expected['expected_cm']\n            \n            # Determine std based on relationship (closer relationships have more variation)\n            if expected_cm > 3000:  # Parent-child\n                std_cm = 200\n            elif expected_cm > 2000:  # Full sibling\n                std_cm = 300\n            elif expected_cm > 1500:  # Half-sibling/grandparent\n                std_cm = 250\n            elif expected_cm > 700:  # First cousin\n                std_cm = 200\n            else:\n                std_cm = expected_cm * 0.2  # 20% of expected for distant relationships\n            \n            # Gaussian score\n            score_contrib = stats.norm.pdf(observed_cm, expected_cm, std_cm)\n            # Normalize to 0-1 range (roughly)\n            score_contrib = score_contrib / stats.norm.pdf(expected_cm, expected_cm, std_cm)\n            \n            ibd_explanation_score += score_contrib\n        \n        # 2. Penalty for pairs with IBD but no path in pedigree\n        missing_relationship_penalty = 0\n        for (ind1, ind2), cm in self.pair_sharing.items():\n            if cm < 20:  # Ignore very small segments\n                continue\n                \n            # Check if there's a path in the pedigree\n            if (ind1, ind2) not in pedigree_relationships and (ind2, ind1) not in pedigree_relationships:\n                # Calculate penalty based on IBD amount (more IBD = higher penalty for missing)\n                if cm > 1500:  # Close relationship\n                    penalty = 5.0\n                elif cm > 700:  # First cousin level\n                    penalty = 2.0\n                elif cm > 300:  # Second cousin level\n                    penalty = 1.0\n                elif cm > 100:  # Distant relationship\n                    penalty = 0.5\n                else:\n                    penalty = 0.1\n                    \n                missing_relationship_penalty += penalty\n        \n        # 3. Complexity penalty (prefer simpler pedigrees)\n        num_edges = pedigree.graph.number_of_edges()\n        num_nodes = pedigree.graph.number_of_nodes()\n        phantom_nodes = sum(1 for n, attrs in pedigree.individuals.items() if attrs.get('is_phantom', False))\n        \n        # Penalize complexity, especially phantom nodes\n        complexity_penalty = 0.1 * num_edges + 0.5 * phantom_nodes\n        \n        # 4. Consistency score (reward biologically consistent pedigrees)\n        consistency_score = 10 if pedigree.is_consistent() else 0\n        \n        # Combine all scoring components\n        total_score = ibd_explanation_score - missing_relationship_penalty - complexity_penalty + consistency_score\n        \n        return total_score\n    \n    def _build_possible_moves(self):\n        \"\"\"\n        Build a list of possible moves for modifying the pedigree.\n        \n        Returns:\n            list: List of move types and parameters\n        \"\"\"\n        moves = []\n        \n        # 1. Add relationship between existing individuals\n        for ind1 in self.all_individuals:\n            for ind2 in self.all_individuals:\n                if ind1 == ind2:\n                    continue\n                \n                # Check if there's significant IBD between them\n                pair_cm = self.pair_sharing.get((ind1, ind2), 0)\n                if pair_cm == 0:\n                    pair_cm = self.pair_sharing.get((ind2, ind1), 0)\n                \n                if pair_cm > 20:  # Only consider pairs with meaningful IBD\n                    # For parent-child, we need to determine direction\n                    if pair_cm > 2800:  # Potential parent-child\n                        # Try to determine direction from birth years\n                        ind1_birth = self.current_pedigree.individuals.get(ind1, {}).get('birth_year')\n                        ind2_birth = self.current_pedigree.individuals.get(ind2, {}).get('birth_year')\n                        \n                        if ind1_birth is not None and ind2_birth is not None:\n                            if ind1_birth < ind2_birth:\n                                moves.append(('add_relationship', ind1, ind2, 'parent-child'))\n                            else:\n                                moves.append(('add_relationship', ind2, ind1, 'parent-child'))\n                        else:\n                            # Without birth years, try both directions\n                            moves.append(('add_relationship', ind1, ind2, 'parent-child'))\n                            moves.append(('add_relationship', ind2, ind1, 'parent-child'))\n                    else:\n                        # For other relationship types, we'll use phantom nodes in apply_move\n                        moves.append(('connect_individuals', ind1, ind2))\n        \n        # 2. Remove relationship\n        for parent, child in self.current_pedigree.graph.edges():\n            moves.append(('remove_relationship', parent, child))\n        \n        # 3. Swap relationships (change parent)\n        for child, child_attrs in self.current_pedigree.individuals.items():\n            # Get current parents\n            parents = list(self.current_pedigree.graph.predecessors(child))\n            \n            # Potential new parents (anyone older than the child)\n            child_birth = child_attrs.get('birth_year')\n            potential_parents = []\n            \n            for ind, attrs in self.current_pedigree.individuals.items():\n                if ind == child:\n                    continue\n                    \n                # Check if older (or unknown birth year)\n                ind_birth = attrs.get('birth_year')\n                if (ind_birth is None or child_birth is None or ind_birth < child_birth) and ind not in parents:\n                    potential_parents.append(ind)\n            \n            # Add swap moves\n            for old_parent in parents:\n                for new_parent in potential_parents:\n                    moves.append(('swap_parent', child, old_parent, new_parent))\n        \n        # 4. Add/remove phantom node\n        for ind1 in self.all_individuals:\n            for ind2 in self.all_individuals:\n                if ind1 == ind2:\n                    continue\n                \n                # Check if there's significant IBD\n                pair_cm = self.pair_sharing.get((ind1, ind2), 0)\n                if pair_cm == 0:\n                    pair_cm = self.pair_sharing.get((ind2, ind1), 0)\n                \n                if pair_cm > 200 and pair_cm < 2800:  # Potential distant relationship needing phantom\n                    moves.append(('add_phantom_connection', ind1, ind2))\n        \n        # 5. Move a subtree (e.g., move a whole family branch)\n        for node in self.current_pedigree.graph.nodes():\n            # Skip if it's a leaf node (no children)\n            if self.current_pedigree.graph.out_degree(node) == 0:\n                continue\n                \n            # Get ancestors that could be new parents\n            ancestors = []\n            for potential_parent in self.current_pedigree.graph.nodes():\n                if potential_parent == node:\n                    continue\n                \n                # Check if potential_parent is not a descendant of node\n                if not nx.has_path(self.current_pedigree.graph, node, potential_parent):\n                    ancestors.append(potential_parent)\n            \n            # Add moves to connect node to each potential new parent\n            for new_parent in ancestors:\n                moves.append(('move_subtree', node, new_parent))\n        \n        return moves\n    \n    def _apply_move(self, move):\n        \"\"\"\n        Apply a move to the current pedigree.\n        \n        Args:\n            move: Tuple describing the move to apply\n            \n        Returns:\n            Pedigree: The modified pedigree\n        \"\"\"\n        # Create a copy of the current pedigree\n        new_pedigree = self.current_pedigree.copy()\n        \n        move_type = move[0]\n        \n        if move_type == 'add_relationship':\n            # Add direct relationship between two individuals\n            parent, child, rel_type = move[1], move[2], move[3]\n            success = new_pedigree.add_relationship(parent, child, rel_type=rel_type)\n        \n        elif move_type == 'remove_relationship':\n            # Remove a relationship\n            parent, child = move[1], move[2]\n            if new_pedigree.graph.has_edge(parent, child):\n                new_pedigree.graph.remove_edge(parent, child)\n                # Also remove from relationships dictionary\n                if (parent, child) in new_pedigree.relationships:\n                    del new_pedigree.relationships[(parent, child)]\n                success = True\n            else:\n                success = False\n        \n        elif move_type == 'swap_parent':\n            # Change a child's parent\n            child, old_parent, new_parent = move[1], move[2], move[3]\n            \n            # Check if both parents exist\n            if old_parent in new_pedigree.individuals and new_parent in new_pedigree.individuals:\n                # Store old relationship attributes\n                old_attrs = new_pedigree.graph.edges.get((old_parent, child), {}).copy()\n                \n                # Remove old relationship\n                if new_pedigree.graph.has_edge(old_parent, child):\n                    new_pedigree.graph.remove_edge(old_parent, child)\n                    if (old_parent, child) in new_pedigree.relationships:\n                        del new_pedigree.relationships[(old_parent, child)]\n                \n                # Add new relationship with same attributes\n                success = new_pedigree.add_relationship(new_parent, child, **old_attrs)\n            else:\n                success = False\n        \n        elif move_type == 'connect_individuals':\n            # Connect two individuals through appropriate phantom nodes\n            ind1, ind2 = move[1], move[2]\n            \n            # Get IBD amount to determine relationship type\n            pair_cm = self.pair_sharing.get((ind1, ind2), 0)\n            if pair_cm == 0:\n                pair_cm = self.pair_sharing.get((ind2, ind1), 0)\n            \n            # Determine birth years if available\n            ind1_birth = new_pedigree.individuals.get(ind1, {}).get('birth_year')\n            ind2_birth = new_pedigree.individuals.get(ind2, {}).get('birth_year')\n            \n            # Create phantom node ID\n            phantom_id = f\"phantom_{ind1}_{ind2}\"\n            \n            if 1500 < pair_cm <= 2800:  # Potential siblings or half-siblings\n                # Add phantom parent\n                if phantom_id not in new_pedigree.individuals:\n                    # Estimate birth year for phantom parent\n                    parent_birth = None\n                    if ind1_birth is not None and ind2_birth is not None:\n                        avg_birth = (ind1_birth + ind2_birth) // 2\n                        parent_birth = avg_birth - 25  # Approximate parent birth year\n                    \n                    if parent_birth:\n                        new_pedigree.add_individual(phantom_id, birth_year=parent_birth, is_phantom=True)\n                    else:\n                        new_pedigree.add_individual(phantom_id, is_phantom=True)\n                \n                # Add relationships to both individuals\n                success1 = new_pedigree.add_relationship(phantom_id, ind1, rel_type='parent-child')\n                success2 = new_pedigree.add_relationship(phantom_id, ind2, rel_type='parent-child')\n                \n                success = success1 and success2\n            \n            elif 700 < pair_cm <= 1500:  # Potential grandparent or avuncular\n                # Determine likely relationship direction if birth years available\n                if ind1_birth is not None and ind2_birth is not None:\n                    year_diff = abs(ind1_birth - ind2_birth)\n                    \n                    if year_diff > 30:  # Likely grandparent-grandchild\n                        if ind1_birth < ind2_birth:\n                            older, younger = ind1, ind2\n                        else:\n                            older, younger = ind2, ind1\n                        \n                        # Add phantom parent in between\n                        phantom_parent_id = f\"phantom_parent_{older}_{younger}\"\n                        \n                        # Estimate birth year\n                        parent_birth = None\n                        if ind1_birth is not None and ind2_birth is not None:\n                            parent_birth = (ind1_birth + ind2_birth) // 2\n                        \n                        if parent_birth:\n                            new_pedigree.add_individual(phantom_parent_id, birth_year=parent_birth, is_phantom=True)\n                        else:\n                            new_pedigree.add_individual(phantom_parent_id, is_phantom=True)\n                        \n                        # Add relationships\n                        success1 = new_pedigree.add_relationship(older, phantom_parent_id, rel_type='parent-child')\n                        success2 = new_pedigree.add_relationship(phantom_parent_id, younger, rel_type='parent-child')\n                        \n                        success = success1 and success2\n                    \n                    else:  # Likely avuncular (aunt/uncle - niece/nephew)\n                        if ind1_birth < ind2_birth:\n                            older, younger = ind1, ind2\n                        else:\n                            older, younger = ind2, ind1\n                        \n                        # Add phantom common ancestor\n                        phantom_ancestor_id = f\"phantom_ancestor_{older}_{younger}\"\n                        \n                        # Estimate birth year\n                        ancestor_birth = None\n                        if older_birth := new_pedigree.individuals.get(older, {}).get('birth_year'):\n                            ancestor_birth = older_birth - 25\n                        \n                        if ancestor_birth:\n                            new_pedigree.add_individual(phantom_ancestor_id, birth_year=ancestor_birth, is_phantom=True)\n                        else:\n                            new_pedigree.add_individual(phantom_ancestor_id, is_phantom=True)\n                        \n                        # Add phantom parent for younger\n                        phantom_parent_id = f\"phantom_parent_{younger}\"\n                        \n                        # Estimate birth year\n                        parent_birth = None\n                        if younger_birth := new_pedigree.individuals.get(younger, {}).get('birth_year'):\n                            parent_birth = younger_birth - 25\n                        \n                        if parent_birth:\n                            new_pedigree.add_individual(phantom_parent_id, birth_year=parent_birth, is_phantom=True)\n                        else:\n                            new_pedigree.add_individual(phantom_parent_id, is_phantom=True)\n                        \n                        # Add relationships\n                        success1 = new_pedigree.add_relationship(phantom_ancestor_id, older, rel_type='parent-child')\n                        success2 = new_pedigree.add_relationship(phantom_ancestor_id, phantom_parent_id, rel_type='parent-child')\n                        success3 = new_pedigree.add_relationship(phantom_parent_id, younger, rel_type='parent-child')\n                        \n                        success = success1 and success2 and success3\n                else:\n                    # Without birth years, use a generic approach (just connect through a phantom)\n                    if phantom_id not in new_pedigree.individuals:\n                        new_pedigree.add_individual(phantom_id, is_phantom=True)\n                    \n                    success1 = new_pedigree.add_relationship(phantom_id, ind1, rel_type='connection')\n                    success2 = new_pedigree.add_relationship(phantom_id, ind2, rel_type='connection')\n                    \n                    success = success1 and success2\n            \n            elif 200 < pair_cm <= 700:  # Potential cousins\n                # Add phantom common ancestor\n                if phantom_id not in new_pedigree.individuals:\n                    # Estimate birth year (if available)\n                    ancestor_birth = None\n                    if ind1_birth is not None and ind2_birth is not None:\n                        min_birth = min(ind1_birth, ind2_birth)\n                        ancestor_birth = min_birth - 50  # Approx. for common ancestor of cousins\n                    \n                    if ancestor_birth:\n                        new_pedigree.add_individual(phantom_id, birth_year=ancestor_birth, is_phantom=True)\n                    else:\n                        new_pedigree.add_individual(phantom_id, is_phantom=True)\n                \n                # Add phantom parents\n                phantom_parent1_id = f\"phantom_parent_{ind1}\"\n                phantom_parent2_id = f\"phantom_parent_{ind2}\"\n                \n                # Estimate birth years (if available)\n                parent1_birth = None\n                parent2_birth = None\n                if ind1_birth is not None:\n                    parent1_birth = ind1_birth - 25\n                if ind2_birth is not None:\n                    parent2_birth = ind2_birth - 25\n                \n                # Add phantom parents\n                if phantom_parent1_id not in new_pedigree.individuals:\n                    if parent1_birth:\n                        new_pedigree.add_individual(phantom_parent1_id, birth_year=parent1_birth, is_phantom=True)\n                    else:\n                        new_pedigree.add_individual(phantom_parent1_id, is_phantom=True)\n                \n                if phantom_parent2_id not in new_pedigree.individuals:\n                    if parent2_birth:\n                        new_pedigree.add_individual(phantom_parent2_id, birth_year=parent2_birth, is_phantom=True)\n                    else:\n                        new_pedigree.add_individual(phantom_parent2_id, is_phantom=True)\n                \n                # Add relationships\n                success1 = new_pedigree.add_relationship(phantom_id, phantom_parent1_id, rel_type='parent-child')\n                success2 = new_pedigree.add_relationship(phantom_id, phantom_parent2_id, rel_type='parent-child')\n                success3 = new_pedigree.add_relationship(phantom_parent1_id, ind1, rel_type='parent-child')\n                success4 = new_pedigree.add_relationship(phantom_parent2_id, ind2, rel_type='parent-child')\n                \n                success = success1 and success2 and success3 and success4\n            \n            else:  # Very distant or unsupported relationship\n                success = False\n        \n        elif move_type == 'add_phantom_connection':\n            # Add a phantom node to connect two individuals\n            ind1, ind2 = move[1], move[2]\n            phantom_id = f\"phantom_connector_{ind1}_{ind2}\"\n            \n            # Create phantom node\n            if phantom_id not in new_pedigree.individuals:\n                new_pedigree.add_individual(phantom_id, is_phantom=True)\n            \n            # Connect both individuals to phantom\n            success1 = new_pedigree.add_relationship(phantom_id, ind1, rel_type='connection')\n            success2 = new_pedigree.add_relationship(phantom_id, ind2, rel_type='connection')\n            \n            success = success1 and success2\n        \n        elif move_type == 'move_subtree':\n            # Move a subtree by changing the parent of the subtree root\n            subtree_root, new_parent = move[1], move[2]\n            \n            # Get current parents\n            current_parents = list(new_pedigree.graph.predecessors(subtree_root))\n            \n            # Check if this would create a cycle\n            if new_pedigree.would_create_cycle(new_parent, subtree_root):\n                success = False\n            else:\n                # Remove current parent connections\n                for parent in current_parents:\n                    if new_pedigree.graph.has_edge(parent, subtree_root):\n                        new_pedigree.graph.remove_edge(parent, subtree_root)\n                        if (parent, subtree_root) in new_pedigree.relationships:\n                            del new_pedigree.relationships[(parent, subtree_root)]\n                \n                # Add new parent connection\n                success = new_pedigree.add_relationship(new_parent, subtree_root, rel_type='parent-child')\n        \n        else:\n            # Unknown move type\n            success = False\n        \n        return new_pedigree if success else None\n    \n    def _get_random_move(self):\n        \"\"\"Get a random move from the possible moves list.\"\"\"\n        if not self.possible_moves:\n            return None\n        return random.choice(self.possible_moves)\n    \n    def _acceptance_probability(self, old_score, new_score, temperature):\n        \"\"\"\n        Calculate the probability of accepting a move that changes the score.\n        \n        Args:\n            old_score: Score before the move\n            new_score: Score after the move\n            temperature: Current temperature (controls acceptance probability)\n            \n        Returns:\n            float: Probability of accepting the move (0-1)\n        \"\"\"\n        # If the new solution is better, accept it with probability 1\n        if new_score > old_score:\n            return 1.0\n        \n        # If the new solution is worse, calculate acceptance probability\n        # The higher the temperature, the more likely we are to accept a worse solution\n        try:\n            return math.exp((new_score - old_score) / temperature)\n        except OverflowError:\n            # Handle very large exponents\n            return 0.0 if new_score < old_score else 1.0\n    \n    def optimize(self, max_iterations=1000, initial_temp=10.0, cooling_rate=0.003, min_temp=0.01):\n        \"\"\"\n        Run the simulated annealing optimization process.\n        \n        Args:\n            max_iterations: Maximum number of iterations\n            initial_temp: Initial temperature\n            cooling_rate: Rate at which temperature decreases\n            min_temp: Minimum temperature to stop at\n            \n        Returns:\n            tuple: (best_pedigree, metrics)\n        \"\"\"\n        # Initialize tracking variables\n        current_temp = initial_temp\n        iteration = 0\n        \n        # Metrics to track progress\n        metrics = {\n            'iterations': 0,\n            'attempted_moves': 0,\n            'accepted_moves': 0,\n            'rejected_moves': 0,\n            'temperature_history': [],\n            'score_history': [],\n            'best_score_history': []\n        }\n        \n        # Main simulated annealing loop\n        progress_bar = tqdm(total=max_iterations, desc=\"Optimizing Pedigree\")\n        \n        while iteration < max_iterations and current_temp > min_temp:\n            # Update metrics\n            metrics['iterations'] = iteration\n            metrics['temperature_history'].append(current_temp)\n            metrics['score_history'].append(self.current_score)\n            metrics['best_score_history'].append(self.best_score)\n            \n            # Get a random move\n            move = self._get_random_move()\n            if move is None:\n                break\n            \n            # Apply the move\n            metrics['attempted_moves'] += 1\n            new_pedigree = self._apply_move(move)\n            \n            # Skip if the move was invalid\n            if new_pedigree is None:\n                continue\n            \n            # Score the new pedigree\n            new_score = self._score_pedigree(new_pedigree)\n            \n            # Decide whether to accept the move\n            acceptance_prob = self._acceptance_probability(self.current_score, new_score, current_temp)\n            if random.random() < acceptance_prob:\n                # Accept the move\n                self.current_pedigree = new_pedigree\n                self.current_score = new_score\n                metrics['accepted_moves'] += 1\n                \n                # Update best pedigree if this is the best we've seen\n                if new_score > self.best_score:\n                    self.best_pedigree = new_pedigree.copy()\n                    self.best_score = new_score\n            else:\n                # Reject the move\n                metrics['rejected_moves'] += 1\n            \n            # Cool the temperature\n            current_temp *= (1 - cooling_rate)\n            iteration += 1\n            \n            # Update progress bar\n            progress_bar.update(1)\n            \n            # Update possible moves occasionally to reflect the changed pedigree\n            if iteration % 50 == 0:\n                self.possible_moves = self._build_possible_moves()\n        \n        progress_bar.close()\n        \n        # Final update to metrics\n        metrics['iterations'] = iteration\n        metrics['temperature_history'].append(current_temp)\n        metrics['score_history'].append(self.current_score)\n        metrics['best_score_history'].append(self.best_score)\n        \n        return self.best_pedigree, metrics"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Test the simulated annealing implementation with the synthetic data\n\n# First, build an initial pedigree using the greedy algorithm\ngreedy_builder = GreedyPedigreeBuilder(synthetic_segments, synthetic_individuals)\ninitial_pedigree, greedy_metrics = greedy_builder.build_pedigree(min_certainty=0.3)\n\n# Now, optimize it using simulated annealing\noptimizer = SimulatedAnnealingPedigreeOptimizer(initial_pedigree, synthetic_segments, synthetic_individuals)\n\n# Run the optimization\nbest_pedigree, sa_metrics = optimizer.optimize(\n    max_iterations=200,  # Reduced for notebook demonstration\n    initial_temp=10.0,\n    cooling_rate=0.01,\n    min_temp=0.1\n)\n\n# Display metrics\nprint(\"\\nSimulated Annealing Metrics:\")\nprint(f\"Iterations: {sa_metrics['iterations']}\")\nprint(f\"Attempted moves: {sa_metrics['attempted_moves']}\")\nprint(f\"Accepted moves: {sa_metrics['accepted_moves']}\")\nprint(f\"Rejected moves: {sa_metrics['rejected_moves']}\")\nprint(f\"Initial score: {sa_metrics['score_history'][0]}\")\nprint(f\"Final score: {sa_metrics['score_history'][-1]}\")\nprint(f\"Best score: {sa_metrics['best_score_history'][-1]}\")\n\n# Compare greedy and optimized pedigrees\nprint(\"\\nComparison:\")\nprint(f\"Greedy pedigree score: {optimizer._score_pedigree(initial_pedigree)}\")\nprint(f\"Optimized pedigree score: {optimizer._score_pedigree(best_pedigree)}\")\nprint(f\"Improvement: {100 * (optimizer._score_pedigree(best_pedigree) - optimizer._score_pedigree(initial_pedigree)) / abs(optimizer._score_pedigree(initial_pedigree)):.2f}%\")\n\n# Plot temperature and score history\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n\n# Temperature plot\nax1.plot(sa_metrics['temperature_history'], 'r-')\nax1.set_xlabel('Iteration')\nax1.set_ylabel('Temperature')\nax1.set_title('Temperature Decay During Simulated Annealing')\nax1.grid(True, alpha=0.3)\n\n# Score plot\nax2.plot(sa_metrics['score_history'], 'b-', alpha=0.5, label='Current Score')\nax2.plot(sa_metrics['best_score_history'], 'g-', linewidth=2, label='Best Score')\nax2.set_xlabel('Iteration')\nax2.set_ylabel('Score')\nax2.set_title('Score Evolution During Simulated Annealing')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Visualize the optimized pedigree\nplt.figure(figsize=(12, 8))\nbest_pedigree.visualize()\nplt.title('Optimized Pedigree from Simulated Annealing')\nplt.show()\n\n# Visualize the initial (greedy) pedigree for comparison\nplt.figure(figsize=(12, 8))\ninitial_pedigree.visualize()\nplt.title('Initial Pedigree from Greedy Algorithm')\nplt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 2.3 Genetic Algorithms for Pedigree Optimization\n\nGenetic algorithms provide another optimization approach, inspired by biological evolution. This method maintains a population of candidate pedigrees and evolves them through selection, crossover, and mutation to find optimal solutions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's implement a genetic algorithm for pedigree optimization\nclass GeneticPedigreeOptimizer:\n    \"\"\"\n    A class for optimizing pedigrees using genetic algorithms.\n    \n    Genetic algorithms maintain a population of candidate solutions (pedigrees) and\n    evolve them through selection, crossover, and mutation operations, mimicking\n    natural selection and evolution.\n    \"\"\"\n    \n    def __init__(self, ibd_data, individuals_metadata=None, population_size=20):\n        \"\"\"\n        Initialize the optimizer.\n        \n        Args:\n            ibd_data: DataFrame with IBD segments\n            individuals_metadata: Optional DataFrame with metadata about individuals\n            population_size: Size of the population to maintain\n        \"\"\"\n        self.ibd_data = ibd_data\n        self.individuals_metadata = individuals_metadata\n        self.population_size = population_size\n        \n        # Store all individuals\n        self.all_individuals = set(ibd_data['sample1']).union(set(ibd_data['sample2']))\n        \n        # Calculate IBD sharing between pairs for quick lookup\n        self.pair_sharing = self._calculate_pair_sharing()\n        \n        # Initialize population\n        self.population = self._initialize_population()\n        \n        # Track the best solution\n        self.best_pedigree = self.population[0]\n        self.best_score = self._score_pedigree(self.best_pedigree)\n    \n    def _calculate_pair_sharing(self):\n        \"\"\"Calculate total IBD sharing for each pair.\"\"\"\n        # Group by pairs and sum segment lengths\n        return self.ibd_data.groupby(['sample1', 'sample2'])['gen_seg_len'].sum().to_dict()\n    \n    def _initialize_population(self):\n        \"\"\"\n        Create the initial population of pedigrees.\n        \n        Returns:\n            list: List of Pedigree objects\n        \"\"\"\n        population = []\n        \n        # Create some greedy pedigrees with different parameters\n        greedy_certainties = [0.2, 0.3, 0.5, 0.7]\n        for certainty in greedy_certainties:\n            # Create a greedy pedigree with this certainty threshold\n            builder = GreedyPedigreeBuilder(self.ibd_data, self.individuals_metadata)\n            pedigree, _ = builder.build_pedigree(min_certainty=certainty)\n            population.append(pedigree)\n        \n        # Create some random pedigrees\n        for _ in range(self.population_size - len(greedy_certainties)):\n            # Create a random pedigree\n            pedigree = self._create_random_pedigree()\n            population.append(pedigree)\n        \n        # Evaluate all pedigrees\n        population_with_scores = [(p, self._score_pedigree(p)) for p in population]\n        \n        # Sort by score\n        population_with_scores.sort(key=lambda x: x[1], reverse=True)\n        \n        # Update best pedigree\n        if population_with_scores:\n            self.best_pedigree = population_with_scores[0][0].copy()\n            self.best_score = population_with_scores[0][1]\n        \n        # Return sorted population\n        return [p for p, _ in population_with_scores]\n    \n    def _create_random_pedigree(self):\n        \"\"\"\n        Create a random pedigree.\n        \n        Returns:\n            Pedigree: A randomly generated pedigree\n        \"\"\"\n        pedigree = Pedigree()\n        \n        # Add all individuals\n        for ind_id in self.all_individuals:\n            # Get metadata if available\n            metadata = {}\n            if self.individuals_metadata is not None:\n                match = self.individuals_metadata[self.individuals_metadata['id'] == ind_id]\n                if len(match) > 0:\n                    metadata = match.iloc[0].to_dict()\n            \n            pedigree.add_individual(ind_id, **metadata)\n        \n        # Add some random relationships based on IBD sharing\n        for (ind1, ind2), cm in self.pair_sharing.items():\n            if cm < 20:  # Ignore very small segments\n                continue\n                \n            # Add relationships with higher probability for higher IBD\n            probability = min(0.8, cm / 3500)  # Cap at 80% even for very high IBD\n            \n            if random.random() < probability:\n                # Determine relationship type based on cM\n                if cm > 2800:  # Likely parent-child\n                    # Try to determine direction\n                    ind1_birth = pedigree.individuals.get(ind1, {}).get('birth_year')\n                    ind2_birth = pedigree.individuals.get(ind2, {}).get('birth_year')\n                    \n                    if ind1_birth is not None and ind2_birth is not None:\n                        if ind1_birth < ind2_birth:\n                            parent, child = ind1, ind2\n                        else:\n                            parent, child = ind2, ind1\n                    else:\n                        # Without birth years, use random direction\n                        if random.random() < 0.5:\n                            parent, child = ind1, ind2\n                        else:\n                            parent, child = ind2, ind1\n                    \n                    # Check if adding this relationship would be valid\n                    if not pedigree.would_create_cycle(parent, child):\n                        pedigree.add_relationship(parent, child, certainty=probability, rel_type='parent-child')\n                    \n                elif cm > 1500:  # Siblings or half-siblings\n                    # For siblings, we need a common parent\n                    phantom_parent_id = f\"phantom_parent_{ind1}_{ind2}\"\n                    \n                    # Add phantom parent\n                    if phantom_parent_id not in pedigree.individuals:\n                        # Estimate birth year if possible\n                        p1_birth = pedigree.individuals.get(ind1, {}).get('birth_year')\n                        p2_birth = pedigree.individuals.get(ind2, {}).get('birth_year')\n                        \n                        parent_birth = None\n                        if p1_birth is not None and p2_birth is not None:\n                            avg_birth = (p1_birth + p2_birth) // 2\n                            parent_birth = avg_birth - 25  # Approximate parent birth year\n                        \n                        if parent_birth:\n                            pedigree.add_individual(phantom_parent_id, birth_year=parent_birth, is_phantom=True)\n                        else:\n                            pedigree.add_individual(phantom_parent_id, is_phantom=True)\n                    \n                    # Add relationships\n                    pedigree.add_relationship(phantom_parent_id, ind1, certainty=probability, rel_type='parent-child')\n                    pedigree.add_relationship(phantom_parent_id, ind2, certainty=probability, rel_type='parent-child')\n                \n                elif cm > 700:  # Cousins or avuncular\n                    # For these relationships, we'll add a suitable phantom structure\n                    if random.random() < 0.5:  # Avuncular\n                        phantom_parent_id = f\"phantom_parent_{ind1}_{ind2}\"\n                        \n                        # Add phantom parent\n                        if phantom_parent_id not in pedigree.individuals:\n                            pedigree.add_individual(phantom_parent_id, is_phantom=True)\n                        \n                        # Determine direction randomly\n                        if random.random() < 0.5:\n                            pedigree.add_relationship(phantom_parent_id, ind1, certainty=probability, rel_type='parent-child')\n                            pedigree.add_relationship(ind1, ind2, certainty=probability, rel_type='avuncular')\n                        else:\n                            pedigree.add_relationship(phantom_parent_id, ind2, certainty=probability, rel_type='parent-child')\n                            pedigree.add_relationship(ind2, ind1, certainty=probability, rel_type='avuncular')\n                    \n                    else:  # First cousins\n                        phantom_grandparent_id = f\"phantom_grandparent_{ind1}_{ind2}\"\n                        phantom_parent1_id = f\"phantom_parent1_{ind1}_{ind2}\"\n                        phantom_parent2_id = f\"phantom_parent2_{ind1}_{ind2}\"\n                        \n                        # Add phantom individuals\n                        if phantom_grandparent_id not in pedigree.individuals:\n                            pedigree.add_individual(phantom_grandparent_id, is_phantom=True)\n                        if phantom_parent1_id not in pedigree.individuals:\n                            pedigree.add_individual(phantom_parent1_id, is_phantom=True)\n                        if phantom_parent2_id not in pedigree.individuals:\n                            pedigree.add_individual(phantom_parent2_id, is_phantom=True)\n                        \n                        # Add relationships\n                        pedigree.add_relationship(phantom_grandparent_id, phantom_parent1_id, certainty=probability, rel_type='parent-child')\n                        pedigree.add_relationship(phantom_grandparent_id, phantom_parent2_id, certainty=probability, rel_type='parent-child')\n                        pedigree.add_relationship(phantom_parent1_id, ind1, certainty=probability, rel_type='parent-child')\n                        pedigree.add_relationship(phantom_parent2_id, ind2, certainty=probability, rel_type='parent-child')\n        \n        return pedigree\n    \n    def _score_pedigree(self, pedigree):\n        \"\"\"\n        Calculate a score for the pedigree.\n        \n        Args:\n            pedigree: Pedigree object to score\n            \n        Returns:\n            float: Score (higher is better)\n        \"\"\"\n        # This is the same scoring function used in SimulatedAnnealingPedigreeOptimizer\n        # We'll use a simplified version here for clarity\n        \n        # 1. Calculate how well pedigree explains IBD segments\n        ibd_explanation_score = 0\n        \n        # Get all pairs in the pedigree with paths\n        pedigree_relationships = {}\n        for ind1 in pedigree.individuals:\n            for ind2 in pedigree.individuals:\n                if ind1 == ind2:\n                    continue\n                    \n                # Check if there's a path connecting them\n                try:\n                    path1 = nx.has_path(pedigree.graph, ind1, ind2)\n                    path2 = nx.has_path(pedigree.graph, ind2, ind1)\n                    if path1 or path2:\n                        # Try to determine relationship degree\n                        try:\n                            if path1:\n                                path_length = len(nx.shortest_path(pedigree.graph, ind1, ind2)) - 1\n                            else:\n                                path_length = len(nx.shortest_path(pedigree.graph, ind2, ind1)) - 1\n                            \n                            # Convert path length to expected cM\n                            if path_length == 1:  # Parent-child\n                                expected_cm = 3400\n                            elif path_length == 2:  # Grandparent or avuncular\n                                expected_cm = 1700\n                            elif path_length == 3:  # First cousin or great-grandparent\n                                expected_cm = 850\n                            elif path_length == 4:\n                                expected_cm = 425\n                            elif path_length == 5:\n                                expected_cm = 212\n                            else:\n                                expected_cm = 850 * (0.5 ** (path_length - 3))\n                            \n                            pedigree_relationships[(ind1, ind2)] = {\n                                'path_length': path_length,\n                                'expected_cm': expected_cm\n                            }\n                        except:\n                            # If there's an error calculating the path, use a default\n                            pedigree_relationships[(ind1, ind2)] = {\n                                'path_length': 0,\n                                'expected_cm': 0\n                            }\n                except:\n                    pass\n        \n        # Compare pedigree relationships with observed IBD\n        for pair, expected in pedigree_relationships.items():\n            # Check if this pair has observed IBD\n            observed_cm = self.pair_sharing.get((pair[0], pair[1]), 0)\n            if observed_cm == 0:\n                observed_cm = self.pair_sharing.get((pair[1], pair[0]), 0)\n            \n            # Calculate score contribution\n            expected_cm = expected['expected_cm']\n            \n            # Determine std based on relationship\n            if expected_cm > 3000:  # Parent-child\n                std_cm = 200\n            elif expected_cm > 2000:  # Full sibling\n                std_cm = 300\n            elif expected_cm > 1500:  # Half-sibling/grandparent\n                std_cm = 250\n            elif expected_cm > 700:  # First cousin\n                std_cm = 200\n            else:\n                std_cm = expected_cm * 0.2\n            \n            # Gaussian score\n            score_contrib = stats.norm.pdf(observed_cm, expected_cm, std_cm)\n            # Normalize to 0-1 range\n            score_contrib = score_contrib / stats.norm.pdf(expected_cm, expected_cm, std_cm)\n            \n            ibd_explanation_score += score_contrib\n        \n        # 2. Penalty for pairs with IBD but no path in pedigree\n        missing_relationship_penalty = 0\n        for (ind1, ind2), cm in self.pair_sharing.items():\n            if cm < 20:  # Ignore very small segments\n                continue\n                \n            # Check if there's a path in the pedigree\n            if (ind1, ind2) not in pedigree_relationships and (ind2, ind1) not in pedigree_relationships:\n                # Calculate penalty based on IBD amount\n                if cm > 1500:  # Close relationship\n                    penalty = 5.0\n                elif cm > 700:  # First cousin level\n                    penalty = 2.0\n                elif cm > 300:  # Second cousin level\n                    penalty = 1.0\n                elif cm > 100:  # Distant relationship\n                    penalty = 0.5\n                else:\n                    penalty = 0.1\n                    \n                missing_relationship_penalty += penalty\n        \n        # 3. Complexity penalty\n        num_edges = pedigree.graph.number_of_edges()\n        phantom_nodes = sum(1 for n, attrs in pedigree.individuals.items() if attrs.get('is_phantom', False))\n        \n        # Penalize complexity\n        complexity_penalty = 0.1 * num_edges + 0.5 * phantom_nodes\n        \n        # 4. Consistency score\n        consistency_score = 10 if pedigree.is_consistent() else 0\n        \n        # Combine all scoring components\n        total_score = ibd_explanation_score - missing_relationship_penalty - complexity_penalty + consistency_score\n        \n        return total_score\n    \n    def _select_parent(self, scores):\n        \"\"\"\n        Select a parent for crossover using tournament selection.\n        \n        Args:\n            scores: List of scores for each pedigree\n            \n        Returns:\n            int: Index of the selected parent\n        \"\"\"\n        # Tournament selection\n        # Select k individuals at random and return the best\n        k = 3  # Tournament size\n        indices = random.sample(range(len(scores)), k)\n        best_idx = max(indices, key=lambda i: scores[i])\n        return best_idx\n    \n    def _crossover(self, parent1, parent2):\n        \"\"\"\n        Create a child pedigree by combining elements from two parents.\n        \n        Args:\n            parent1: First parent pedigree\n            parent2: Second parent pedigree\n            \n        Returns:\n            Pedigree: Child pedigree\n        \"\"\"\n        # Create a new empty pedigree\n        child = Pedigree()\n        \n        # Add all individuals from both parents\n        all_individuals = set(parent1.individuals.keys()).union(set(parent2.individuals.keys()))\n        for ind_id in all_individuals:\n            # Get attributes from either parent\n            attrs = {}\n            if ind_id in parent1.individuals:\n                attrs = parent1.individuals[ind_id].copy()\n            elif ind_id in parent2.individuals:\n                attrs = parent2.individuals[ind_id].copy()\n            \n            # Add individual to child\n            child.add_individual(ind_id, **attrs)\n        \n        # Cross over relationships\n        # We'll take some relationships from parent1 and some from parent2\n        \n        # Get all edges from both parents\n        all_edges = set(parent1.graph.edges()).union(set(parent2.graph.edges()))\n        \n        # Sort edges to ensure deterministic behavior\n        all_edges = sorted(all_edges)\n        \n        # For each edge, randomly choose whether to include it in the child\n        for parent, child_id in all_edges:\n            # Skip if either node doesn't exist in the child\n            if parent not in child.individuals or child_id not in child.individuals:\n                continue\n                \n            # Get relationship attributes from the appropriate parent\n            attrs = {}\n            if (parent, child_id) in parent1.graph.edges():\n                attrs = parent1.graph.edges[parent, child_id].copy()\n            elif (parent, child_id) in parent2.graph.edges():\n                attrs = parent2.graph.edges[parent, child_id].copy()\n            \n            # Decide whether to add this relationship to the child\n            if random.random() < 0.5:\n                # Check if this would create a cycle (skip if it would)\n                if not child.would_create_cycle(parent, child_id):\n                    child.add_relationship(parent, child_id, **attrs)\n        \n        return child\n    \n    def _mutate(self, pedigree, mutation_rate=0.1):\n        \"\"\"\n        Apply random mutations to a pedigree.\n        \n        Args:\n            pedigree: Pedigree to mutate\n            mutation_rate: Probability of each mutation type\n            \n        Returns:\n            Pedigree: Mutated pedigree\n        \"\"\"\n        # Create a copy of the pedigree\n        mutated = pedigree.copy()\n        \n        # 1. Randomly remove some relationships\n        for parent, child in list(mutated.graph.edges()):  # Create a list to avoid modifying during iteration\n            if random.random() < mutation_rate:\n                mutated.graph.remove_edge(parent, child)\n                if (parent, child) in mutated.relationships:\n                    del mutated.relationships[(parent, child)]\n        \n        # 2. Randomly add some relationships\n        # For each pair with significant IBD\n        for (ind1, ind2), cm in self.pair_sharing.items():\n            if cm < 100:  # Only consider pairs with meaningful IBD\n                continue\n                \n            if random.random() < mutation_rate * (cm / 3500):  # Higher probability for higher IBD\n                # Determine relationship type based on cM\n                if cm > 2800:  # Likely parent-child\n                    # Try to determine direction\n                    ind1_birth = mutated.individuals.get(ind1, {}).get('birth_year')\n                    ind2_birth = mutated.individuals.get(ind2, {}).get('birth_year')\n                    \n                    if ind1_birth is not None and ind2_birth is not None:\n                        if ind1_birth < ind2_birth:\n                            parent, child = ind1, ind2\n                        else:\n                            parent, child = ind2, ind1\n                    else:\n                        # Without birth years, use random direction\n                        if random.random() < 0.5:\n                            parent, child = ind1, ind2\n                        else:\n                            parent, child = ind2, ind1\n                    \n                    # Check if adding this relationship would be valid\n                    if not mutated.would_create_cycle(parent, child):\n                        mutated.add_relationship(parent, child, rel_type='parent-child')\n        \n        # 3. Randomly add phantom nodes to connect individuals\n        if random.random() < mutation_rate:\n            # Select two random individuals with IBD but no connection\n            disconnected_pairs = []\n            for (ind1, ind2), cm in self.pair_sharing.items():\n                if cm < 100:  # Only consider pairs with meaningful IBD\n                    continue\n                    \n                # Check if there's a path in the pedigree\n                try:\n                    path1 = nx.has_path(mutated.graph, ind1, ind2)\n                    path2 = nx.has_path(mutated.graph, ind2, ind1)\n                    if not (path1 or path2):\n                        disconnected_pairs.append((ind1, ind2, cm))\n                except:\n                    disconnected_pairs.append((ind1, ind2, cm))\n            \n            if disconnected_pairs:\n                # Select a random pair, with higher probability for higher IBD\n                weights = [cm for _, _, cm in disconnected_pairs]\n                total_weight = sum(weights)\n                if total_weight > 0:\n                    r = random.uniform(0, total_weight)\n                    cum_weight = 0\n                    for idx, (ind1, ind2, cm) in enumerate(disconnected_pairs):\n                        cum_weight += cm\n                        if cum_weight >= r:\n                            selected_pair = (ind1, ind2)\n                            break\n                    else:\n                        selected_pair = disconnected_pairs[-1][:2]\n                    \n                    # Add a phantom node to connect them\n                    phantom_id = f\"phantom_mutation_{ind1}_{ind2}\"\n                    \n                    # Add phantom node\n                    if phantom_id not in mutated.individuals:\n                        mutated.add_individual(phantom_id, is_phantom=True)\n                    \n                    # Add relationships\n                    mutated.add_relationship(phantom_id, ind1, rel_type='connection')\n                    mutated.add_relationship(phantom_id, ind2, rel_type='connection')\n        \n        return mutated\n    \n    def optimize(self, generations=50, mutation_rate=0.1):\n        \"\"\"\n        Run the genetic algorithm optimization process.\n        \n        Args:\n            generations: Number of generations to evolve\n            mutation_rate: Probability of mutation\n            \n        Returns:\n            tuple: (best_pedigree, metrics)\n        \"\"\"\n        # Initialize metrics\n        metrics = {\n            'generations': 0,\n            'population_size': self.population_size,\n            'mean_score_history': [],\n            'max_score_history': [],\n            'best_score': self.best_score\n        }\n        \n        # Main loop\n        progress_bar = tqdm(total=generations, desc=\"Evolving Pedigrees\")\n        \n        for generation in range(generations):\n            # Evaluate all pedigrees\n            scores = [self._score_pedigree(p) for p in self.population]\n            \n            # Update metrics\n            mean_score = sum(scores) / len(scores)\n            max_score = max(scores)\n            metrics['mean_score_history'].append(mean_score)\n            metrics['max_score_history'].append(max_score)\n            \n            # Update best pedigree if improved\n            best_idx = scores.index(max_score)\n            if max_score > self.best_score:\n                self.best_pedigree = self.population[best_idx].copy()\n                self.best_score = max_score\n                metrics['best_score'] = max_score\n            \n            # Create next generation\n            next_generation = []\n            \n            # Elitism: keep the best individual\n            next_generation.append(self.population[best_idx].copy())\n            \n            # Create the rest through crossover and mutation\n            while len(next_generation) < self.population_size:\n                # Select parents\n                parent1_idx = self._select_parent(scores)\n                parent2_idx = self._select_parent(scores)\n                \n                # Create child through crossover\n                child = self._crossover(self.population[parent1_idx], self.population[parent2_idx])\n                \n                # Apply mutation\n                if random.random() < mutation_rate:\n                    child = self._mutate(child, mutation_rate)\n                \n                # Add to next generation\n                next_generation.append(child)\n            \n            # Replace population\n            self.population = next_generation\n            \n            # Update progress bar\n            progress_bar.update(1)\n        \n        progress_bar.close()\n        \n        # Final update to metrics\n        metrics['generations'] = generations\n        \n        return self.best_pedigree, metrics\n\n# Test the genetic algorithm with the synthetic data\n# Initialize the optimizer\nga_optimizer = GeneticPedigreeOptimizer(synthetic_segments, synthetic_individuals, population_size=10)\n\n# Run the optimization\nga_best_pedigree, ga_metrics = ga_optimizer.optimize(generations=20, mutation_rate=0.2)\n\n# Display metrics\nprint(\"\\nGenetic Algorithm Metrics:\")\nprint(f\"Generations: {ga_metrics['generations']}\")\nprint(f\"Population size: {ga_metrics['population_size']}\")\nprint(f\"Initial best score: {ga_metrics['max_score_history'][0]}\")\nprint(f\"Final best score: {ga_metrics['max_score_history'][-1]}\")\nprint(f\"Overall best score: {ga_metrics['best_score']}\")\n\n# Compare with previous methods\nsa_score = optimizer._score_pedigree(best_pedigree)\nga_score = optimizer._score_pedigree(ga_best_pedigree)\ngreedy_score = optimizer._score_pedigree(initial_pedigree)\n\nprint(\"\\nComparison of All Methods:\")\nprint(f\"Greedy algorithm score: {greedy_score}\")\nprint(f\"Simulated annealing score: {sa_score}\")\nprint(f\"Genetic algorithm score: {ga_score}\")\n\n# Plot evolution of scores during genetic algorithm\nplt.figure(figsize=(10, 6))\nplt.plot(ga_metrics['mean_score_history'], 'b-', label='Mean Score')\nplt.plot(ga_metrics['max_score_history'], 'r-', label='Max Score')\nplt.xlabel('Generation')\nplt.ylabel('Score')\nplt.title('Evolution of Pedigree Scores in Genetic Algorithm')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# Visualize the genetic algorithm's best pedigree\nplt.figure(figsize=(12, 8))\nga_best_pedigree.visualize()\nplt.title('Best Pedigree from Genetic Algorithm')\nplt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<cell_type>markdown</cell_type>## 3. Comparing Optimization Approaches\n\nNow that we've implemented and tested three different optimization approaches (greedy incremental construction, simulated annealing, and genetic algorithms), let's compare their effectiveness, efficiency, and suitability for different pedigree reconstruction scenarios.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's systematically compare our three optimization approaches\n# Create a function to run all three methods on the same data and compare results\n\ndef compare_optimization_methods(ibd_data, individuals_metadata, \n                               greedy_min_certainty=0.3,\n                               sa_iterations=200, sa_initial_temp=10.0, sa_cooling_rate=0.01, sa_min_temp=0.1,\n                               ga_population_size=10, ga_generations=20, ga_mutation_rate=0.2):\n    \"\"\"\n    Compare the three optimization methods on the same dataset.\n    \n    Args:\n        ibd_data: DataFrame with IBD segments\n        individuals_metadata: DataFrame with individual metadata\n        greedy_min_certainty: Minimum certainty for greedy algorithm\n        sa_iterations, sa_initial_temp, sa_cooling_rate, sa_min_temp: Simulated annealing parameters\n        ga_population_size, ga_generations, ga_mutation_rate: Genetic algorithm parameters\n        \n    Returns:\n        tuple: (results_df, best_pedigrees)\n    \"\"\"\n    results = []\n    best_pedigrees = {}\n    \n    # Run greedy algorithm\n    print(\"Running greedy incremental construction...\")\n    start_time = time.time()\n    greedy_builder = GreedyPedigreeBuilder(ibd_data, individuals_metadata)\n    greedy_pedigree, greedy_metrics = greedy_builder.build_pedigree(min_certainty=greedy_min_certainty)\n    greedy_time = time.time() - start_time\n    \n    # Score greedy pedigree\n    scorer = SimulatedAnnealingPedigreeOptimizer(greedy_pedigree, ibd_data, individuals_metadata)\n    greedy_score = scorer._score_pedigree(greedy_pedigree)\n    \n    # Save results\n    results.append({\n        'Method': 'Greedy Incremental Construction',\n        'Score': greedy_score,\n        'Time (s)': greedy_time,\n        'Num Individuals': len(greedy_pedigree.individuals),\n        'Num Relationships': greedy_pedigree.graph.number_of_edges(),\n        'Num Phantom Nodes': sum(1 for _, attrs in greedy_pedigree.individuals.items() if attrs.get('is_phantom', False))\n    })\n    best_pedigrees['Greedy'] = greedy_pedigree\n    \n    # Run simulated annealing\n    print(\"Running simulated annealing...\")\n    start_time = time.time()\n    sa_optimizer = SimulatedAnnealingPedigreeOptimizer(greedy_pedigree, ibd_data, individuals_metadata)\n    sa_pedigree, sa_metrics = sa_optimizer.optimize(\n        max_iterations=sa_iterations,\n        initial_temp=sa_initial_temp,\n        cooling_rate=sa_cooling_rate,\n        min_temp=sa_min_temp\n    )\n    sa_time = time.time() - start_time\n    sa_score = scorer._score_pedigree(sa_pedigree)\n    \n    # Save results\n    results.append({\n        'Method': 'Simulated Annealing',\n        'Score': sa_score,\n        'Time (s)': sa_time,\n        'Num Individuals': len(sa_pedigree.individuals),\n        'Num Relationships': sa_pedigree.graph.number_of_edges(),\n        'Num Phantom Nodes': sum(1 for _, attrs in sa_pedigree.individuals.items() if attrs.get('is_phantom', False))\n    })\n    best_pedigrees['Simulated Annealing'] = sa_pedigree\n    \n    # Run genetic algorithm\n    print(\"Running genetic algorithm...\")\n    start_time = time.time()\n    ga_optimizer = GeneticPedigreeOptimizer(ibd_data, individuals_metadata, population_size=ga_population_size)\n    ga_pedigree, ga_metrics = ga_optimizer.optimize(generations=ga_generations, mutation_rate=ga_mutation_rate)\n    ga_time = time.time() - start_time\n    ga_score = scorer._score_pedigree(ga_pedigree)\n    \n    # Save results\n    results.append({\n        'Method': 'Genetic Algorithm',\n        'Score': ga_score,\n        'Time (s)': ga_time,\n        'Num Individuals': len(ga_pedigree.individuals),\n        'Num Relationships': ga_pedigree.graph.number_of_edges(),\n        'Num Phantom Nodes': sum(1 for _, attrs in ga_pedigree.individuals.items() if attrs.get('is_phantom', False))\n    })\n    best_pedigrees['Genetic Algorithm'] = ga_pedigree\n    \n    # Create DataFrame\n    results_df = pd.DataFrame(results)\n    \n    return results_df, best_pedigrees\n\n# Run the comparison on our synthetic data\nprint(\"Comparing optimization methods on synthetic data...\")\ncomparison_results, best_pedigrees = compare_optimization_methods(\n    synthetic_segments, synthetic_individuals,\n    greedy_min_certainty=0.3,\n    sa_iterations=150,  # Reduced for demonstration\n    sa_initial_temp=10.0,\n    sa_cooling_rate=0.01,\n    sa_min_temp=0.1,\n    ga_population_size=8,  # Reduced for demonstration\n    ga_generations=15,    # Reduced for demonstration\n    ga_mutation_rate=0.2\n)\n\n# Display results\nprint(\"\\nOptimization Method Comparison:\")\ndisplay(comparison_results)\n\n# Create a bar chart comparing the methods\nplt.figure(figsize=(10, 6))\ncomparison_results.set_index('Method')['Score'].plot(kind='bar', color=['blue', 'green', 'orange'])\nplt.title('Pedigree Score by Optimization Method')\nplt.ylabel('Score')\nplt.xticks(rotation=45)\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Create a bar chart comparing execution time\nplt.figure(figsize=(10, 6))\ncomparison_results.set_index('Method')['Time (s)'].plot(kind='bar', color=['blue', 'green', 'orange'])\nplt.title('Execution Time by Optimization Method')\nplt.ylabel('Time (seconds)')\nplt.xticks(rotation=45)\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Create a grouped bar chart for structural comparison\ncomparison_results_melted = pd.melt(\n    comparison_results, \n    id_vars=['Method'], \n    value_vars=['Num Individuals', 'Num Relationships', 'Num Phantom Nodes'],\n    var_name='Metric', \n    value_name='Count'\n)\n\nplt.figure(figsize=(12, 6))\nsns.barplot(data=comparison_results_melted, x='Method', y='Count', hue='Metric')\nplt.title('Structural Comparison of Pedigrees')\nplt.xlabel('')\nplt.xticks(rotation=45)\nplt.legend(title='')\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Display the best pedigree from each method for visual comparison\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\nfor i, (method, pedigree) in enumerate(best_pedigrees.items()):\n    plt.sca(axes[i])\n    pedigree.visualize()\n    plt.title(f'Best Pedigree: {method}')\n    plt.tight_layout()\n\nplt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<cell_type>markdown</cell_type>### 3.1 Optimization Algorithm Tradeoffs\n\nLet's analyze the tradeoffs between our three optimization approaches:\n\n1. **Greedy Incremental Construction**\n   - **Advantages**: Fast, simple to implement, good for initializing other methods\n   - **Disadvantages**: Gets stuck in local optima, order-dependent, doesn't handle conflicting evidence well\n   - **Best for**: Small pedigrees, well-separated relationships, initial exploration, generating starting points for other optimization methods\n\n2. **Simulated Annealing**\n   - **Advantages**: Can escape local optima, flexible move operators, single sequence to track/debug\n   - **Disadvantages**: Parameter tuning required (cooling schedule), slower than greedy\n   - **Best for**: Medium-sized pedigrees with complex relationships, refining greedy solutions\n\n3. **Genetic Algorithms**\n   - **Advantages**: Explores multiple solutions in parallel, good for large search spaces, resistant to getting stuck\n   - **Disadvantages**: Implementation complexity, resource intensive, difficult to engineer effective crossover\n   - **Best for**: Large pedigrees, exploring diverse solution topologies, problems with many local optima\n\nIn real-world applications, Bonsai often uses these methods in combination:\n1. Begin with greedy construction to build initial pedigree \n2. Refine with simulated annealing for better local structure\n3. Use genetic algorithms for exploring alternative global structures",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<cell_type>markdown</cell_type>### 3.2 Hybrid Approach\n\nLet's implement a hybrid optimization approach that combines the strengths of each method:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's implement a hybrid optimization approach\nclass HybridPedigreeOptimizer:\n    \"\"\"\n    A hybrid optimization approach for pedigree reconstruction that combines\n    greedy construction, simulated annealing, and genetic algorithms.\n    \"\"\"\n    \n    def __init__(self, ibd_data, individuals_metadata=None):\n        \"\"\"\n        Initialize the optimizer.\n        \n        Args:\n            ibd_data: DataFrame with IBD segments\n            individuals_metadata: Optional DataFrame with metadata about individuals\n        \"\"\"\n        self.ibd_data = ibd_data\n        self.individuals_metadata = individuals_metadata\n        \n        # Store the best pedigree and score\n        self.best_pedigree = None\n        self.best_score = float('-inf')\n    \n    def optimize(self, greedy_min_certainties=None, \n                 sa_iterations=100, sa_cooling_rates=None, \n                 ga_population_size=10, ga_generations=15):\n        \"\"\"\n        Run the hybrid optimization process.\n        \n        Args:\n            greedy_min_certainties: List of certainty thresholds for greedy construction\n            sa_iterations: Number of iterations for simulated annealing\n            sa_cooling_rates: List of cooling rates for simulated annealing\n            ga_population_size: Size of the population for genetic algorithm\n            ga_generations: Number of generations for genetic algorithm\n            \n        Returns:\n            tuple: (best_pedigree, metrics)\n        \"\"\"\n        # Default parameter values\n        if greedy_min_certainties is None:\n            greedy_min_certainties = [0.3, 0.4, 0.5, 0.6]\n        \n        if sa_cooling_rates is None:\n            sa_cooling_rates = [0.005, 0.01, 0.02]\n        \n        # Initialize metrics\n        metrics = {\n            'greedy_pedigrees': [],\n            'sa_pedigrees': [],\n            'ga_best_pedigree': None,\n            'score_progression': [],\n            'time_greedy': 0,\n            'time_sa': 0,\n            'time_ga': 0,\n            'total_time': 0\n        }\n        \n        start_total_time = time.time()\n        \n        # Step 1: Generate different greedy pedigrees with varying certainty thresholds\n        print(\"Step 1: Generating greedy pedigrees with different certainty thresholds...\")\n        start_time = time.time()\n        \n        greedy_pedigrees = []\n        for min_certainty in greedy_min_certainties:\n            print(f\"  Building greedy pedigree with min_certainty={min_certainty}...\")\n            builder = GreedyPedigreeBuilder(self.ibd_data, self.individuals_metadata)\n            pedigree, _ = builder.build_pedigree(min_certainty=min_certainty)\n            greedy_pedigrees.append(pedigree)\n            \n            # Score the pedigree\n            scorer = SimulatedAnnealingPedigreeOptimizer(pedigree, self.ibd_data, self.individuals_metadata)\n            score = scorer._score_pedigree(pedigree)\n            \n            # Update best if improved\n            if score > self.best_score:\n                self.best_pedigree = pedigree.copy()\n                self.best_score = score\n            \n            # Update metrics\n            metrics['greedy_pedigrees'].append({\n                'min_certainty': min_certainty,\n                'score': score,\n                'num_relationships': pedigree.graph.number_of_edges()\n            })\n            metrics['score_progression'].append({\n                'step': 'greedy',\n                'parameter': min_certainty,\n                'score': score\n            })\n        \n        metrics['time_greedy'] = time.time() - start_time\n        \n        # Step 2: Apply simulated annealing to each greedy pedigree with different cooling rates\n        print(\"\\nStep 2: Refining with simulated annealing using different cooling rates...\")\n        start_time = time.time()\n        \n        sa_pedigrees = []\n        for i, pedigree in enumerate(greedy_pedigrees):\n            for cooling_rate in sa_cooling_rates:\n                print(f\"  Running SA on greedy pedigree {i+1} with cooling_rate={cooling_rate}...\")\n                sa_optimizer = SimulatedAnnealingPedigreeOptimizer(pedigree, self.ibd_data, self.individuals_metadata)\n                sa_pedigree, _ = sa_optimizer.optimize(\n                    max_iterations=sa_iterations,\n                    initial_temp=10.0,\n                    cooling_rate=cooling_rate,\n                    min_temp=0.1\n                )\n                sa_pedigrees.append(sa_pedigree)\n                \n                # Score the pedigree\n                scorer = SimulatedAnnealingPedigreeOptimizer(sa_pedigree, self.ibd_data, self.individuals_metadata)\n                score = scorer._score_pedigree(sa_pedigree)\n                \n                # Update best if improved\n                if score > self.best_score:\n                    self.best_pedigree = sa_pedigree.copy()\n                    self.best_score = score\n                \n                # Update metrics\n                metrics['sa_pedigrees'].append({\n                    'greedy_index': i,\n                    'cooling_rate': cooling_rate,\n                    'score': score,\n                    'num_relationships': sa_pedigree.graph.number_of_edges()\n                })\n                metrics['score_progression'].append({\n                    'step': 'simulated_annealing',\n                    'parameter': cooling_rate,\n                    'score': score\n                })\n        \n        metrics['time_sa'] = time.time() - start_time\n        \n        # Step 3: Use genetic algorithm with the best pedigrees so far as part of the initial population\n        print(\"\\nStep 3: Running genetic algorithm with best pedigrees as seed population...\")\n        start_time = time.time()\n        \n        # Collect all pedigrees from previous steps\n        all_pedigrees = greedy_pedigrees + sa_pedigrees\n        \n        # Sort by score\n        pedigree_scores = []\n        for p in all_pedigrees:\n            scorer = SimulatedAnnealingPedigreeOptimizer(p, self.ibd_data, self.individuals_metadata)\n            pedigree_scores.append((p, scorer._score_pedigree(p)))\n        \n        pedigree_scores.sort(key=lambda x: x[1], reverse=True)\n        \n        # Take the top pedigrees as initial population for GA\n        initial_population = [p for p, _ in pedigree_scores[:min(ga_population_size, len(pedigree_scores))]]\n        \n        # If we need more for the population, create random ones\n        while len(initial_population) < ga_population_size:\n            print(f\"  Adding random pedigree to initial GA population...\")\n            ga_optimizer = GeneticPedigreeOptimizer(self.ibd_data, self.individuals_metadata, population_size=1)\n            random_pedigree = ga_optimizer._create_random_pedigree()\n            initial_population.append(random_pedigree)\n        \n        # Create custom GA optimizer that starts with our population\n        class SeededGeneticPedigreeOptimizer(GeneticPedigreeOptimizer):\n            def __init__(self, ibd_data, initial_population, individuals_metadata=None):\n                self.ibd_data = ibd_data\n                self.individuals_metadata = individuals_metadata\n                self.population_size = len(initial_population)\n                \n                # Use the provided initial population\n                self.population = initial_population\n                \n                # Store all individuals\n                self.all_individuals = set(ibd_data['sample1']).union(set(ibd_data['sample2']))\n                \n                # Calculate IBD sharing between pairs for quick lookup\n                self.pair_sharing = self._calculate_pair_sharing()\n                \n                # Evaluate the population\n                population_with_scores = [(p, self._score_pedigree(p)) for p in self.population]\n                population_with_scores.sort(key=lambda x: x[1], reverse=True)\n                \n                # Track the best solution\n                self.best_pedigree = population_with_scores[0][0].copy()\n                self.best_score = population_with_scores[0][1]\n        \n        # Run the genetic algorithm with the seeded population\n        print(f\"  Running GA with population_size={ga_population_size}, generations={ga_generations}...\")\n        ga_optimizer = SeededGeneticPedigreeOptimizer(self.ibd_data, initial_population, self.individuals_metadata)\n        ga_pedigree, ga_metrics = ga_optimizer.optimize(generations=ga_generations, mutation_rate=0.2)\n        \n        # Score the pedigree\n        scorer = SimulatedAnnealingPedigreeOptimizer(ga_pedigree, self.ibd_data, self.individuals_metadata)\n        ga_score = scorer._score_pedigree(ga_pedigree)\n        \n        # Update best if improved\n        if ga_score > self.best_score:\n            self.best_pedigree = ga_pedigree.copy()\n            self.best_score = ga_score\n        \n        # Update metrics\n        metrics['ga_best_pedigree'] = {\n            'score': ga_score,\n            'num_relationships': ga_pedigree.graph.number_of_edges()\n        }\n        metrics['score_progression'].append({\n            'step': 'genetic_algorithm',\n            'parameter': ga_generations,\n            'score': ga_score\n        })\n        \n        metrics['time_ga'] = time.time() - start_time\n        metrics['total_time'] = time.time() - start_total_time\n        \n        print(\"\\nHybrid optimization complete!\")\n        print(f\"Best score: {self.best_score}\")\n        \n        return self.best_pedigree, metrics\n\n# Let's test our hybrid approach on the synthetic data\nprint(\"Running hybrid optimization on synthetic data...\")\nhybrid_optimizer = HybridPedigreeOptimizer(synthetic_segments, synthetic_individuals)\n\n# Run with reduced parameters for demonstration purposes\nhybrid_best_pedigree, hybrid_metrics = hybrid_optimizer.optimize(\n    greedy_min_certainties=[0.3, 0.5],\n    sa_iterations=75,  # Reduced for demonstration\n    sa_cooling_rates=[0.01, 0.02],\n    ga_population_size=6,  # Reduced for demonstration\n    ga_generations=10  # Reduced for demonstration\n)\n\n# Display timing information\nprint(\"\\nExecution times:\")\nprint(f\"Greedy phase: {hybrid_metrics['time_greedy']:.2f} seconds\")\nprint(f\"Simulated annealing phase: {hybrid_metrics['time_sa']:.2f} seconds\")\nprint(f\"Genetic algorithm phase: {hybrid_metrics['time_ga']:.2f} seconds\")\nprint(f\"Total time: {hybrid_metrics['total_time']:.2f} seconds\")\n\n# Create a DataFrame for the score progression\nscore_progression_df = pd.DataFrame(hybrid_metrics['score_progression'])\nprint(\"\\nScore progression:\")\ndisplay(score_progression_df)\n\n# Plot the score progression\nplt.figure(figsize=(12, 6))\ncolors = {'greedy': 'blue', 'simulated_annealing': 'green', 'genetic_algorithm': 'orange'}\nmarkers = {'greedy': 'o', 'simulated_annealing': 's', 'genetic_algorithm': '^'}\n\nfor step in score_progression_df['step'].unique():\n    step_data = score_progression_df[score_progression_df['step'] == step]\n    plt.scatter(\n        range(len(step_data)), \n        step_data['score'], \n        label=step.replace('_', ' ').title(),\n        color=colors.get(step, 'gray'),\n        marker=markers.get(step, 'x'),\n        s=100\n    )\n\nplt.plot(range(len(score_progression_df)), score_progression_df['score'], 'k-', alpha=0.3)\nplt.axhline(y=hybrid_optimizer.best_score, color='r', linestyle='--', alpha=0.7, label='Best Score')\n\nplt.xlabel('Optimization Step')\nplt.ylabel('Score')\nplt.title('Score Progression During Hybrid Optimization')\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n# Visualize the final pedigree\nplt.figure(figsize=(12, 8))\nhybrid_best_pedigree.visualize()\nplt.title('Best Pedigree from Hybrid Approach')\nplt.show()\n\n# Compare the hybrid approach with the individual methods\nprint(\"\\nFinal comparison:\")\nfinal_comparison = pd.DataFrame([\n    {\n        'Method': 'Greedy',\n        'Score': optimizer._score_pedigree(initial_pedigree),\n        'Num Relationships': initial_pedigree.graph.number_of_edges()\n    },\n    {\n        'Method': 'Simulated Annealing',\n        'Score': optimizer._score_pedigree(best_pedigree),\n        'Num Relationships': best_pedigree.graph.number_of_edges()\n    },\n    {\n        'Method': 'Genetic Algorithm',\n        'Score': optimizer._score_pedigree(ga_best_pedigree),\n        'Num Relationships': ga_best_pedigree.graph.number_of_edges()\n    },\n    {\n        'Method': 'Hybrid Approach',\n        'Score': optimizer._score_pedigree(hybrid_best_pedigree),\n        'Num Relationships': hybrid_best_pedigree.graph.number_of_edges()\n    }\n])\n\ndisplay(final_comparison)\n\n# Plot the final comparison\nplt.figure(figsize=(10, 6))\nfinal_comparison.set_index('Method')['Score'].plot(kind='bar', color=['blue', 'green', 'orange', 'red'])\nplt.title('Final Score Comparison')\nplt.ylabel('Score')\nplt.xticks(rotation=45)\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<cell_type>markdown</cell_type>## 4. Practical Considerations for Pedigree Optimization\n\nWhen applying these optimization techniques to real-world pedigree reconstruction problems, several practical considerations become important:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<cell_type>markdown</cell_type>### 4.1 Balancing Computational Resources\n\nPedigree optimization can be computationally intensive. Some strategies to manage resources:\n\n1. **Divide and conquer**: Split large pedigrees into smaller connected components\n2. **Incremental optimization**: Start with a subset of individuals, then grow the pedigree\n3. **Time budgeting**: Allocate computation time proportionally to pedigree size and complexity\n4. **Parallelization**: Run multiple optimization instances in parallel (especially for GA)\n5. **Early stopping**: Terminate optimization when improvements plateau\n\nLet's implement a simple utility to analyze the computational complexity of pedigree optimization:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Analyze computational complexity of pedigree optimization\ndef analyze_optimization_complexity(num_individuals_range):\n    \"\"\"\n    Analyze the computational complexity of different optimization methods.\n    \n    Args:\n        num_individuals_range: Range of numbers of individuals to analyze\n        \n    Returns:\n        DataFrame with complexity metrics\n    \"\"\"\n    complexity_metrics = []\n    \n    for num_individuals in num_individuals_range:\n        # Calculate theoretical complexity metrics\n        \n        # Search space size\n        search_space_size = 2 ** (num_individuals * (num_individuals - 1))\n        \n        # Greedy algorithm complexity\n        # O(n^2) for considering all pairs, with additional factor for relationship determination\n        greedy_complexity = num_individuals**2 * math.log(num_individuals)\n        \n        # Simulated annealing complexity\n        # O(iterations * move_cost), where move_cost is typically O(log n) for graph operations\n        sa_iterations = 1000  # typical number\n        sa_complexity = sa_iterations * num_individuals * math.log(num_individuals)\n        \n        # Genetic algorithm complexity\n        # O(generations * population_size * (crossover_cost + mutation_cost + evaluation_cost))\n        ga_generations = 50  # typical number\n        ga_population = 20  # typical size\n        ga_evaluation_cost = num_individuals**2 * math.log(num_individuals)  # pedigree scoring\n        ga_complexity = ga_generations * ga_population * ga_evaluation_cost\n        \n        # Store metrics\n        complexity_metrics.append({\n            'Num Individuals': num_individuals,\n            'Search Space Size': search_space_size,\n            'Greedy Complexity': greedy_complexity,\n            'SA Complexity': sa_complexity,\n            'GA Complexity': ga_complexity,\n            'Hybrid Complexity': greedy_complexity + sa_complexity + ga_complexity\n        })\n    \n    return pd.DataFrame(complexity_metrics)\n\n# Run the analysis for different numbers of individuals\ncomplexity_df = analyze_optimization_complexity(range(5, 21, 5))\n\n# Format large numbers for display\ncomplexity_df['Search Space Size'] = complexity_df['Search Space Size'].apply(lambda x: f\"{x:.2e}\")\n\n# Display the results\nprint(\"Computational Complexity Analysis:\")\ndisplay(complexity_df)\n\n# Plot the complexity growth\nplt.figure(figsize=(12, 6))\n\ncomplexity_plot_df = analyze_optimization_complexity(range(5, 51, 5))\nplt.semilogy(complexity_plot_df['Num Individuals'], complexity_plot_df['Greedy Complexity'], 'b-', label='Greedy')\nplt.semilogy(complexity_plot_df['Num Individuals'], complexity_plot_df['SA Complexity'], 'g-', label='Simulated Annealing')\nplt.semilogy(complexity_plot_df['Num Individuals'], complexity_plot_df['GA Complexity'], 'r-', label='Genetic Algorithm')\n\nplt.xlabel('Number of Individuals')\nplt.ylabel('Computational Complexity (log scale)')\nplt.title('Scaling of Computational Complexity with Problem Size')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Function to estimate runtime based on problem size\ndef estimate_runtime(num_individuals, base_runtime, base_individuals):\n    \"\"\"\n    Estimate runtime for a given number of individuals based on a reference runtime.\n    \n    Args:\n        num_individuals: Number of individuals in the target problem\n        base_runtime: Runtime for the base problem (in seconds)\n        base_individuals: Number of individuals in the base problem\n        \n    Returns:\n        Estimated runtime in seconds\n    \"\"\"\n    # We'll use a complexity of O(n^2 * log(n)) as a rough approximation\n    complexity_ratio = (num_individuals**2 * math.log(num_individuals)) / (base_individuals**2 * math.log(base_individuals))\n    estimated_runtime = base_runtime * complexity_ratio\n    return estimated_runtime\n\n# Base runtime from our hybrid optimization\nbase_runtime = hybrid_metrics['total_time']\nbase_individuals = len(synthetic_individuals)\n\n# Estimate runtime for larger problems\nruntime_estimates = []\nfor n in [10, 20, 50, 100, 200, 500, 1000]:\n    runtime_sec = estimate_runtime(n, base_runtime, base_individuals)\n    \n    # Convert to appropriate time units\n    if runtime_sec < 60:\n        runtime_str = f\"{runtime_sec:.2f} seconds\"\n    elif runtime_sec < 3600:\n        runtime_str = f\"{runtime_sec/60:.2f} minutes\"\n    elif runtime_sec < 86400:\n        runtime_str = f\"{runtime_sec/3600:.2f} hours\"\n    else:\n        runtime_str = f\"{runtime_sec/86400:.2f} days\"\n    \n    runtime_estimates.append({\n        'Num Individuals': n,\n        'Estimated Runtime': runtime_str,\n        'Runtime (seconds)': runtime_sec\n    })\n\n# Display runtime estimates\nprint(\"\\nEstimated Runtimes:\")\ndisplay(pd.DataFrame(runtime_estimates))\n\n# Plot the runtime estimates\nplt.figure(figsize=(10, 6))\nruntime_df = pd.DataFrame(runtime_estimates)\nplt.semilogy(runtime_df['Num Individuals'], runtime_df['Runtime (seconds)'], 'o-', color='purple')\nplt.axhline(y=60, color='green', linestyle='--', alpha=0.7, label='1 minute')\nplt.axhline(y=3600, color='orange', linestyle='--', alpha=0.7, label='1 hour')\nplt.axhline(y=86400, color='red', linestyle='--', alpha=0.7, label='1 day')\n\nplt.xlabel('Number of Individuals')\nplt.ylabel('Estimated Runtime (seconds, log scale)')\nplt.title('Estimated Runtime vs. Problem Size')\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<cell_type>markdown</cell_type>### 4.2 Managing Uncertainty and Ambiguity\n\nReal-world genetic data often contains uncertainty and ambiguity that affects pedigree reconstruction:\n\n1. **Measurement errors**: IBD segments with incorrect boundaries or false positives\n2. **Missing individuals**: Pedigrees with \"phantom\" ancestors not in the dataset\n3. **Relationship ambiguity**: Multiple relationship types with similar IBD patterns\n4. **Endogamy**: Population groups with high levels of relatedness that complicate inference\n\nLet's implement a utility to analyze the robustness of our optimization algorithms to uncertainty:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Analyze robustness to uncertainty\ndef test_robustness_to_uncertainty(ibd_data, individuals_metadata, noise_levels=None):\n    \"\"\"\n    Test the robustness of optimization algorithms to different levels of noise.\n    \n    Args:\n        ibd_data: Original IBD segment data\n        individuals_metadata: Metadata about individuals\n        noise_levels: List of noise levels to test (standard deviation as fraction of mean)\n        \n    Returns:\n        DataFrame with robustness metrics\n    \"\"\"\n    if noise_levels is None:\n        noise_levels = [0.0, 0.05, 0.1, 0.2, 0.3]\n    \n    robustness_metrics = []\n    \n    # Get baseline results\n    print(\"Computing baseline results...\")\n    greedy_builder = GreedyPedigreeBuilder(ibd_data, individuals_metadata)\n    baseline_pedigree, _ = greedy_builder.build_pedigree(min_certainty=0.3)\n    scorer = SimulatedAnnealingPedigreeOptimizer(baseline_pedigree, ibd_data, individuals_metadata)\n    baseline_score = scorer._score_pedigree(baseline_pedigree)\n    \n    # For each noise level\n    for noise_level in noise_levels:\n        print(f\"\\nTesting noise level: {noise_level}\")\n        \n        # Create noisy IBD data by perturbing segment lengths\n        noisy_ibd = ibd_data.copy()\n        \n        if noise_level > 0:\n            # Add noise to segment lengths\n            mean_length = noisy_ibd['gen_seg_len'].mean()\n            std_dev = noise_level * mean_length\n            noise = np.random.normal(0, std_dev, len(noisy_ibd))\n            noisy_ibd['gen_seg_len'] = noisy_ibd['gen_seg_len'] + noise\n            \n            # Ensure segment lengths remain positive\n            noisy_ibd['gen_seg_len'] = noisy_ibd['gen_seg_len'].clip(lower=1)\n        \n        # Run greedy algorithm on noisy data\n        print(\"  Running greedy algorithm...\")\n        greedy_builder = GreedyPedigreeBuilder(noisy_ibd, individuals_metadata)\n        greedy_pedigree, _ = greedy_builder.build_pedigree(min_certainty=0.3)\n        \n        # Score the greedy pedigree against the original data (to measure robustness)\n        greedy_score_on_original = scorer._score_pedigree(greedy_pedigree)\n        greedy_score_ratio = greedy_score_on_original / baseline_score\n        \n        # Run simulated annealing on noisy data\n        print(\"  Running simulated annealing...\")\n        sa_optimizer = SimulatedAnnealingPedigreeOptimizer(greedy_pedigree, noisy_ibd, individuals_metadata)\n        sa_pedigree, _ = sa_optimizer.optimize(\n            max_iterations=100,  # Reduced for demonstration\n            initial_temp=10.0,\n            cooling_rate=0.01,\n            min_temp=0.1\n        )\n        \n        # Score the SA pedigree against the original data\n        sa_score_on_original = scorer._score_pedigree(sa_pedigree)\n        sa_score_ratio = sa_score_on_original / baseline_score\n        \n        # Store metrics\n        robustness_metrics.append({\n            'Noise Level': noise_level,\n            'Greedy Score': greedy_score_on_original,\n            'Greedy Score Ratio': greedy_score_ratio,\n            'SA Score': sa_score_on_original,\n            'SA Score Ratio': sa_score_ratio\n        })\n    \n    return pd.DataFrame(robustness_metrics)\n\n# Set a random seed for reproducibility\nnp.random.seed(42)\n\n# Test robustness with lower noise levels for demonstration\nprint(\"Testing robustness to uncertainty...\")\nrobustness_df = test_robustness_to_uncertainty(\n    synthetic_segments, synthetic_individuals,\n    noise_levels=[0.0, 0.05, 0.1, 0.15, 0.2]\n)\n\n# Display the results\nprint(\"\\nRobustness to Uncertainty:\")\ndisplay(robustness_df)\n\n# Plot the robustness results\nplt.figure(figsize=(10, 6))\n\nplt.plot(robustness_df['Noise Level'], robustness_df['Greedy Score Ratio'], 'b-o', label='Greedy Algorithm')\nplt.plot(robustness_df['Noise Level'], robustness_df['SA Score Ratio'], 'g-o', label='Simulated Annealing')\n\nplt.xlabel('Noise Level (fraction of mean)')\nplt.ylabel('Score Ratio (noisy/baseline)')\nplt.title('Robustness to Noise in IBD Data')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Let's also look at relationship identification consistency\ndef analyze_relationship_consistency(pedigree1, pedigree2):\n    \"\"\"\n    Analyze the consistency of relationships between two pedigrees.\n    \n    Args:\n        pedigree1: First pedigree\n        pedigree2: Second pedigree\n        \n    Returns:\n        dict: Consistency metrics\n    \"\"\"\n    # Get all edges from both pedigrees\n    edges1 = set(pedigree1.graph.edges())\n    edges2 = set(pedigree2.graph.edges())\n    \n    # Calculate consistency metrics\n    common_edges = edges1.intersection(edges2)\n    only_in_1 = edges1 - edges2\n    only_in_2 = edges2 - edges1\n    \n    # Calculate consistency scores\n    if len(edges1) > 0 and len(edges2) > 0:\n        jaccard = len(common_edges) / len(edges1.union(edges2))\n        precision = len(common_edges) / len(edges1) if len(edges1) > 0 else 0\n        recall = len(common_edges) / len(edges2) if len(edges2) > 0 else 0\n        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n    else:\n        jaccard = precision = recall = f1 = 0\n    \n    return {\n        'Common Edges': len(common_edges),\n        'Only in First': len(only_in_1),\n        'Only in Second': len(only_in_2),\n        'Jaccard Similarity': jaccard,\n        'Precision': precision,\n        'Recall': recall,\n        'F1 Score': f1\n    }\n\n# Compare relationship consistency across noise levels\nprint(\"\\nAnalyzing relationship consistency across noise levels...\")\nconsistency_metrics = []\n\nfor i in range(len(robustness_df) - 1):\n    noise_level = robustness_df.iloc[i+1]['Noise Level']\n    \n    # Run optimization on original and noisy data\n    print(f\"  Testing noise level: {noise_level}\")\n    \n    # Create noisy IBD data\n    noisy_ibd = synthetic_segments.copy()\n    mean_length = noisy_ibd['gen_seg_len'].mean()\n    std_dev = noise_level * mean_length\n    noise = np.random.normal(0, std_dev, len(noisy_ibd))\n    noisy_ibd['gen_seg_len'] = noisy_ibd['gen_seg_len'] + noise\n    noisy_ibd['gen_seg_len'] = noisy_ibd['gen_seg_len'].clip(lower=1)\n    \n    # Run greedy on original data\n    greedy_builder = GreedyPedigreeBuilder(synthetic_segments, synthetic_individuals)\n    original_pedigree, _ = greedy_builder.build_pedigree(min_certainty=0.3)\n    \n    # Run greedy on noisy data\n    greedy_builder = GreedyPedigreeBuilder(noisy_ibd, synthetic_individuals)\n    noisy_pedigree, _ = greedy_builder.build_pedigree(min_certainty=0.3)\n    \n    # Analyze consistency\n    consistency = analyze_relationship_consistency(original_pedigree, noisy_pedigree)\n    consistency['Noise Level'] = noise_level\n    \n    consistency_metrics.append(consistency)\n\n# Create DataFrame\nconsistency_df = pd.DataFrame(consistency_metrics)\n\n# Display the results\nprint(\"\\nRelationship Consistency Analysis:\")\ndisplay(consistency_df)\n\n# Plot the consistency metrics\nplt.figure(figsize=(10, 6))\n\nplt.plot(consistency_df['Noise Level'], consistency_df['Jaccard Similarity'], 'b-o', label='Jaccard Similarity')\nplt.plot(consistency_df['Noise Level'], consistency_df['Precision'], 'g-o', label='Precision')\nplt.plot(consistency_df['Noise Level'], consistency_df['Recall'], 'r-o', label='Recall')\nplt.plot(consistency_df['Noise Level'], consistency_df['F1 Score'], 'k-o', label='F1 Score')\n\nplt.xlabel('Noise Level (fraction of mean)')\nplt.ylabel('Consistency Metric')\nplt.title('Relationship Consistency with Increasing Noise')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()"
   ],
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<cell_type>markdown</cell_type>## 5. Summary and Best Practices\n\nIn this lab, we've explored the optimization algorithms that power Bonsai's pedigree reconstruction capabilities. We've implemented and evaluated three key approaches:\n\n1. **Greedy Incremental Construction**: A fast, straightforward approach that builds pedigrees by adding the most confident relationships first\n2. **Simulated Annealing**: A probabilistic technique that can escape local optima by temporarily accepting worse solutions\n3. **Genetic Algorithms**: A population-based method that evolves multiple candidate pedigrees in parallel\n\nWe've also implemented a hybrid approach that combines the strengths of these methods, and analyzed practical considerations like computational complexity and robustness to uncertainty.\n\n### Key Insights\n\n1. The pedigree reconstruction optimization problem is extremely challenging:\n   - Vast search space that grows exponentially with the number of individuals\n   - Multiple local optima and complex constraints\n   - Uncertain and ambiguous data\n\n2. Each optimization approach has different strengths and weaknesses:\n   - Greedy algorithms are fast but get stuck in local optima\n   - Simulated annealing can escape local optima but requires parameter tuning\n   - Genetic algorithms explore diverse solutions but are computationally intensive\n\n3. Hybrid approaches tend to perform best by leveraging the strengths of each method:\n   - Starting with greedy construction provides a good initial solution\n   - Refining with simulated annealing improves local structure\n   - Using genetic algorithms explores alternative global structures\n\n### Best Practices\n\n1. **Data Preparation**:\n   - Carefully preprocess IBD data to filter spurious segments\n   - Incorporate demographic information when available\n   - Identify and handle endogamous populations separately\n\n2. **Algorithm Selection**:\n   - For small pedigrees (< 20 individuals): Greedy construction followed by simulated annealing\n   - For medium pedigrees (20-100 individuals): Hybrid approach with limited genetic algorithm generations\n   - For large pedigrees (> 100 individuals): Divide and conquer or incremental optimization\n\n3. **Parameter Tuning**:\n   - Use multiple certainty thresholds for greedy construction\n   - Experiment with different cooling schedules for simulated annealing\n   - For genetic algorithms, prioritize population diversity over size\n\n4. **Evaluation**:\n   - Score against holdout data when possible\n   - Consider robustness to noise and missing data\n   - Validate with known relationships or genealogical records\n\n### Next Steps\n\nIn the next lab, we'll explore how to apply these optimization techniques to real-world genetic genealogy datasets and evaluate the quality of the reconstructed pedigrees.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<cell_type>markdown</cell_type>## 6. Exercises\n\n1. **Parameter Sensitivity Analysis**:\n   - Experiment with different parameter settings for simulated annealing (initial temperature, cooling rate)\n   - Analyze how these parameters affect the quality of the reconstructed pedigree\n   - Plot the relationship between parameter values and pedigree score\n\n2. **Custom Move Operators**:\n   - Implement additional move operators for simulated annealing (e.g., subtree relocation, relationship reversal)\n   - Compare the effectiveness of different move operators on pedigree reconstruction\n   - Design a move selection strategy that adapts based on the current pedigree state\n\n3. **Constraint Handling**:\n   - Modify the scoring function to incorporate additional constraints (e.g., maximum number of children, age constraints)\n   - Implement a constraint satisfaction approach that guarantees valid pedigrees\n   - Compare hard constraint enforcement vs. soft penalty approaches\n\n4. **Performance Optimization**:\n   - Profile the execution time of different components of the optimization process\n   - Implement parallelization for the genetic algorithm (e.g., parallel fitness evaluation)\n   - Design a caching strategy to avoid redundant computation of relationship likelihoods\n\n5. **Advanced Hybrid Approaches**:\n   - Design and implement a different hybrid optimization strategy\n   - Compare its performance against the approaches presented in this lab\n   - Analyze the tradeoffs between computation time and solution quality",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "<cell_type>markdown</cell_type>## 7. References and Further Reading\n\n1. **Pedigree Reconstruction**\n   - Koller, D., & Friedman, N. (2009). *Probabilistic Graphical Models: Principles and Techniques*. MIT Press.\n   - Kirkpatrick, B., Ge, S., & Wang, L. (2019). Advances in computational methods for identifying relatives from genetic data. *Nature Reviews Genetics*, 20(5), 273-284.\n\n2. **Optimization Algorithms**\n   - Russell, S. J., & Norvig, P. (2016). *Artificial Intelligence: A Modern Approach*. Pearson.\n   - Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization by simulated annealing. *Science*, 220(4598), 671-680.\n   - Mitchell, M. (1998). *An Introduction to Genetic Algorithms*. MIT Press.\n\n3. **Genetic Genealogy**\n   - Browning, S. R., & Browning, B. L. (2012). Identity by descent between distant relatives: detection and applications. *Annual Review of Genetics*, 46, 617-633.\n   - Speed, D., & Balding, D. J. (2015). Relatedness in the post-genomic era: is it still useful? *Nature Reviews Genetics*, 16(1), 33-44.\n\n4. **Software and Tools**\n   - Staples, J., et al. (2016). PRIMUS: Rapid reconstruction of pedigrees from genome-wide estimates of identity by descent. *American Journal of Human Genetics*, 98(6), 1193-1204.\n   - Ko, A., & Nielsen, R. (2017). Composite likelihood method for inferring local pedigrees. *PLoS Genetics*, 13(8), e1006963.\n\n5. **Online Resources**\n   - Bonsai Algorithm Documentation: [https://myheritage.github.io/bonsai](https://github.com/MyHeritage/bonsai)\n   - ISOGG Wiki - Identity by Descent: [https://isogg.org/wiki/Identity_by_descent](https://isogg.org/wiki/Identity_by_descent)\n   - Genetic Genealogy Tools: [https://geneticgenealogist.net/](https://thegeneticgenealogist.com/)",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}