{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n",
    "from IPython.display import Markdown, display\n",
    "import subprocess\n",
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "notebook_dir = Path(os.getcwd())\n",
    "project_root = notebook_dir.parent\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(env_path, override=True)\n",
    "print(f\"Looking for .env at: {env_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
    "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
    "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
    "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
    "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
    "\n",
    "print(f\"Working Directory: {working_directory}\")\n",
    "print(f\"Data Directory: {data_directory}\")\n",
    "print(f\"References Directory: {references_directory}\")\n",
    "print(f\"Results Directory: {results_directory}\")\n",
    "print(f\"Utils Directory: {utils_directory}\")\n",
    "\n",
    "os.chdir(working_directory)\n",
    "print(f\"The current directory is {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\"):\n",
    "    \"\"\"\n",
    "    Configure logging for both file and console handlers.\n",
    "\n",
    "    Args:\n",
    "        log_filename (str): Path to the log file where logs will be written.\n",
    "        log_file_debug_level (str): Logging level for the file handler.\n",
    "        console_debug_level (str): Logging level for the console handler.\n",
    "    \"\"\"\n",
    "    # Create a root logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)  # Capture all messages at the root level\n",
    "\n",
    "    # Convert level names to numeric levels\n",
    "    file_level = getattr(logging, log_file_debug_level.upper(), logging.INFO)\n",
    "    console_level = getattr(logging, console_debug_level.upper(), logging.INFO)\n",
    "\n",
    "    # File handler: Logs messages at file_level and above to the file\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(file_level)\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "\n",
    "    # Console handler: Logs messages at console_level and above to the console\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(console_level)\n",
    "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "\n",
    "    # Add handlers to the root logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "def clear_logger():\n",
    "    \"\"\"Remove all handlers from the root logger.\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_filename = os.path.join(results_directory, \"lab0_download_1kgnomes_log.txt\")\n",
    "print(f\"The log file is located at {log_filename}.\")\n",
    "\n",
    "# Ensure the results_directory exists\n",
    "if not os.path.exists(results_directory):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "# Check if the file exists; if not, create it\n",
    "if not os.path.exists(log_filename):\n",
    "    with open(log_filename, 'w') as file:\n",
    "        pass  # The file is now created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_logger() # Clear the logger before reconfiguring it\n",
    "configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download 1000 Genomes Project Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the 1000 Genomes reference directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create the reference directory path\n",
    "    onethousandgenomes_seq = Path(references_directory) / \"onethousandgenomes_seq\"\n",
    "    \n",
    "    # Create directory (and parents if needed)\n",
    "    onethousandgenomes_seq.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Display result with markdown for better visibility\n",
    "    display(Markdown(f\"**Reference Directory Setup:**\"))\n",
    "    display(Markdown(f\"✅ 1000 Genomes sequence directory: `{onethousandgenomes_seq}`\"))\n",
    "    \n",
    "    # Log for record-keeping\n",
    "    logging.info(f\"1000 Genomes directory configured at: {onethousandgenomes_seq}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    # Visual error display\n",
    "    display(Markdown(f\"❌ **ERROR:** Failed to create reference directory: {str(e)}\"))\n",
    "    logging.error(f\"Reference directory setup failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chromosome Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_chromosome_selection_jupyter():\n",
    "    \"\"\"\n",
    "    Interactive chromosome selection using IPython widgets for Jupyter.\n",
    "    Returns a tuple of (selection_code, chromosome_list)\n",
    "    \"\"\"\n",
    "    from IPython.display import display\n",
    "    import ipywidgets as widgets\n",
    "    from functools import partial\n",
    "    \n",
    "    # Set up the radio buttons for selection\n",
    "    selection_widget = widgets.RadioButtons(\n",
    "        options=[\n",
    "            ('Range: 1 to 22', 'a'),\n",
    "            ('Range: 1 to 22 plus X', 'b'),\n",
    "            ('Multiple: 1 and 20 (default)', 'c'), \n",
    "            ('Single: chromosome 20', 'd'),\n",
    "            ('Single: chromosome X', 'e'),\n",
    "            ('Custom range', 'f')\n",
    "        ],\n",
    "        value='c',\n",
    "        description='Chromosomes:',\n",
    "        layout={'width': 'max-content'}\n",
    "    )\n",
    "    \n",
    "    # Custom range inputs (initially hidden)\n",
    "    start_dropdown = widgets.Dropdown(\n",
    "        options=[str(i) for i in range(1, 23)] + ['X'],\n",
    "        value='1',\n",
    "        description='Start:',\n",
    "        disabled=True\n",
    "    )\n",
    "    \n",
    "    end_dropdown = widgets.Dropdown(\n",
    "        options=[str(i) for i in range(1, 23)] + ['X'],\n",
    "        value='22',\n",
    "        description='End:',\n",
    "        disabled=True\n",
    "    )\n",
    "    \n",
    "    # Status output\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Store the final selection\n",
    "    result = {'selection': 'c', 'chromosomes': [1, 20]}\n",
    "    \n",
    "    def update_custom_fields(change):\n",
    "        \"\"\"Enable/disable custom fields based on selection\"\"\"\n",
    "        if change['new'] == 'f':\n",
    "            start_dropdown.disabled = False\n",
    "            end_dropdown.disabled = False\n",
    "        else:\n",
    "            start_dropdown.disabled = True\n",
    "            end_dropdown.disabled = True\n",
    "    \n",
    "    def process_selection(btn):\n",
    "        \"\"\"Process the chromosome selection and update result\"\"\"\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            \n",
    "            selection = selection_widget.value\n",
    "            options = {\n",
    "                \"a\": list(range(1, 23)),  # Sequential range 1 to 22\n",
    "                \"b\": list(range(1, 23)) + [\"X\"],  # Range 1 to 22 plus X\n",
    "                \"c\": [1, 20],  # Default - chromosomes 1 and 20\n",
    "                \"d\": [20],  # Single chromosome\n",
    "                \"e\": [\"X\"],  # X chromosome\n",
    "            }\n",
    "            \n",
    "            if selection == 'f':\n",
    "                # Handle custom range\n",
    "                start = start_dropdown.value\n",
    "                end = end_dropdown.value\n",
    "                \n",
    "                # Convert to appropriate types\n",
    "                start_val = \"X\" if start == \"X\" else int(start)\n",
    "                end_val = \"X\" if end == \"X\" else int(end)\n",
    "                \n",
    "                # Generate chromosome range\n",
    "                if start_val == \"X\" or end_val == \"X\":\n",
    "                    if start_val == \"X\":\n",
    "                        chromosomes = [\"X\"]\n",
    "                    else:\n",
    "                        chromosomes = list(range(int(start), 23)) + [\"X\"]\n",
    "                else:\n",
    "                    start_int, end_int = int(start), int(end)\n",
    "                    if start_int <= end_int:\n",
    "                        chromosomes = list(range(start_int, end_int + 1))\n",
    "                    else:\n",
    "                        chromosomes = list(range(end_int, start_int + 1))\n",
    "                \n",
    "                result['chromosomes'] = chromosomes\n",
    "            else:\n",
    "                result['chromosomes'] = options[selection]\n",
    "            \n",
    "            result['selection'] = selection\n",
    "            print(f\"Selected option: {selection}\")\n",
    "            print(f\"Chromosomes to process: {result['chromosomes']}\")\n",
    "    \n",
    "    # Button to confirm selection\n",
    "    confirm_btn = widgets.Button(\n",
    "        description='Select',\n",
    "        button_style='success',\n",
    "        tooltip='Click to confirm your chromosome selection'\n",
    "    )\n",
    "    confirm_btn.on_click(process_selection)\n",
    "    \n",
    "    # Update custom fields when selection changes\n",
    "    selection_widget.observe(update_custom_fields, names='value')\n",
    "    \n",
    "    # Display the widgets\n",
    "    display(selection_widget)\n",
    "    display(widgets.HBox([start_dropdown, end_dropdown]))\n",
    "    display(confirm_btn)\n",
    "    display(output)\n",
    "    \n",
    "    # Return a function that gets the current selection\n",
    "    def get_result():\n",
    "        return result['selection'], result['chromosomes']\n",
    "    \n",
    "    return get_result\n",
    "\n",
    "get_selection = prompt_chromosome_selection_jupyter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and index selected chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm  # Make sure to install tqdm with `pip install tqdm`\n",
    "\n",
    "def index_downloaded_files(vcf_path):\n",
    "    if os.path.isfile(vcf_path):\n",
    "        logging.info(f\"Indexing {vcf_path}...\")\n",
    "        result = subprocess.run(\n",
    "            [\"tabix\", \"-f\", \"-p\", \"vcf\", vcf_path],\n",
    "            stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            error_message = result.stderr.decode().strip()\n",
    "            logging.error(f\"Failed to index {vcf_path}: {error_message}\")\n",
    "        else:\n",
    "            logging.info(f\"Successfully indexed {vcf_path}.\")\n",
    "    else:\n",
    "        logging.error(f\"File {vcf_path} not found.\")\n",
    "\n",
    "def process_chromosome(chromosome, base_url, destination_dir):\n",
    "    # Print a status message indicating the start of processing for the chromosome\n",
    "    logging.info(f\"Downloading chromosome {chromosome}...\")\n",
    "\n",
    "    if chromosome == \"X\":\n",
    "        vcf_filename = f\"1kGP_high_coverage_Illumina.chr{chromosome}.filtered.SNV_INDEL_SV_phased_panel.v2.vcf.gz\"\n",
    "    else:\n",
    "        vcf_filename = f\"1kGP_high_coverage_Illumina.chr{chromosome}.filtered.SNV_INDEL_SV_phased_panel.vcf.gz\"\n",
    "\n",
    "    new_vcf_filename = f\"onethousandgenomes_sequenced_phased.chr{chromosome}.vcf.gz\"\n",
    "    vcf_url = f\"{base_url}/{vcf_filename}\"\n",
    "\n",
    "    logging.info(f\"Downloading {vcf_filename} from {vcf_url}...\")\n",
    "    vcf_path = os.path.join(destination_dir, new_vcf_filename)\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        [\"wget\", \"-O\", vcf_path, vcf_url], check=True\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        logging.error(f\"Failed to download {vcf_filename}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    if not os.path.isfile(vcf_path):\n",
    "        logging.error(f\"{vcf_filename} was not downloaded.\")\n",
    "        return\n",
    "\n",
    "    index_downloaded_files(vcf_path)\n",
    "    if not os.path.isfile(vcf_path + \".tbi\"):\n",
    "        logging.error(f\"{vcf_filename} was not indexed\")\n",
    "    else:\n",
    "        logging.info(f\"Successfully indexed {vcf_filename}\")\n",
    "\n",
    "    logging.info(f\"Successfully downloaded and verified files for chromosome {chromosome}.\")\n",
    "\n",
    "def download_index_files_parallel(base_url, chromosomes, destination_dir, max_workers=4):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_chromosome, chrom, base_url, destination_dir): chrom for chrom in chromosomes}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing chromosomes\"):\n",
    "            chrom = futures[future]\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing chromosome {chrom}: {e}\")\n",
    "                \n",
    "\n",
    "base_url = \"https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20220422_3202_phased_SNV_INDEL_SV\"\n",
    "selection, chromosomes = get_selection()\n",
    "download_index_files_parallel(base_url, chromosomes, onethousandgenomes_seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the 1000 Genomes Project Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Array Manifest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_array_manifest(references_dir):\n",
    "    print(\"Downloading and extracting Illumina manifest file...\")\n",
    "    # https://support.illumina.com/array/array_kits/infinium-global-diversity-array.html\n",
    "    # https://support.illumina.com/downloads/infinium-global-diversity-array-v1-product-files.html\n",
    "\n",
    "    # Define the URL and paths\n",
    "    url = \"https://webdata.illumina.com/downloads/productfiles/global-diversity-array/infinium-global-diversity-array-8-v1-0-D2-manifest-file-csv.zip\"\n",
    "    zip_file = os.path.join(references_dir, \"infinium-global-diversity-array.zip\")\n",
    "\n",
    "    # Download the manifest ZIP file\n",
    "    try:\n",
    "        print(f\"Downloading manifest file from {url}...\")\n",
    "        subprocess.run([\"wget\", url, \"-O\", zip_file], check=True)\n",
    "        print(f\"Download complete: {zip_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error downloading the manifest file: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Extract the ZIP file\n",
    "    try:\n",
    "        print(\"Extracting manifest file...\")\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(references_dir)\n",
    "        csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]\n",
    "        if len(csv_files) == 1:\n",
    "            manifest_file = os.path.join(references_dir, csv_files[0])\n",
    "            print(f\"Manifest file located: {manifest_file}\")\n",
    "            print(f\"Deleting ZIP file: {zip_file}\")\n",
    "            os.remove(zip_file)\n",
    "            return manifest_file\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected number of CSV files found in the ZIP archive.\")\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"Error extracting ZIP file: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error during extraction: {e}\")\n",
    "        raise\n",
    "    \n",
    "manifest_file = download_array_manifest(references_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the SNP Subset file for use in subseting the 1000 Genomes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snp_set(manifest_file):\n",
    "    print(\"Reading SNP set from manifest file...\")\n",
    "\n",
    "    # Validate file existence\n",
    "    if not os.path.exists(manifest_file):\n",
    "        raise FileNotFoundError(f\"Manifest file not found: {manifest_file}\")\n",
    "\n",
    "    # Read the first 8 lines to extract column headers\n",
    "    try:\n",
    "        print(\"Extracting column headers...\")\n",
    "        column_headers = []\n",
    "        with open(manifest_file, 'r') as file:\n",
    "            for i in range(8):\n",
    "                line = file.readline()\n",
    "                if i == 7:\n",
    "                    column_headers = line.strip().split(',')\n",
    "\n",
    "        print(\"Parsing SNP data...\")\n",
    "        snp_set = pd.read_csv(manifest_file, skiprows=8, header=None, low_memory=False)\n",
    "        snp_set.columns = column_headers\n",
    "        print(f\"SNP set successfully parsed with {len(snp_set)} entries.\")\n",
    "        return snp_set\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing the SNP manifest file: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        raise\n",
    "\n",
    "def prepare_snp_subset_file(snp_set, references_directory):\n",
    "    \"\"\"\n",
    "    Prepares a SNP subset file for bcftools based on the SNP set from the Illumina manifest.\n",
    "\n",
    "    Parameters:\n",
    "    - snp_set (pd.DataFrame): DataFrame containing SNPs with columns 'Chr' and 'MapInfo'.\n",
    "    - references_directory (str): Directory to save the SNP subset file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Path to the SNP subset file.\n",
    "    \"\"\"\n",
    "    # Drop rows with NaN values in 'MapInfo' column\n",
    "    snp_set = snp_set.dropna(subset=['MapInfo'])\n",
    "\n",
    "    # Ensure 'Chr' and 'MapInfo' columns are correctly formatted\n",
    "    snp_set.loc[:, 'Chr'] = 'chr' + snp_set['Chr'].astype(str)\n",
    "    snp_set.loc[:, 'MapInfo'] = snp_set['MapInfo'].astype(int)\n",
    "\n",
    "\n",
    "    # Create a new DataFrame with the required columns formatted for bcftools\n",
    "    formatted_df = snp_set[['Chr', 'MapInfo']].rename(columns={'Chr': 'CHROM', 'MapInfo': 'POS'})\n",
    "\n",
    "    # Save the SNP subset file\n",
    "    output_path = os.path.join(references_directory, \"snp_file.txt\")\n",
    "    print(f\"Saving SNP subset file to {output_path}...\")\n",
    "    formatted_df.to_csv(output_path, header=False, index=False, sep='\\t')\n",
    "\n",
    "    print(f\"SNP subset file saved: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "snp_set = get_snp_set(manifest_file)\n",
    "logging.info(f\"SNP set loaded with {len(snp_set)} entries.\")\n",
    "\n",
    "snp_subset_path = prepare_snp_subset_file(snp_set, references_directory)\n",
    "logging.info(f\"SNP subset file ready at {snp_subset_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the 1000 Genomes Project data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def subset_1000_genomes(references_directory, snp_file_path):\n",
    "    \"\"\"\n",
    "    Subsets 1000 Genomes VCF files using Illumina SNPs and saves results in a new directory.\n",
    "\n",
    "    Parameters:\n",
    "    - references_directory (str): Path to the directory containing 1000 Genomes VCF files.\n",
    "    - snp_file_path (str): Path to the SNP subset file for bcftools.\n",
    "    \"\"\"\n",
    "    # Define directories\n",
    "    input_dir = os.path.join(references_directory, \"onethousandgenomes_seq\")\n",
    "    # Exit if input directory doesn't exist\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory not found: {input_dir}\")\n",
    "        return\n",
    "    \n",
    "    output_dir = os.path.join(references_directory, \"onethousandgenomes_genotype\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Identify available chromosome files in the input directory\n",
    "    print(\"Scanning input directory for VCF files...\")\n",
    "    available_files = [f for f in os.listdir(input_dir)\n",
    "                       if f.endswith(\".vcf.gz\") and not f.endswith(\".vcf.gz.tbi\")]\n",
    "\n",
    "    # Extract chromosome identifiers from valid VCF filenames\n",
    "    chromosomes = sorted(\n",
    "        set(f.split(\".\")[1].replace(\"chr\", \"\") for f in available_files if \"chr\" in f)\n",
    "    )\n",
    "\n",
    "    if not chromosomes:\n",
    "        print(\"No valid VCF files found in the input directory. Exiting...\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found VCF files for chromosomes: {', '.join(chromosomes)}\")\n",
    "\n",
    "    # Create chr-to-num mapping file\n",
    "    mapping_file = os.path.join(output_dir, \"chr_to_num.txt\")\n",
    "    with open(mapping_file, 'w') as f:\n",
    "        for i in range(1, 23):\n",
    "            f.write(f\"chr{i}\\t{i}\\n\")\n",
    "        f.write(\"chrX\\tX\\n\")\n",
    "        f.write(\"chrY\\tY\\n\")\n",
    "\n",
    "    # Function to process a single chromosome\n",
    "    def process_chromosome(chromosome):\n",
    "        print(f\"Starting process for chromosome {chromosome} at {datetime.now()}\")\n",
    "\n",
    "        input_vcf = os.path.join(input_dir, f\"onethousandgenomes_sequenced_phased.chr{chromosome}.vcf.gz\")\n",
    "        output_vcf = os.path.join(output_dir, f\"onethousandgenomes_genotyped_phased.chr{chromosome}.vcf.gz\")\n",
    "\n",
    "        # Check if input VCF and index files exist\n",
    "        if not os.path.exists(input_vcf) or not os.path.exists(input_vcf + \".tbi\"):\n",
    "            print(f\"Required files missing for chromosome {chromosome}: VCF or its index. Skipping...\")\n",
    "            return\n",
    "\n",
    "        # First subset, then rename chromosomes\n",
    "        try:\n",
    "            temp_vcf = os.path.join(output_dir, f\"temp.chr{chromosome}.vcf.gz\")\n",
    "            subprocess.run(\n",
    "                [\"bcftools\", \"view\", \"-R\", snp_file_path, input_vcf, \"-Oz\", \"-o\", temp_vcf],\n",
    "                check=True\n",
    "            )\n",
    "            subprocess.run([\n",
    "                \"bcftools\", \"annotate\",\n",
    "                \"--rename-chrs\", mapping_file,\n",
    "                \"-Oz\", \"-o\", output_vcf,\n",
    "                temp_vcf\n",
    "            ], check=True)\n",
    "            os.remove(temp_vcf)\n",
    "            print(f\"Subsetted and renamed VCF saved for chromosome {chromosome}.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error processing VCF file for chromosome {chromosome}: {e}\")\n",
    "            if os.path.exists(temp_vcf):\n",
    "                os.remove(temp_vcf)\n",
    "            return\n",
    "\n",
    "        # Index the subset VCF file\n",
    "        try:\n",
    "            subprocess.run([\"tabix\", \"-p\", \"vcf\", output_vcf], check=True)\n",
    "            print(f\"Indexing completed for chromosome {chromosome}.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to index VCF file for chromosome {chromosome}: {e}\")\n",
    "            return\n",
    "\n",
    "        # Count SNPs in the subsetted file\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [\"bcftools\", \"view\", \"-v\", \"snps\", output_vcf],\n",
    "                stdout=subprocess.PIPE,\n",
    "                text=True,\n",
    "                check=True\n",
    "            )\n",
    "            snp_count = sum(1 for line in result.stdout.splitlines() if not line.startswith(\"#\"))\n",
    "            print(f\"Number of SNPs in chromosome {chromosome}: {snp_count}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Failed to count SNPs in chromosome {chromosome}: {e}\")\n",
    "            return\n",
    "\n",
    "        print(f\"Finished processing for chromosome {chromosome} at {datetime.now()}\")\n",
    "\n",
    "    # Run process_chromosome concurrently for all chromosomes\n",
    "    max_workers = min(len(chromosomes), os.cpu_count() or 1)\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Map the function over chromosomes concurrently\n",
    "        list(executor.map(process_chromosome, chromosomes))\n",
    "\n",
    "    print(\"All chromosomes processed successfully.\")\n",
    "\n",
    "subset_1000_genomes(references_directory, snp_subset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup \n",
    "\n",
    "Delete the onethousandgenomes_seq directory. The subsetted data is in the onethousandgenomes_genotype directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_name = os.path.join(references_directory, \"onethousandgenomes_seq\")\n",
    "if os.path.exists(directory_name):\n",
    "    shutil.rmtree(directory_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: With these new subsetted genome VCF files, we should add code to revise the headers so that they reflect the actual data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
