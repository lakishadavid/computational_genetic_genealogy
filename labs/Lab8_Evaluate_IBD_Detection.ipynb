{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import IPython\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "from intervaltree import IntervalTree\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from: /home/lakishadavid/computational_genetic_genealogy/.env\n",
      "Working Directory: /home/lakishadavid/computational_genetic_genealogy\n",
      "Data Directory: /home/lakishadavid/computational_genetic_genealogy/data\n",
      "References Directory: /home/lakishadavid/computational_genetic_genealogy/references\n",
      "Results Directory: /home/lakishadavid/computational_genetic_genealogy/results\n",
      "Utils Directory: /home/lakishadavid/computational_genetic_genealogy/utils\n",
      "The current directory is /home/lakishadavid/computational_genetic_genealogy\n"
     ]
    }
   ],
   "source": [
    "def find_comp_gen_dir():\n",
    "    \"\"\"Find the computational_genetic_genealogy directory by searching up from current directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Search up through parent directories\n",
    "    while current != current.parent:\n",
    "        # Check if target directory exists in current path\n",
    "        target = current / 'computational_genetic_genealogy'\n",
    "        if target.is_dir():\n",
    "            return target\n",
    "        # Move up one directory\n",
    "        current = current.parent\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find computational_genetic_genealogy directory\")\n",
    "\n",
    "def load_env_file():\n",
    "    \"\"\"Find and load the .env file from the computational_genetic_genealogy directory.\"\"\"\n",
    "    try:\n",
    "        # Find the computational_genetic_genealogy directory\n",
    "        comp_gen_dir = find_comp_gen_dir()\n",
    "        \n",
    "        # Look for .env file\n",
    "        env_path = comp_gen_dir / '.env'\n",
    "        if not env_path.exists():\n",
    "            print(f\"Warning: No .env file found in {comp_gen_dir}\")\n",
    "            return None\n",
    "        \n",
    "        # Load the .env file\n",
    "        load_dotenv(env_path, override=True)\n",
    "        print(f\"Loaded environment variables from: {env_path}\")\n",
    "        return env_path\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use the function\n",
    "env_path = load_env_file()\n",
    "\n",
    "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
    "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
    "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
    "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
    "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
    "\n",
    "os.environ[\"WORKING_DIRECTORY\"] = working_directory\n",
    "os.environ[\"DATA_DIRECTORY\"] = data_directory\n",
    "os.environ[\"REFERENCES_DIRECTORY\"] = references_directory\n",
    "os.environ[\"RESULTS_DIRECTORY\"] = results_directory\n",
    "os.environ[\"UTILS_DIRECTORY\"] = utils_directory\n",
    "\n",
    "print(f\"Working Directory: {working_directory}\")\n",
    "print(f\"Data Directory: {data_directory}\")\n",
    "print(f\"References Directory: {references_directory}\")\n",
    "print(f\"Results Directory: {results_directory}\")\n",
    "print(f\"Utils Directory: {utils_directory}\")\n",
    "\n",
    "os.chdir(working_directory)\n",
    "print(f\"The current directory is {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lab 8 log file is located at /home/lakishadavid/computational_genetic_genealogy/results/lab8_log.txt.\n"
     ]
    }
   ],
   "source": [
    "def configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\"):\n",
    "    \"\"\"\n",
    "    Configure logging for both file and console handlers.\n",
    "\n",
    "    Args:\n",
    "        log_filename (str): Path to the log file where logs will be written.\n",
    "        log_file_debug_level (str): Logging level for the file handler.\n",
    "        console_debug_level (str): Logging level for the console handler.\n",
    "    \"\"\"\n",
    "    # Create a root logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)  # Capture all messages at the root level\n",
    "\n",
    "    # Convert level names to numeric levels\n",
    "    file_level = getattr(logging, log_file_debug_level.upper(), logging.INFO)\n",
    "    console_level = getattr(logging, console_debug_level.upper(), logging.INFO)\n",
    "\n",
    "    # File handler: Logs messages at file_level and above to the file\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(file_level)\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "\n",
    "    # Console handler: Logs messages at console_level and above to the console\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(console_level)\n",
    "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "\n",
    "    # Add handlers to the root logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "def clear_logger():\n",
    "    \"\"\"Remove all handlers from the root logger.\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "        \n",
    "log_filename = os.path.join(results_directory, \"lab8_log.txt\")\n",
    "print(f\"The Lab 8 log file is located at {log_filename}.\")\n",
    "\n",
    "# Ensure the results_directory exists\n",
    "if not os.path.exists(results_directory):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "# Check if the file exists; if not, create it\n",
    "if not os.path.exists(log_filename):\n",
    "    with open(log_filename, 'w') as file:\n",
    "        pass  # The file is now created.\n",
    "    \n",
    "clear_logger() # Clear the logger before reconfiguring it\n",
    "configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, you need to use the simulated data VCF file with Lab4 (skip the `Prepare Supplemental Data` section), Lab5, Lab6, and Lab7 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /home/lakishadavid/computational_genetic_genealogy/results/ped_sim_run2.seg\n",
      "File exists: /home/lakishadavid/computational_genetic_genealogy/results/merged_opensnps_data_autosomes_refinedibd.seg\n",
      "File exists: /home/lakishadavid/computational_genetic_genealogy/results/merged_opensnps_data_autosomes_hapibd.seg\n",
      "File exists: /home/lakishadavid/computational_genetic_genealogy/results/merged_opensnps_data_autosomes_ibis.seg\n"
     ]
    }
   ],
   "source": [
    "prefix = \"merged_opensnps_autosomes_ped_sim\"\n",
    "\n",
    "segments_pedsim = Path(results_directory) / f\"{prefix}.seg\"\n",
    "segments_refinedibd = Path(results_directory) /f\"{prefix}_refinedibd.seg\"\n",
    "segments_hapibd = Path(results_directory) / f\"{prefix}_hapibd.seg\"\n",
    "segments_ibis = Path(results_directory) / f\"{prefix}_ibis.seg\"\n",
    "\n",
    "# Check for alternative naming patterns\n",
    "if not segments_refinedibd.exists():\n",
    "    segments_refinedibd_alt = Path(results_directory) / prefix / \"segments\" / f\"{prefix}_autosomes_refinedibd.seg\"\n",
    "    if segments_refinedibd_alt.exists():\n",
    "        segments_refinedibd = segments_refinedibd_alt\n",
    "        print(f\"Using alternative path for Refined-IBD: {segments_refinedibd}\")\n",
    "        \n",
    "if not segments_hapibd.exists():\n",
    "    segments_hapibd_alt = Path(results_directory) / prefix / \"segments\" / f\"{prefix}_autosomes_hapibd.seg\"\n",
    "    if segments_hapibd_alt.exists():\n",
    "        segments_hapibd = segments_hapibd_alt\n",
    "        print(f\"Using alternative path for Hap-IBD: {segments_hapibd}\")\n",
    "        \n",
    "if not segments_ibis.exists():\n",
    "    segments_ibis_alt = Path(results_directory) / prefix / \"segments\" / f\"{prefix}_autosomes_ibis.seg\"\n",
    "    if segments_ibis_alt.exists():\n",
    "        segments_ibis = segments_ibis_alt\n",
    "        print(f\"Using alternative path for IBIS: {segments_ibis}\")\n",
    "\n",
    "segment_files = [segments_pedsim, segments_refinedibd, segments_hapibd, segments_ibis]\n",
    "\n",
    "# Check if each file exists\n",
    "missing_files = []\n",
    "for file_path in segment_files:\n",
    "    if not file_path.exists():\n",
    "        print(f\"Warning: File not found - {file_path}\")\n",
    "        missing_files.append(file_path.name)\n",
    "    else:\n",
    "        print(f\"File exists: {file_path}\")\n",
    "\n",
    "# Provide instructions if files are missing\n",
    "if missing_files:\n",
    "    print(\"\\nMissing segment files. To fix this issue:\")\n",
    "    print(\"1. Make sure you've run the corresponding IBD detection labs (Lab4-Lab7) first\")\n",
    "    print(\"2. Check the output directories in your results folder\")\n",
    "    print(\"3. For missing PedSim ground truth, try running cell 4 to copy it from the expected location\")\n",
    "    print(\"\\nMissing files: \" + \", \".join(missing_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of /home/lakishadavid/computational_genetic_genealogy/results/ped_sim_run2.seg:\n",
      "1000\t1003\t1\t817341\t44617788\tIBD1\t0.0\t68.343071\t68.343071\n",
      "1000\t1003\t1\t44617789\t205983275\tIBD1\t68.343113\t200.153155\t131.810042\n",
      "1000\t1003\t1\t205983276\t242249428\tIBD1\t200.153157\t250.580913\t50.427756\n",
      "1000\t1003\t1\t242249429\t248876512\tIBD1\t250.580914\t261.713366\t11.132452\n",
      "1000\t1003\t2\t118913\t4929466\tIBD1\t0.0\t8.741841\t8.741841\n",
      "\n",
      "\n",
      "Head of /home/lakishadavid/computational_genetic_genealogy/results/merged_opensnps_data_autosomes_refinedibd.seg:\n",
      "user1496\t1\tuser4864\t2\t9\t76282819\t78487112\t12.1\t3.507\n",
      "user4614\t2\tuser4996\t2\t9\t89693745\t91724340\t14.93\t3.23\n",
      "user4361\t1\tuser4818\t1\t9\t113393148\t114960003\t17.02\t3.214\n",
      "user2708\t2\tuser4041\t1\t9\t39004143\t71308166\t9.3\t4.664\n",
      "user4910\t1\tuser5111\t1\t9\t135491367\t138117319\t16.76\t5.934\n",
      "\n",
      "\n",
      "Head of /home/lakishadavid/computational_genetic_genealogy/results/merged_opensnps_data_autosomes_hapibd.seg:\n",
      "user3025\t2\tuser4654\t1\t1\t44421690\t47626076\t2.155\n",
      "user4597\t1\tuser5559\t2\t1\t44492314\t47626076\t2.013\n",
      "user4954\t2\tuser5076\t2\t1\t44589194\t47654415\t2.002\n",
      "user12148\t1\tuser1308\t2\t1\t46156068\t48055105\t2.048\n",
      "user12148\t1\tuser3190\t2\t1\t46156068\t48055105\t2.048\n",
      "\n",
      "\n",
      "Head of /home/lakishadavid/computational_genetic_genealogy/results/merged_opensnps_data_autosomes_ibis.seg:\n",
      "user1001\tuser12218\t6\t24033861\t31545625\tIBD1\t24.033859\t31.545624\t7.511765\t1088\t0\t0.000000\n",
      "user1001\tuser3190\t6\t24975963\t32212119\tIBD1\t24.975964\t32.212120\t7.236156\t1024\t0\t0.000000\n",
      "user1001\tuser4460\t6\t23479400\t30544386\tIBD1\t23.479401\t30.544386\t7.064985\t1024\t0\t0.000000\n",
      "user1001\tuser5109\t6\t23479400\t30544386\tIBD1\t23.479401\t30.544386\t7.064985\t1024\t0\t0.000000\n",
      "user1035\tuser1495\t2\t86012649\t101375445\tIBD1\t86.012650\t101.375450\t15.362801\t640\t0\t0.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = [segments_pedsim, segments_refinedibd, segments_hapibd, segments_ibis]\n",
    "# See head of each file\n",
    "for file in files:\n",
    "    print(f\"Head of {file}:\")\n",
    "    with open(file, 'r') as f:\n",
    "        for _ in range(5):\n",
    "            print(f.readline().strip())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IBD segments from files...\n",
      "Loaded 7975 segments from Refined IBD\n",
      "Loaded 40908 segments from Hap IBD\n",
      "Loaded 199342 segments from IBIS\n",
      "\n",
      "Comparing RefinedIBD vs HapIBD...\n",
      "Created 14524 interval trees for RefinedIBD\n",
      "HapIBD segments matched with RefinedIBD: 2318 of 40908 (5.67%)\n",
      "RefinedIBD segments detected in HapIBD: 2325 of 7975 (29.15%)\n",
      "\n",
      "Comparing RefinedIBD vs IBIS...\n",
      "Created 14524 interval trees for RefinedIBD\n",
      "IBIS segments matched with RefinedIBD: 121 of 199342 (0.06%)\n",
      "RefinedIBD segments detected in IBIS: 1132 of 7975 (14.19%)\n",
      "\n",
      "Comparing HapIBD vs IBIS...\n",
      "Created 78416 interval trees for HapIBD\n",
      "IBIS segments matched with HapIBD: 0 of 199342 (0.00%)\n",
      "HapIBD segments detected in IBIS: 0 of 40908 (0.00%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tool1</th>\n",
       "      <th>Tool2</th>\n",
       "      <th>Tool1_Total_Segments</th>\n",
       "      <th>Tool2_Total_Segments</th>\n",
       "      <th>Tool2_Segments_Matched</th>\n",
       "      <th>Tool2_Match_Percentage</th>\n",
       "      <th>Tool1_Segments_Detected</th>\n",
       "      <th>Tool1_Detection_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RefinedIBD</td>\n",
       "      <td>HapIBD</td>\n",
       "      <td>7975</td>\n",
       "      <td>40908</td>\n",
       "      <td>2318</td>\n",
       "      <td>5.666373</td>\n",
       "      <td>2325</td>\n",
       "      <td>29.153605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RefinedIBD</td>\n",
       "      <td>IBIS</td>\n",
       "      <td>7975</td>\n",
       "      <td>199342</td>\n",
       "      <td>121</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>1132</td>\n",
       "      <td>14.194357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HapIBD</td>\n",
       "      <td>IBIS</td>\n",
       "      <td>40908</td>\n",
       "      <td>199342</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tool1   Tool2  Tool1_Total_Segments  Tool2_Total_Segments  \\\n",
       "0  RefinedIBD  HapIBD                  7975                 40908   \n",
       "1  RefinedIBD    IBIS                  7975                199342   \n",
       "2      HapIBD    IBIS                 40908                199342   \n",
       "\n",
       "   Tool2_Segments_Matched  Tool2_Match_Percentage  Tool1_Segments_Detected  \\\n",
       "0                    2318                5.666373                     2325   \n",
       "1                     121                0.060700                     1132   \n",
       "2                       0                0.000000                        0   \n",
       "\n",
       "   Tool1_Detection_Percentage  \n",
       "0                   29.153605  \n",
       "1                   14.194357  \n",
       "2                    0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_ibd_segment_files(refinedibd_path, hapibd_path, ibis_path):\n",
    "    \"\"\"\n",
    "    Directly compare IBD segment files from different tools\n",
    "    \n",
    "    Args:\n",
    "        refinedibd_path: Path to Refined IBD segments file\n",
    "        hapibd_path: Path to Hap IBD segments file\n",
    "        ibis_path: Path to IBIS segments file\n",
    "    \"\"\"\n",
    "    # Load the segment files\n",
    "    print(\"Loading IBD segments from files...\")\n",
    "    \n",
    "    # Load Refined IBD segments\n",
    "    refined_df = load_refined_ibd(refinedibd_path)\n",
    "    \n",
    "    # Load Hap IBD segments\n",
    "    hap_df = load_hap_ibd(hapibd_path)\n",
    "    \n",
    "    # Load IBIS segments\n",
    "    ibis_df = load_ibis(ibis_path)\n",
    "    \n",
    "    print(f\"Loaded {len(refined_df)} segments from Refined IBD\")\n",
    "    print(f\"Loaded {len(hap_df)} segments from Hap IBD\")\n",
    "    print(f\"Loaded {len(ibis_df)} segments from IBIS\")\n",
    "    \n",
    "    # Create pairs of tools to compare\n",
    "    tool_pairs = [\n",
    "        (\"RefinedIBD\", \"HapIBD\", refined_df, hap_df),\n",
    "        (\"RefinedIBD\", \"IBIS\", refined_df, ibis_df),\n",
    "        (\"HapIBD\", \"IBIS\", hap_df, ibis_df)\n",
    "    ]\n",
    "    \n",
    "    comparison_results = []\n",
    "    \n",
    "    # For each pair of tools\n",
    "    for tool1_name, tool2_name, tool1_df, tool2_df in tool_pairs:\n",
    "        print(f\"\\nComparing {tool1_name} vs {tool2_name}...\")\n",
    "        \n",
    "        # Create interval trees from tool1 data\n",
    "        tool1_trees = {}\n",
    "        \n",
    "        # Build interval trees for efficient overlap checking\n",
    "        for _, row in tool1_df.iterrows():\n",
    "            # Create keys for sample pairs in both directions\n",
    "            pairs = [\n",
    "                ((row['sample1'], row.get('sample1_haplotype', 0)), \n",
    "                 (row['sample2'], row.get('sample2_haplotype', 0)),\n",
    "                 row['chrom']),\n",
    "                ((row['sample2'], row.get('sample2_haplotype', 0)), \n",
    "                 (row['sample1'], row.get('sample1_haplotype', 0)),\n",
    "                 row['chrom'])\n",
    "            ]\n",
    "            \n",
    "            for sample1, sample2, chrom in pairs:\n",
    "                pair_key = (sample1, sample2)\n",
    "                if (pair_key, chrom) not in tool1_trees:\n",
    "                    tool1_trees[(pair_key, chrom)] = IntervalTree()\n",
    "                \n",
    "                tool1_trees[(pair_key, chrom)].addi(row['start'], row['end'], row['segment_id'])\n",
    "        \n",
    "        print(f\"Created {len(tool1_trees)} interval trees for {tool1_name}\")\n",
    "        \n",
    "        # Initialize columns for tracking matches in tool2\n",
    "        tool2_df = tool2_df.copy()\n",
    "        tool2_df['matched_with_tool1'] = False\n",
    "        tool2_df['overlap_pct'] = 0.0\n",
    "        tool2_df['tool1_id'] = None\n",
    "        \n",
    "        # Track statistics\n",
    "        total_segments = len(tool2_df)\n",
    "        matched_segments = 0\n",
    "        \n",
    "        # Check each segment in tool2 against tool1's trees\n",
    "        for idx, row in tool2_df.iterrows():\n",
    "            # Check regular and reversed sample pairs\n",
    "            sample_pairs = [\n",
    "                ((row['sample1'], row.get('sample1_haplotype', 0)), \n",
    "                 (row['sample2'], row.get('sample2_haplotype', 0)),\n",
    "                 row['chrom']),\n",
    "                ((row['sample2'], row.get('sample2_haplotype', 0)), \n",
    "                 (row['sample1'], row.get('sample1_haplotype', 0)),\n",
    "                 row['chrom'])\n",
    "            ]\n",
    "            \n",
    "            found_match = False\n",
    "            for sample1, sample2, chrom in sample_pairs:\n",
    "                pair_key = (sample1, sample2)\n",
    "                if (pair_key, chrom) in tool1_trees:\n",
    "                    # Calculate overlap with segments in the tree\n",
    "                    overlap_pct, tool1_id = calculate_overlap(row, tool1_trees[(pair_key, chrom)])\n",
    "                    if overlap_pct > 0:\n",
    "                        tool2_df.at[idx, 'overlap_pct'] = overlap_pct\n",
    "                        tool2_df.at[idx, 'tool1_id'] = tool1_id\n",
    "                        tool2_df.at[idx, 'matched_with_tool1'] = (overlap_pct >= 0.5)\n",
    "                        matched_segments += 1 if overlap_pct >= 0.5 else 0\n",
    "                        found_match = True\n",
    "                        break\n",
    "            \n",
    "            # Try again without haplotype info if no match found\n",
    "            if not found_match and 'sample1_haplotype' in row:\n",
    "                sample_pairs_no_hap = [\n",
    "                    ((row['sample1'], None), (row['sample2'], None), row['chrom']),\n",
    "                    ((row['sample2'], None), (row['sample1'], None), row['chrom'])\n",
    "                ]\n",
    "                \n",
    "                for sample1, sample2, chrom in sample_pairs_no_hap:\n",
    "                    pair_key = (sample1, sample2)\n",
    "                    if (pair_key, chrom) in tool1_trees:\n",
    "                        overlap_pct, tool1_id = calculate_overlap(row, tool1_trees[(pair_key, chrom)])\n",
    "                        if overlap_pct > 0:\n",
    "                            tool2_df.at[idx, 'overlap_pct'] = overlap_pct\n",
    "                            tool2_df.at[idx, 'tool1_id'] = tool1_id\n",
    "                            tool2_df.at[idx, 'matched_with_tool1'] = (overlap_pct >= 0.5)\n",
    "                            matched_segments += 1 if overlap_pct >= 0.5 else 0\n",
    "                            break\n",
    "        \n",
    "        # Calculate matching percentages\n",
    "        match_percentage = (matched_segments/total_segments*100) if total_segments > 0 else 0\n",
    "        \n",
    "        # Count unique segments from tool1 that were detected in tool2\n",
    "        matched_tool1_ids = set([x for x in tool2_df['tool1_id'] if x is not None])\n",
    "        unique_tool1_segments = len(matched_tool1_ids)\n",
    "        total_tool1_segments = len(tool1_df)\n",
    "        tool1_detection_pct = (unique_tool1_segments/total_tool1_segments*100) if total_tool1_segments > 0 else 0\n",
    "        \n",
    "        print(f\"{tool2_name} segments matched with {tool1_name}: {matched_segments} of {total_segments} ({match_percentage:.2f}%)\")\n",
    "        print(f\"{tool1_name} segments detected in {tool2_name}: {unique_tool1_segments} of {total_tool1_segments} ({tool1_detection_pct:.2f}%)\")\n",
    "        \n",
    "        # Store results\n",
    "        comparison_results.append({\n",
    "            'Tool1': tool1_name,\n",
    "            'Tool2': tool2_name,\n",
    "            'Tool1_Total_Segments': total_tool1_segments,\n",
    "            'Tool2_Total_Segments': total_segments,\n",
    "            'Tool2_Segments_Matched': matched_segments,\n",
    "            'Tool2_Match_Percentage': match_percentage,\n",
    "            'Tool1_Segments_Detected': unique_tool1_segments,\n",
    "            'Tool1_Detection_Percentage': tool1_detection_pct\n",
    "        })\n",
    "        \n",
    "        # Save the overlap histogram for this pair\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(tool2_df['overlap_pct'], bins=20, alpha=0.7)\n",
    "        plt.title(f'Overlap Distribution: {tool2_name} segments vs {tool1_name}')\n",
    "        plt.xlabel('Overlap Percentage')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.savefig(Path(results_directory) / f'ibd_overlap_{tool2_name}_vs_{tool1_name}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    \n",
    "    # Generate summary visualizations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Tool1', y='Tool1_Detection_Percentage', hue='Tool2', data=comparison_df)\n",
    "    plt.title('Percentage of Segments Detected Across Tools')\n",
    "    plt.xlabel('Reference Tool')\n",
    "    plt.ylabel('Percentage of Segments Detected by Comparison Tool')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "    plt.savefig(Path(results_directory) / 'ibd_tool_comparison_summary.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "# Run the comparison with the three segment files\n",
    "comparison_df = compare_ibd_segment_files(\n",
    "    segments_refinedibd,\n",
    "    segments_hapibd,\n",
    "    segments_ibis\n",
    ")\n",
    "\n",
    "# Display the results table\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_refined_ibd(filepath):\n",
    "    \"\"\"Load Refined IBD output file\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep=\"\\t\", header=None)\n",
    "        df.columns = [\"sample1\", \"sample1_haplotype\", \"sample2\", \n",
    "                      \"sample2_haplotype\", \"chrom\", \"start\", \"end\", \"LOD\", \"cM\"]\n",
    "        # Create a unique segment ID for each segment\n",
    "        df['segment_id'] = range(len(df))\n",
    "        df['tool'] = 'RefinedIBD'\n",
    "        df['length'] = df['end'] - df['start']\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Refined IBD file: {e}\")\n",
    "        cols = [\"sample1\", \"sample1_haplotype\", \"sample2\", \"sample2_haplotype\", \n",
    "                \"chrom\", \"start\", \"end\", \"LOD\", \"cM\"]\n",
    "        return pd.DataFrame(columns=cols + ['segment_id', 'tool', 'length'])\n",
    "\n",
    "def load_hap_ibd(filepath):\n",
    "   \"\"\"Load Hap IBD output file\"\"\"\n",
    "   try:\n",
    "       df = pd.read_csv(filepath, sep=\"\\t\", header=None)\n",
    "       df.columns = [\"sample1\", \"sample1_haplotype\", \"sample2\", \n",
    "                     \"sample2_haplotype\", \"chrom\", \"start\", \"end\", \"cM\"]\n",
    "       df['segment_id'] = range(len(df))\n",
    "       df['tool'] = 'HapIBD'\n",
    "       df['length'] = df['end'] - df['start']\n",
    "       # Since LOD isn't in the HapIBD output, create a placeholder or use cM as proxy\n",
    "       df['LOD'] = df['cM']  # Using cM as a proxy for confidence\n",
    "       return df\n",
    "   except Exception as e:\n",
    "       print(f\"Error loading Hap IBD file: {e}\")\n",
    "       cols = [\"sample1\", \"sample1_haplotype\", \"sample2\", \"sample2_haplotype\", \n",
    "               \"chrom\", \"start\", \"end\", \"cM\"]\n",
    "       return pd.DataFrame(columns=cols + ['segment_id', 'tool', 'length', 'LOD'])\n",
    "\n",
    "def load_ibis(filepath):\n",
    "    \"\"\"Load IBIS output file\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep=\"\\t\", header=None)\n",
    "        df.columns = [\"sample1\", \"sample2\", \"chrom\", \n",
    "                    \"phys_start_pos\", \"phys_end_pos\", \n",
    "                    \"IBD_type\", \"genetic_start_pos\", \n",
    "                    \"genetic_end_pos\", \"genetic_seg_length\", \n",
    "                    \"marker_count\", \"error_count\", \"error_density\"]\n",
    "        \n",
    "        # Map IBIS columns to standardized column names for evaluation\n",
    "        df['start'] = df['phys_start_pos']\n",
    "        df['end'] = df['phys_end_pos']\n",
    "        df['cM'] = df['genetic_seg_length']\n",
    "        df['segment_id'] = range(len(df))\n",
    "        df['tool'] = 'IBIS'\n",
    "        df['length'] = df['end'] - df['start']\n",
    "        \n",
    "        # Create LOD-like score based on error density (lower error = higher score)\n",
    "        # Invert error_density to make higher values better\n",
    "        df['LOD'] = 1.0 / (df['error_density'] + 0.001)  # Add small constant to avoid division by zero\n",
    "        \n",
    "        # Add haplotype columns if needed for consistent evaluation\n",
    "        df['sample1_haplotype'] = 0  # Placeholder if IBIS doesn't specify haplotypes\n",
    "        df['sample2_haplotype'] = 0\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading IBIS file: {e}\")\n",
    "        cols = [\"sample1\", \"sample2\", \"chrom\", \"phys_start_pos\", \"phys_end_pos\", \n",
    "                \"IBD_type\", \"genetic_start_pos\", \"genetic_end_pos\", \"genetic_seg_length\", \n",
    "                \"marker_count\", \"error_count\", \"error_density\"]\n",
    "        return pd.DataFrame(columns=cols + ['start', 'end', 'segment_id', 'tool', 'length', 'LOD', \n",
    "                                           'sample1_haplotype', 'sample2_haplotype'])\n",
    "\n",
    "def load_pedsim_truth(filepath):\n",
    "   \"\"\"Load ground truth IBD segments from ped-sim\"\"\"\n",
    "   try:\n",
    "       df = pd.read_csv(filepath, sep=\"\\t\", header=None)\n",
    "       df.columns = [\"id1\", \"id2\", \"chromosome\", \"physical_position_start\", \n",
    "                    \"physical_position_end\", \"IBD_type\", \"genetic_position_start\", \n",
    "                    \"genetic_position_end\", \"genetic_length\"]\n",
    "       \n",
    "       # Map to standardized column names used in evaluation\n",
    "       df['sample1'] = df['id1']\n",
    "       df['sample2'] = df['id2']\n",
    "       df['chrom'] = df['chromosome']\n",
    "       df['start'] = df['physical_position_start']\n",
    "       df['end'] = df['physical_position_end']\n",
    "       df['cM'] = df['genetic_length']\n",
    "       df['sample1_haplotype'] = 0  # Add placeholder haplotypes if needed\n",
    "       df['sample2_haplotype'] = 0  # These can be updated if actual haplotype info exists\n",
    "       \n",
    "       df['segment_id'] = range(len(df))\n",
    "       df['tool'] = 'Truth'\n",
    "       df['length'] = df['end'] - df['start']\n",
    "       return df\n",
    "   except Exception as e:\n",
    "       print(f\"Error loading PedSim truth file: {e}\")\n",
    "       cols = [\"id1\", \"id2\", \"chromosome\", \"physical_position_start\", \n",
    "              \"physical_position_end\", \"IBD_type\", \"genetic_position_start\", \n",
    "              \"genetic_position_end\", \"genetic_length\"]\n",
    "       return pd.DataFrame(columns=cols + ['sample1', 'sample2', 'chrom', 'start', 'end', \n",
    "                                         'cM', 'segment_id', 'tool', 'length',\n",
    "                                         'sample1_haplotype', 'sample2_haplotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7975 Refined IBD segments\n",
      "Loaded 40908 Hap IBD segments\n",
      "Loaded 199342 IBIS segments\n",
      "Loaded 183061 truth segments from ped-sim\n"
     ]
    }
   ],
   "source": [
    "refined_df = load_refined_ibd(segments_refinedibd)\n",
    "hap_df = load_hap_ibd(segments_hapibd)\n",
    "ibis_df = load_ibis(segments_ibis)\n",
    "truth_df = load_pedsim_truth(segments_pedsim)\n",
    "\n",
    "# Print data summaries\n",
    "print(f\"Loaded {len(refined_df)} Refined IBD segments\")\n",
    "print(f\"Loaded {len(hap_df)} Hap IBD segments\")\n",
    "print(f\"Loaded {len(ibis_df)} IBIS segments\")\n",
    "print(f\"Loaded {len(truth_df)} truth segments from ped-sim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping sample IDs using the provided dictionary...\n",
      "Loaded 520 sample ID mappings\n"
     ]
    }
   ],
   "source": [
    "def map_sample_ids_using_dict(mapping_file_path, truth_df):\n",
    "    \"\"\"Map sample IDs in truth data using the provided mapping dictionary\"\"\"\n",
    "    # Read the mapping dictionary\n",
    "    sample_id_map = {}\n",
    "    with open(mapping_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                original_id, numeric_id = parts\n",
    "                # Create mapping from numeric ID to 'userXXXX' format\n",
    "                sample_id_map[str(numeric_id)] = f\"user{numeric_id}\"\n",
    "    \n",
    "    print(f\"Loaded {len(sample_id_map)} sample ID mappings\")\n",
    "    \n",
    "    # Make a copy of the truth dataframe\n",
    "    truth_df = truth_df.copy()\n",
    "    \n",
    "    # Apply the mapping to both sample1/sample2 and id1/id2 if they exist\n",
    "    if 'sample1' in truth_df.columns:\n",
    "        truth_df['sample1'] = truth_df['sample1'].astype(str).map(sample_id_map)\n",
    "    if 'sample2' in truth_df.columns:\n",
    "        truth_df['sample2'] = truth_df['sample2'].astype(str).map(sample_id_map)\n",
    "    if 'id1' in truth_df.columns:\n",
    "        truth_df['id1'] = truth_df['id1'].astype(str).map(sample_id_map)\n",
    "    if 'id2' in truth_df.columns:\n",
    "        truth_df['id2'] = truth_df['id2'].astype(str).map(sample_id_map)\n",
    "    \n",
    "    return truth_df\n",
    "\n",
    "# Path to the mapping file\n",
    "mapping_file_path = Path(results_directory) / \"ped_sim_run2.seg_dict.txt\"\n",
    "\n",
    "# Apply the mapping to truth data\n",
    "print(\"Mapping sample IDs using the provided dictionary...\")\n",
    "truth_df = map_sample_ids_using_dict(mapping_file_path, truth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_data_format_issues(all_results, truth_df):\n",
    "    \"\"\"Diagnose potential format inconsistencies between tool outputs and truth data\"\"\"\n",
    "    print(\"\\n=== Data Format Diagnosis ===\")\n",
    "    \n",
    "    # Check chromosome formats\n",
    "    truth_chroms = set(truth_df['chrom'].unique())\n",
    "    print(f\"Truth data chromosome formats (sample of 5): {list(truth_chroms)[:5]}\")\n",
    "    \n",
    "    for tool_name in ['RefinedIBD', 'HapIBD', 'IBIS']:\n",
    "        tool_df = all_results[all_results['tool'] == tool_name]\n",
    "        if len(tool_df) == 0:\n",
    "            continue\n",
    "            \n",
    "        tool_chroms = set(tool_df['chrom'].unique())\n",
    "        print(f\"{tool_name} chromosome formats (sample of 5): {list(tool_chroms)[:5]}\")\n",
    "        \n",
    "        # Check for chromosome format mismatches\n",
    "        if not truth_chroms.intersection(tool_chroms):\n",
    "            print(f\"⚠️ WARNING: No matching chromosome formats between truth and {tool_name}!\")\n",
    "            print(f\"  Consider standardizing chromosome formats (e.g., '1' vs 'chr1')\")\n",
    "    \n",
    "    # Check sample ID formats\n",
    "    if 'sample1' in truth_df.columns and 'sample2' in truth_df.columns:\n",
    "        truth_samples = set(truth_df['sample1'].unique()).union(set(truth_df['sample2'].unique()))\n",
    "        print(f\"Truth data sample ID formats (sample of 5): {list(truth_samples)[:5]}\")\n",
    "        \n",
    "        for tool_name in ['RefinedIBD', 'HapIBD', 'IBIS']:\n",
    "            tool_df = all_results[all_results['tool'] == tool_name]\n",
    "            if len(tool_df) == 0 or 'sample1' not in tool_df.columns or 'sample2' not in tool_df.columns:\n",
    "                continue\n",
    "                \n",
    "            tool_samples = set(tool_df['sample1'].unique()).union(set(tool_df['sample2'].unique()))\n",
    "            print(f\"{tool_name} sample ID formats (sample of 5): {list(tool_samples)[:5]}\")\n",
    "            \n",
    "            # Check for sample ID format mismatches\n",
    "            if not truth_samples.intersection(tool_samples):\n",
    "                print(f\"⚠️ WARNING: No matching sample IDs between truth and {tool_name}!\")\n",
    "                print(f\"  Consider standardizing sample ID formats\")\n",
    "    \n",
    "    # Check position ranges\n",
    "    truth_min_pos = truth_df['start'].min()\n",
    "    truth_max_pos = truth_df['end'].max()\n",
    "    print(f\"Truth data position range: {truth_min_pos:,} - {truth_max_pos:,}\")\n",
    "    \n",
    "    for tool_name in ['RefinedIBD', 'HapIBD', 'IBIS']:\n",
    "        tool_df = all_results[all_results['tool'] == tool_name]\n",
    "        if len(tool_df) == 0:\n",
    "            continue\n",
    "            \n",
    "        tool_min_pos = tool_df['start'].min()\n",
    "        tool_max_pos = tool_df['end'].max()\n",
    "        print(f\"{tool_name} position range: {tool_min_pos:,} - {tool_max_pos:,}\")\n",
    "        \n",
    "        # Check for major position range mismatches\n",
    "        if (tool_min_pos > truth_max_pos) or (tool_max_pos < truth_min_pos):\n",
    "            print(f\"⚠️ WARNING: Position ranges don't overlap between truth and {tool_name}!\")\n",
    "            print(f\"  Consider checking for coordinate system differences\")\n",
    "    \n",
    "    print(\"\\n=== End of Diagnosis ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interval_tree(truth_df):\n",
    "    \"\"\"Create an interval tree from truth segments for efficient overlap checking\"\"\"\n",
    "    trees = {}\n",
    "    \n",
    "    print(\"Building interval trees from truth data...\")\n",
    "    \n",
    "    # First try with standard column names\n",
    "    if all(col in truth_df.columns for col in ['sample1', 'sample2', 'chrom', 'start', 'end']):\n",
    "        sample1_col, sample2_col = 'sample1', 'sample2'\n",
    "    # Then try with ped-sim column names\n",
    "    elif all(col in truth_df.columns for col in ['id1', 'id2', 'chromosome', 'physical_position_start', 'physical_position_end']):\n",
    "        sample1_col, sample2_col = 'id1', 'id2'\n",
    "        # Map columns for consistency\n",
    "        truth_df['sample1'] = truth_df['id1']\n",
    "        truth_df['sample2'] = truth_df['id2']\n",
    "        truth_df['chrom'] = truth_df['chromosome']\n",
    "        truth_df['start'] = truth_df['physical_position_start']\n",
    "        truth_df['end'] = truth_df['physical_position_end']\n",
    "    else:\n",
    "        print(\"Error: Could not identify required columns in truth data\")\n",
    "        return trees\n",
    "    \n",
    "    # Add haplotype columns if they don't exist\n",
    "    if 'sample1_haplotype' not in truth_df.columns:\n",
    "        truth_df['sample1_haplotype'] = 0\n",
    "    if 'sample2_haplotype' not in truth_df.columns:\n",
    "        truth_df['sample2_haplotype'] = 0\n",
    "    \n",
    "    # Create trees with and without haplotype information\n",
    "    for _, row in truth_df.iterrows():\n",
    "        # Create keys in both orders to handle either order in tool data\n",
    "        pairs = [\n",
    "            # With haplotypes\n",
    "            ((row['sample1'], row['sample1_haplotype']), \n",
    "             (row['sample2'], row['sample2_haplotype']), \n",
    "             row['chrom']),\n",
    "            ((row['sample2'], row['sample2_haplotype']), \n",
    "             (row['sample1'], row['sample1_haplotype']), \n",
    "             row['chrom']),\n",
    "            # Without haplotypes\n",
    "            ((row['sample1'], None), (row['sample2'], None), row['chrom']),\n",
    "            ((row['sample2'], None), (row['sample1'], None), row['chrom'])\n",
    "        ]\n",
    "        \n",
    "        for sample1, sample2, chrom in pairs:\n",
    "            pair_key = (sample1, sample2)\n",
    "            if (pair_key, chrom) not in trees:\n",
    "                trees[(pair_key, chrom)] = IntervalTree()\n",
    "            \n",
    "            trees[(pair_key, chrom)].addi(row['start'], row['end'], row['segment_id'])\n",
    "    \n",
    "    print(f\"Created {len(trees)} interval trees\")\n",
    "    return trees\n",
    "\n",
    "def calculate_overlap(segment, tree):\n",
    "    \"\"\"Calculate overlap between a segment and truth segments in the tree\"\"\"\n",
    "    overlaps = tree.overlap(segment['start'], segment['end'])\n",
    "    if not overlaps:\n",
    "        return 0, None\n",
    "    \n",
    "    # Find the best overlapping segment\n",
    "    best_overlap = 0\n",
    "    best_truth_id = None\n",
    "    \n",
    "    for interval in overlaps:\n",
    "        overlap_start = max(segment['start'], interval.begin)\n",
    "        overlap_end = min(segment['end'], interval.end)\n",
    "        overlap_length = overlap_end - overlap_start\n",
    "        \n",
    "        if overlap_length > best_overlap:\n",
    "            best_overlap = overlap_length\n",
    "            best_truth_id = interval.data\n",
    "    \n",
    "    return best_overlap / (segment['end'] - segment['start']), best_truth_id\n",
    "\n",
    "def evaluate_tool(tool_df, truth_trees):\n",
    "    \"\"\"Evaluate IBD detection performance for a specific tool\"\"\"\n",
    "    # If the DataFrame is empty, return it without processing\n",
    "    if len(tool_df) == 0:\n",
    "        print(f\"Tool: {tool_df.name if hasattr(tool_df, 'name') else 'Unknown'} - No segments to evaluate\")\n",
    "        return tool_df\n",
    "        \n",
    "    # Add columns for evaluation metrics\n",
    "    tool_df['detected_truth'] = False\n",
    "    tool_df['overlap_pct'] = 0.0\n",
    "    tool_df['truth_id'] = None\n",
    "    \n",
    "    # Debug counters\n",
    "    total_segments = len(tool_df)\n",
    "    matched_segments = 0\n",
    "    \n",
    "    for idx, row in tool_df.iterrows():\n",
    "        # Check if we have both sample pair in regular and reversed order\n",
    "        sample_pairs = [\n",
    "            # Regular order\n",
    "            ((row['sample1'], row.get('sample1_haplotype', 0)), \n",
    "             (row['sample2'], row.get('sample2_haplotype', 0)),\n",
    "             row['chrom']),\n",
    "            # Reversed order\n",
    "            ((row['sample2'], row.get('sample2_haplotype', 0)), \n",
    "             (row['sample1'], row.get('sample1_haplotype', 0)),\n",
    "             row['chrom'])\n",
    "        ]\n",
    "        \n",
    "        found_match = False\n",
    "        for sample1, sample2, chrom in sample_pairs:\n",
    "            pair_key = (sample1, sample2)\n",
    "            if (pair_key, chrom) in truth_trees:\n",
    "                overlap_pct, truth_id = calculate_overlap(row, truth_trees[(pair_key, chrom)])\n",
    "                if overlap_pct > 0:\n",
    "                    tool_df.at[idx, 'overlap_pct'] = overlap_pct\n",
    "                    tool_df.at[idx, 'truth_id'] = truth_id\n",
    "                    tool_df.at[idx, 'detected_truth'] = (overlap_pct >= 0.5)  # Consider >=50% overlap a true positive\n",
    "                    matched_segments += 1 if overlap_pct >= 0.5 else 0\n",
    "                    found_match = True\n",
    "                    break\n",
    "        \n",
    "        # Try without haplotypes if no match found and haplotypes present\n",
    "        if not found_match and 'sample1_haplotype' in row:\n",
    "            # Create keys without haplotype information\n",
    "            sample_pairs_no_hap = [\n",
    "                ((row['sample1'], None), (row['sample2'], None), row['chrom']),\n",
    "                ((row['sample2'], None), (row['sample1'], None), row['chrom'])\n",
    "            ]\n",
    "            \n",
    "            for sample1, sample2, chrom in sample_pairs_no_hap:\n",
    "                pair_key = (sample1, sample2)\n",
    "                if (pair_key, chrom) in truth_trees:\n",
    "                    overlap_pct, truth_id = calculate_overlap(row, truth_trees[(pair_key, chrom)])\n",
    "                    if overlap_pct > 0:\n",
    "                        tool_df.at[idx, 'overlap_pct'] = overlap_pct\n",
    "                        tool_df.at[idx, 'truth_id'] = truth_id\n",
    "                        tool_df.at[idx, 'detected_truth'] = (overlap_pct >= 0.5)\n",
    "                        matched_segments += 1 if overlap_pct >= 0.5 else 0\n",
    "                        break\n",
    "    \n",
    "    # Get the tool name safely\n",
    "    tool_name = tool_df['tool'].iloc[0] if len(tool_df) > 0 else \"Unknown\"\n",
    "    \n",
    "    # Calculate percentage safely\n",
    "    percentage = (matched_segments/total_segments*100) if total_segments > 0 else 0\n",
    "    \n",
    "    print(f\"Tool: {tool_name} - Matched {matched_segments} of {total_segments} segments ({percentage:.2f}%)\")\n",
    "    return tool_df\n",
    "\n",
    "def evaluate_all_tools(refined_df, hap_df, ibis_df, truth_df):\n",
    "    \"\"\"Evaluate all IBD detection tools\"\"\"\n",
    "    # Create interval trees for truth segments\n",
    "    truth_trees = create_interval_tree(truth_df)\n",
    "    \n",
    "    # Evaluate each tool\n",
    "    refined_eval = evaluate_tool(refined_df, truth_trees)\n",
    "    \n",
    "    # Only evaluate tools with data\n",
    "    if len(hap_df) > 0:\n",
    "        hap_eval = evaluate_tool(hap_df, truth_trees)\n",
    "    else:\n",
    "        print(\"Tool: HapIBD - No segments to evaluate\")\n",
    "        hap_eval = hap_df.copy()\n",
    "        hap_eval['tool'] = 'HapIBD'  # Ensure tool column exists\n",
    "    \n",
    "    ibis_eval = evaluate_tool(ibis_df, truth_trees)\n",
    "    \n",
    "    # Combine results\n",
    "    all_results = pd.concat([refined_eval, hap_eval, ibis_eval], ignore_index=True)\n",
    "    \n",
    "    return all_results, truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating IBD detection tools...\n",
      "Building interval trees from truth data...\n",
      "Created 292748 interval trees\n",
      "Tool: RefinedIBD - Matched 0 of 7975 segments (0.00%)\n",
      "Tool: HapIBD - Matched 4 of 40908 segments (0.01%)\n",
      "Tool: IBIS - Matched 0 of 199342 segments (0.00%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tools\n",
    "print(\"Evaluating IBD detection tools...\")\n",
    "all_results, truth_df = evaluate_all_tools(refined_df, hap_df, ibis_df, truth_df)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Format Diagnosis ===\n",
      "Truth data chromosome formats (sample of 5): [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "RefinedIBD chromosome formats (sample of 5): [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "HapIBD chromosome formats (sample of 5): [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "IBIS chromosome formats (sample of 5): [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "Truth data sample ID formats (sample of 5): ['user1376', 'user1435', 'user1510', 'user1439', 'user1511']\n",
      "RefinedIBD sample ID formats (sample of 5): ['user1376', 'user8208', 'user3983', 'user12164', 'user5550']\n",
      "HapIBD sample ID formats (sample of 5): ['user1376', 'user8208', 'user3983', 'user12164', 'user5550']\n",
      "IBIS sample ID formats (sample of 5): ['user1376', 'user8208', 'user3983', 'user12164', 'user5550']\n",
      "Truth data position range: 46,239 - 248,876,512\n",
      "RefinedIBD position range: 19,817 - 248,903,861\n",
      "HapIBD position range: 19,817 - 248,903,861\n",
      "IBIS position range: 19,817 - 248,903,861\n",
      "\n",
      "=== End of Diagnosis ===\n"
     ]
    }
   ],
   "source": [
    "diagnose_data_format_issues(all_results, truth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_length_distribution(all_results, truth_df):\n",
    "    \"\"\"Plot the distribution of segment lengths for each tool and truth\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Combine all data\n",
    "    all_data = pd.concat([\n",
    "        all_results[all_results['tool'] == 'RefinedIBD'][['length', 'tool']],\n",
    "        all_results[all_results['tool'] == 'HapIBD'][['length', 'tool']],\n",
    "        all_results[all_results['tool'] == 'IBIS'][['length', 'tool']],\n",
    "        truth_df[['length', 'tool']]\n",
    "    ])\n",
    "    \n",
    "    # Convert length from bp to Mbp\n",
    "    all_data['length'] = all_data['length'] / 1_000_000\n",
    "    \n",
    "    # Plot density\n",
    "    sns.kdeplot(data=all_data, x='length', hue='tool', fill=True, alpha=0.5)\n",
    "    \n",
    "    plt.title('Distribution of IBD Segment Lengths')\n",
    "    plt.xlabel('Segment Length (Mbp)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(results_directory) / prefix / 'segments' / 'ibd_length_distribution.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_precision_recall(all_results, truth_df):\n",
    "    \"\"\"Plot precision-recall curves for each tool\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    has_data = False\n",
    "    # For each tool, calculate precision and recall using overlap percentage as score\n",
    "    for tool_name, color in zip(['RefinedIBD', 'HapIBD', 'IBIS'], ['blue', 'green', 'red']):\n",
    "        tool_df = all_results[all_results['tool'] == tool_name]\n",
    "        \n",
    "        # Skip if no data for this tool\n",
    "        if len(tool_df) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Check if we have true positives\n",
    "        if tool_df['detected_truth'].sum() == 0:\n",
    "            print(f\"Warning: No true positives found for {tool_name}, skipping PR curve\")\n",
    "            continue\n",
    "            \n",
    "        has_data = True\n",
    "        \n",
    "        if 'LOD' in tool_df.columns and not tool_df['LOD'].isna().all():\n",
    "            score = tool_df['LOD']  # Use LOD score if available\n",
    "        else:\n",
    "            score = tool_df['length']  # Otherwise use length as a proxy for confidence\n",
    "            \n",
    "        y_true = tool_df['detected_truth'].astype(int)\n",
    "        \n",
    "        try:\n",
    "            # Calculate precision and recall\n",
    "            precision, recall, _ = precision_recall_curve(y_true, score)\n",
    "            avg_precision = average_precision_score(y_true, score)\n",
    "            \n",
    "            # Plot PR curve\n",
    "            plt.plot(recall, precision, lw=2, color=color,\n",
    "                     label=f'{tool_name} (AP={avg_precision:.2f})')\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting PR curve for {tool_name}: {e}\")\n",
    "    \n",
    "    if has_data:\n",
    "        plt.title('Precision-Recall Curves for IBD Detection Tools')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(results_directory) / prefix / 'segments' / 'ibd_precision_recall.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Skipping PR curve plot: No valid data\")\n",
    "\n",
    "def plot_roc_curves(all_results, truth_df):\n",
    "    \"\"\"Plot ROC curves for each tool\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    has_data = False\n",
    "    # For each tool, calculate ROC using overlap percentage as score\n",
    "    for tool_name, color in zip(['RefinedIBD', 'HapIBD', 'IBIS'], ['blue', 'green', 'red']):\n",
    "        tool_df = all_results[all_results['tool'] == tool_name]\n",
    "        \n",
    "        # Skip if no data for this tool\n",
    "        if len(tool_df) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Check if we have true positives\n",
    "        if tool_df['detected_truth'].sum() == 0:\n",
    "            print(f\"Warning: No true positives found for {tool_name}, skipping ROC curve\")\n",
    "            continue\n",
    "            \n",
    "        has_data = True\n",
    "        \n",
    "        if 'LOD' in tool_df.columns and not tool_df['LOD'].isna().all():\n",
    "            score = tool_df['LOD']  # Use LOD score if available\n",
    "        else:\n",
    "            score = tool_df['length']  # Otherwise use length as a proxy for confidence\n",
    "            \n",
    "        y_true = tool_df['detected_truth'].astype(int)\n",
    "        \n",
    "        try:\n",
    "            # Calculate ROC\n",
    "            fpr, tpr, _ = roc_curve(y_true, score)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            # Plot ROC curve\n",
    "            plt.plot(fpr, tpr, lw=2, color=color,\n",
    "                     label=f'{tool_name} (AUC={roc_auc:.2f})')\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting ROC curve for {tool_name}: {e}\")\n",
    "    \n",
    "    if has_data:\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='gray', alpha=0.8)\n",
    "        plt.title('ROC Curves for IBD Detection Tools')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(Path(results_directory) / prefix / 'segments' / 'ibd_roc_curves.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Skipping ROC curve plot: No valid data\")\n",
    "\n",
    "def plot_overlap_histogram(all_results):\n",
    "    \"\"\"Plot histogram of overlap percentages for each tool\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for tool_name, color in zip(['RefinedIBD', 'HapIBD', 'IBIS'], ['blue', 'green', 'red']):\n",
    "        tool_df = all_results[all_results['tool'] == tool_name]\n",
    "        plt.hist(tool_df['overlap_pct'], bins=20, alpha=0.5, color=color, label=tool_name)\n",
    "    \n",
    "    plt.title('Distribution of Overlap with Truth Segments')\n",
    "    plt.xlabel('Overlap Percentage')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(results_directory) / prefix / 'segments' / 'ibd_overlap_histogram.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate visualizations\n",
    "print(\"Generating visualizations...\")\n",
    "plot_length_distribution(all_results, truth_df)\n",
    "plot_precision_recall(all_results, truth_df)\n",
    "plot_roc_curves(all_results, truth_df)\n",
    "plot_overlap_histogram(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_summary_metrics(all_results, truth_df):\n",
    "    \"\"\"Calculate summary statistics for each tool\"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    # Count total truth segments\n",
    "    total_truth = len(truth_df)\n",
    "    print(f\"Total truth segments: {total_truth}\")\n",
    "    \n",
    "    for tool_name in ['RefinedIBD', 'HapIBD', 'IBIS']:\n",
    "        tool_df = all_results[all_results['tool'] == tool_name]\n",
    "        \n",
    "        if len(tool_df) == 0:\n",
    "            print(f\"No segments found for {tool_name}, skipping metrics\")\n",
    "            continue\n",
    "        \n",
    "        # Count true positives (segments with >50% overlap)\n",
    "        true_positives = tool_df['detected_truth'].sum()\n",
    "        \n",
    "        # Count false positives (segments with ≤50% overlap)\n",
    "        false_positives = len(tool_df) - true_positives\n",
    "        \n",
    "        # Count truth segments detected by this tool\n",
    "        detected_truth_ids = set([x for x in tool_df['truth_id'] if x is not None])\n",
    "        detected_truths = len(detected_truth_ids)\n",
    "        \n",
    "        # Calculate recall (proportion of truth segments detected)\n",
    "        recall = detected_truths / total_truth if total_truth > 0 else 0\n",
    "        \n",
    "        # Calculate precision (proportion of detected segments that are true)\n",
    "        precision = true_positives / len(tool_df) if len(tool_df) > 0 else 0\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        # Print detailed debug info\n",
    "        print(f\"\\n{tool_name} Summary:\")\n",
    "        print(f\"  Total segments: {len(tool_df)}\")\n",
    "        print(f\"  True positives: {true_positives} ({true_positives/len(tool_df)*100:.2f}% of segments)\")\n",
    "        print(f\"  False positives: {false_positives} ({false_positives/len(tool_df)*100:.2f}% of segments)\")\n",
    "        print(f\"  Unique truth segments detected: {detected_truths} ({detected_truths/total_truth*100:.2f}% of truth)\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        metrics.append({\n",
    "            'Tool': tool_name,\n",
    "            'Total Segments': len(tool_df),\n",
    "            'True Positives': true_positives,\n",
    "            'False Positives': false_positives,\n",
    "            'Detected Truth Segments': detected_truths,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1\n",
    "        })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    \n",
    "    # Check if we have meaningful metrics\n",
    "    if len(metrics_df) == 0 or metrics_df['True Positives'].sum() == 0:\n",
    "        print(\"\\n⚠️ WARNING: No true positives detected across any tool!\")\n",
    "        print(\"This suggests an issue with matching segments to ground truth.\")\n",
    "        print(\"Possible causes:\")\n",
    "        print(\"1. Column name mismatches between tool output and truth data\")\n",
    "        print(\"2. Sample ID format differences\")\n",
    "        print(\"3. Chromosome notation differences (e.g., 'chr1' vs '1')\")\n",
    "        print(\"4. Position coordinate system differences\")\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Calculate and display summary metrics\n",
    "print(\"Calculating summary metrics...\")\n",
    "metrics_df = calculate_summary_metrics(all_results, truth_df)\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary_barplot(metrics_df):\n",
    "    \"\"\"Plot summary metrics as a bar chart\"\"\"\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Melt the dataframe to make it suitable for grouped bar chart\n",
    "    plot_metrics = ['Precision', 'Recall', 'F1 Score']\n",
    "    plot_df = pd.melt(metrics_df, id_vars=['Tool'], value_vars=plot_metrics, \n",
    "                      var_name='Metric', value_name='Value')\n",
    "    \n",
    "    # Create grouped bar chart\n",
    "    sns.barplot(x='Tool', y='Value', hue='Metric', data=plot_df)\n",
    "    \n",
    "    plt.title('Performance Metrics by IBD Detection Tool')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(results_directory) / prefix / 'segments' / 'ibd_performance_metrics.png')\n",
    "    plt.show()\n",
    "    \n",
    "plot_summary_barplot(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chromosome_performance(all_results, truth_df):\n",
    "    \"\"\"Plot performance metrics by chromosome\"\"\"\n",
    "    # Get unique chromosomes\n",
    "    all_chroms = sorted(truth_df['chrom'].unique())\n",
    "    \n",
    "    # Initialize metrics dictionary\n",
    "    chrom_metrics = {tool: {chrom: {'precision': 0, 'recall': 0, 'f1': 0} \n",
    "                           for chrom in all_chroms} \n",
    "                    for tool in ['RefinedIBD', 'HapIBD', 'IBIS']}\n",
    "    \n",
    "    # Calculate metrics per chromosome\n",
    "    for chrom in all_chroms:\n",
    "        # Count truth segments in this chromosome\n",
    "        truth_in_chrom = truth_df[truth_df['chrom'] == chrom]\n",
    "        total_truth = len(truth_in_chrom)\n",
    "        \n",
    "        for tool in ['RefinedIBD', 'HapIBD', 'IBIS']:\n",
    "            # Get tool results for this chromosome\n",
    "            tool_results = all_results[(all_results['tool'] == tool) & \n",
    "                                       (all_results['chrom'] == chrom)]\n",
    "            \n",
    "            if len(tool_results) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Count true positives\n",
    "            true_positives = tool_results['detected_truth'].sum()\n",
    "            \n",
    "            # Count detected truth segments\n",
    "            detected_truth_ids = set([x for x in tool_results['truth_id'] if x is not None])\n",
    "            detected_truths = len(detected_truth_ids)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = true_positives / len(tool_results) if len(tool_results) > 0 else 0\n",
    "            recall = detected_truths / total_truth if total_truth > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            chrom_metrics[tool][chrom]['precision'] = precision\n",
    "            chrom_metrics[tool][chrom]['recall'] = recall\n",
    "            chrom_metrics[tool][chrom]['f1'] = f1\n",
    "    \n",
    "    # Create dataframes for plotting\n",
    "    plot_data = []\n",
    "    for tool in chrom_metrics:\n",
    "        for chrom in chrom_metrics[tool]:\n",
    "            for metric in ['precision', 'recall', 'f1']:\n",
    "                plot_data.append({\n",
    "                    'Tool': tool,\n",
    "                    'Chromosome': chrom,\n",
    "                    'Metric': metric.capitalize(),\n",
    "                    'Value': chrom_metrics[tool][chrom][metric]\n",
    "                })\n",
    "    \n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    g = sns.FacetGrid(plot_df, col='Metric', row='Tool', height=3, aspect=2)\n",
    "    g.map_dataframe(sns.barplot, x='Chromosome', y='Value')\n",
    "    g.set_axis_labels('Chromosome', 'Score')\n",
    "    g.set_titles('{row_name} - {col_name}')\n",
    "    \n",
    "    for ax in g.axes.flat:\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(results_directory) / prefix / 'segments' / 'ibd_chromosome_performance.png')\n",
    "    plt.show()\n",
    "    \n",
    "plot_chromosome_performance(all_results, truth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<cell_type>markdown</cell_type>⚠️ **Warning**: The next cell (cell 18) can take a very long time to run (approximately 76 minutes). This is because it performs a detailed analysis for each segment length bin.\n",
    "\n",
    "**Options for proceeding:**\n",
    "\n",
    "1. **Run the full analysis** if you have plenty of time and computing resources.\n",
    "2. **Use a subset** of the data by modifying the code to use fewer bins or process only certain chromosomes.\n",
    "3. **Skip the cell** entirely and continue with the rest of the notebook - the analysis is supplemental and not critical for understanding the core concepts.\n",
    "\n",
    "If you're in a workshop or classroom setting with limited time, option 3 is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_by_length(all_results, truth_df, sample_size=None):\n",
    "    \"\"\"\n",
    "    Plot detection accuracy as a function of segment length.\n",
    "    \n",
    "    Args:\n",
    "        all_results: DataFrame with IBD detection results\n",
    "        truth_df: DataFrame with ground truth segments\n",
    "        sample_size: If provided, limit analysis to this many truth segments for faster execution\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Bin truth segments by length\n",
    "    bins = [0, 1e4, 5e4, 1e5, 5e5, 1e6, 5e6, float('inf')]\n",
    "    bin_labels = ['<10kb', '10-50kb', '50-100kb', '0.1-0.5Mb', '0.5-1Mb', '1-5Mb', '>5Mb']\n",
    "    \n",
    "    # Add length bins to truth dataframe\n",
    "    truth_df['length_bin'] = pd.cut(truth_df['length'], bins=bins, labels=bin_labels)\n",
    "    \n",
    "    # Optionally sample the truth data for faster execution\n",
    "    if sample_size is not None and len(truth_df) > sample_size:\n",
    "        # Stratified sampling to maintain distribution across bins\n",
    "        truth_df = truth_df.groupby('length_bin', observed=True).apply(\n",
    "            lambda x: x.sample(min(len(x), max(1, int(sample_size * len(x) / len(truth_df)))))\n",
    "        ).reset_index(drop=True)\n",
    "        print(f\"Using a stratified sample of {len(truth_df)} truth segments for faster execution\")\n",
    "    \n",
    "    # Count total truth segments per bin\n",
    "    truth_counts = truth_df.groupby('length_bin', observed=True).size()\n",
    "    \n",
    "    # For each tool, calculate detection rate by length bin using vectorized operations\n",
    "    for tool_name, color in zip(['RefinedIBD', 'HapIBD', 'IBIS'], ['blue', 'green', 'red']):\n",
    "        detection_rates = []\n",
    "        \n",
    "        # Get the tool's dataframe\n",
    "        tool_df = all_results[all_results['tool'] == tool_name]\n",
    "        if len(tool_df) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Create a set of truth_ids detected by this tool for faster lookup\n",
    "        detected_truth_ids = set(tool_df['truth_id'].dropna())\n",
    "        \n",
    "        for bin_label in bin_labels:\n",
    "            # Get truth segments in this bin\n",
    "            bin_truth = truth_df[truth_df['length_bin'] == bin_label]\n",
    "            total = len(bin_truth)\n",
    "            \n",
    "            if total == 0:\n",
    "                detection_rates.append(0)\n",
    "                continue\n",
    "            \n",
    "            # Count how many were detected by this tool - vectorized approach\n",
    "            detected = sum(id in detected_truth_ids for id in bin_truth['segment_id'])\n",
    "            detection_rates.append(detected / total if total > 0 else 0)\n",
    "        \n",
    "        plt.plot(bin_labels, detection_rates, marker='o', label=tool_name, color=color, linewidth=2)\n",
    "    \n",
    "    plt.title('IBD Detection Rate by Segment Length')\n",
    "    plt.xlabel('Segment Length')\n",
    "    plt.ylabel('Detection Rate')\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(results_directory) / prefix / 'segments' / 'ibd_detection_by_length.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Also create a bar chart showing segment counts by length\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    truth_counts.plot(kind='bar', color='purple')\n",
    "    plt.title('Number of Truth Segments by Length')\n",
    "    plt.xlabel('Segment Length')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(results_directory) / prefix / 'segments' / 'ibd_truth_segments_by_length.png')\n",
    "    plt.show()\n",
    "\n",
    "# Choose one of these calls:\n",
    "\n",
    "# 1. Full analysis (takes ~76 minutes)\n",
    "# plot_accuracy_by_length(all_results, truth_df)\n",
    "\n",
    "# 2. Faster version with sampling (takes ~5-10 minutes)\n",
    "plot_accuracy_by_length(all_results, truth_df, sample_size=1000)\n",
    "\n",
    "# 3. Comment out both lines above to skip this analysis entirely"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
