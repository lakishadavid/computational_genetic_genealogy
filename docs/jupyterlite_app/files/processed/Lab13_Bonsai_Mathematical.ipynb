{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 13: Mathematical Foundations of Bonsai\n",
    "\n",
    "Building upon our exploration of IBD segments in Lab 12, we now delve into the mathematical principles that underpin the Bonsai algorithm. This lab will focus on the probabilistic framework, likelihood functions, and optimization techniques that power Bonsai's pedigree reconstruction capabilities.\n",
    "\n",
    "**Learning Objectives**:\n",
    "- Master the probabilistic framework that underpins the Bonsai algorithm\n",
    "- Understand how likelihood functions quantify the probability of observed IBD patterns\n",
    "- Analyze the mathematical models for different relationship types\n",
    "- Explore IBD moment calculations and their role in pedigree inference\n",
    "- Examine Bonsai's optimization algorithms for finding maximum likelihood pedigrees\n",
    "- Implement and interpret key mathematical components of the Bonsai algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from scipy.stats import poisson, expon, norm, multivariate_normal\n",
    "from collections import defaultdict, deque\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Probabilistic Framework of Bonsai\n",
    "\n",
    "At its core, Bonsai is a statistical algorithm that uses probabilistic inference to reconstruct pedigrees from genetic data. The algorithm employs a Bayesian approach, balancing prior knowledge about relationship structures with the observed evidence from IBD segment patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Inference in Pedigree Reconstruction\n",
    "\n",
    "Bonsai uses Bayesian inference to reason about unobserved structures (pedigrees) based on observed data (IBD segments). The Bayesian framework is expressed as:\n",
    "\n",
    "$$P(\\text{Pedigree} | \\text{IBD data}) \\propto P(\\text{IBD data} | \\text{Pedigree}) \\times P(\\text{Pedigree})$$\n",
    "\n",
    "where:\n",
    "- $P(\\text{Pedigree} | \\text{IBD data})$ is the posterior probability of a pedigree given the IBD data\n",
    "- $P(\\text{IBD data} | \\text{Pedigree})$ is the likelihood of observing the IBD data given a particular pedigree\n",
    "- $P(\\text{Pedigree})$ is the prior probability of the pedigree\n",
    "\n",
    "Bonsai seeks to find the pedigree that maximizes this posterior probability, which is equivalent to maximizing the log-likelihood when using uniform priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(pedigree, ibd_data, prior_weight=1.0):\n",
    "    \"\"\"Calculate the log posterior probability of a pedigree given IBD data.\n",
    "    \n",
    "    Args:\n",
    "        pedigree: A representation of the pedigree structure\n",
    "        ibd_data: Observed IBD segment data\n",
    "        prior_weight: Weight to apply to the prior (default: 1.0)\n",
    "        \n",
    "    Returns:\n",
    "        Log posterior probability\n",
    "    \"\"\"\n",
    "    # Calculate log likelihood\n",
    "    log_likelihood = calculate_log_likelihood(pedigree, ibd_data)\n",
    "    \n",
    "    # Calculate log prior\n",
    "    log_prior = calculate_log_prior(pedigree) * prior_weight\n",
    "    \n",
    "    # Combine to get log posterior\n",
    "    return log_likelihood + log_prior\n",
    "\n",
    "def calculate_log_likelihood(pedigree, ibd_data):\n",
    "    \"\"\"Calculate the log likelihood of observing the IBD data given the pedigree.\n",
    "    \n",
    "    This is a simplified implementation for demonstration purposes.\n",
    "    \"\"\"\n",
    "    # Placeholder for actual likelihood calculation\n",
    "    # In a real implementation, this would use the mathematical models\n",
    "    # described in the following sections\n",
    "    return 0.0\n",
    "\n",
    "def calculate_log_prior(pedigree):\n",
    "    \"\"\"Calculate the log prior probability of a pedigree.\n",
    "    \n",
    "    This is a simplified implementation for demonstration purposes.\n",
    "    \"\"\"\n",
    "    # For simplicity, we'll use a uniform prior (log prior = 0)\n",
    "    # In a real implementation, this might incorporate domain knowledge\n",
    "    # such as demographic patterns, typical family structures, etc.\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Likelihood Functions: Quantifying the Evidence\n",
    "\n",
    "The likelihood function measures how well a proposed pedigree explains the observed IBD data. In Bonsai, this function is built from probabilistic models of IBD segment inheritance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBD Likelihood Models\n",
    "\n",
    "For a pair of individuals, the likelihood of their IBD sharing given a specific relationship can be expressed as:\n",
    "\n",
    "$$L(r | \\text{IBD}) = P(\\text{IBD} | r)$$\n",
    "\n",
    "where:\n",
    "- $r$ is the relationship type (e.g., parent-child, siblings, cousins)\n",
    "- IBD represents the observed IBD segments between the individuals\n",
    "\n",
    "Let's implement some basic likelihood models for different relationship types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_child_likelihood(segments):\n",
    "    \"\"\"Calculate likelihood of a parent-child relationship.\n",
    "    \n",
    "    Args:\n",
    "        segments: List of IBD segments with attributes: length, type (IBD1 or IBD2)\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood of the relationship\n",
    "    \"\"\"\n",
    "    # For parent-child:\n",
    "    # - Expect IBD1 across entire genome (~3500 cM)\n",
    "    # - No IBD2 segments expected\n",
    "    \n",
    "    # Calculate total IBD1 length\n",
    "    ibd1_length = sum(seg['length'] for seg in segments if seg['type'] == 'IBD1')\n",
    "    \n",
    "    # Count IBD2 segments\n",
    "    ibd2_count = sum(1 for seg in segments if seg['type'] == 'IBD2')\n",
    "    \n",
    "    # Calculate coverage (proportion of genome covered by IBD1)\n",
    "    genome_length = 3500  # cM\n",
    "    coverage = min(1.0, ibd1_length / genome_length)\n",
    "    \n",
    "    # High likelihood if coverage is close to 100% and no IBD2\n",
    "    if coverage > 0.95 and ibd2_count == 0:\n",
    "        return math.log(0.99)  # High log-likelihood\n",
    "    else:\n",
    "        # Penalize based on how far from expected\n",
    "        penalty = ((1.0 - coverage) ** 2) * 10 + (ibd2_count ** 2)\n",
    "        return -penalty  # Negative log-likelihood\n",
    "\n",
    "def sibling_likelihood(segments):\n",
    "    \"\"\"Calculate likelihood of a full sibling relationship.\n",
    "    \n",
    "    Args:\n",
    "        segments: List of IBD segments with attributes: length, type (IBD1 or IBD2)\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood of the relationship\n",
    "    \"\"\"\n",
    "    # For full siblings:\n",
    "    # - Expect ~25% IBD0, ~50% IBD1, ~25% IBD2\n",
    "    # - Total IBD sharing around 2550 cM\n",
    "    \n",
    "    # Calculate IBD lengths\n",
    "    ibd1_length = sum(seg['length'] for seg in segments if seg['type'] == 'IBD1')\n",
    "    ibd2_length = sum(seg['length'] for seg in segments if seg['type'] == 'IBD2')\n",
    "    total_length = ibd1_length + 2 * ibd2_length  # IBD2 counts double\n",
    "    \n",
    "    # Calculate proportions\n",
    "    genome_length = 3500  # cM\n",
    "    ibd0_prop = max(0, 1 - (ibd1_length + ibd2_length) / genome_length)\n",
    "    ibd1_prop = ibd1_length / genome_length\n",
    "    ibd2_prop = ibd2_length / genome_length\n",
    "    \n",
    "    # Expected proportions for siblings\n",
    "    expected_ibd0 = 0.25\n",
    "    expected_ibd1 = 0.50\n",
    "    expected_ibd2 = 0.25\n",
    "    \n",
    "    # Calculate squared error from expected proportions\n",
    "    error = ((ibd0_prop - expected_ibd0) ** 2 + \n",
    "             (ibd1_prop - expected_ibd1) ** 2 + \n",
    "             (ibd2_prop - expected_ibd2) ** 2)\n",
    "    \n",
    "    # Convert to log-likelihood (higher is better)\n",
    "    return -10 * error\n",
    "\n",
    "def distant_relationship_likelihood(segments, meioses):\n",
    "    \"\"\"Calculate likelihood of a distant relationship with specified meioses.\n",
    "    \n",
    "    Args:\n",
    "        segments: List of IBD segments with attributes: length, type (IBD1 or IBD2)\n",
    "        meioses: Number of meioses separating the individuals\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood of the relationship\n",
    "    \"\"\"\n",
    "    # For distant relationships:\n",
    "    # - Expect segment count and length to follow theoretical distributions\n",
    "    # - Almost all segments should be IBD1 (very rare IBD2)\n",
    "    \n",
    "    # Filter to include only segments above minimum threshold\n",
    "    min_cm = 7  # Minimum segment length in cM\n",
    "    filtered_segments = [seg for seg in segments \n",
    "                         if seg['type'] == 'IBD1' and seg['length'] >= min_cm]\n",
    "    \n",
    "    # Calculate observed moments\n",
    "    segment_count = len(filtered_segments)\n",
    "    total_length = sum(seg['length'] for seg in filtered_segments)\n",
    "    \n",
    "    # Calculate expected moments based on relationship\n",
    "    relatedness = 2 ** (-meioses)\n",
    "    expected_count = calculate_expected_segments(relatedness, min_cm)\n",
    "    expected_length = calculate_expected_length(relatedness, min_cm)\n",
    "    \n",
    "    # Use Poisson distribution for segment count likelihood\n",
    "    count_log_like = poisson.logpmf(segment_count, expected_count)\n",
    "    \n",
    "    # Use Gamma distribution for total length likelihood (simplified)\n",
    "    length_factor = 0.0\n",
    "    if segment_count > 0 and expected_count > 0:\n",
    "        # Simple approximation using normal distribution\n",
    "        length_log_like = norm.logpdf(total_length, \n",
    "                                      expected_length, \n",
    "                                      expected_length / math.sqrt(expected_count))\n",
    "        length_factor = length_log_like\n",
    "    \n",
    "    # Combine the likelihoods (weighting count more heavily)\n",
    "    return count_log_like * 0.7 + length_factor * 0.3\n",
    "\n",
    "# Helper functions for calculating expected moments\n",
    "def calculate_expected_segments(relatedness, min_cm=7):\n",
    "    \"\"\"Calculate expected number of IBD segments for a given relatedness.\"\"\"\n",
    "    # Based on theoretical model\n",
    "    r = -math.log(relatedness) / math.log(2)  # meioses\n",
    "    genome_length = 3500  # cM\n",
    "    \n",
    "    # Expected number of segments above min_cm\n",
    "    # This is a simplified approximation\n",
    "    expected = (genome_length / 100) * relatedness * math.exp(-r * min_cm) * 22\n",
    "    return expected\n",
    "\n",
    "def calculate_expected_length(relatedness, min_cm=7):\n",
    "    \"\"\"Calculate expected total length of IBD segments.\"\"\"\n",
    "    # Based on theoretical model\n",
    "    r = -math.log(relatedness) / math.log(2)  # meioses\n",
    "    genome_length = 3500  # cM\n",
    "    \n",
    "    # Expected total length\n",
    "    # This is a simplified approximation\n",
    "    expected = genome_length * relatedness * (1 + r * min_cm) * math.exp(-r * min_cm)\n",
    "    return expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Likelihood Models for Different Relationships\n",
    "\n",
    "Let's compare how these likelihood models behave for different relationship scenarios. We'll create synthetic IBD data for various relationships and see how well our models can distinguish them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_ibd(relationship_type, noise_level=0.1):\n",
    "    \"\"\"Generate synthetic IBD data for a specific relationship type.\n",
    "    \n",
    "    Args:\n",
    "        relationship_type: One of 'parent-child', 'siblings', 'grandparent', \n",
    "                          'half-siblings', 'first-cousins', 'second-cousins'\n",
    "        noise_level: Level of noise/randomness to add (0.0-1.0)\n",
    "        \n",
    "    Returns:\n",
    "        List of synthetic IBD segments\n",
    "    \"\"\"\n",
    "    genome_length = 3500  # cM\n",
    "    segments = []\n",
    "    \n",
    "    if relationship_type == 'parent-child':\n",
    "        # Parent-child: ~100% IBD1, no IBD2\n",
    "        # Create segments covering the entire genome with some fragmentation\n",
    "        remaining = genome_length\n",
    "        while remaining > 0:\n",
    "            # Create segments of varying sizes but maintain total coverage\n",
    "            seg_length = min(remaining, random.uniform(50, 200))\n",
    "            segments.append({\n",
    "                'type': 'IBD1',\n",
    "                'length': seg_length * (1.0 + random.uniform(-noise_level, noise_level))\n",
    "            })\n",
    "            remaining -= seg_length\n",
    "            \n",
    "    elif relationship_type == 'siblings':\n",
    "        # Siblings: ~25% IBD0, ~50% IBD1, ~25% IBD2\n",
    "        ibd0_target = 0.25 * genome_length\n",
    "        ibd1_target = 0.50 * genome_length\n",
    "        ibd2_target = 0.25 * genome_length\n",
    "        \n",
    "        # Add noise to targets\n",
    "        ibd0_target *= (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        ibd1_target *= (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        ibd2_target *= (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        \n",
    "        # Create IBD1 segments\n",
    "        ibd1_remaining = ibd1_target\n",
    "        while ibd1_remaining > 10:  # Minimum segment size\n",
    "            seg_length = min(ibd1_remaining, random.uniform(10, 100))\n",
    "            segments.append({\n",
    "                'type': 'IBD1',\n",
    "                'length': seg_length\n",
    "            })\n",
    "            ibd1_remaining -= seg_length\n",
    "            \n",
    "        # Create IBD2 segments\n",
    "        ibd2_remaining = ibd2_target\n",
    "        while ibd2_remaining > 10:  # Minimum segment size\n",
    "            seg_length = min(ibd2_remaining, random.uniform(10, 100))\n",
    "            segments.append({\n",
    "                'type': 'IBD2',\n",
    "                'length': seg_length\n",
    "            })\n",
    "            ibd2_remaining -= seg_length\n",
    "            \n",
    "    elif relationship_type in ['half-siblings', 'grandparent']:\n",
    "        # Half-siblings/Grandparent: ~50% IBD0, ~50% IBD1, no IBD2\n",
    "        ibd1_target = 0.50 * genome_length * (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        \n",
    "        # Create IBD1 segments\n",
    "        ibd1_remaining = ibd1_target\n",
    "        while ibd1_remaining > 10:  # Minimum segment size\n",
    "            seg_length = min(ibd1_remaining, random.uniform(10, 100))\n",
    "            segments.append({\n",
    "                'type': 'IBD1',\n",
    "                'length': seg_length\n",
    "            })\n",
    "            ibd1_remaining -= seg_length\n",
    "            \n",
    "    elif relationship_type == 'first-cousins':\n",
    "        # First cousins: ~12.5% IBD1\n",
    "        ibd1_target = 0.125 * genome_length * (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        \n",
    "        # Create IBD1 segments\n",
    "        ibd1_remaining = ibd1_target\n",
    "        while ibd1_remaining > 7:  # Minimum segment size\n",
    "            seg_length = min(ibd1_remaining, random.uniform(7, 50))\n",
    "            segments.append({\n",
    "                'type': 'IBD1',\n",
    "                'length': seg_length\n",
    "            })\n",
    "            ibd1_remaining -= seg_length\n",
    "            \n",
    "    elif relationship_type == 'second-cousins':\n",
    "        # Second cousins: ~3.125% IBD1\n",
    "        ibd1_target = 0.03125 * genome_length * (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        \n",
    "        # Create IBD1 segments\n",
    "        ibd1_remaining = ibd1_target\n",
    "        while ibd1_remaining > 7:  # Minimum segment size\n",
    "            seg_length = min(ibd1_remaining, random.uniform(7, 30))\n",
    "            segments.append({\n",
    "                'type': 'IBD1',\n",
    "                'length': seg_length\n",
    "            })\n",
    "            ibd1_remaining -= seg_length\n",
    "    \n",
    "    # Sort segments by length (largest first)\n",
    "    return sorted(segments, key=lambda x: x['length'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic IBD data for different relationships\n",
    "relationship_types = ['parent-child', 'siblings', 'half-siblings', 'first-cousins', 'second-cousins']\n",
    "synthetic_data = {}\n",
    "\n",
    "for rel_type in relationship_types:\n",
    "    synthetic_data[rel_type] = generate_synthetic_ibd(rel_type)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    total_ibd1 = sum(seg['length'] for seg in synthetic_data[rel_type] if seg['type'] == 'IBD1')\n",
    "    total_ibd2 = sum(seg['length'] for seg in synthetic_data[rel_type] if seg['type'] == 'IBD2')\n",
    "    ibd1_count = sum(1 for seg in synthetic_data[rel_type] if seg['type'] == 'IBD1')\n",
    "    ibd2_count = sum(1 for seg in synthetic_data[rel_type] if seg['type'] == 'IBD2')\n",
    "    \n",
    "    print(f\"{rel_type}:\")\n",
    "    print(f\"  IBD1: {total_ibd1:.1f} cM in {ibd1_count} segments\")\n",
    "    print(f\"  IBD2: {total_ibd2:.1f} cM in {ibd2_count} segments\")\n",
    "    print(f\"  Total: {total_ibd1 + total_ibd2:.1f} cM\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate likelihoods for each relationship type using each model\n",
    "results = []\n",
    "\n",
    "for true_rel in relationship_types:\n",
    "    data = synthetic_data[true_rel]\n",
    "    \n",
    "    # Calculate likelihoods\n",
    "    pc_like = parent_child_likelihood(data)\n",
    "    sib_like = sibling_likelihood(data)\n",
    "    \n",
    "    # Distant relationship likelihoods\n",
    "    hs_like = distant_relationship_likelihood(data, 2)  # Half-siblings: 2 meioses\n",
    "    fc_like = distant_relationship_likelihood(data, 4)  # First cousins: 4 meioses\n",
    "    sc_like = distant_relationship_likelihood(data, 6)  # Second cousins: 6 meioses\n",
    "    \n",
    "    results.append({\n",
    "        'True Relationship': true_rel,\n",
    "        'Parent-Child Log-Likelihood': pc_like,\n",
    "        'Sibling Log-Likelihood': sib_like,\n",
    "        'Half-Sibling Log-Likelihood': hs_like,\n",
    "        'First-Cousin Log-Likelihood': fc_like,\n",
    "        'Second-Cousin Log-Likelihood': sc_like\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "likelihood_df = pd.DataFrame(results)\n",
    "likelihood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highest likelihood model for each relationship\n",
    "likelihood_columns = [\n",
    "    'Parent-Child Log-Likelihood',\n",
    "    'Sibling Log-Likelihood',\n",
    "    'Half-Sibling Log-Likelihood',\n",
    "    'First-Cousin Log-Likelihood',\n",
    "    'Second-Cousin Log-Likelihood'\n",
    "]\n",
    "\n",
    "# Find max likelihood for each row\n",
    "likelihood_df['Max Likelihood'] = likelihood_df[likelihood_columns].max(axis=1)\n",
    "likelihood_df['Predicted Relationship'] = likelihood_df[likelihood_columns].idxmax(axis=1)\n",
    "\n",
    "# Clean up the predicted relationship string\n",
    "likelihood_df['Predicted Relationship'] = likelihood_df['Predicted Relationship'].str.replace('-Log-Likelihood', '')\n",
    "\n",
    "# Display results\n",
    "likelihood_df[['True Relationship', 'Predicted Relationship', 'Max Likelihood']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBD Moments Model\n",
    "\n",
    "A key innovation in Bonsai is the use of \"IBD moments\" to summarize the IBD sharing between individuals. Let's implement a function to calculate these moments from IBD segment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ibd_moments(segment_list, min_length=7):\n",
    "    \"\"\"Calculate IBD moments from a list of segments.\n",
    "    \n",
    "    Args:\n",
    "        segment_list: List of IBD segments with 'length' attribute\n",
    "        min_length: Minimum segment length to consider\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with first moment (count) and second moment (total length)\n",
    "    \"\"\"\n",
    "    # Filter segments by minimum length\n",
    "    filtered_segments = [seg for seg in segment_list if seg['length'] >= min_length]\n",
    "    \n",
    "    # First moment: number of segments\n",
    "    first_moment = len(filtered_segments)\n",
    "    \n",
    "    # Second moment: total length of segments\n",
    "    second_moment = sum(seg['length'] for seg in filtered_segments)\n",
    "    \n",
    "    # Third moment (optional): sum of squared lengths\n",
    "    third_moment = sum(seg['length']**2 for seg in filtered_segments)\n",
    "    \n",
    "    return {\n",
    "        \"first_moment\": first_moment,\n",
    "        \"second_moment\": second_moment,\n",
    "        \"third_moment\": third_moment\n",
    "    }\n",
    "\n",
    "# Calculate moments for each relationship type\n",
    "moments_results = []\n",
    "\n",
    "for rel_type, data in synthetic_data.items():\n",
    "    moments = calculate_ibd_moments(data)\n",
    "    moments_results.append({\n",
    "        'Relationship': rel_type,\n",
    "        'Segment Count': moments['first_moment'],\n",
    "        'Total Length (cM)': moments['second_moment'],\n",
    "        'Mean Segment Length': moments['second_moment'] / max(1, moments['first_moment'])\n",
    "    })\n",
    "\n",
    "moments_df = pd.DataFrame(moments_results)\n",
    "moments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the moments by relationship type\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Sort by total length for better visualization\n",
    "moments_df = moments_df.sort_values('Total Length (cM)', ascending=False)\n",
    "\n",
    "# Plot segment count and total length\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "moments_df.plot(x='Relationship', y='Segment Count', kind='bar', ax=ax)\n",
    "plt.title('First Moment: Segment Count')\n",
    "plt.ylabel('Number of Segments (>7cM)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "moments_df.plot(x='Relationship', y='Total Length (cM)', kind='bar', ax=ax)\n",
    "plt.title('Second Moment: Total IBD Length')\n",
    "plt.ylabel('Total Length (cM)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Up-Node Dictionary: Encoding Pedigree Structures\n",
    "\n",
    "A key data structure in Bonsai is the \"up-node dictionary,\" which encodes the pedigree structure in a way that facilitates efficient likelihood calculations and structural modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_up_node_dict(individuals):\n",
    "    \"\"\"Create an empty up-node dictionary for a set of individuals.\n",
    "    \n",
    "    Args:\n",
    "        individuals: List of individual IDs\n",
    "        \n",
    "    Returns:\n",
    "        Empty up-node dictionary\n",
    "    \"\"\"\n",
    "    up_node_dict = {}\n",
    "    for ind in individuals:\n",
    "        up_node_dict[ind] = {}  # Empty dictionary indicates no parents\n",
    "    return up_node_dict\n",
    "\n",
    "def add_relationship(up_node_dict, child, parent1, parent2=None):\n",
    "    \"\"\"Add a parent-child relationship to the up-node dictionary.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: The up-node dictionary to modify\n",
    "        child: ID of the child\n",
    "        parent1: ID of the first parent\n",
    "        parent2: ID of the second parent (optional)\n",
    "        \n",
    "    Returns:\n",
    "        Modified up-node dictionary\n",
    "    \"\"\"\n",
    "    if child not in up_node_dict:\n",
    "        up_node_dict[child] = {}\n",
    "    \n",
    "    # Add first parent\n",
    "    up_node_dict[child][parent1] = 1\n",
    "    \n",
    "    # Add second parent if provided\n",
    "    if parent2 is not None:\n",
    "        up_node_dict[child][parent2] = 1\n",
    "    \n",
    "    # Make sure parents exist in the dictionary\n",
    "    if parent1 not in up_node_dict:\n",
    "        up_node_dict[parent1] = {}\n",
    "    if parent2 is not None and parent2 not in up_node_dict:\n",
    "        up_node_dict[parent2] = {}\n",
    "    \n",
    "    return up_node_dict\n",
    "\n",
    "def visualize_pedigree(up_node_dict):\n",
    "    \"\"\"Create a visualization of the pedigree from an up-node dictionary.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "    \"\"\"\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for child, parents in up_node_dict.items():\n",
    "        G.add_node(child)\n",
    "        for parent in parents:\n",
    "            G.add_node(parent)\n",
    "            G.add_edge(parent, child)  # Direction from parent to child\n",
    "    \n",
    "    # Set node colors: green for real individuals (positive IDs), white for latent (negative IDs)\n",
    "    node_colors = ['lightgreen' if isinstance(node, int) and node > 0 else 'lightgray' \n",
    "                   for node in G.nodes()]\n",
    "    \n",
    "    # Calculate layout\n",
    "    pos = nx.nx_agraph.graphviz_layout(G, prog='dot') if nx.nx_agraph else nx.spring_layout(G)\n",
    "    \n",
    "    # Draw the graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, \n",
    "            node_size=700, font_size=10, arrows=True)\n",
    "    plt.title('Pedigree Structure')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple example pedigree\n",
    "individuals = [1000, 1001, 1002, 1003, 1004, 1005]\n",
    "up_node_dict = create_empty_up_node_dict(individuals)\n",
    "\n",
    "# Add relationships\n",
    "up_node_dict = add_relationship(up_node_dict, 1003, 1001, 1002)  # 1003 has parents 1001 and 1002\n",
    "up_node_dict = add_relationship(up_node_dict, 1004, 1001, 1002)  # 1004 has the same parents\n",
    "up_node_dict = add_relationship(up_node_dict, 1005, 1000, 1003)  # 1005 has parents 1000 and 1003\n",
    "\n",
    "# Visualize the pedigree\n",
    "visualize_pedigree(up_node_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Genetic Relationships Using the Up-Node Dictionary\n",
    "\n",
    "One of the key operations in Bonsai is calculating the genetic relationship coefficient between individuals based on the pedigree structure. Let's implement this calculation using the up-node dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genetic_paths(up_node_dict, individual, path=None, paths=None, ancestor=None):\n",
    "    \"\"\"Find all paths from an individual to their ancestors.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        individual: ID of the individual to trace\n",
    "        path: Current path being explored (for recursion)\n",
    "        paths: Dictionary of collected paths (for recursion)\n",
    "        ancestor: Current ancestor being considered (for recursion)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping ancestor IDs to lists of paths\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        path = []\n",
    "    if paths is None:\n",
    "        paths = {individual: [[]]}  # Start with self path\n",
    "    \n",
    "    # If this individual has no parents, return current paths\n",
    "    if individual not in up_node_dict or not up_node_dict[individual]:\n",
    "        return paths\n",
    "    \n",
    "    # Process each parent\n",
    "    for parent in up_node_dict[individual]:\n",
    "        # Create a new path for this parent\n",
    "        new_path = path + [parent]\n",
    "        \n",
    "        # Add this path to the parent's paths\n",
    "        if parent not in paths:\n",
    "            paths[parent] = []\n",
    "        paths[parent].append(new_path)\n",
    "        \n",
    "        # Recursively process this parent's ancestors\n",
    "        get_genetic_paths(up_node_dict, parent, new_path, paths, parent)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def calculate_relationship_coefficient(up_node_dict, id1, id2):\n",
    "    \"\"\"Calculate the relationship coefficient between two individuals.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        id1: ID of the first individual\n",
    "        id2: ID of the second individual\n",
    "        \n",
    "    Returns:\n",
    "        Relationship coefficient (proportion of shared genetic material)\n",
    "    \"\"\"\n",
    "    if id1 == id2:\n",
    "        return 1.0  # Self-relationship is 1.0\n",
    "    \n",
    "    # Direct parent-child relationship check\n",
    "    if id1 in up_node_dict.get(id2, {}) or id2 in up_node_dict.get(id1, {}):\n",
    "        return 0.5  # Parent-child share 50%\n",
    "    \n",
    "    # Get genetic paths to ancestors for each individual\n",
    "    paths1 = get_genetic_paths(up_node_dict, id1)\n",
    "    paths2 = get_genetic_paths(up_node_dict, id2)\n",
    "    \n",
    "    # Find common ancestors and calculate contributions\n",
    "    relatedness = 0.0\n",
    "    common_ancestors = set(paths1.keys()) & set(paths2.keys())\n",
    "    \n",
    "    for ancestor in common_ancestors:\n",
    "        if ancestor == id1 or ancestor == id2:\n",
    "            continue  # Skip self-paths\n",
    "            \n",
    "        # Each path contributes 0.5^(length of path)\n",
    "        for path1 in paths1[ancestor]:\n",
    "            for path2 in paths2[ancestor]:\n",
    "                contribution = 0.5**(len(path1) + len(path2))\n",
    "                relatedness += contribution\n",
    "    \n",
    "    return relatedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display relationship coefficients for all pairs\n",
    "relationship_results = []\n",
    "\n",
    "for id1 in individuals:\n",
    "    for id2 in individuals:\n",
    "        if id1 < id2:  # Avoid duplicates and self-relationships\n",
    "            coef = calculate_relationship_coefficient(up_node_dict, id1, id2)\n",
    "            relationship_name = \"Unknown\"\n",
    "            \n",
    "            # Map coefficient to relationship name\n",
    "            if coef == 0.5:\n",
    "                relationship_name = \"Parent-Child\"\n",
    "            elif coef == 0.25:\n",
    "                relationship_name = \"Grandparent or Half-Sibling\"\n",
    "            elif coef == 0.125:\n",
    "                relationship_name = \"First Cousin or Great-Grandparent\"\n",
    "            elif 0.24 < coef < 0.26:  # Full siblings (theoretical 0.25, but can vary)\n",
    "                relationship_name = \"Full Siblings\"\n",
    "            \n",
    "            relationship_results.append({\n",
    "                'Individual 1': id1,\n",
    "                'Individual 2': id2,\n",
    "                'Relationship Coefficient': coef,\n",
    "                'Relationship': relationship_name\n",
    "            })\n",
    "\n",
    "rel_df = pd.DataFrame(relationship_results)\n",
    "rel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimization Algorithms in Bonsai\n",
    "\n",
    "Bonsai uses sophisticated optimization algorithms to search for the pedigree structure that maximizes the likelihood of the observed IBD data. Let's implement a simplified version of these algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pedigree_likelihood(up_node_dict, ibd_segments, min_cm=7):\n",
    "    \"\"\"Calculate the likelihood of a pedigree given IBD segment data.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        ibd_segments: Dictionary mapping pairs of individuals to their IBD segments\n",
    "        min_cm: Minimum segment length to consider\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood of the pedigree\n",
    "    \"\"\"\n",
    "    # This is a simplified placeholder implementation\n",
    "    total_log_likelihood = 0.0\n",
    "    \n",
    "    # Process each pair of individuals\n",
    "    for (id1, id2), segments in ibd_segments.items():\n",
    "        # Skip if either individual is not in the pedigree\n",
    "        if id1 not in up_node_dict or id2 not in up_node_dict:\n",
    "            continue\n",
    "            \n",
    "        # Calculate expected relationship coefficient\n",
    "        expected_coef = calculate_relationship_coefficient(up_node_dict, id1, id2)\n",
    "        \n",
    "        # Calculate observed moments\n",
    "        moments = calculate_ibd_moments(segments, min_cm)\n",
    "        \n",
    "        # Skip pairs with no IBD sharing above threshold\n",
    "        if moments['first_moment'] == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate expected moments\n",
    "        expected_count = calculate_expected_segments(expected_coef, min_cm)\n",
    "        expected_length = calculate_expected_length(expected_coef, min_cm)\n",
    "        \n",
    "        # Calculate likelihood using Poisson model for segment count\n",
    "        count_log_like = poisson.logpmf(moments['first_moment'], expected_count) if expected_count > 0 else 0\n",
    "        \n",
    "        # Use a normal approximation for total length\n",
    "        length_log_like = 0\n",
    "        if expected_count > 0 and moments['first_moment'] > 0:\n",
    "            length_log_like = norm.logpdf(moments['second_moment'], \n",
    "                                         expected_length, \n",
    "                                         expected_length / math.sqrt(expected_count))\n",
    "        \n",
    "        # Combine likelihoods\n",
    "        pair_log_like = count_log_like * 0.7 + length_log_like * 0.3\n",
    "        total_log_likelihood += pair_log_like\n",
    "    \n",
    "    return total_log_likelihood\n",
    "\n",
    "def propose_pedigree_modification(up_node_dict, ids=None):\n",
    "    \"\"\"Propose a modification to the pedigree structure.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Current up-node dictionary\n",
    "        ids: List of individual IDs to consider (if None, uses all IDs)\n",
    "        \n",
    "    Returns:\n",
    "        Modified up-node dictionary\n",
    "    \"\"\"\n",
    "    # Create a deep copy to avoid modifying the original\n",
    "    new_dict = {}\n",
    "    for ind, parents in up_node_dict.items():\n",
    "        new_dict[ind] = parents.copy()\n",
    "    \n",
    "    # If no IDs provided, use all individuals in the dictionary\n",
    "    if ids is None:\n",
    "        ids = [id for id in up_node_dict.keys() if isinstance(id, int) and id > 0]\n",
    "    \n",
    "    # Choose a random individual\n",
    "    if not ids:\n",
    "        return new_dict  # No individuals to modify\n",
    "        \n",
    "    ind = random.choice(ids)\n",
    "    \n",
    "    # Choose a modification type\n",
    "    mod_type = random.choice(['add_parent', 'remove_parent', 'swap_parent'])\n",
    "    \n",
    "    if mod_type == 'add_parent':\n",
    "        # Add a parent to the individual\n",
    "        if len(new_dict[ind]) < 2:  # Can only add if fewer than 2 parents\n",
    "            # Create a new latent parent (negative ID)\n",
    "            new_parent = -random.randint(1, 1000)\n",
    "            while new_parent in new_dict:  # Ensure unique ID\n",
    "                new_parent = -random.randint(1, 1000)\n",
    "                \n",
    "            # Add the parent\n",
    "            new_dict[ind][new_parent] = 1\n",
    "            new_dict[new_parent] = {}  # Initialize parent with no ancestors\n",
    "    \n",
    "    elif mod_type == 'remove_parent':\n",
    "        # Remove a parent if any exist\n",
    "        if new_dict[ind]:\n",
    "            parent = random.choice(list(new_dict[ind].keys()))\n",
    "            del new_dict[ind][parent]\n",
    "    \n",
    "    elif mod_type == 'swap_parent':\n",
    "        # Replace a parent with another individual or a new latent parent\n",
    "        if new_dict[ind]:\n",
    "            parent = random.choice(list(new_dict[ind].keys()))\n",
    "            \n",
    "            # Create a new latent parent\n",
    "            new_parent = -random.randint(1, 1000)\n",
    "            while new_parent in new_dict:  # Ensure unique ID\n",
    "                new_parent = -random.randint(1, 1000)\n",
    "                \n",
    "            # Replace the parent\n",
    "            del new_dict[ind][parent]\n",
    "            new_dict[ind][new_parent] = 1\n",
    "            new_dict[new_parent] = {}  # Initialize parent with no ancestors\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "def build_pedigree_with_optimization(individuals, ibd_segments, min_cm=7):\n",
    "    \"\"\"Build a pedigree using optimization techniques.\n",
    "    \n",
    "    Args:\n",
    "        individuals: List of individual IDs\n",
    "        ibd_segments: Dictionary mapping pairs of individuals to their IBD segments\n",
    "        min_cm: Minimum segment length to consider\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (best pedigree, best likelihood)\n",
    "    \"\"\"\n",
    "    # Initialize with empty pedigree\n",
    "    pedigree = create_empty_up_node_dict(individuals)\n",
    "    \n",
    "    # Calculate initial likelihood\n",
    "    current_likelihood = calculate_pedigree_likelihood(pedigree, ibd_segments, min_cm)\n",
    "    best_pedigree = {k: v.copy() for k, v in pedigree.items()}\n",
    "    best_likelihood = current_likelihood\n",
    "    \n",
    "    # Optimization parameters\n",
    "    temperature = 1.0\n",
    "    cooling_rate = 0.99\n",
    "    iterations = 100  # Reduced for demonstration\n",
    "    \n",
    "    # Track progress\n",
    "    likelihoods = [current_likelihood]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Propose a modification to the pedigree\n",
    "        new_pedigree = propose_pedigree_modification(pedigree)\n",
    "        \n",
    "        # Calculate new likelihood\n",
    "        new_likelihood = calculate_pedigree_likelihood(new_pedigree, ibd_segments, min_cm)\n",
    "        \n",
    "        # Accept or reject based on likelihood and temperature\n",
    "        if new_likelihood > current_likelihood:\n",
    "            # Always accept improvements\n",
    "            accept = True\n",
    "        else:\n",
    "            # Sometimes accept worse solutions based on temperature\n",
    "            delta = new_likelihood - current_likelihood\n",
    "            accept_probability = math.exp(delta / temperature)\n",
    "            accept = random.random() < accept_probability\n",
    "        \n",
    "        if accept:\n",
    "            pedigree = new_pedigree\n",
    "            current_likelihood = new_likelihood\n",
    "            \n",
    "            # Update best pedigree if improved\n",
    "            if current_likelihood > best_likelihood:\n",
    "                best_pedigree = {k: v.copy() for k, v in pedigree.items()}\n",
    "                best_likelihood = current_likelihood\n",
    "        \n",
    "        # Cool the temperature\n",
    "        temperature *= cooling_rate\n",
    "        \n",
    "        # Track progress\n",
    "        likelihoods.append(current_likelihood)\n",
    "        \n",
    "        # Occasionally print progress\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"Iteration {i+1}: Current likelihood = {current_likelihood:.2f}, Best = {best_likelihood:.2f}\")\n",
    "    \n",
    "    # Plot optimization progress\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(likelihoods)\n",
    "    plt.title('Optimization Progress')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Log Likelihood')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return best_pedigree, best_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing IBD Data for Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert synthetic data into the format expected by optimization\n",
    "# In this case, a dictionary mapping (id1, id2) to list of segments\n",
    "\n",
    "# First, generate a more complete set of synthetic relationships\n",
    "synthetic_relationships = {\n",
    "    (1000, 1003): generate_synthetic_ibd('parent-child'),\n",
    "    (1001, 1003): generate_synthetic_ibd('parent-child'),\n",
    "    (1001, 1004): generate_synthetic_ibd('parent-child'),\n",
    "    (1002, 1004): generate_synthetic_ibd('parent-child'),\n",
    "    (1003, 1004): generate_synthetic_ibd('siblings'),\n",
    "    (1000, 1004): generate_synthetic_ibd('half-siblings'),\n",
    "    (1000, 1005): generate_synthetic_ibd('first-cousins'),\n",
    "    (1002, 1005): generate_synthetic_ibd('second-cousins')\n",
    "}\n",
    "\n",
    "# Display the data structure\n",
    "for (id1, id2), segments in list(synthetic_relationships.items())[:2]:  # Show first two for brevity\n",
    "    print(f\"Relationship between {id1} and {id2}:\")\n",
    "    print(f\"  Number of segments: {len(segments)}\")\n",
    "    print(f\"  Total IBD length: {sum(seg['length'] for seg in segments):.1f} cM\")\n",
    "    print(f\"  First few segments: {segments[:2]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimization to reconstruct the pedigree\n",
    "# Note: This is a simplified demonstration; actual Bonsai optimization is more complex\n",
    "try:\n",
    "    # We'll use a timeout to avoid running too long in the notebook\n",
    "    import signal\n",
    "    class TimeoutException(Exception): pass\n",
    "    \n",
    "    def timeout_handler(signum, frame):\n",
    "        raise TimeoutException(\"Timed out!\")\n",
    "    \n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    signal.alarm(300)  # 5 minute timeout\n",
    "    \n",
    "    # Run the optimization\n",
    "    inferred_pedigree, final_likelihood = build_pedigree_with_optimization(\n",
    "        individuals, synthetic_relationships, min_cm=7\n",
    "    )\n",
    "    \n",
    "    signal.alarm(0)  # Cancel the alarm\n",
    "    \n",
    "    # Visualize the inferred pedigree\n",
    "    print(\"\\nInferred Pedigree:\")\n",
    "    visualize_pedigree(inferred_pedigree)\n",
    "    \n",
    "    # Compare with the true pedigree\n",
    "    print(\"\\nTrue Pedigree:\")\n",
    "    visualize_pedigree(up_node_dict)\n",
    "    \n",
    "except TimeoutException:\n",
    "    print(\"Optimization timed out. This is expected in the notebook demonstration.\")\n",
    "    print(\"For a full analysis, consider running the optimization with more carefully selected parameters.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during optimization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mathematical Extensions and Improvements\n",
    "\n",
    "Let's explore some mathematical extensions that can improve Bonsai's performance, such as handling age constraints and incorporating additional relationship information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incorporate_age_constraints(up_node_dict, ages, min_parent_age=12):\n",
    "    \"\"\"Check if a pedigree satisfies age constraints.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        ages: Dictionary mapping individual IDs to ages\n",
    "        min_parent_age: Minimum age difference between parent and child\n",
    "        \n",
    "    Returns:\n",
    "        True if all constraints are satisfied, False otherwise\n",
    "    \"\"\"\n",
    "    for child, parents in up_node_dict.items():\n",
    "        if child < 0 or not parents:  # Skip inferred individuals or those without parents\n",
    "            continue\n",
    "            \n",
    "        child_age = ages.get(child)\n",
    "        if child_age is None:\n",
    "            continue\n",
    "            \n",
    "        for parent in parents:\n",
    "            if parent < 0:  # Skip inferred parents\n",
    "                continue\n",
    "                \n",
    "            parent_age = ages.get(parent)\n",
    "            if parent_age is None:\n",
    "                continue\n",
    "                \n",
    "            # Check if parent is older than child by at least min_parent_age\n",
    "            if parent_age <= child_age + min_parent_age:\n",
    "                return False  # Age constraint violated\n",
    "    \n",
    "    return True  # All constraints satisfied\n",
    "\n",
    "def calculate_pedigree_likelihood_with_constraints(up_node_dict, ibd_segments, ages=None, min_cm=7):\n",
    "    \"\"\"Calculate pedigree likelihood with additional constraints.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        ibd_segments: Dictionary mapping pairs of individuals to their IBD segments\n",
    "        ages: Dictionary mapping individual IDs to ages (optional)\n",
    "        min_cm: Minimum segment length to consider\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood of the pedigree\n",
    "    \"\"\"\n",
    "    # Check age constraints if ages provided\n",
    "    if ages is not None and not incorporate_age_constraints(up_node_dict, ages):\n",
    "        return float('-inf')  # Invalid pedigree due to age constraints\n",
    "    \n",
    "    # Otherwise, calculate likelihood as before\n",
    "    return calculate_pedigree_likelihood(up_node_dict, ibd_segments, min_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using age constraints\n",
    "# Assign ages to individuals\n",
    "ages = {\n",
    "    1000: 70,\n",
    "    1001: 65,\n",
    "    1002: 68,\n",
    "    1003: 40,\n",
    "    1004: 38,\n",
    "    1005: 15\n",
    "}\n",
    "\n",
    "# Check if our example pedigree satisfies age constraints\n",
    "age_valid = incorporate_age_constraints(up_node_dict, ages)\n",
    "print(f\"Pedigree satisfies age constraints: {age_valid}\")\n",
    "\n",
    "# Create an invalid pedigree for demonstration\n",
    "invalid_pedigree = create_empty_up_node_dict(individuals)\n",
    "invalid_pedigree = add_relationship(invalid_pedigree, 1001, 1003)  # Invalid: 1003 is younger than 1001\n",
    "\n",
    "# Check if the invalid pedigree satisfies age constraints\n",
    "age_valid = incorporate_age_constraints(invalid_pedigree, ages)\n",
    "print(f\"Invalid pedigree satisfies age constraints: {age_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exercises\n",
    "\n",
    "Complete the following exercises to deepen your understanding of the mathematical foundations of Bonsai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Expected IBD Segment Distribution\n",
    "\n",
    "Implement a function to calculate the expected distribution of IBD segment lengths for a given relationship coefficient. Plot this distribution for various relationship types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Likelihood Sensitivity Analysis\n",
    "\n",
    "Analyze how the likelihood function responds to changes in IBD segment patterns. Create a series of synthetic IBD patterns with varying degrees of noise and observe how the likelihood changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Improved Relationship Coefficient Calculation\n",
    "\n",
    "Enhance the `calculate_relationship_coefficient` function to handle more complex pedigree structures, such as inbreeding. Test your implementation on examples with known inbreeding coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Optimization Algorithm Comparison\n",
    "\n",
    "Implement an alternative optimization algorithm (e.g., genetic algorithm, hill climbing) and compare its performance to the simulated annealing approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Age-Constrained Pedigree Reconstruction\n",
    "\n",
    "Enhance the pedigree reconstruction algorithm to incorporate age constraints during the optimization process, not just as a validation step afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab, we explored the mathematical foundations of the Bonsai algorithm for pedigree reconstruction. We implemented key components of the algorithm, including likelihood functions, the up-node dictionary data structure, and optimization techniques. We also examined how additional constraints, such as age information, can be incorporated to improve reconstruction accuracy.\n",
    "\n",
    "Key takeaways:\n",
    "- Bonsai uses a Bayesian framework to find the most likely pedigree given observed IBD segment patterns\n",
    "- Different relationship types have characteristic likelihood models based on theoretical expectations\n",
    "- The up-node dictionary provides an efficient representation of pedigree structures\n",
    "- Optimization algorithms like simulated annealing help search the vast space of possible pedigrees\n",
    "- Additional constraints and information can be incorporated to improve reconstruction accuracy\n",
    "\n",
    "In the next lab, we will explore the data structures used in Bonsai in more detail, focusing on how they enable efficient pedigree manipulation and analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}