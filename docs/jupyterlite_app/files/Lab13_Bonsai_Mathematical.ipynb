{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 13: Mathematical Foundations of Bonsai\n",
    "\n",
    "Building upon our exploration of IBD segments in Lab 12, we now delve into the mathematical principles that underpin the Bonsai algorithm. This lab will focus on the probabilistic framework, likelihood functions, and optimization techniques that power Bonsai's pedigree reconstruction capabilities.\n",
    "\n",
    "**Learning Objectives**:\n",
    "- Master the probabilistic framework that underpins the Bonsai algorithm\n",
    "- Understand how likelihood functions quantify the probability of observed IBD patterns\n",
    "- Analyze the mathematical models for different relationship types\n",
    "- Explore IBD moment calculations and their role in pedigree inference\n",
    "- Examine Bonsai's optimization algorithms for finding maximum likelihood pedigrees\n",
    "- Implement and interpret key mathematical components of the Bonsai algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install --no-root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from scipy.stats import poisson, expon, norm, multivariate_normal\n",
    "from collections import defaultdict, deque\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from dotenv import load_dotenv\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup code removed for JupyterLite compatibility\n",
    "# In JupyterLite, files are accessed directly from the files directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\"):\n",
    "    \"\"\"\n",
    "    Configure logging for both file and console handlers.\n",
    "\n",
    "    Args:\n",
    "        log_filename (str): Path to the log file where logs will be written.\n",
    "        log_file_debug_level (str): Logging level for the file handler.\n",
    "        console_debug_level (str): Logging level for the console handler.\n",
    "    \"\"\"\n",
    "    # Create a root logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)  # Capture all messages at the root level\n",
    "\n",
    "    # Convert level names to numeric levels\n",
    "    file_level = getattr(logging, log_file_debug_level.upper(), logging.INFO)\n",
    "    console_level = getattr(logging, console_debug_level.upper(), logging.INFO)\n",
    "\n",
    "    # File handler: Logs messages at file_level and above to the file\n",
    "    file_handler = logging.FileHandler(log_filename)\n",
    "    file_handler.setLevel(file_level)\n",
    "    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(file_formatter)\n",
    "\n",
    "    # Console handler: Logs messages at console_level and above to the console\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(console_level)\n",
    "    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    console_handler.setFormatter(console_formatter)\n",
    "\n",
    "    # Add handlers to the root logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "    \n",
    "def clear_logger():\n",
    "    \"\"\"Remove all handlers from the root logger.\"\"\"\n",
    "    logger = logging.getLogger()\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "\n",
    "# Define logs directory\n",
    "logs_directory = os.path.join(working_directory, \"logs\")\n",
    "\n",
    "# Ensure the logs directory exists\n",
    "if not os.path.exists(logs_directory):\n",
    "    os.makedirs(logs_directory)\n",
    "        \n",
    "log_filename = os.path.join(logs_directory, \"lab13_log.txt\")\n",
    "print(f\"The Lab 13 log file is located at {log_filename}.\")\n",
    "\n",
    "# Check if the file exists; if not, create it\n",
    "if not os.path.exists(log_filename):\n",
    "    with open(log_filename, 'w') as file:\n",
    "        pass  # The file is now created.\n",
    "    \n",
    "clear_logger() # Clear the logger before reconfiguring it\n",
    "configure_logging(log_filename, log_file_debug_level=\"INFO\", console_debug_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Probabilistic Framework of Bonsai\n",
    "\n",
    "At its core, Bonsai is a statistical algorithm designed to infer pedigree structures from genetic data, primarily relying on patterns of Identity-by-Descent (IBD) sharing between individuals. It uses a probabilistic approach to evaluate how well different potential pedigrees explain the observed genetic evidence.\n",
    "\n",
    "### Likelihood-Based Pedigree Inference\n",
    "\n",
    "The central component of Bonsai's statistical framework is the **likelihood function**. This function quantifies the probability of observing the actual IBD data *given* a specific, hypothesized pedigree structure. It is expressed as:\n",
    "\n",
    "$$L(\\text{Pedigree} | \\text{IBD data}) = P(\\text{IBD data} | \\text{Pedigree})$$\n",
    "\n",
    "where:\n",
    "- $L(\\text{Pedigree} | \\text{IBD data})$ is the likelihood *of* the proposed pedigree structure, given the observed IBD data.\n",
    "- $P(\\text{IBD data} | \\text{Pedigree})$ is the probability of the observed IBD segment patterns occurring if the proposed pedigree were the true underlying structure.\n",
    "\n",
    "Bonsai's primary goal is to find the pedigree structure ($\\hat{\\mathcal{P}}$) that **maximizes this likelihood function**:\n",
    "\n",
    "$$\\hat{\\mathcal{P}} = \\arg\\max_{\\mathcal{P}} P(\\text{IBD data} | \\mathcal{P})$$\n",
    "\n",
    "This process is known as **Maximum Likelihood Estimation (MLE)**. Finding this optimal pedigree involves:\n",
    "1.  Developing accurate models for $P(\\text{IBD data} | \\text{Pedigree})$ that reflect genetic principles (e.g., recombination, segregation) for different relationship types within the pedigree.\n",
    "2.  Employing sophisticated **optimization algorithms** to search the vast space of possible pedigree structures and identify the one yielding the highest likelihood score.\n",
    "\n",
    "While the core is MLE, Bonsai often incorporates additional information and constraints:\n",
    "*   **Structural Constraints:** It only considers pedigrees consistent with fundamental biological rules (e.g., Mendelian inheritance, individuals having at most two parents, no temporal paradoxes). These act as implicit hard priors, defining the valid search space.\n",
    "*   **Data Integration:** Other data, such as individual ages or sexes, can be integrated into the likelihood model (e.g., evaluating $P(\\text{IBD data}, \\text{Ages} | \\text{Pedigree})$), effectively penalizing pedigrees that imply biologically improbable age differences between relatives.\n",
    "*   **Search Heuristics:** The optimization strategy itself might use heuristics that implicitly guide the search, sometimes favoring simpler or more plausible structures.\n",
    "\n",
    "*(The rest of the notebook then delves into modeling the likelihood components and the optimization search.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implementation is inspired by the actual Bonsai codebase in bonsaitree/v3/likelihoods.py\n",
    "# It's structured to be runnable in this notebook while demonstrating the key components\n",
    "# of Bonsai's likelihood-based approach to pedigree inference.\n",
    "\n",
    "def calculate_pedigree_likelihood(pedigree, ibd_data, age_data=None):\n",
    "    \"\"\"\n",
    "    Calculate the total log-likelihood of a pedigree given IBD and age data.\n",
    "    \n",
    "    This is the core scoring function that Bonsai optimizes - it evaluates how well\n",
    "    a proposed pedigree structure explains the observed IBD patterns. Follows the\n",
    "    approach described in Jewett et al. (2021) AJHG paper.\n",
    "    \n",
    "    Args:\n",
    "        pedigree: Dictionary representing pedigree structure (up-node dictionary)\n",
    "        ibd_data: Dictionary mapping (id1,id2) pairs to their IBD segments\n",
    "        age_data: Optional dictionary mapping individual IDs to ages\n",
    "        \n",
    "    Returns:\n",
    "        Total log-likelihood score for the pedigree\n",
    "    \"\"\"\n",
    "    # 1. Initialize total log-likelihood\n",
    "    total_log_likelihood = 0.0\n",
    "    \n",
    "    # 2. Get all genotyped individuals (in Bonsai, these are positive integer IDs)\n",
    "    genotyped_ids = [id for id in pedigree if isinstance(id, int) and id > 0]\n",
    "    \n",
    "    # 3. Iterate through all unique pairs of individuals\n",
    "    from itertools import combinations\n",
    "    for id1, id2 in combinations(genotyped_ids, 2):\n",
    "        # Skip pairs with no IBD data\n",
    "        if (id1, id2) not in ibd_data and (id2, id1) not in ibd_data:\n",
    "            continue\n",
    "        \n",
    "        # 4. Determine the relationship implied by the pedigree structure\n",
    "        relationship = determine_relationship(pedigree, id1, id2)\n",
    "        \n",
    "        # 5. Calculate the genetic component of likelihood (based on IBD patterns)\n",
    "        ibd_segments = get_pair_ibd_segments(ibd_data, id1, id2)\n",
    "        genetic_likelihood = calculate_genetic_likelihood(relationship, ibd_segments)\n",
    "        \n",
    "        # 6. Calculate the age component of likelihood (if age data is available)\n",
    "        age_likelihood = 0.0\n",
    "        if age_data and id1 in age_data and id2 in age_data:\n",
    "            age_diff = age_data[id1] - age_data[id2]\n",
    "            age_likelihood = calculate_age_likelihood(relationship, age_diff)\n",
    "        \n",
    "        # 7. Add this pair's contribution to the total score\n",
    "        pair_likelihood = genetic_likelihood + age_likelihood\n",
    "        total_log_likelihood += pair_likelihood\n",
    "    \n",
    "    return total_log_likelihood\n",
    "\n",
    "def determine_relationship(pedigree, id1, id2):\n",
    "    \"\"\"\n",
    "    Determine the relationship between two individuals in a pedigree.\n",
    "    \n",
    "    Bonsai typically represents relationships as tuples (up, down, num_ancs) where:\n",
    "    - up: generations from id1 up to common ancestor\n",
    "    - down: generations from common ancestor down to id2  \n",
    "    - num_ancs: number of common ancestors (1 or 2)\n",
    "    \n",
    "    For example:\n",
    "    - Parent-child: (0,1,1) or (1,0,1)\n",
    "    - Full siblings: (1,1,2)\n",
    "    - Half-siblings: (1,1,1)\n",
    "    - First cousins: (2,2,2)\n",
    "    \n",
    "    Returns:\n",
    "        Relationship tuple or None if unrelated\n",
    "    \"\"\"\n",
    "    # In a real implementation, this would trace paths through the pedigree\n",
    "    # to find common ancestors and calculate meiotic distances\n",
    "    \n",
    "    # For this simplified version, we'll check a few basic relationships\n",
    "    \n",
    "    # Check for self-relationship\n",
    "    if id1 == id2:\n",
    "        return (0, 0, 1)  # Self\n",
    "    \n",
    "    # Check for direct parent-child relationship\n",
    "    if id1 in pedigree.get(id2, {}):\n",
    "        return (1, 0, 1)  # id1 is parent of id2\n",
    "    if id2 in pedigree.get(id1, {}):\n",
    "        return (0, 1, 1)  # id2 is parent of id1\n",
    "    \n",
    "    # Check for sibling relationship (same parents)\n",
    "    parents1 = set(pedigree.get(id1, {}).keys())\n",
    "    parents2 = set(pedigree.get(id2, {}).keys())\n",
    "    \n",
    "    common_parents = parents1.intersection(parents2)\n",
    "    if len(common_parents) > 0:\n",
    "        if len(common_parents) == 2:\n",
    "            return (1, 1, 2)  # Full siblings (share 2 parents)\n",
    "        else:\n",
    "            return (1, 1, 1)  # Half siblings (share 1 parent)\n",
    "    \n",
    "    # For more distant relationships, we'd need to trace through the pedigree\n",
    "    # In this simplified version, we'll return None (unrelated) for any other case\n",
    "    return None\n",
    "\n",
    "def calculate_genetic_likelihood(relationship, ibd_segments):\n",
    "    \"\"\"\n",
    "    Calculate the genetic component of likelihood based on IBD patterns.\n",
    "    \n",
    "    In Bonsai, this uses models based on:\n",
    "    1. Number of segments (count)\n",
    "    2. Total length of IBD sharing (cM)\n",
    "    3. Type of IBD (IBD1 vs IBD2) \n",
    "    \n",
    "    Different relationships have distinct expected patterns, e.g.:\n",
    "    - Parent-child: ~100% IBD1, no IBD2\n",
    "    - Siblings: ~50% IBD1, ~25% IBD2\n",
    "    - First cousins: ~12.5% IBD1, no IBD2\n",
    "    \n",
    "    Returns:\n",
    "        Log-likelihood score\n",
    "    \"\"\"\n",
    "    # This is a simplified implementation for demonstration\n",
    "    # Real Bonsai uses more sophisticated statistical models\n",
    "    \n",
    "    if not ibd_segments:\n",
    "        return -10.0  # Penalty for no IBD when a relationship is expected\n",
    "    \n",
    "    # Calculate total IBD1 and IBD2 sharing\n",
    "    total_ibd1 = sum(seg['length'] for seg in ibd_segments if seg['type'] == 'IBD1')\n",
    "    total_ibd2 = sum(seg['length'] for seg in ibd_segments if seg['type'] == 'IBD2')\n",
    "    \n",
    "    # Genome length in centiMorgans (cM)\n",
    "    genome_length = 3500.0\n",
    "    \n",
    "    # Proportion of genome sharing IBD1 and IBD2\n",
    "    prop_ibd1 = total_ibd1 / genome_length\n",
    "    prop_ibd2 = total_ibd2 / genome_length\n",
    "    \n",
    "    # If relationship is unknown (None), check if consistent with unrelated\n",
    "    if relationship is None:\n",
    "        # Unrelated pairs should have minimal IBD sharing\n",
    "        if prop_ibd1 < 0.01 and prop_ibd2 < 0.001:\n",
    "            return 0.0  # Good fit for unrelated\n",
    "        else:\n",
    "            return -5.0  # Too much IBD for unrelated individuals\n",
    "    \n",
    "    # Expected proportions for different relationship types\n",
    "    expected_ibd1 = 0.0\n",
    "    expected_ibd2 = 0.0\n",
    "    \n",
    "    if relationship == (0, 1, 1) or relationship == (1, 0, 1):  # Parent-child\n",
    "        expected_ibd1 = 1.0\n",
    "        expected_ibd2 = 0.0\n",
    "    elif relationship == (1, 1, 2):  # Full siblings\n",
    "        expected_ibd1 = 0.5\n",
    "        expected_ibd2 = 0.25\n",
    "    elif relationship == (1, 1, 1):  # Half siblings\n",
    "        expected_ibd1 = 0.25\n",
    "        expected_ibd2 = 0.0\n",
    "    elif relationship == (2, 2, 2):  # First cousins\n",
    "        expected_ibd1 = 0.125\n",
    "        expected_ibd2 = 0.0\n",
    "    \n",
    "    # Calculate squared error from expected proportions\n",
    "    error = ((prop_ibd1 - expected_ibd1) ** 2 + \n",
    "             (prop_ibd2 - expected_ibd2) ** 2)\n",
    "    \n",
    "    # Convert to log-likelihood (higher is better)\n",
    "    return -10.0 * error\n",
    "\n",
    "def calculate_age_likelihood(relationship, age_diff):\n",
    "    \"\"\"\n",
    "    Calculate the age component of likelihood based on age difference.\n",
    "    \n",
    "    In Bonsai, different relationships have expected age difference distributions:\n",
    "    - Parent-child: ~20-40 years (parent older)\n",
    "    - Siblings: ~0-10 years difference\n",
    "    - Grandparent-grandchild: ~40-80 years (grandparent older)\n",
    "    \n",
    "    Returns:\n",
    "        Log-likelihood score\n",
    "    \"\"\"\n",
    "    # This is a simplified implementation for demonstration\n",
    "    import math\n",
    "    \n",
    "    # If no relationship is specified (unrelated), any age difference is plausible\n",
    "    if relationship is None:\n",
    "        return 0.0\n",
    "    \n",
    "    # Expected mean and standard deviation for different relationships\n",
    "    mean_age_diff = 0.0\n",
    "    std_age_diff = 10.0  # Default\n",
    "    \n",
    "    if relationship == (0, 1, 1):  # Parent-child (parent is id1)\n",
    "        mean_age_diff = 30.0\n",
    "        std_age_diff = 8.0\n",
    "    elif relationship == (1, 0, 1):  # Child-parent (child is id1)\n",
    "        mean_age_diff = -30.0\n",
    "        std_age_diff = 8.0\n",
    "    elif relationship == (1, 1, 2) or relationship == (1, 1, 1):  # Siblings\n",
    "        mean_age_diff = 0.0\n",
    "        std_age_diff = 5.0\n",
    "    elif relationship == (2, 0, 1):  # Grandchild-grandparent\n",
    "        mean_age_diff = -55.0\n",
    "        std_age_diff = 12.0\n",
    "    elif relationship == (0, 2, 1):  # Grandparent-grandchild\n",
    "        mean_age_diff = 55.0\n",
    "        std_age_diff = 12.0\n",
    "    \n",
    "    # Calculate log-likelihood using Gaussian model\n",
    "    # Log pdf = -ln(\u03c3\u221a2\u03c0) - (x-\u03bc)\u00b2/(2\u03c3\u00b2)\n",
    "    log_likelihood = -math.log(std_age_diff * math.sqrt(2 * math.pi))\n",
    "    log_likelihood -= ((age_diff - mean_age_diff) ** 2) / (2 * std_age_diff ** 2)\n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "def get_pair_ibd_segments(ibd_data, id1, id2):\n",
    "    \"\"\"Helper function to get IBD segments for a pair, handling order.\"\"\"\n",
    "    if (id1, id2) in ibd_data:\n",
    "        return ibd_data[(id1, id2)]\n",
    "    elif (id2, id1) in ibd_data:\n",
    "        return ibd_data[(id2, id1)]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Example usage (to demonstrate the algorithm)\n",
    "if __name__ == \"__main__\":\n",
    "    # In a Jupyter notebook, code here will be executed when the cell is run\n",
    "    \n",
    "    # Example pedigree (up-node dictionary)\n",
    "    pedigree = {\n",
    "        101: {201: 1, 202: 1},  # Individual 101 has parents 201 and 202\n",
    "        102: {201: 1, 202: 1},  # Individual 102 has the same parents (full sibling of 101)\n",
    "        103: {201: 1, 203: 1},  # Individual 103 is half-sibling to 101 and 102\n",
    "        201: {},  # No parents specified\n",
    "        202: {},\n",
    "        203: {}\n",
    "    }\n",
    "    \n",
    "    # Example IBD data\n",
    "    ibd_data = {\n",
    "        (101, 102): [  # Full siblings\n",
    "            {'type': 'IBD1', 'length': 1700},\n",
    "            {'type': 'IBD2', 'length': 900}\n",
    "        ],\n",
    "        (101, 103): [  # Half siblings\n",
    "            {'type': 'IBD1', 'length': 850}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Example age data\n",
    "    age_data = {\n",
    "        101: 25,\n",
    "        102: 27,\n",
    "        103: 30,\n",
    "        201: 55,\n",
    "        202: 53,\n",
    "        203: 58\n",
    "    }\n",
    "    \n",
    "    # Calculate likelihood\n",
    "    likelihood = calculate_pedigree_likelihood(pedigree, ibd_data, age_data)\n",
    "    print(f\"Pedigree log-likelihood: {likelihood:.2f}\")\n",
    "    \n",
    "    # In a real implementation, an optimization algorithm would search for the\n",
    "    # pedigree structure that maximizes this likelihood value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import pprint\n",
    "import numpy as np # Using numpy for easier stats generation\n",
    "from scipy.stats import norm # Using scipy for logpdf calculation\n",
    "\n",
    "# --- 1. Constants: Expected Statistics for Relationships ---\n",
    "# Simplified means (mu) and standard deviations (sigma) for IBD stats and age diff\n",
    "# IBD Stats: T3 (Total IBD3 Length), C3 (Count IBD3), T2 (Total IBD2), C2 (Count IBD2)\n",
    "# Age Diff: Mean difference (id1_age - id2_age), Std Dev\n",
    "\n",
    "RELATIONSHIP_PARAMS = {\n",
    "    # (up, down, nc): {mu_T3, sigma_T3, mu_C3, sigma_C3, mu_T2, sigma_T2, mu_C2, sigma_C2, mu_Age, sigma_Age}\n",
    "    (0, 0, 1):   {'mu_T3': 3500, 'sigma_T3': 50, 'mu_C3': 60, 'sigma_C3': 5,  # Self (approx)\n",
    "                  'mu_T2': 3500, 'sigma_T2': 50, 'mu_C2': 60, 'sigma_C2': 5,\n",
    "                  'mu_Age': 0,    'sigma_Age': 0.1}, # Need small sigma for age match\n",
    "    (1, 0, 1):   {'mu_T3': 3500, 'sigma_T3': 100, 'mu_C3': 60, 'sigma_C3': 10, # Child-Parent\n",
    "                  'mu_T2': 0,    'sigma_T2': 10,  'mu_C2': 0,  'sigma_C2': 1,\n",
    "                  'mu_Age': -30,  'sigma_Age': 7},\n",
    "    (0, 1, 1):   {'mu_T3': 3500, 'sigma_T3': 100, 'mu_C3': 60, 'sigma_C3': 10, # Parent-Child\n",
    "                  'mu_T2': 0,    'sigma_T2': 10,  'mu_C2': 0,  'sigma_C2': 1,\n",
    "                  'mu_Age': 30,   'sigma_Age': 7},\n",
    "    (1, 1, 2):   {'mu_T3': 2600, 'sigma_T3': 250, 'mu_C3': 45, 'sigma_C3': 8,  # Full Siblings\n",
    "                  'mu_T2': 800,  'sigma_T2': 200, 'mu_C2': 15, 'sigma_C2': 5,\n",
    "                  'mu_Age': 0,    'sigma_Age': 7},\n",
    "    (1, 1, 1):   {'mu_T3': 1750, 'sigma_T3': 200, 'mu_C3': 30, 'sigma_C3': 7,  # Half Siblings / Grandparent\n",
    "                  'mu_T2': 0,    'sigma_T2': 20,  'mu_C2': 0,  'sigma_C2': 2,\n",
    "                  'mu_Age': 0,    'sigma_Age': 9}, # Wider age range than full sibs generally\n",
    "    (2, 0, 1):   {'mu_T3': 1750, 'sigma_T3': 200, 'mu_C3': 30, 'sigma_C3': 7,  # Grandchild-Grandparent\n",
    "                  'mu_T2': 0,    'sigma_T2': 20,  'mu_C2': 0,  'sigma_C2': 2,\n",
    "                  'mu_Age': -55,  'sigma_Age': 10},\n",
    "     (0, 2, 1):  {'mu_T3': 1750, 'sigma_T3': 200, 'mu_C3': 30, 'sigma_C3': 7,  # Grandparent-Grandchild\n",
    "                  'mu_T2': 0,    'sigma_T2': 20,  'mu_C2': 0,  'sigma_C2': 2,\n",
    "                  'mu_Age': 55,   'sigma_Age': 10},\n",
    "    (2, 2, 2):   {'mu_T3': 875,  'sigma_T3': 150, 'mu_C3': 20, 'sigma_C3': 6,  # First Cousins\n",
    "                  'mu_T2': 0,    'sigma_T2': 30,  'mu_C2': 0,  'sigma_C2': 3,\n",
    "                  'mu_Age': 0,    'sigma_Age': 12},\n",
    "    None:        {'mu_T3': 15,   'sigma_T3': 10,  'mu_C3': 1,  'sigma_C3': 1,  # Unrelated (allowing small background)\n",
    "                  'mu_T2': 0,    'sigma_T2': 5,   'mu_C2': 0,  'sigma_C2': 0.5,\n",
    "                  'mu_Age': 0,    'sigma_Age': 25}, # Wide age variation\n",
    "}\n",
    "# Add relationship type string for clarity later\n",
    "for r, p in RELATIONSHIP_PARAMS.items():\n",
    "    if r == (0,0,1): p['name'] = 'Self'\n",
    "    elif r == (1,0,1) or r == (0,1,1): p['name'] = 'Parent/Child'\n",
    "    elif r == (1,1,2): p['name'] = 'Full Sib'\n",
    "    elif r == (1,1,1): p['name'] = 'Half Sib'\n",
    "    elif r == (2,0,1) or r == (0,2,1): p['name'] = 'Grandparent/Child'\n",
    "    elif r == (2,2,2): p['name'] = 'First Cousin'\n",
    "    elif r is None: p['name'] = 'Unrelated'\n",
    "    else: p['name'] = str(r) # Default for others\n",
    "\n",
    "# --- 2. IBD Simulation ---\n",
    "\n",
    "class IBDStats:\n",
    "    \"\"\"Simple class to hold IBD summary stats.\"\"\"\n",
    "    def __init__(self, t3, c3, t2, c2):\n",
    "        self.t3 = t3\n",
    "        self.c3 = c3\n",
    "        self.t2 = t2\n",
    "        self.c2 = c2\n",
    "    def __repr__(self):\n",
    "        return f\"IBD(T3={self.t3:.1f}, C3={self.c3}, T2={self.t2:.1f}, C2={self.c2})\"\n",
    "\n",
    "def simulate_ibd_stats(relationship_tuple):\n",
    "    \"\"\"Simulate IBD stats based on expected parameters for a relationship.\"\"\"\n",
    "    params = RELATIONSHIP_PARAMS.get(relationship_tuple, RELATIONSHIP_PARAMS[None]) # Default to unrelated\n",
    "\n",
    "    # Simulate using normal distribution, ensuring non-negativity\n",
    "    t3 = max(0, random.gauss(params['mu_T3'], params['sigma_T3']))\n",
    "    c3 = max(0, int(round(random.gauss(params['mu_C3'], params['sigma_C3']))))\n",
    "    t2 = max(0, random.gauss(params['mu_T2'], params['sigma_T2']))\n",
    "    c2 = max(0, int(round(random.gauss(params['mu_C2'], params['sigma_C2']))))\n",
    "\n",
    "    # Ensure basic consistency (e.g., T2 <= T3, C2 <= C3)\n",
    "    t2 = min(t2, t3)\n",
    "    c2 = min(c2, c3)\n",
    "    if c3 == 0: t3 = 0\n",
    "    if c2 == 0: t2 = 0\n",
    "\n",
    "    return IBDStats(t3, c3, t2, c2)\n",
    "\n",
    "# --- 3. Relationship Determination (Simplified) ---\n",
    "\n",
    "def determine_relationship(pedigree, id1, id2):\n",
    "    \"\"\"\n",
    "    Simplified relationship determination from pedigree dictionary.\n",
    "    Handles self, parent/child, siblings. Returns None otherwise.\n",
    "    \"\"\"\n",
    "    if id1 == id2: return (0, 0, 1)\n",
    "    parents1 = set(pedigree.get(id1, {}).keys())\n",
    "    parents2 = set(pedigree.get(id2, {}).keys())\n",
    "\n",
    "    if id1 in parents2: return (0, 1, 1) # id1 is parent of id2\n",
    "    if id2 in parents1: return (1, 0, 1) # id2 is parent of id1\n",
    "\n",
    "    common_parents = parents1.intersection(parents2)\n",
    "    if len(common_parents) == 2 and len(parents1) == 2 and len(parents2) == 2:\n",
    "        return (1, 1, 2) # Full Siblings\n",
    "    elif len(common_parents) == 1:\n",
    "        # Could be half-sib or other complex case, simplified to half-sib\n",
    "         return (1, 1, 1) # Half Siblings\n",
    "\n",
    "    # --- Add grandparent check for illustration ---\n",
    "    grandparents1 = set()\n",
    "    for p1 in parents1:\n",
    "        grandparents1.update(pedigree.get(p1, {}).keys())\n",
    "    if id2 in grandparents1: return (2, 0, 1) # id2 is grandparent of id1\n",
    "\n",
    "    grandparents2 = set()\n",
    "    for p2 in parents2:\n",
    "        grandparents2.update(pedigree.get(p2, {}).keys())\n",
    "    if id1 in grandparents2: return (0, 2, 1) # id1 is grandparent of id2\n",
    "    # --- End grandparent check ---\n",
    "\n",
    "    # NOTE: This does NOT find cousins or more complex relationships.\n",
    "    return None # Assume unrelated otherwise\n",
    "\n",
    "# --- 4. Likelihood Calculation Functions ---\n",
    "\n",
    "def calculate_pairwise_loglik(observed_ibd: IBDStats, age1: float | None, age2: float | None, relationship_tuple):\n",
    "    \"\"\"Calculates the composite pairwise log-likelihood.\"\"\"\n",
    "    expected_params = RELATIONSHIP_PARAMS.get(relationship_tuple, RELATIONSHIP_PARAMS[None])\n",
    "\n",
    "    log_lik_g = 0.0\n",
    "    # Calculate genetic component using Gaussian log PDF\n",
    "    # Handling sigma=0 separately is important in practice, norm.logpdf does this\n",
    "    log_lik_g += norm.logpdf(observed_ibd.t3, loc=expected_params['mu_T3'], scale=expected_params['sigma_T3']) if expected_params['sigma_T3'] > 0 else (0 if observed_ibd.t3==expected_params['mu_T3'] else -np.inf)\n",
    "    log_lik_g += norm.logpdf(observed_ibd.c3, loc=expected_params['mu_C3'], scale=expected_params['sigma_C3']) if expected_params['sigma_C3'] > 0 else (0 if observed_ibd.c3==expected_params['mu_C3'] else -np.inf)\n",
    "    log_lik_g += norm.logpdf(observed_ibd.t2, loc=expected_params['mu_T2'], scale=expected_params['sigma_T2']) if expected_params['sigma_T2'] > 0 else (0 if observed_ibd.t2==expected_params['mu_T2'] else -np.inf)\n",
    "    log_lik_g += norm.logpdf(observed_ibd.c2, loc=expected_params['mu_C2'], scale=expected_params['sigma_C2']) if expected_params['sigma_C2'] > 0 else (0 if observed_ibd.c2==expected_params['mu_C2'] else -np.inf)\n",
    "\n",
    "    log_lik_a = 0.0\n",
    "    if age1 is not None and age2 is not None:\n",
    "        age_diff = age1 - age2\n",
    "        mu_age, sigma_age = expected_params['mu_Age'], expected_params['sigma_Age']\n",
    "        log_lik_a += norm.logpdf(age_diff, loc=mu_age, scale=sigma_age) if sigma_age > 0 else (0 if age_diff==mu_age else -np.inf)\n",
    "\n",
    "    # Check for -inf results which indicate impossibility under the model\n",
    "    if np.isinf(log_lik_g) or np.isinf(log_lik_a):\n",
    "      return -np.inf\n",
    "\n",
    "    return log_lik_g + log_lik_a\n",
    "\n",
    "\n",
    "def calculate_pedigree_log_likelihood(pedigree, all_pairwise_ibd_stats, all_ages):\n",
    "    \"\"\"Calculates the total pedigree log-likelihood.\"\"\"\n",
    "    total_log_likelihood = 0.0\n",
    "    # Consider only individuals present in the pedigree keys/values\n",
    "    ped_individuals = set(pedigree.keys())\n",
    "    for parents_dict in pedigree.values():\n",
    "        ped_individuals.update(parents_dict.keys())\n",
    "\n",
    "    processed_pairs = set() # To avoid calculating twice if data access is symmetric\n",
    "\n",
    "    for id1, id2 in itertools.combinations(ped_individuals, 2):\n",
    "         # Ensure we process each pair only once\n",
    "        pair_key = tuple(sorted((id1, id2)))\n",
    "        if pair_key in processed_pairs:\n",
    "            continue\n",
    "\n",
    "        # Determine relationship based on the *proposed* pedigree structure\n",
    "        relationship_tuple = determine_relationship(pedigree, id1, id2)\n",
    "\n",
    "        # Get the *observed* (simulated) IBD data for this pair\n",
    "        observed_ibd = all_pairwise_ibd_stats.get(pair_key)\n",
    "        # If no IBD was simulated (maybe truly unrelated), create stats obj with zeros\n",
    "        if observed_ibd is None:\n",
    "             observed_ibd = IBDStats(0, 0, 0, 0)\n",
    "\n",
    "        # Get ages\n",
    "        age1 = all_ages.get(id1)\n",
    "        age2 = all_ages.get(id2)\n",
    "\n",
    "        # Calculate pairwise likelihood using observed data and relationship from pedigree\n",
    "        pair_ll = calculate_pairwise_loglik(observed_ibd, age1, age2, relationship_tuple)\n",
    "        total_log_likelihood += pair_ll\n",
    "        processed_pairs.add(pair_key)\n",
    "\n",
    "    return total_log_likelihood\n",
    "\n",
    "\n",
    "# --- 5. Demonstration ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"--- Setting up True Pedigree and Data ---\")\n",
    "    # Define a slightly more complex \"true\" pedigree\n",
    "    true_pedigree = {\n",
    "        # Gen 3\n",
    "        101: {201: 1, 202: 1},\n",
    "        102: {201: 1, 202: 1}, # Full sib to 101\n",
    "        103: {201: 1, 203: 1}, # Half sib to 101, 102 (common father 201)\n",
    "        104: {204: 1, 205: 1}, # Unrelated family line\n",
    "        # Gen 2\n",
    "        201: {301: 1, 302: 1}, # Father of 101, 102, 103\n",
    "        202: {303: 1, 304: 1}, # Mother of 101, 102\n",
    "        203: {305: 1, 306: 1}, # Mother of 103\n",
    "        204: {307: 1, 308: 1}, # Parent of 104\n",
    "        205: {309: 1, 310: 1}, # Parent of 104\n",
    "        # Gen 1 (Founders)\n",
    "        301: {}, 302: {}, 303: {}, 304: {}, 305: {}, 306: {},\n",
    "        307: {}, 308: {}, 309: {}, 310: {},\n",
    "    }\n",
    "\n",
    "    # Define ages consistent with the pedigree\n",
    "    ages = {\n",
    "        101: 25, 102: 27, 103: 30, 104: 26, # Gen 3\n",
    "        201: 55, 202: 53, 203: 58, 204: 54, 205: 56, # Gen 2\n",
    "        301: 80, 302: 79, 303: 78, 304: 81, 305: 82, 306: 77, # Gen 1\n",
    "        307: 80, 308: 79, 309: 78, 310: 81,\n",
    "    }\n",
    "\n",
    "    # Get all individuals involved\n",
    "    all_individuals = set(true_pedigree.keys())\n",
    "    for parents_dict in true_pedigree.values():\n",
    "        all_individuals.update(parents_dict.keys())\n",
    "    all_individuals = sorted(list(all_individuals))\n",
    "\n",
    "    print(\"True Pedigree Structure:\")\n",
    "    pprint.pprint(true_pedigree)\n",
    "    print(\"\\nAges:\")\n",
    "    pprint.pprint(ages)\n",
    "\n",
    "    print(\"\\n--- Simulating Pairwise IBD Data based on True Pedigree ---\")\n",
    "    # Simulate IBD data for ALL pairs based on their TRUE relationship\n",
    "    simulated_pairwise_ibd = {}\n",
    "    for id1, id2 in itertools.combinations(all_individuals, 2):\n",
    "        true_relationship = determine_relationship(true_pedigree, id1, id2)\n",
    "        sim_ibd = simulate_ibd_stats(true_relationship)\n",
    "        # Store only if significant IBD simulated (or based on relationship)\n",
    "        # Here we store all for completeness in calculation, even zeros\n",
    "        simulated_pairwise_ibd[tuple(sorted((id1, id2)))] = sim_ibd\n",
    "        # Print some examples\n",
    "        if true_relationship is not None and random.random() < 0.1: # Print ~10% of related pairs\n",
    "             rel_name = RELATIONSHIP_PARAMS.get(true_relationship, {}).get('name', str(true_relationship))\n",
    "             print(f\"  Simulated IBD for ({id1}, {id2}) (True Rel: {rel_name}): {sim_ibd}\")\n",
    "        elif true_relationship is None and random.random() < 0.01: # Print ~1% of unrelated pairs\n",
    "             print(f\"  Simulated IBD for ({id1}, {id2}) (True Rel: Unrelated): {sim_ibd}\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Evaluating Pedigree Likelihoods ---\")\n",
    "\n",
    "    # 1. Evaluate the TRUE pedigree\n",
    "    ll_true = calculate_pedigree_log_likelihood(true_pedigree, simulated_pairwise_ibd, ages)\n",
    "    print(f\"Log-Likelihood of TRUE Pedigree: {ll_true:.2f}\")\n",
    "\n",
    "    # 2. Evaluate an INCORRECT pedigree (e.g., swap parents for 103)\n",
    "    incorrect_pedigree_1 = true_pedigree.copy() # Shallow copy is okay for this change\n",
    "    incorrect_pedigree_1[103] = {202: 1, 203: 1} # Incorrect: Makes 103 full sib to 101/102\n",
    "                                                # and child of 202, not 201.\n",
    "    ll_incorrect_1 = calculate_pedigree_log_likelihood(incorrect_pedigree_1, simulated_pairwise_ibd, ages)\n",
    "    print(f\"Log-Likelihood of INCORRECT Pedigree 1 (103 Full Sib): {ll_incorrect_1:.2f}\")\n",
    "\n",
    "    # 3. Evaluate another INCORRECT pedigree (e.g., make unrelated line related)\n",
    "    incorrect_pedigree_2 = true_pedigree.copy()\n",
    "    incorrect_pedigree_2[104] = {201: 1, 205: 1} # Incorrect: Makes 104 child of 201 (half-sib to 101/102/103)\n",
    "                                                # instead of child of 204/205.\n",
    "    ll_incorrect_2 = calculate_pedigree_log_likelihood(incorrect_pedigree_2, simulated_pairwise_ibd, ages)\n",
    "    print(f\"Log-Likelihood of INCORRECT Pedigree 2 (104 Half Sib): {ll_incorrect_2:.2f}\")\n",
    "\n",
    "    print(\"\\n--- Conclusion ---\")\n",
    "    print(\"The pedigree structure yielding the HIGHEST (least negative) log-likelihood\")\n",
    "    print(\"is considered the best fit to the observed genetic and age data.\")\n",
    "    print(\"Ideally, the score for the 'TRUE Pedigree' should be significantly higher\")\n",
    "    print(\"than the scores for the incorrect structures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of the Runnable Likelihood Demonstration\n",
    "\n",
    "This code cell provides a runnable demonstration of the core principle behind Bonsai's evaluation of pedigrees: **calculating a pedigree's log-likelihood by summing pairwise contributions.** It illustrates how different proposed pedigree structures are scored against observed genetic (IBD) and demographic (age) data.\n",
    "\n",
    "**Code Breakdown:**\n",
    "\n",
    "1.  **Constants (`RELATIONSHIP_PARAMS`):** This dictionary defines *simplified expectations* (mean `mu` and standard deviation `sigma`) for various IBD summary statistics (Total Length and Count for IBD3/IBD2) and age differences for common relationship types.\n",
    "    *   *Note:* In a real Bonsai implementation (Jewett et al. 2021), these parameters are derived empirically from vast datasets and simulations, not hardcoded simple values. The structure here, however, represents the *kind* of information needed.\n",
    "\n",
    "2.  **IBD Simulation (`simulate_ibd_stats`):** This function generates *plausible \"observed\" IBD data* for a specific relationship. It uses the defined constants and Gaussian sampling to create `IBDStats` objects (T3, C3, T2, C2). This simulates the output you might get from an IBD detection tool applied to real genetic data for pairs with known relationships.\n",
    "\n",
    "3.  **Relationship Determination (`determine_relationship`):** Given a *candidate* pedigree structure (represented as an up-node dictionary), this function determines the specific genealogical relationship `(up, down, num_ancs)` between two individuals *within that structure*.\n",
    "    *   *Note:* The provided version is **highly simplified** and only correctly identifies self, parent/child, full/half-siblings, and grandparent relationships based on direct links. A real implementation needs complex graph traversal algorithms to find the Most Recent Common Ancestor(s) (MRCAs) and calculate meiotic paths for *all* possible relationships (cousins, avuncular, etc.).\n",
    "\n",
    "4.  **Pairwise Likelihood (`calculate_pairwise_loglik`):** This is the core calculation for a single pair. It takes:\n",
    "    *   The *observed* (simulated) IBD statistics for the pair.\n",
    "    *   The *observed* ages for the pair.\n",
    "    *   The *relationship implied by the pedigree being tested*.\n",
    "    It then calculates a log-likelihood score based on how well the observed IBD and age difference match the *expected* values (from `RELATIONSHIP_PARAMS`) for that specific relationship, using Gaussian probability density functions (via `scipy.stats.norm.logpdf`). It sums the genetic and age components.\n",
    "\n",
    "5.  **Pedigree Likelihood (`calculate_pedigree_log_likelihood`):** This function orchestrates the overall scoring. It iterates through all unique pairs of individuals present in the *candidate* pedigree, determines their relationship *within that structure* using `determine_relationship`, fetches the *observed* (simulated) data for that pair, calculates their pairwise log-likelihood using `calculate_pairwise_loglik`, and sums these scores to get the total log-likelihood for the entire pedigree.\n",
    "\n",
    "6.  **Demonstration (`if __name__ == \"__main__\":`)**\n",
    "    *   Sets up a \"true\" pedigree and corresponding ages.\n",
    "    *   Generates simulated IBD data for all pairs based on their *true* relationships.\n",
    "    *   Calculates the log-likelihood score for the `true_pedigree` using the simulated data.\n",
    "    *   Creates two `incorrect_pedigree` structures.\n",
    "    *   Calculates the log-likelihood scores for these incorrect pedigrees using the *same* simulated data.\n",
    "\n",
    "**Connecting to Theory (ERSA, Distributions, etc.):**\n",
    "\n",
    "This demonstration uses simplified Gaussian models for IBD statistics for ease of implementation. However, it illustrates the *principle* used in more sophisticated methods:\n",
    "\n",
    "*   **Likelihood Principle:** The core idea is $P(\\text{Data} | \\text{Model})$, where the \"Data\" is the observed IBD/age for a pair, and the \"Model\" is the specific relationship implied by the pedigree.\n",
    "*   **IBD Models:** More rigorous methods model IBD segment properties based on genetic theory:\n",
    "    *   **Segment Lengths:** Often modeled using the **Exponential distribution** (for segments arising from a single meiosis path) or the **Gamma distribution** (for total length, which is a sum of segment lengths). The mean length is inversely proportional to the number of meioses separating the individuals.\n",
    "    *   **Segment Counts:** Often modeled using the **Poisson distribution** (as in the ERSA method by Huff et al. 2011) or the more flexible **Negative Binomial distribution** (as discussed in Jewett et al. 2024 preprint) to account for overdispersion. The expected count decreases rapidly with distance.\n",
    "*   **This Notebook's Context:** Ideally, explorations of the Exponential distribution for segment lengths and Poisson for counts would precede this demonstration to provide theoretical grounding. This script uses Gaussian approximations for simplicity but embodies the same goal: quantifying the match between observed IBD and the expectation under a given relationship. The use of summary statistics (Total Length, Count) aligns with methods like ERSA and the inputs to the Kirkpatrick/Huff Bonsai, whereas the 23andMe Bonsai (Jewett et al. 2021) also uses these stats (fitted empirically) in its likelihood calculation.\n",
    "\n",
    "**Interpreting the Output:**\n",
    "\n",
    "The script calculates and prints the total log-likelihood scores for the true pedigree and two incorrect variations, using the *same* underlying simulated IBD/age data (which was generated based on the true pedigree).\n",
    "\n",
    "*   **Log-Likelihood Values:** These scores are typically negative (since they are logs of probabilities, which are <= 1). **Higher values (closer to zero) indicate a better fit.**\n",
    "*   **Expected Result:** The `Log-Likelihood of TRUE Pedigree` should be significantly higher (less negative) than the scores for the `INCORRECT Pedigree` examples.\n",
    "*   **Why?** When evaluating the true pedigree, the `determine_relationship` function finds the correct relationship for each pair. The `calculate_pairwise_loglik` then compares the observed (simulated) data against the *correct* expected parameters, leading to a relatively good fit and a higher likelihood score. When evaluating an incorrect pedigree, `determine_relationship` will find *incorrect* relationships for some pairs. `calculate_pairwise_loglik` then compares the observed data (generated under the *true* relationship) against the expected parameters for the *wrong* relationship, leading to a poor fit and a lower (more negative) likelihood score for those pairs, dragging down the total pedigree score.\n",
    "\n",
    "**Overall Significance:**\n",
    "\n",
    "This demonstration highlights how the log-likelihood score acts as an objective function. It provides a quantitative measure of how well any given pedigree structure explains the observed data. Optimization algorithms used in Bonsai (like Simulated Annealing or Integer Linear Programming) explore the vast space of possible pedigrees, using this log-likelihood calculation repeatedly to guide their search towards the structure(s) that best fit the evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Likelihood Functions: Quantifying the Evidence\n",
    "\n",
    "The likelihood function measures how well a proposed pedigree explains the observed IBD data. In Bonsai, this function is built from probabilistic models of IBD segment inheritance.\n",
    "\n",
    "### IBD Likelihood Models\n",
    "\n",
    "For a pair of individuals, the likelihood of their IBD sharing given a specific relationship can be expressed as:\n",
    "\n",
    "$$L(r | \\text{IBD}) = P(\\text{IBD} | r)$$\n",
    "\n",
    "where:\n",
    "- $r$ is the relationship type (e.g., parent-child, siblings, cousins)\n",
    "- IBD represents the observed IBD segments between the individuals\n",
    "\n",
    "Let's implement some basic likelihood models for different relationship types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Illustration: Expected IBD Proportions and Total Sharing ---\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Theoretical expectations\n",
    "relationships = ['Parent-Child', 'Full Siblings', 'Half-Siblings/\\nGrandparent', 'First Cousins', 'Unrelated']\n",
    "expected_ibd0 = [0.0, 0.25, 0.50, 0.75, 1.0]\n",
    "expected_ibd1 = [1.0, 0.50, 0.50, 0.25, 0.0]\n",
    "expected_ibd2 = [0.0, 0.25, 0.0,  0.0,  0.0]\n",
    "expected_total_cm = [3500, 2600, 1750, 875, 0] # Approximate total cM shared\n",
    "\n",
    "exp_df = pd.DataFrame({\n",
    "    'Relationship': relationships,\n",
    "    'IBD0 (%)': [p * 100 for p in expected_ibd0],\n",
    "    'IBD1 (%)': [p * 100 for p in expected_ibd1],\n",
    "    'IBD2 (%)': [p * 100 for p in expected_ibd2],\n",
    "    'Total Shared (cM)': expected_total_cm\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot IBD Proportions\n",
    "exp_df.plot(x='Relationship', y=['IBD0 (%)', 'IBD1 (%)', 'IBD2 (%)'], kind='bar',\n",
    "            stacked=True, ax=axes[0], colormap='viridis')\n",
    "axes[0].set_title('Expected IBD State Proportions')\n",
    "axes[0].set_ylabel('Genome Proportion (%)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].legend(title='IBD State')\n",
    "\n",
    "# Plot Total Sharing\n",
    "exp_df.plot(x='Relationship', y='Total Shared (cM)', kind='bar', ax=axes[1], color='skyblue')\n",
    "axes[1].set_title('Expected Total Shared IBD')\n",
    "axes[1].set_ylabel('Approx. Centimorgans (cM)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].get_legend().remove()\n",
    "\n",
    "plt.suptitle('Theoretical IBD Sharing Expectations by Relationship', fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to prevent title overlap\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: These are theoretical averages. Actual sharing varies due to randomness of recombination.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Likelihood Models for Different Relationships\n",
    "\n",
    "Let's compare how these likelihood models behave for different relationship scenarios. We'll create synthetic IBD data for various relationships and see how well our models can distinguish them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_ibd(relationship_type, noise_level=0.1):\n",
    "    \"\"\"Generate synthetic IBD data for a specific relationship type.\n",
    "    \n",
    "    Args:\n",
    "        relationship_type: One of 'parent-child', 'siblings', 'grandparent', \n",
    "                          'half-siblings', 'first-cousins', 'second-cousins'\n",
    "        noise_level: Level of noise/randomness to add (0.0-1.0)\n",
    "        \n",
    "    Returns:\n",
    "        List of synthetic IBD segments\n",
    "    \"\"\"\n",
    "    genome_length = 3500  # cM\n",
    "    segments = []\n",
    "    \n",
    "    if relationship_type == 'parent-child':\n",
    "        # Parent-child: ~100% IBD1, no IBD2\n",
    "        # Create segments covering the entire genome with some fragmentation\n",
    "        remaining = genome_length\n",
    "        while remaining > 0:\n",
    "            # Create segments of varying sizes but maintain total coverage\n",
    "            seg_length = min(remaining, random.uniform(50, 200))\n",
    "            segments.append({\n",
    "                'type': 'IBD1',\n",
    "                'length': seg_length * (1.0 + random.uniform(-noise_level, noise_level))\n",
    "            })\n",
    "            remaining -= seg_length\n",
    "            \n",
    "    elif relationship_type == 'siblings':\n",
    "        # Siblings: ~25% IBD0, ~50% IBD1, ~25% IBD2\n",
    "        ibd0_target = 0.25 * genome_length\n",
    "        ibd1_target = 0.50 * genome_length\n",
    "        ibd2_target = 0.25 * genome_length\n",
    "        \n",
    "        # Add noise to targets\n",
    "        ibd0_target *= (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        ibd1_target *= (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        ibd2_target *= (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        \n",
    "        # Create IBD1 segments\n",
    "        ibd1_remaining = ibd1_target\n",
    "        while ibd1_remaining > 10:  # Minimum segment size\n",
    "            seg_length = min(ibd1_remaining, random.uniform(10, 100))\n",
    "            segments.append({\n",
    "                'type': 'IBD1',\n",
    "                'length': seg_length\n",
    "            })\n",
    "            ibd1_remaining -= seg_length\n",
    "            \n",
    "        # Create IBD2 segments\n",
    "        ibd2_remaining = ibd2_target\n",
    "        while ibd2_remaining > 10:  # Minimum segment size\n",
    "            seg_length = min(ibd2_remaining, random.uniform(10, 100))\n",
    "            segments.append({\n",
    "                'type': 'IBD2',\n",
    "                'length': seg_length\n",
    "            })\n",
    "            ibd2_remaining -= seg_length\n",
    "            \n",
    "    elif relationship_type in ['half-siblings', 'grandparent']:\n",
    "        # Half-siblings/Grandparent: ~50% IBD0, ~50% IBD1, no IBD2\n",
    "        ibd1_target = 0.50 * genome_length * (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        \n",
    "        # Create IBD1 segments\n",
    "        ibd1_remaining = ibd1_target\n",
    "        while ibd1_remaining > 10:  # Minimum segment size\n",
    "            seg_length = min(ibd1_remaining, random.uniform(10, 100))\n",
    "            segments.append({\n",
    "                'type': 'IBD1',\n",
    "                'length': seg_length\n",
    "            })\n",
    "            ibd1_remaining -= seg_length\n",
    "            \n",
    "    elif relationship_type == 'first-cousins':\n",
    "        # First cousins: ~12.5% IBD1\n",
    "        ibd1_target = 0.125 * genome_length * (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        \n",
    "        # Create IBD1 segments\n",
    "        ibd1_remaining = ibd1_target\n",
    "        while ibd1_remaining > 7:  # Minimum segment size\n",
    "            seg_length = min(ibd1_remaining, random.uniform(7, 50))\n",
    "            segments.append({\n",
    "                'type': 'IBD1',\n",
    "                'length': seg_length\n",
    "            })\n",
    "            ibd1_remaining -= seg_length\n",
    "            \n",
    "    elif relationship_type == 'second-cousins':\n",
    "        # Second cousins: ~3.125% IBD1\n",
    "        ibd1_target = 0.03125 * genome_length * (1.0 + random.uniform(-noise_level, noise_level))\n",
    "        \n",
    "        # Create IBD1 segments\n",
    "        ibd1_remaining = ibd1_target\n",
    "        while ibd1_remaining > 7:  # Minimum segment size\n",
    "            seg_length = min(ibd1_remaining, random.uniform(7, 30))\n",
    "            segments.append({\n",
    "                'type': 'IBD1',\n",
    "                'length': seg_length\n",
    "            })\n",
    "            ibd1_remaining -= seg_length\n",
    "    \n",
    "    # Sort segments by length (largest first)\n",
    "    return sorted(segments, key=lambda x: x['length'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic IBD data for different relationships\n",
    "relationship_types = ['parent-child', 'siblings', 'half-siblings', 'first-cousins', 'second-cousins']\n",
    "synthetic_data = {}\n",
    "\n",
    "for rel_type in relationship_types:\n",
    "    synthetic_data[rel_type] = generate_synthetic_ibd(rel_type)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    total_ibd1 = sum(seg['length'] for seg in synthetic_data[rel_type] if seg['type'] == 'IBD1')\n",
    "    total_ibd2 = sum(seg['length'] for seg in synthetic_data[rel_type] if seg['type'] == 'IBD2')\n",
    "    ibd1_count = sum(1 for seg in synthetic_data[rel_type] if seg['type'] == 'IBD1')\n",
    "    ibd2_count = sum(1 for seg in synthetic_data[rel_type] if seg['type'] == 'IBD2')\n",
    "    \n",
    "    print(f\"{rel_type}:\")\n",
    "    print(f\"  IBD1: {total_ibd1:.1f} cM in {ibd1_count} segments\")\n",
    "    print(f\"  IBD2: {total_ibd2:.1f} cM in {ibd2_count} segments\")\n",
    "    print(f\"  Total: {total_ibd1 + total_ibd2:.1f} cM\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate likelihoods for each relationship type using each model\n",
    "results = []\n",
    "\n",
    "for true_rel in relationship_types:\n",
    "    data = synthetic_data[true_rel]\n",
    "    \n",
    "    # Calculate likelihoods\n",
    "    pc_like = parent_child_likelihood(data)\n",
    "    sib_like = sibling_likelihood(data)\n",
    "    \n",
    "    # Distant relationship likelihoods\n",
    "    hs_like = distant_relationship_likelihood(data, 2)  # Half-siblings: 2 meioses\n",
    "    fc_like = distant_relationship_likelihood(data, 4)  # First cousins: 4 meioses\n",
    "    sc_like = distant_relationship_likelihood(data, 6)  # Second cousins: 6 meioses\n",
    "    \n",
    "    results.append({\n",
    "        'True Relationship': true_rel,\n",
    "        'Parent-Child Log-Likelihood': pc_like,\n",
    "        'Sibling Log-Likelihood': sib_like,\n",
    "        'Half-Sibling Log-Likelihood': hs_like,\n",
    "        'First-Cousin Log-Likelihood': fc_like,\n",
    "        'Second-Cousin Log-Likelihood': sc_like\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "likelihood_df = pd.DataFrame(results)\n",
    "likelihood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the highest likelihood model for each relationship\n",
    "likelihood_columns = [\n",
    "    'Parent-Child Log-Likelihood',\n",
    "    'Sibling Log-Likelihood',\n",
    "    'Half-Sibling Log-Likelihood',\n",
    "    'First-Cousin Log-Likelihood',\n",
    "    'Second-Cousin Log-Likelihood'\n",
    "]\n",
    "\n",
    "# Find max likelihood for each row\n",
    "likelihood_df['Max Likelihood'] = likelihood_df[likelihood_columns].max(axis=1)\n",
    "likelihood_df['Predicted Relationship'] = likelihood_df[likelihood_columns].idxmax(axis=1)\n",
    "\n",
    "# Clean up the predicted relationship string\n",
    "likelihood_df['Predicted Relationship'] = likelihood_df['Predicted Relationship'].str.replace('-Log-Likelihood', '')\n",
    "\n",
    "# Display results\n",
    "likelihood_df[['True Relationship', 'Predicted Relationship', 'Max Likelihood']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports for Likelihood Calculations ---\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import poisson, norm\n",
    "# Note: Ensure 'synthetic_data' dictionary is defined in a previous cell\n",
    "\n",
    "# --- Simplified Likelihood Function Definitions ---\n",
    "\n",
    "def parent_child_likelihood(segments):\n",
    "    \"\"\"Calculate likelihood of a parent-child relationship (simplified model).\"\"\"\n",
    "    # For parent-child: Expect ~100% IBD1, no IBD2\n",
    "    ibd1_length = sum(seg.get('length', 0) for seg in segments if seg.get('type') == 'IBD1')\n",
    "    ibd2_count = sum(1 for seg in segments if seg.get('type') == 'IBD2')\n",
    "    genome_length = 3500.0\n",
    "    coverage = min(1.0, ibd1_length / genome_length if genome_length > 0 else 0)\n",
    "\n",
    "    # Heuristic scoring based on closeness to expectation\n",
    "    if coverage > 0.95 and ibd2_count == 0:\n",
    "        # Very likely Parent-Child if high coverage and no IBD2\n",
    "        # Return a high log-likelihood (close to 0)\n",
    "        # Using log(0.99) might be too specific, let's use a scale\n",
    "        return -0.1 # High likelihood (small negative number)\n",
    "    else:\n",
    "        # Penalize deviations from expected pattern\n",
    "        # Penalty for low coverage OR presence of IBD2\n",
    "        coverage_penalty = ((1.0 - coverage) ** 2) * 50 # Penalize low coverage heavily\n",
    "        ibd2_penalty = (ibd2_count ** 2) * 5         # Penalize IBD2 segments\n",
    "        # Return a lower log-likelihood (more negative)\n",
    "        # Ensure it's clearly distinct from the \"good\" case\n",
    "        return -(coverage_penalty + ibd2_penalty + 1.0) # Base penalty + deviation penalties\n",
    "\n",
    "def sibling_likelihood(segments):\n",
    "    \"\"\"Calculate likelihood of a full sibling relationship (simplified model).\"\"\"\n",
    "    # For full siblings: Expect ~25% IBD0, ~50% IBD1, ~25% IBD2\n",
    "    ibd1_length = sum(seg.get('length', 0) for seg in segments if seg.get('type') == 'IBD1')\n",
    "    ibd2_length = sum(seg.get('length', 0) for seg in segments if seg.get('type') == 'IBD2')\n",
    "    genome_length = 3500.0\n",
    "\n",
    "    # Calculate observed proportions\n",
    "    # Ensure genome_length is positive to avoid division by zero\n",
    "    prop_ibd1 = ibd1_length / genome_length if genome_length > 0 else 0\n",
    "    prop_ibd2 = ibd2_length / genome_length if genome_length > 0 else 0\n",
    "    # IBD0 is the remaining fraction of the genome\n",
    "    prop_ibd0 = max(0.0, 1.0 - (prop_ibd1 + prop_ibd2))\n",
    "\n",
    "    # Expected proportions for full siblings\n",
    "    expected_ibd0 = 0.25\n",
    "    expected_ibd1 = 0.50\n",
    "    expected_ibd2 = 0.25\n",
    "\n",
    "    # Calculate squared error from expected proportions\n",
    "    error = ((prop_ibd0 - expected_ibd0) ** 2 +\n",
    "             (prop_ibd1 - expected_ibd1) ** 2 +\n",
    "             (prop_ibd2 - expected_ibd2) ** 2)\n",
    "\n",
    "    # Convert error to a log-likelihood score (higher error = lower likelihood)\n",
    "    # Scale the error to make differences more apparent\n",
    "    return -20.0 * error # Larger negative value for larger error\n",
    "\n",
    "# --- Helper functions for distant likelihood ---\n",
    "def calculate_expected_segments(relatedness, min_cm=7):\n",
    "    \"\"\"Calculate expected number of IBD segments (>min_cm) (simplified).\"\"\"\n",
    "    if relatedness <= 0 or relatedness > 1: return 0.1 # Handle invalid input\n",
    "    # Avoid log(0) for unrelated\n",
    "    if relatedness < 1e-9: return 0.1\n",
    "    try:\n",
    "        meioses = -math.log2(relatedness)\n",
    "    except ValueError:\n",
    "        return 0.1 # Should not happen with checks above\n",
    "\n",
    "    genome_length_cm = 3500.0\n",
    "    chromosomes = 22\n",
    "    # Heuristic formula from previous example - NOT theoretically rigorous for m=1, 2\n",
    "    # but aims to show decreasing trend for distant relatives\n",
    "    decay_factor = math.exp(-(meioses / 100.0) * min_cm) # Simplified decay\n",
    "    # Adjusting formula slightly - use '2 * relatedness * genome_length' as base rate?\n",
    "    # Let's try a simpler form for distant: lambda ~ 2*phi*L / E[Length]\n",
    "    # E[Length | > min_cm] ~ (100/m) * (1 + m/100 * min_cm) / exp(-m/100*min_cm) -- complex\n",
    "    # Using the heuristic from the previous plot's code for consistency in demo:\n",
    "    expected = (genome_length_cm / 100.0) * (meioses + chromosomes) * relatedness * decay_factor\n",
    "    return max(0.1, expected) # Ensure lambda > 0 for Poisson\n",
    "\n",
    "def calculate_expected_length(relatedness, min_cm=7):\n",
    "    \"\"\"Calculate expected total length of IBD segments (>min_cm) (simplified).\"\"\"\n",
    "    if relatedness <= 0 or relatedness > 1: return 0.1 # Handle invalid input\n",
    "    if relatedness < 1e-9: return 0.1\n",
    "    try:\n",
    "        meioses = -math.log2(relatedness)\n",
    "    except ValueError:\n",
    "        return 0.1\n",
    "\n",
    "    genome_length_cm = 3500.0\n",
    "    total_expected_uncond = genome_length_cm * relatedness\n",
    "    # Apply a heuristic correction factor for the minimum length threshold\n",
    "    decay_factor = math.exp(-(meioses / 100.0) * min_cm)\n",
    "    length_increase_factor = (1 + (meioses / 100.0) * min_cm) # Accounts for longer avg length when conditioned\n",
    "    # Combine: Expected total = Unconditional Total * Prob(Seg > min_cm) * Length Increase factor? No...\n",
    "    # Let's use the heuristic from the previous code block for consistency:\n",
    "    expected = total_expected_uncond * decay_factor * length_increase_factor\n",
    "    return max(0.1, expected) # Ensure positive length\n",
    "\n",
    "def distant_relationship_likelihood(segments, meioses):\n",
    "    \"\"\"Calculate likelihood for distant relations using Poisson/Normal approx.\"\"\"\n",
    "    if meioses <= 0: # Invalid input\n",
    "        return -float('inf')\n",
    "\n",
    "    min_cm = 7\n",
    "    # Ensure segments is iterable and dicts have keys\n",
    "    if not hasattr(segments, '__iter__'): segments = []\n",
    "    filtered_segments = [seg for seg in segments\n",
    "                         if isinstance(seg, dict) and seg.get('type') == 'IBD1' and seg.get('length', 0) >= min_cm]\n",
    "\n",
    "    segment_count = len(filtered_segments)\n",
    "    total_length = sum(seg['length'] for seg in filtered_segments)\n",
    "\n",
    "    # Calculate relatedness safely\n",
    "    relatedness = 2.0 ** (-meioses)\n",
    "\n",
    "    # Get expected values using helper functions\n",
    "    expected_count = calculate_expected_segments(relatedness, min_cm)\n",
    "    expected_length = calculate_expected_length(relatedness, min_cm)\n",
    "\n",
    "    # --- Calculate Poisson log-likelihood for count ---\n",
    "    # Handle edge cases for poisson.logpmf(k, mu)\n",
    "    # If mu=0, logpmf is 0 only if k=0, else -inf.\n",
    "    # If mu>0, calculation is standard.\n",
    "    count_log_like = 0.0\n",
    "    if expected_count < 1e-9: # Treat as zero\n",
    "        count_log_like = 0.0 if segment_count == 0 else -float('inf')\n",
    "    else:\n",
    "        # poisson.logpmf requires k>=0 integer, mu>=0\n",
    "        if segment_count >= 0:\n",
    "             try:\n",
    "                 count_log_like = poisson.logpmf(segment_count, expected_count)\n",
    "             except (ValueError, TypeError): # k might not be integer if data is weird\n",
    "                 count_log_like = -float('inf')\n",
    "        else:\n",
    "             count_log_like = -float('inf') # Negative count is impossible\n",
    "\n",
    "    # --- Calculate Normal log-likelihood for total length ---\n",
    "    length_log_like = 0.0\n",
    "    # Only calculate if there are segments observed AND expected\n",
    "    # Also need expected_length > 0 and expected_count > 0 for scale calculation\n",
    "    if segment_count > 0 and expected_count > 1e-9 and expected_length > 1e-9:\n",
    "        # Calculate scale (std dev) - proportional to expected_length / sqrt(expected_count)\n",
    "        # Add epsilon to avoid division by zero if expected_count is tiny but positive\n",
    "        scale = expected_length / math.sqrt(expected_count + 1e-9)\n",
    "        if scale > 1e-9: # Ensure scale is reasonably positive\n",
    "            try:\n",
    "                length_log_like = norm.logpdf(total_length, loc=expected_length, scale=scale)\n",
    "            except (ValueError, TypeError):\n",
    "                length_log_like = -float('inf')\n",
    "        else: # If scale is effectively zero, treat as delta function\n",
    "             length_log_like = 0.0 if abs(total_length - expected_length) < 1e-6 else -float('inf')\n",
    "    elif segment_count == 0 and expected_count < 1e-9:\n",
    "        # If no segments observed and none expected, this is consistent.\n",
    "        # Length component likelihood is neutral (log(1)=0) or based on P(Count=0)\n",
    "        # which is already handled by count_log_like. So set length_log_like = 0.\n",
    "        length_log_like = 0.0\n",
    "    elif segment_count > 0 and expected_count < 1e-9:\n",
    "        # Observed segments but none expected - this is inconsistent via count_log_like already\n",
    "        length_log_like = 0.0 # Let count_log_like dominate\n",
    "    elif segment_count == 0 and expected_count > 1e-9:\n",
    "         # No segments observed, but some expected. Count likelihood handles this.\n",
    "         length_log_like = 0.0 # Let count_log_like dominate\n",
    "\n",
    "    # --- Combine likelihoods (weighted) ---\n",
    "    # Check for NaN/Inf before weighting to avoid issues like inf * 0\n",
    "    if np.isinf(count_log_like) or np.isnan(count_log_like):\n",
    "        w_count_ll = -10000.0 # Assign large penalty if count is impossible/undefined\n",
    "    else:\n",
    "        w_count_ll = count_log_like * 0.7\n",
    "\n",
    "    if np.isinf(length_log_like) or np.isnan(length_log_like):\n",
    "        w_length_ll = -10000.0 # Assign large penalty if length is impossible/undefined\n",
    "    else:\n",
    "        w_length_ll = length_log_like * 0.3\n",
    "\n",
    "    # Final combined log-likelihood\n",
    "    final_ll = w_count_ll + w_length_ll\n",
    "\n",
    "    # Ensure it doesn't become positive infinity if both somehow were +inf\n",
    "    if np.isinf(final_ll) and final_ll > 0:\n",
    "        final_ll = -float('inf')\n",
    "\n",
    "    # Handle case where both components are valid but sum is NaN (shouldn't happen with checks)\n",
    "    if np.isnan(final_ll):\n",
    "        final_ll = -float('inf')\n",
    "\n",
    "    return final_ll\n",
    "\n",
    "# --- Demonstration using Synthetic Data ---\n",
    "# (Assumes Cell 14 creating 'synthetic_data' has been run)\n",
    "\n",
    "print(\"\\n--- Demonstrating Simplified Likelihood Functions ---\")\n",
    "\n",
    "# Check if synthetic_data exists in the current scope\n",
    "if 'synthetic_data' in locals() and isinstance(synthetic_data, dict):\n",
    "    # Get example data, providing empty list if key is missing\n",
    "    pc_data = synthetic_data.get('parent-child', [])\n",
    "    sib_data = synthetic_data.get('siblings', [])\n",
    "    fc_data = synthetic_data.get('first-cousins', [])\n",
    "    sc_data = synthetic_data.get('second-cousins', [])\n",
    "\n",
    "    # Calculate likelihoods for matching data/models\n",
    "    ll_pc_as_pc = parent_child_likelihood(pc_data)\n",
    "    ll_sib_as_sib = sibling_likelihood(sib_data)\n",
    "    ll_fc_as_fc = distant_relationship_likelihood(fc_data, 4) # 4 meioses for 1st cousins\n",
    "    ll_sc_as_sc = distant_relationship_likelihood(sc_data, 6) # 6 meioses for 2nd cousins\n",
    "\n",
    "    print(f\"LogLik(Parent-Child Data | Parent-Child Model) : {ll_pc_as_pc:.2f}\")\n",
    "    print(f\"LogLik(Sibling Data       | Sibling Model)        : {ll_sib_as_sib:.2f}\")\n",
    "    print(f\"LogLik(1st Cousin Data    | Distant Model, m=4)   : {ll_fc_as_fc:.2f}\")\n",
    "    print(f\"LogLik(2nd Cousin Data    | Distant Model, m=6)   : {ll_sc_as_sc:.2f}\")\n",
    "\n",
    "    # Calculate likelihoods for mismatching data/models\n",
    "    ll_pc_as_sib = sibling_likelihood(pc_data)\n",
    "    ll_sib_as_pc = parent_child_likelihood(sib_data)\n",
    "    ll_sib_as_fc = distant_relationship_likelihood(sib_data, 4)\n",
    "    ll_fc_as_sib = sibling_likelihood(fc_data)\n",
    "\n",
    "    print(f\"\\n--- Examples of Mismatches ---\")\n",
    "    print(f\"LogLik(Parent-Child Data | Sibling Model)        : {ll_pc_as_sib:.2f} (Expected lower than {ll_pc_as_pc:.2f})\")\n",
    "    print(f\"LogLik(Sibling Data       | Parent-Child Model)   : {ll_sib_as_pc:.2f} (Expected lower than {ll_sib_as_sib:.2f})\")\n",
    "    print(f\"LogLik(Sibling Data       | Distant Model, m=4)   : {ll_sib_as_fc:.2f} (Expected lower than {ll_sib_as_sib:.2f})\")\n",
    "    print(f\"LogLik(1st Cousin Data    | Sibling Model)        : {ll_fc_as_sib:.2f} (Expected lower than {ll_fc_as_fc:.2f})\")\n",
    "\n",
    "\n",
    "    print(\"\\nNote: Higher (less negative) log-likelihood indicates a better fit between\")\n",
    "    print(\"the data and the assumed relationship model.\")\n",
    "    print(\"These functions use simplified models for demonstration purposes.\")\n",
    "    print(\"Real likelihood models are more complex and often empirically derived.\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: 'synthetic_data' dictionary not found.\")\n",
    "    print(\"Please ensure the cell that generates 'synthetic_data' (e.g., Cell 13/14) has been run successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBD Moments Model\n",
    "\n",
    "A key innovation in Bonsai is the use of \"IBD moments\" to summarize the IBD sharing between individuals. Let's implement a function to calculate these moments from IBD segment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ibd_moments(segment_list, min_length=7):\n",
    "    \"\"\"Calculate IBD moments from a list of segments.\n",
    "    \n",
    "    Args:\n",
    "        segment_list: List of IBD segments with 'length' attribute\n",
    "        min_length: Minimum segment length to consider\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with first moment (count) and second moment (total length)\n",
    "    \"\"\"\n",
    "    # Filter segments by minimum length\n",
    "    filtered_segments = [seg for seg in segment_list if seg['length'] >= min_length]\n",
    "    \n",
    "    # First moment: number of segments\n",
    "    first_moment = len(filtered_segments)\n",
    "    \n",
    "    # Second moment: total length of segments\n",
    "    second_moment = sum(seg['length'] for seg in filtered_segments)\n",
    "    \n",
    "    # Third moment (optional): sum of squared lengths\n",
    "    third_moment = sum(seg['length']**2 for seg in filtered_segments)\n",
    "    \n",
    "    return {\n",
    "        \"first_moment\": first_moment,\n",
    "        \"second_moment\": second_moment,\n",
    "        \"third_moment\": third_moment\n",
    "    }\n",
    "\n",
    "# Calculate moments for each relationship type\n",
    "moments_results = []\n",
    "\n",
    "for rel_type, data in synthetic_data.items():\n",
    "    moments = calculate_ibd_moments(data)\n",
    "    moments_results.append({\n",
    "        'Relationship': rel_type,\n",
    "        'Segment Count': moments['first_moment'],\n",
    "        'Total Length (cM)': moments['second_moment'],\n",
    "        'Mean Segment Length': moments['second_moment'] / max(1, moments['first_moment'])\n",
    "    })\n",
    "\n",
    "moments_df = pd.DataFrame(moments_results)\n",
    "moments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the moments by relationship type\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Sort by total length for better visualization\n",
    "moments_df = moments_df.sort_values('Total Length (cM)', ascending=False)\n",
    "\n",
    "# Plot segment count and total length\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "moments_df.plot(x='Relationship', y='Segment Count', kind='bar', ax=ax)\n",
    "plt.title('First Moment: Segment Count')\n",
    "plt.ylabel('Number of Segments (>7cM)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "moments_df.plot(x='Relationship', y='Total Length (cM)', kind='bar', ax=ax)\n",
    "plt.title('Second Moment: Total IBD Length')\n",
    "plt.ylabel('Total Length (cM)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Up-Node Dictionary: Encoding Pedigree Structures\n",
    "\n",
    "A key data structure in Bonsai is the \"up-node dictionary,\" which encodes the pedigree structure in a way that facilitates efficient likelihood calculations and structural modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_up_node_dict(individuals):\n",
    "    \"\"\"Create an empty up-node dictionary for a set of individuals.\n",
    "    \n",
    "    Args:\n",
    "        individuals: List of individual IDs\n",
    "        \n",
    "    Returns:\n",
    "        Empty up-node dictionary\n",
    "    \"\"\"\n",
    "    up_node_dict = {}\n",
    "    for ind in individuals:\n",
    "        up_node_dict[ind] = {}  # Empty dictionary indicates no parents\n",
    "    return up_node_dict\n",
    "\n",
    "def add_relationship(up_node_dict, child, parent1, parent2=None):\n",
    "    \"\"\"Add a parent-child relationship to the up-node dictionary.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: The up-node dictionary to modify\n",
    "        child: ID of the child\n",
    "        parent1: ID of the first parent\n",
    "        parent2: ID of the second parent (optional)\n",
    "        \n",
    "    Returns:\n",
    "        Modified up-node dictionary\n",
    "    \"\"\"\n",
    "    if child not in up_node_dict:\n",
    "        up_node_dict[child] = {}\n",
    "    \n",
    "    # Add first parent\n",
    "    up_node_dict[child][parent1] = 1\n",
    "    \n",
    "    # Add second parent if provided\n",
    "    if parent2 is not None:\n",
    "        up_node_dict[child][parent2] = 1\n",
    "    \n",
    "    # Make sure parents exist in the dictionary\n",
    "    if parent1 not in up_node_dict:\n",
    "        up_node_dict[parent1] = {}\n",
    "    if parent2 is not None and parent2 not in up_node_dict:\n",
    "        up_node_dict[parent2] = {}\n",
    "    \n",
    "    return up_node_dict\n",
    "\n",
    "def visualize_pedigree(up_node_dict):\n",
    "    \"\"\"Create a visualization of the pedigree from an up-node dictionary.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "    \"\"\"\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for child, parents in up_node_dict.items():\n",
    "        G.add_node(child)\n",
    "        for parent in parents:\n",
    "            G.add_node(parent)\n",
    "            G.add_edge(parent, child)  # Direction from parent to child\n",
    "    \n",
    "    # Set node colors: green for real individuals (positive IDs), white for latent (negative IDs)\n",
    "    node_colors = ['lightgreen' if isinstance(node, int) and node > 0 else 'lightgray' \n",
    "                   for node in G.nodes()]\n",
    "    \n",
    "    # Calculate layout\n",
    "    pos = nx.nx_agraph.graphviz_layout(G, prog='dot') if nx.nx_agraph else nx.spring_layout(G)\n",
    "    \n",
    "    # Draw the graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, \n",
    "            node_size=700, font_size=10, arrows=True)\n",
    "    plt.title('Pedigree Structure')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple example pedigree\n",
    "individuals = [1000, 1001, 1002, 1003, 1004, 1005]\n",
    "up_node_dict = create_empty_up_node_dict(individuals)\n",
    "\n",
    "# Add relationships\n",
    "up_node_dict = add_relationship(up_node_dict, 1003, 1001, 1002)  # 1003 has parents 1001 and 1002\n",
    "up_node_dict = add_relationship(up_node_dict, 1004, 1001, 1002)  # 1004 has the same parents\n",
    "up_node_dict = add_relationship(up_node_dict, 1005, 1000, 1003)  # 1005 has parents 1000 and 1003\n",
    "\n",
    "# Visualize the pedigree\n",
    "visualize_pedigree(up_node_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Genetic Relationships Using the Up-Node Dictionary\n",
    "\n",
    "One of the key operations in Bonsai is calculating the genetic relationship coefficient between individuals based on the pedigree structure. Let's implement this calculation using the up-node dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genetic_paths(up_node_dict, individual, path=None, paths=None, ancestor=None):\n",
    "    \"\"\"Find all paths from an individual to their ancestors.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        individual: ID of the individual to trace\n",
    "        path: Current path being explored (for recursion)\n",
    "        paths: Dictionary of collected paths (for recursion)\n",
    "        ancestor: Current ancestor being considered (for recursion)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping ancestor IDs to lists of paths\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        path = []\n",
    "    if paths is None:\n",
    "        paths = {individual: [[]]}  # Start with self path\n",
    "    \n",
    "    # If this individual has no parents, return current paths\n",
    "    if individual not in up_node_dict or not up_node_dict[individual]:\n",
    "        return paths\n",
    "    \n",
    "    # Process each parent\n",
    "    for parent in up_node_dict[individual]:\n",
    "        # Create a new path for this parent\n",
    "        new_path = path + [parent]\n",
    "        \n",
    "        # Add this path to the parent's paths\n",
    "        if parent not in paths:\n",
    "            paths[parent] = []\n",
    "        paths[parent].append(new_path)\n",
    "        \n",
    "        # Recursively process this parent's ancestors\n",
    "        get_genetic_paths(up_node_dict, parent, new_path, paths, parent)\n",
    "    \n",
    "    return paths\n",
    "\n",
    "def calculate_relationship_coefficient(up_node_dict, id1, id2):\n",
    "    \"\"\"Calculate the relationship coefficient between two individuals.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        id1: ID of the first individual\n",
    "        id2: ID of the second individual\n",
    "        \n",
    "    Returns:\n",
    "        Relationship coefficient (proportion of shared genetic material)\n",
    "    \"\"\"\n",
    "    if id1 == id2:\n",
    "        return 1.0  # Self-relationship is 1.0\n",
    "    \n",
    "    # Direct parent-child relationship check\n",
    "    if id1 in up_node_dict.get(id2, {}) or id2 in up_node_dict.get(id1, {}):\n",
    "        return 0.5  # Parent-child share 50%\n",
    "    \n",
    "    # Get genetic paths to ancestors for each individual\n",
    "    paths1 = get_genetic_paths(up_node_dict, id1)\n",
    "    paths2 = get_genetic_paths(up_node_dict, id2)\n",
    "    \n",
    "    # Find common ancestors and calculate contributions\n",
    "    relatedness = 0.0\n",
    "    common_ancestors = set(paths1.keys()) & set(paths2.keys())\n",
    "    \n",
    "    for ancestor in common_ancestors:\n",
    "        if ancestor == id1 or ancestor == id2:\n",
    "            continue  # Skip self-paths\n",
    "            \n",
    "        # Each path contributes 0.5^(length of path)\n",
    "        for path1 in paths1[ancestor]:\n",
    "            for path2 in paths2[ancestor]:\n",
    "                contribution = 0.5**(len(path1) + len(path2))\n",
    "                relatedness += contribution\n",
    "    \n",
    "    return relatedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display relationship coefficients for all pairs\n",
    "relationship_results = []\n",
    "\n",
    "for id1 in individuals:\n",
    "    for id2 in individuals:\n",
    "        if id1 < id2:  # Avoid duplicates and self-relationships\n",
    "            coef = calculate_relationship_coefficient(up_node_dict, id1, id2)\n",
    "            relationship_name = \"Unknown\"\n",
    "            \n",
    "            # Map coefficient to relationship name\n",
    "            if coef == 0.5:\n",
    "                relationship_name = \"Parent-Child\"\n",
    "            elif coef == 0.25:\n",
    "                relationship_name = \"Grandparent or Half-Sibling\"\n",
    "            elif coef == 0.125:\n",
    "                relationship_name = \"First Cousin or Great-Grandparent\"\n",
    "            elif 0.24 < coef < 0.26:  # Full siblings (theoretical 0.25, but can vary)\n",
    "                relationship_name = \"Full Siblings\"\n",
    "            \n",
    "            relationship_results.append({\n",
    "                'Individual 1': id1,\n",
    "                'Individual 2': id2,\n",
    "                'Relationship Coefficient': coef,\n",
    "                'Relationship': relationship_name\n",
    "            })\n",
    "\n",
    "rel_df = pd.DataFrame(relationship_results)\n",
    "rel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimization Algorithms in Bonsai\n",
    "\n",
    "Bonsai uses sophisticated optimization algorithms to search for the pedigree structure that maximizes the likelihood of the observed IBD data. Let's implement a simplified version of these algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pedigree_likelihood(up_node_dict, ibd_segments, min_cm=7):\n",
    "    \"\"\"Calculate the likelihood of a pedigree given IBD segment data.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        ibd_segments: Dictionary mapping pairs of individuals to their IBD segments\n",
    "        min_cm: Minimum segment length to consider\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood of the pedigree\n",
    "    \"\"\"\n",
    "    # This is a simplified placeholder implementation\n",
    "    total_log_likelihood = 0.0\n",
    "    \n",
    "    # Process each pair of individuals\n",
    "    for (id1, id2), segments in ibd_segments.items():\n",
    "        # Skip if either individual is not in the pedigree\n",
    "        if id1 not in up_node_dict or id2 not in up_node_dict:\n",
    "            continue\n",
    "            \n",
    "        # Calculate expected relationship coefficient\n",
    "        expected_coef = calculate_relationship_coefficient(up_node_dict, id1, id2)\n",
    "        \n",
    "        # Calculate observed moments\n",
    "        moments = calculate_ibd_moments(segments, min_cm)\n",
    "        \n",
    "        # Skip pairs with no IBD sharing above threshold\n",
    "        if moments['first_moment'] == 0:\n",
    "            continue\n",
    "            \n",
    "        # Calculate expected moments\n",
    "        expected_count = calculate_expected_segments(expected_coef, min_cm)\n",
    "        expected_length = calculate_expected_length(expected_coef, min_cm)\n",
    "        \n",
    "        # Calculate likelihood using Poisson model for segment count\n",
    "        count_log_like = poisson.logpmf(moments['first_moment'], expected_count) if expected_count > 0 else 0\n",
    "        \n",
    "        # Use a normal approximation for total length\n",
    "        length_log_like = 0\n",
    "        if expected_count > 0 and moments['first_moment'] > 0:\n",
    "            length_log_like = norm.logpdf(moments['second_moment'], \n",
    "                                         expected_length, \n",
    "                                         expected_length / math.sqrt(expected_count))\n",
    "        \n",
    "        # Combine likelihoods\n",
    "        pair_log_like = count_log_like * 0.7 + length_log_like * 0.3\n",
    "        total_log_likelihood += pair_log_like\n",
    "    \n",
    "    return total_log_likelihood\n",
    "\n",
    "def propose_pedigree_modification(up_node_dict, ids=None):\n",
    "    \"\"\"Propose a modification to the pedigree structure.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Current up-node dictionary\n",
    "        ids: List of individual IDs to consider (if None, uses all IDs)\n",
    "        \n",
    "    Returns:\n",
    "        Modified up-node dictionary\n",
    "    \"\"\"\n",
    "    # Create a deep copy to avoid modifying the original\n",
    "    new_dict = {}\n",
    "    for ind, parents in up_node_dict.items():\n",
    "        new_dict[ind] = parents.copy()\n",
    "    \n",
    "    # If no IDs provided, use all individuals in the dictionary\n",
    "    if ids is None:\n",
    "        ids = [id for id in up_node_dict.keys() if isinstance(id, int) and id > 0]\n",
    "    \n",
    "    # Choose a random individual\n",
    "    if not ids:\n",
    "        return new_dict  # No individuals to modify\n",
    "        \n",
    "    ind = random.choice(ids)\n",
    "    \n",
    "    # Choose a modification type\n",
    "    mod_type = random.choice(['add_parent', 'remove_parent', 'swap_parent'])\n",
    "    \n",
    "    if mod_type == 'add_parent':\n",
    "        # Add a parent to the individual\n",
    "        if len(new_dict[ind]) < 2:  # Can only add if fewer than 2 parents\n",
    "            # Create a new latent parent (negative ID)\n",
    "            new_parent = -random.randint(1, 1000)\n",
    "            while new_parent in new_dict:  # Ensure unique ID\n",
    "                new_parent = -random.randint(1, 1000)\n",
    "                \n",
    "            # Add the parent\n",
    "            new_dict[ind][new_parent] = 1\n",
    "            new_dict[new_parent] = {}  # Initialize parent with no ancestors\n",
    "    \n",
    "    elif mod_type == 'remove_parent':\n",
    "        # Remove a parent if any exist\n",
    "        if new_dict[ind]:\n",
    "            parent = random.choice(list(new_dict[ind].keys()))\n",
    "            del new_dict[ind][parent]\n",
    "    \n",
    "    elif mod_type == 'swap_parent':\n",
    "        # Replace a parent with another individual or a new latent parent\n",
    "        if new_dict[ind]:\n",
    "            parent = random.choice(list(new_dict[ind].keys()))\n",
    "            \n",
    "            # Create a new latent parent\n",
    "            new_parent = -random.randint(1, 1000)\n",
    "            while new_parent in new_dict:  # Ensure unique ID\n",
    "                new_parent = -random.randint(1, 1000)\n",
    "                \n",
    "            # Replace the parent\n",
    "            del new_dict[ind][parent]\n",
    "            new_dict[ind][new_parent] = 1\n",
    "            new_dict[new_parent] = {}  # Initialize parent with no ancestors\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "def build_pedigree_with_optimization(individuals, ibd_segments, min_cm=7):\n",
    "    \"\"\"Build a pedigree using optimization techniques.\n",
    "    \n",
    "    Args:\n",
    "        individuals: List of individual IDs\n",
    "        ibd_segments: Dictionary mapping pairs of individuals to their IBD segments\n",
    "        min_cm: Minimum segment length to consider\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (best pedigree, best likelihood)\n",
    "    \"\"\"\n",
    "    # Initialize with empty pedigree\n",
    "    pedigree = create_empty_up_node_dict(individuals)\n",
    "    \n",
    "    # Calculate initial likelihood\n",
    "    current_likelihood = calculate_pedigree_likelihood(pedigree, ibd_segments, min_cm)\n",
    "    best_pedigree = {k: v.copy() for k, v in pedigree.items()}\n",
    "    best_likelihood = current_likelihood\n",
    "    \n",
    "    # Optimization parameters\n",
    "    temperature = 1.0\n",
    "    cooling_rate = 0.99\n",
    "    iterations = 100  # Reduced for demonstration\n",
    "    \n",
    "    # Track progress\n",
    "    likelihoods = [current_likelihood]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Propose a modification to the pedigree\n",
    "        new_pedigree = propose_pedigree_modification(pedigree)\n",
    "        \n",
    "        # Calculate new likelihood\n",
    "        new_likelihood = calculate_pedigree_likelihood(new_pedigree, ibd_segments, min_cm)\n",
    "        \n",
    "        # Accept or reject based on likelihood and temperature\n",
    "        if new_likelihood > current_likelihood:\n",
    "            # Always accept improvements\n",
    "            accept = True\n",
    "        else:\n",
    "            # Sometimes accept worse solutions based on temperature\n",
    "            delta = new_likelihood - current_likelihood\n",
    "            accept_probability = math.exp(delta / temperature)\n",
    "            accept = random.random() < accept_probability\n",
    "        \n",
    "        if accept:\n",
    "            pedigree = new_pedigree\n",
    "            current_likelihood = new_likelihood\n",
    "            \n",
    "            # Update best pedigree if improved\n",
    "            if current_likelihood > best_likelihood:\n",
    "                best_pedigree = {k: v.copy() for k, v in pedigree.items()}\n",
    "                best_likelihood = current_likelihood\n",
    "        \n",
    "        # Cool the temperature\n",
    "        temperature *= cooling_rate\n",
    "        \n",
    "        # Track progress\n",
    "        likelihoods.append(current_likelihood)\n",
    "        \n",
    "        # Occasionally print progress\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"Iteration {i+1}: Current likelihood = {current_likelihood:.2f}, Best = {best_likelihood:.2f}\")\n",
    "    \n",
    "    # Plot optimization progress\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(likelihoods)\n",
    "    plt.title('Optimization Progress')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Log Likelihood')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return best_pedigree, best_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing IBD Data for Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert synthetic data into the format expected by optimization\n",
    "# In this case, a dictionary mapping (id1, id2) to list of segments\n",
    "\n",
    "# First, generate a more complete set of synthetic relationships\n",
    "synthetic_relationships = {\n",
    "    (1000, 1003): generate_synthetic_ibd('parent-child'),\n",
    "    (1001, 1003): generate_synthetic_ibd('parent-child'),\n",
    "    (1001, 1004): generate_synthetic_ibd('parent-child'),\n",
    "    (1002, 1004): generate_synthetic_ibd('parent-child'),\n",
    "    (1003, 1004): generate_synthetic_ibd('siblings'),\n",
    "    (1000, 1004): generate_synthetic_ibd('half-siblings'),\n",
    "    (1000, 1005): generate_synthetic_ibd('first-cousins'),\n",
    "    (1002, 1005): generate_synthetic_ibd('second-cousins')\n",
    "}\n",
    "\n",
    "# Display the data structure\n",
    "for (id1, id2), segments in list(synthetic_relationships.items())[:2]:  # Show first two for brevity\n",
    "    print(f\"Relationship between {id1} and {id2}:\")\n",
    "    print(f\"  Number of segments: {len(segments)}\")\n",
    "    print(f\"  Total IBD length: {sum(seg['length'] for seg in segments):.1f} cM\")\n",
    "    print(f\"  First few segments: {segments[:2]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimization to reconstruct the pedigree\n",
    "# Note: This is a simplified demonstration; actual Bonsai optimization is more complex\n",
    "try:\n",
    "    # We'll use a timeout to avoid running too long in the notebook\n",
    "    import signal\n",
    "    class TimeoutException(Exception): pass\n",
    "    \n",
    "    def timeout_handler(signum, frame):\n",
    "        raise TimeoutException(\"Timed out!\")\n",
    "    \n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    signal.alarm(300)  # 5 minute timeout\n",
    "    \n",
    "    # Run the optimization\n",
    "    inferred_pedigree, final_likelihood = build_pedigree_with_optimization(\n",
    "        individuals, synthetic_relationships, min_cm=7\n",
    "    )\n",
    "    \n",
    "    signal.alarm(0)  # Cancel the alarm\n",
    "    \n",
    "    # Visualize the inferred pedigree\n",
    "    print(\"\\nInferred Pedigree:\")\n",
    "    visualize_pedigree(inferred_pedigree)\n",
    "    \n",
    "    # Compare with the true pedigree\n",
    "    print(\"\\nTrue Pedigree:\")\n",
    "    visualize_pedigree(up_node_dict)\n",
    "    \n",
    "except TimeoutException:\n",
    "    print(\"Optimization timed out. This is expected in the notebook demonstration.\")\n",
    "    print(\"For a full analysis, consider running the optimization with more carefully selected parameters.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during optimization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mathematical Extensions and Improvements\n",
    "\n",
    "Let's explore some mathematical extensions that can improve Bonsai's performance, such as handling age constraints and incorporating additional relationship information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incorporate_age_constraints(up_node_dict, ages, min_parent_age=12):\n",
    "    \"\"\"Check if a pedigree satisfies age constraints.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        ages: Dictionary mapping individual IDs to ages\n",
    "        min_parent_age: Minimum age difference between parent and child\n",
    "        \n",
    "    Returns:\n",
    "        True if all constraints are satisfied, False otherwise\n",
    "    \"\"\"\n",
    "    for child, parents in up_node_dict.items():\n",
    "        if child < 0 or not parents:  # Skip inferred individuals or those without parents\n",
    "            continue\n",
    "            \n",
    "        child_age = ages.get(child)\n",
    "        if child_age is None:\n",
    "            continue\n",
    "            \n",
    "        for parent in parents:\n",
    "            if parent < 0:  # Skip inferred parents\n",
    "                continue\n",
    "                \n",
    "            parent_age = ages.get(parent)\n",
    "            if parent_age is None:\n",
    "                continue\n",
    "                \n",
    "            # Check if parent is older than child by at least min_parent_age\n",
    "            if parent_age <= child_age + min_parent_age:\n",
    "                return False  # Age constraint violated\n",
    "    \n",
    "    return True  # All constraints satisfied\n",
    "\n",
    "def calculate_pedigree_likelihood_with_constraints(up_node_dict, ibd_segments, ages=None, min_cm=7):\n",
    "    \"\"\"Calculate pedigree likelihood with additional constraints.\n",
    "    \n",
    "    Args:\n",
    "        up_node_dict: Up-node dictionary representing the pedigree\n",
    "        ibd_segments: Dictionary mapping pairs of individuals to their IBD segments\n",
    "        ages: Dictionary mapping individual IDs to ages (optional)\n",
    "        min_cm: Minimum segment length to consider\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood of the pedigree\n",
    "    \"\"\"\n",
    "    # Check age constraints if ages provided\n",
    "    if ages is not None and not incorporate_age_constraints(up_node_dict, ages):\n",
    "        return float('-inf')  # Invalid pedigree due to age constraints\n",
    "    \n",
    "    # Otherwise, calculate likelihood as before\n",
    "    return calculate_pedigree_likelihood(up_node_dict, ibd_segments, min_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using age constraints\n",
    "# Assign ages to individuals\n",
    "ages = {\n",
    "    1000: 70,\n",
    "    1001: 65,\n",
    "    1002: 68,\n",
    "    1003: 40,\n",
    "    1004: 38,\n",
    "    1005: 15\n",
    "}\n",
    "\n",
    "# Check if our example pedigree satisfies age constraints\n",
    "age_valid = incorporate_age_constraints(up_node_dict, ages)\n",
    "print(f\"Pedigree satisfies age constraints: {age_valid}\")\n",
    "\n",
    "# Create an invalid pedigree for demonstration\n",
    "invalid_pedigree = create_empty_up_node_dict(individuals)\n",
    "invalid_pedigree = add_relationship(invalid_pedigree, 1001, 1003)  # Invalid: 1003 is younger than 1001\n",
    "\n",
    "# Check if the invalid pedigree satisfies age constraints\n",
    "age_valid = incorporate_age_constraints(invalid_pedigree, ages)\n",
    "print(f\"Invalid pedigree satisfies age constraints: {age_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab, we explored the mathematical foundations of the Bonsai algorithm for pedigree reconstruction. We implemented key components of the algorithm, including likelihood functions, the up-node dictionary data structure, and optimization techniques. We also examined how additional constraints, such as age information, can be incorporated to improve reconstruction accuracy.\n",
    "\n",
    "Key takeaways:\n",
    "- Bonsai uses a Bayesian framework to find the most likely pedigree given observed IBD segment patterns\n",
    "- Different relationship types have characteristic likelihood models based on theoretical expectations\n",
    "- The up-node dictionary provides an efficient representation of pedigree structures\n",
    "- Optimization algorithms like simulated annealing help search the vast space of possible pedigrees\n",
    "- Additional constraints and information can be incorporated to improve reconstruction accuracy\n",
    "\n",
    "In the next lab, we will explore the data structures used in Bonsai in more detail, focusing on how they enable efficient pedigree manipulation and analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}