{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 17: Advanced Likelihood Calculations in Bonsai\n",
    "\n",
    "In this lab, we will explore the mathematical foundation for relationship inference in genetic genealogy using the Bonsai algorithm. Building upon our understanding of Bonsai's architecture from Lab 16, we'll dive deeper into the statistical models and likelihood calculations that power accurate pedigree reconstruction.\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Understanding the mathematical models behind Bonsai is crucial for computational genetic genealogists who want to:\n",
    "- Interpret likelihood scores and evaluate confidence in relationships\n",
    "- Customize likelihood models for specific populations or research questions\n",
    "- Develop new methods for relationship inference\n",
    "- Properly handle complex scenarios like endogamy or admixture\n",
    "- Evaluate competing pedigree hypotheses with statistical rigor\n",
    "\n",
    "**Learning Objectives**:\n",
    "- Understand the statistical foundations of likelihood calculations\n",
    "- Implement core relationship likelihood models for different relationship types\n",
    "- Apply advanced techniques for more accurate relationship inference\n",
    "- Calculate pedigree-level likelihoods from pairwise relationships\n",
    "- Develop specialized models for complex genealogical scenarios\n",
    "- Interpret likelihood results and confidence scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install --no-root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy import stats\n",
    "from scipy.special import comb\n",
    "from scipy.stats import poisson, expon, norm, gamma, multivariate_normal\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_comp_gen_dir():\n",
    "    \"\"\"Find the computational_genetic_genealogy directory by searching up from current directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Search up through parent directories\n",
    "    while current != current.parent:\n",
    "        # Check if target directory exists in current path\n",
    "        target = current / 'computational_genetic_genealogy'\n",
    "        if target.is_dir():\n",
    "            return target\n",
    "        # Move up one directory\n",
    "        current = current.parent\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find computational_genetic_genealogy directory\")\n",
    "\n",
    "def load_env_file():\n",
    "    \"\"\"Find and load the .env file from the computational_genetic_genealogy directory.\"\"\"\n",
    "    try:\n",
    "        # Find the computational_genetic_genealogy directory\n",
    "        comp_gen_dir = find_comp_gen_dir()\n",
    "        \n",
    "        # Look for .env file\n",
    "        env_path = comp_gen_dir / '.env'\n",
    "        if not env_path.exists():\n",
    "            print(f\"Warning: No .env file found in {comp_gen_dir}\")\n",
    "            return None\n",
    "        \n",
    "        # Load the .env file\n",
    "        load_dotenv(env_path, override=True)\n",
    "        print(f\"Loaded environment variables from: {env_path}\")\n",
    "        return env_path\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Use the function\n",
    "env_path = load_env_file()\n",
    "\n",
    "working_directory = os.getenv('PROJECT_WORKING_DIR', default=None)\n",
    "data_directory = os.getenv('PROJECT_DATA_DIR', default=None)\n",
    "references_directory = os.getenv('PROJECT_REFERENCES_DIR', default=None)\n",
    "results_directory = os.getenv('PROJECT_RESULTS_DIR', default=None)\n",
    "utils_directory = os.getenv('PROJECT_UTILS_DIR', default=None)\n",
    "\n",
    "os.environ[\"WORKING_DIRECTORY\"] = working_directory\n",
    "os.environ[\"DATA_DIRECTORY\"] = data_directory\n",
    "os.environ[\"REFERENCES_DIRECTORY\"] = references_directory\n",
    "os.environ[\"RESULTS_DIRECTORY\"] = results_directory\n",
    "os.environ[\"UTILS_DIRECTORY\"] = utils_directory\n",
    "\n",
    "print(f\"Working Directory: {working_directory}\")\n",
    "print(f\"Data Directory: {data_directory}\")\n",
    "print(f\"References Directory: {references_directory}\")\n",
    "print(f\"Results Directory: {results_directory}\")\n",
    "print(f\"Utils Directory: {utils_directory}\")\n",
    "\n",
    "os.chdir(working_directory)\n",
    "print(f\"The current directory is {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Statistical Foundations of Likelihood Calculations\n",
    "\n",
    "At its core, Bonsai uses likelihood functions to evaluate how well different relationship hypotheses explain observed IBD sharing patterns. Let's begin by exploring the statistical foundations of these likelihood calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Likelihood and Maximum Likelihood Estimation\n",
    "\n",
    "In statistics, the likelihood function measures how well a statistical model explains observed data. For relationship inference, we calculate the likelihood of observing a particular pattern of IBD sharing given different relationship hypotheses.\n",
    "\n",
    "The maximum likelihood principle states that we should choose the hypothesis that maximizes the likelihood of the observed data. Let's formalize this concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood(model_parameters, observed_data, probability_function):\n",
    "    \"\"\"Calculate the likelihood of observing data given model parameters.\n",
    "    \n",
    "    Args:\n",
    "        model_parameters: Parameters of the model\n",
    "        observed_data: Observed data points\n",
    "        probability_function: Function that calculates probability of data given parameters\n",
    "        \n",
    "    Returns:\n",
    "        Likelihood value\n",
    "    \"\"\"\n",
    "    # Initialize likelihood to 1 (we'll multiply probabilities)\n",
    "    likelihood = 1.0\n",
    "    \n",
    "    # For each observed data point\n",
    "    for data_point in observed_data:\n",
    "        # Calculate probability of this data point given model parameters\n",
    "        probability = probability_function(data_point, model_parameters)\n",
    "        \n",
    "        # Multiply likelihood by this probability\n",
    "        likelihood *= probability\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "def calculate_log_likelihood(model_parameters, observed_data, log_probability_function):\n",
    "    \"\"\"Calculate the log-likelihood of observing data given model parameters.\n",
    "    \n",
    "    Args:\n",
    "        model_parameters: Parameters of the model\n",
    "        observed_data: Observed data points\n",
    "        log_probability_function: Function that calculates log-probability of data given parameters\n",
    "        \n",
    "    Returns:\n",
    "        Log-likelihood value\n",
    "    \"\"\"\n",
    "    # Initialize log-likelihood to 0 (we'll add log-probabilities)\n",
    "    log_likelihood = 0.0\n",
    "    \n",
    "    # For each observed data point\n",
    "    for data_point in observed_data:\n",
    "        # Calculate log-probability of this data point given model parameters\n",
    "        log_probability = log_probability_function(data_point, model_parameters)\n",
    "        \n",
    "        # Add log-probability to log-likelihood\n",
    "        log_likelihood += log_probability\n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "def find_maximum_likelihood_parameters(observed_data, log_probability_function, parameter_space):\n",
    "    \"\"\"Find model parameters that maximize likelihood of observed data.\n",
    "    \n",
    "    Args:\n",
    "        observed_data: Observed data points\n",
    "        log_probability_function: Function that calculates log-probability of data given parameters\n",
    "        parameter_space: List of possible parameter values to try\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (best_parameters, maximum_log_likelihood)\n",
    "    \"\"\"\n",
    "    best_parameters = None\n",
    "    max_log_likelihood = float('-inf')\n",
    "    \n",
    "    # Try each set of parameters in parameter space\n",
    "    for parameters in parameter_space:\n",
    "        # Calculate log-likelihood for these parameters\n",
    "        log_likelihood = calculate_log_likelihood(parameters, observed_data, log_probability_function)\n",
    "        \n",
    "        # Update best parameters if this is better\n",
    "        if log_likelihood > max_log_likelihood:\n",
    "            max_log_likelihood = log_likelihood\n",
    "            best_parameters = parameters\n",
    "    \n",
    "    return best_parameters, max_log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Applying Likelihood to Relationship Inference\n",
    "\n",
    "In the context of genetic genealogy, our observed data consists of IBD segments shared between pairs of individuals. Our hypotheses are different possible relationships between these individuals. Let's illustrate this with a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple model for total IBD sharing in centiMorgans\n",
    "# Mean and standard deviation for different relationships\n",
    "ibd_sharing_models = {\n",
    "    'parent-child': (3500, 100),    # Mean of 3500 cM, SD of 100 cM\n",
    "    'full-siblings': (2550, 200),   # Mean of 2550 cM, SD of 200 cM\n",
    "    'half-siblings': (1700, 300),   # Mean of 1700 cM, SD of 300 cM\n",
    "    'first-cousins': (850, 200),    # Mean of 850 cM, SD of 200 cM\n",
    "    'second-cousins': (212, 100),   # Mean of 212 cM, SD of 100 cM\n",
    "    'unrelated': (30, 50)           # Mean of 30 cM, SD of 50 cM\n",
    "}\n",
    "\n",
    "def log_probability_total_ibd(observed_total_ibd, relationship):\n",
    "    \"\"\"Calculate log-probability of observing total IBD given relationship.\n",
    "    \n",
    "    Args:\n",
    "        observed_total_ibd: Observed total IBD sharing in centiMorgans\n",
    "        relationship: Relationship type (key in ibd_sharing_models)\n",
    "        \n",
    "    Returns:\n",
    "        Log-probability value\n",
    "    \"\"\"\n",
    "    # Get model parameters for this relationship\n",
    "    mean, sd = ibd_sharing_models[relationship]\n",
    "    \n",
    "    # Calculate log-probability using normal distribution\n",
    "    log_prob = norm.logpdf(observed_total_ibd, mean, sd)\n",
    "    \n",
    "    return log_prob\n",
    "\n",
    "def infer_relationship_from_total_ibd(observed_total_ibd):\n",
    "    \"\"\"Infer most likely relationship based on total IBD sharing.\n",
    "    \n",
    "    Args:\n",
    "        observed_total_ibd: Observed total IBD sharing in centiMorgans\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (most_likely_relationship, log_likelihood, all_log_likelihoods)\n",
    "    \"\"\"\n",
    "    all_log_likelihoods = {}\n",
    "    \n",
    "    # Calculate log-likelihood for each relationship type\n",
    "    for relationship in ibd_sharing_models.keys():\n",
    "        log_likelihood = log_probability_total_ibd(observed_total_ibd, relationship)\n",
    "        all_log_likelihoods[relationship] = log_likelihood\n",
    "    \n",
    "    # Find relationship with maximum log-likelihood\n",
    "    most_likely_relationship = max(all_log_likelihoods.items(), key=lambda x: x[1])[0]\n",
    "    max_log_likelihood = all_log_likelihoods[most_likely_relationship]\n",
    "    \n",
    "    return most_likely_relationship, max_log_likelihood, all_log_likelihoods\n",
    "\n",
    "# Test with some example values\n",
    "example_total_ibd_values = [3450, 2600, 1650, 900, 250, 50]\n",
    "\n",
    "print(\"Relationship inference from total IBD sharing:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Total IBD (cM)':<15} {'Inferred Relationship':<25} {'Log-Likelihood':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for total_ibd in example_total_ibd_values:\n",
    "    relationship, log_likelihood, all_log_likelihoods = infer_relationship_from_total_ibd(total_ibd)\n",
    "    print(f\"{total_ibd:<15} {relationship:<25} {log_likelihood:<15.2f}\")\n",
    "\n",
    "# Visualize the model distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.linspace(0, 4000, 1000)\n",
    "\n",
    "for relationship, (mean, sd) in ibd_sharing_models.items():\n",
    "    y = norm.pdf(x, mean, sd)\n",
    "    plt.plot(x, y, label=relationship)\n",
    "\n",
    "plt.xlabel('Total IBD Sharing (cM)')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Relationship Models Based on Total IBD Sharing')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Beyond Total IBD: Multiple Features\n",
    "\n",
    "Using only total IBD sharing is a simplistic approach. In reality, Bonsai uses multiple features derived from IBD segments to improve relationship inference accuracy. These features might include:\n",
    "\n",
    "1. Total IBD sharing in centiMorgans\n",
    "2. Number of IBD segments\n",
    "3. Length distribution of IBD segments\n",
    "4. Presence of specific chromosomal patterns (e.g., full IBD2 on X chromosome)\n",
    "\n",
    "Let's extend our model to include both total IBD and number of segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a more complex model with two features: total IBD and number of segments\n",
    "# Format: (mean_total_ibd, sd_total_ibd, mean_num_segments, sd_num_segments)\n",
    "multi_feature_models = {\n",
    "    'parent-child': (3500, 100, 40, 5),      # High total IBD, fairly consistent number of segments\n",
    "    'full-siblings': (2550, 200, 35, 5),     # High total IBD, fairly consistent number of segments\n",
    "    'half-siblings': (1700, 300, 25, 5),     # Medium total IBD, medium number of segments\n",
    "    'first-cousins': (850, 200, 15, 5),      # Lower total IBD, fewer segments\n",
    "    'second-cousins': (212, 100, 5, 3),      # Low total IBD, very few segments\n",
    "    'unrelated': (30, 50, 1, 1)              # Very low total IBD, typically 0-1 segments\n",
    "}\n",
    "\n",
    "def log_probability_multi_feature(observed_features, relationship):\n",
    "    \"\"\"Calculate log-probability of observing features given relationship.\n",
    "    \n",
    "    Args:\n",
    "        observed_features: Tuple of (total_ibd, num_segments)\n",
    "        relationship: Relationship type (key in multi_feature_models)\n",
    "        \n",
    "    Returns:\n",
    "        Log-probability value\n",
    "    \"\"\"\n",
    "    total_ibd, num_segments = observed_features\n",
    "    \n",
    "    # Get model parameters for this relationship\n",
    "    mean_total_ibd, sd_total_ibd, mean_num_segments, sd_num_segments = multi_feature_models[relationship]\n",
    "    \n",
    "    # Calculate log-probability for each feature independently\n",
    "    # (assuming features are independent, which is a simplification)\n",
    "    log_prob_total_ibd = norm.logpdf(total_ibd, mean_total_ibd, sd_total_ibd)\n",
    "    log_prob_num_segments = norm.logpdf(num_segments, mean_num_segments, sd_num_segments)\n",
    "    \n",
    "    # Sum log-probabilities (equivalent to multiplying probabilities)\n",
    "    return log_prob_total_ibd + log_prob_num_segments\n",
    "\n",
    "def infer_relationship_from_multi_feature(observed_features):\n",
    "    \"\"\"Infer most likely relationship based on multiple features.\n",
    "    \n",
    "    Args:\n",
    "        observed_features: Tuple of (total_ibd, num_segments)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (most_likely_relationship, log_likelihood, all_log_likelihoods)\n",
    "    \"\"\"\n",
    "    all_log_likelihoods = {}\n",
    "    \n",
    "    # Calculate log-likelihood for each relationship type\n",
    "    for relationship in multi_feature_models.keys():\n",
    "        log_likelihood = log_probability_multi_feature(observed_features, relationship)\n",
    "        all_log_likelihoods[relationship] = log_likelihood\n",
    "    \n",
    "    # Find relationship with maximum log-likelihood\n",
    "    most_likely_relationship = max(all_log_likelihoods.items(), key=lambda x: x[1])[0]\n",
    "    max_log_likelihood = all_log_likelihoods[most_likely_relationship]\n",
    "    \n",
    "    return most_likely_relationship, max_log_likelihood, all_log_likelihoods\n",
    "\n",
    "# Test with some example values: (total_ibd, num_segments)\n",
    "example_multi_feature_values = [\n",
    "    (3450, 38),  # Likely parent-child\n",
    "    (2600, 36),  # Likely full-siblings\n",
    "    (1650, 15),  # Might be half-siblings but fewer segments than expected\n",
    "    (1650, 24),  # Likely half-siblings with expected number of segments\n",
    "    (900, 16),   # Likely first-cousins\n",
    "    (250, 3)     # Likely second-cousins\n",
    "]\n",
    "\n",
    "print(\"Relationship inference from multiple features:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Total IBD (cM)':<15} {'Num Segments':<15} {'Inferred Relationship':<25} {'Log-Likelihood':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for features in example_multi_feature_values:\n",
    "    total_ibd, num_segments = features\n",
    "    relationship, log_likelihood, all_log_likelihoods = infer_relationship_from_multi_feature(features)\n",
    "    print(f\"{total_ibd:<15} {num_segments:<15} {relationship:<25} {log_likelihood:<15.2f}\")\n",
    "\n",
    "# Visualize the multi-feature model\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create a scatter plot for each relationship type\n",
    "for relationship, (mean_total_ibd, sd_total_ibd, mean_num_segments, sd_num_segments) in multi_feature_models.items():\n",
    "    # Generate random samples from this model\n",
    "    np.random.seed(42 + hash(relationship) % 100)  # Different seed for each relationship\n",
    "    total_ibd_samples = np.random.normal(mean_total_ibd, sd_total_ibd, 100)\n",
    "    num_segments_samples = np.random.normal(mean_num_segments, sd_num_segments, 100)\n",
    "    \n",
    "    # Ensure values are reasonable (non-negative)\n",
    "    total_ibd_samples = np.maximum(0, total_ibd_samples)\n",
    "    num_segments_samples = np.maximum(0, num_segments_samples)\n",
    "    \n",
    "    plt.scatter(total_ibd_samples, num_segments_samples, alpha=0.5, label=relationship)\n",
    "\n",
    "plt.xlabel('Total IBD Sharing (cM)')\n",
    "plt.ylabel('Number of IBD Segments')\n",
    "plt.title('Relationship Models Using Multiple Features')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Bayesian Approach: Incorporating Prior Knowledge\n",
    "\n",
    "The likelihood approaches we've discussed so far don't incorporate prior knowledge about relationships. In many cases, we may have prior information (e.g., age constraints, known populations with higher rates of certain relationships) that can improve inference.\n",
    "\n",
    "Bayesian statistics provides a framework for incorporating prior knowledge through Bayes' Theorem:\n",
    "\n",
    "$$P(R|D) = \\frac{P(D|R) \\times P(R)}{P(D)}$$\n",
    "\n",
    "Where:\n",
    "- $P(R|D)$ is the posterior probability of relationship $R$ given data $D$\n",
    "- $P(D|R)$ is the likelihood of observing data $D$ given relationship $R$\n",
    "- $P(R)$ is the prior probability of relationship $R$\n",
    "- $P(D)$ is the marginal probability of data $D$\n",
    "\n",
    "Let's implement a Bayesian relationship inference approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prior probabilities for different relationships\n",
    "# These could be based on demographic information, pedigree structure, etc.\n",
    "# For simplicity, we'll use a uniform prior here\n",
    "prior_probabilities = {\n",
    "    'parent-child': 1/6,\n",
    "    'full-siblings': 1/6,\n",
    "    'half-siblings': 1/6,\n",
    "    'first-cousins': 1/6,\n",
    "    'second-cousins': 1/6,\n",
    "    'unrelated': 1/6\n",
    "}\n",
    "\n",
    "def infer_relationship_bayesian(observed_features):\n",
    "    \"\"\"Infer most likely relationship using Bayesian approach.\n",
    "    \n",
    "    Args:\n",
    "        observed_features: Tuple of (total_ibd, num_segments)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (most_likely_relationship, posterior_probability, all_posteriors)\n",
    "    \"\"\"\n",
    "    all_log_likelihoods = {}\n",
    "    all_posteriors = {}\n",
    "    \n",
    "    # Calculate log-likelihood and unnormalized log-posterior for each relationship\n",
    "    for relationship in multi_feature_models.keys():\n",
    "        # Calculate log-likelihood\n",
    "        log_likelihood = log_probability_multi_feature(observed_features, relationship)\n",
    "        all_log_likelihoods[relationship] = log_likelihood\n",
    "        \n",
    "        # Add log-prior to get unnormalized log-posterior\n",
    "        log_prior = np.log(prior_probabilities[relationship])\n",
    "        log_posterior = log_likelihood + log_prior\n",
    "        all_posteriors[relationship] = log_posterior\n",
    "    \n",
    "    # Normalize posteriors\n",
    "    # First convert log-posteriors to posteriors\n",
    "    max_log_posterior = max(all_posteriors.values())\n",
    "    posteriors = {r: np.exp(lp - max_log_posterior) for r, lp in all_posteriors.items()}\n",
    "    \n",
    "    # Normalize\n",
    "    sum_posteriors = sum(posteriors.values())\n",
    "    posteriors = {r: p / sum_posteriors for r, p in posteriors.items()}\n",
    "    \n",
    "    # Find relationship with maximum posterior probability\n",
    "    most_likely_relationship = max(posteriors.items(), key=lambda x: x[1])[0]\n",
    "    max_posterior = posteriors[most_likely_relationship]\n",
    "    \n",
    "    return most_likely_relationship, max_posterior, posteriors\n",
    "\n",
    "# Define a non-uniform prior that reflects our belief that siblings and cousins are more common\n",
    "custom_prior = {\n",
    "    'parent-child': 0.05,    # Relatively uncommon in genetic databases\n",
    "    'full-siblings': 0.20,   # Common\n",
    "    'half-siblings': 0.10,   # Less common\n",
    "    'first-cousins': 0.30,   # Very common in genetic databases\n",
    "    'second-cousins': 0.25,  # Very common in genetic databases\n",
    "    'unrelated': 0.10        # We're usually looking at related pairs\n",
    "}\n",
    "\n",
    "def infer_relationship_bayesian_custom_prior(observed_features, prior=custom_prior):\n",
    "    \"\"\"Infer most likely relationship using Bayesian approach with custom prior.\n",
    "    \n",
    "    Args:\n",
    "        observed_features: Tuple of (total_ibd, num_segments)\n",
    "        prior: Dictionary of prior probabilities\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (most_likely_relationship, posterior_probability, all_posteriors)\n",
    "    \"\"\"\n",
    "    all_log_likelihoods = {}\n",
    "    all_posteriors = {}\n",
    "    \n",
    "    # Calculate log-likelihood and unnormalized log-posterior for each relationship\n",
    "    for relationship in multi_feature_models.keys():\n",
    "        # Calculate log-likelihood\n",
    "        log_likelihood = log_probability_multi_feature(observed_features, relationship)\n",
    "        all_log_likelihoods[relationship] = log_likelihood\n",
    "        \n",
    "        # Add log-prior to get unnormalized log-posterior\n",
    "        log_prior = np.log(prior[relationship])\n",
    "        log_posterior = log_likelihood + log_prior\n",
    "        all_posteriors[relationship] = log_posterior\n",
    "    \n",
    "    # Normalize posteriors\n",
    "    # First convert log-posteriors to posteriors\n",
    "    max_log_posterior = max(all_posteriors.values())\n",
    "    posteriors = {r: np.exp(lp - max_log_posterior) for r, lp in all_posteriors.items()}\n",
    "    \n",
    "    # Normalize\n",
    "    sum_posteriors = sum(posteriors.values())\n",
    "    posteriors = {r: p / sum_posteriors for r, p in posteriors.items()}\n",
    "    \n",
    "    # Find relationship with maximum posterior probability\n",
    "    most_likely_relationship = max(posteriors.items(), key=lambda x: x[1])[0]\n",
    "    max_posterior = posteriors[most_likely_relationship]\n",
    "    \n",
    "    return most_likely_relationship, max_posterior, posteriors\n",
    "\n",
    "# Compare standard likelihood, uniform prior Bayesian, and custom prior Bayesian\n",
    "print(\"Comparison of inference methods:\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'Total IBD':<10} {'Segments':<10} {'ML Relationship':<20} {'Bayesian (Uniform)':<25} {'Bayesian (Custom)':<25}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for features in example_multi_feature_values:\n",
    "    total_ibd, num_segments = features\n",
    "    \n",
    "    # Maximum likelihood\n",
    "    ml_relationship, _, _ = infer_relationship_from_multi_feature(features)\n",
    "    \n",
    "    # Bayesian with uniform prior\n",
    "    bayes_uniform_relationship, bayes_uniform_prob, _ = infer_relationship_bayesian(features)\n",
    "    \n",
    "    # Bayesian with custom prior\n",
    "    bayes_custom_relationship, bayes_custom_prob, _ = infer_relationship_bayesian_custom_prior(features)\n",
    "    \n",
    "    print(f\"{total_ibd:<10} {num_segments:<10} {ml_relationship:<20} \"\n",
    "          f\"{bayes_uniform_relationship} ({bayes_uniform_prob:.2f}):<25} \"\n",
    "          f\"{bayes_custom_relationship} ({bayes_custom_prob:.2f}):<25}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Relationship Likelihood Models\n",
    "\n",
    "Now that we understand the statistical foundations, let's implement detailed likelihood models for specific relationship types. These models will incorporate knowledge about the expected patterns of IBD sharing for different genetic relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Parent-Child Relationship Model\n",
    "\n",
    "Parent-child relationships have a very distinctive IBD sharing pattern:\n",
    "- They share exactly one copy of each autosomal chromosome (IBD1 across the genome)\n",
    "- Total IBD sharing is approximately 3400-3600 cM\n",
    "- The variation in total IBD is much lower than other relationships\n",
    "- Very specific sex-chromosome inheritance patterns\n",
    "\n",
    "Let's implement a specialized likelihood model for parent-child relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParentChildModel:\n",
    "    \"\"\"Likelihood model for parent-child relationships.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize parent-child model parameters.\"\"\"\n",
    "        # Parameters for total IBD sharing\n",
    "        self.expected_total_ibd = 3540\n",
    "        self.total_ibd_sd = 60  # Very low variance\n",
    "        \n",
    "        # Parameters for number of segments\n",
    "        # Parent-child should have relatively few recombination events\n",
    "        self.expected_segments = 40\n",
    "        self.segments_sd = 5\n",
    "        \n",
    "        # Expected fraction of genome with IBD1 sharing\n",
    "        self.expected_ibd1_fraction = 1.0\n",
    "        self.ibd1_fraction_sd = 0.02  # Allow for small measurement errors\n",
    "        \n",
    "        # Expected fraction of genome with IBD2 sharing\n",
    "        self.expected_ibd2_fraction = 0.0\n",
    "        self.ibd2_fraction_sd = 0.01  # Allow for small measurement errors\n",
    "    \n",
    "    def calculate_log_likelihood(self, features):\n",
    "        \"\"\"Calculate log-likelihood of features under parent-child model.\n",
    "        \n",
    "        Args:\n",
    "            features: Dictionary with keys 'total_ibd', 'num_segments', 'ibd1_fraction', 'ibd2_fraction'\n",
    "        \n",
    "        Returns:\n",
    "            Log-likelihood value\n",
    "        \"\"\"\n",
    "        log_likelihood = 0.0\n",
    "        \n",
    "        # Component for total IBD\n",
    "        if 'total_ibd' in features:\n",
    "            log_likelihood += norm.logpdf(features['total_ibd'], \n",
    "                                         self.expected_total_ibd, \n",
    "                                         self.total_ibd_sd)\n",
    "        \n",
    "        # Component for number of segments\n",
    "        if 'num_segments' in features:\n",
    "            log_likelihood += norm.logpdf(features['num_segments'], \n",
    "                                         self.expected_segments, \n",
    "                                         self.segments_sd)\n",
    "        \n",
    "        # Component for IBD1 fraction\n",
    "        if 'ibd1_fraction' in features:\n",
    "            # Use truncated normal to keep within [0, 1]\n",
    "            # Simplified here with regular normal, but should be truncated in practice\n",
    "            log_likelihood += norm.logpdf(features['ibd1_fraction'], \n",
    "                                         self.expected_ibd1_fraction, \n",
    "                                         self.ibd1_fraction_sd)\n",
    "        \n",
    "        # Component for IBD2 fraction\n",
    "        if 'ibd2_fraction' in features:\n",
    "            # Use truncated normal to keep within [0, 1]\n",
    "            # Simplified here with regular normal, but should be truncated in practice\n",
    "            log_likelihood += norm.logpdf(features['ibd2_fraction'], \n",
    "                                         self.expected_ibd2_fraction, \n",
    "                                         self.ibd2_fraction_sd)\n",
    "        \n",
    "        # Additional components for sex-chromosome patterns could be added here\n",
    "        \n",
    "        return log_likelihood\n",
    "    \n",
    "    def is_consistent_with_sex(self, sex1, sex2):\n",
    "        \"\"\"Check if the sexes are consistent with a parent-child relationship.\n",
    "        \n",
    "        Args:\n",
    "            sex1: Sex of individual 1 ('M', 'F', or 'U' for unknown)\n",
    "            sex2: Sex of individual 2 ('M', 'F', or 'U' for unknown)\n",
    "            \n",
    "        Returns:\n",
    "            Boolean indicating whether sexes are consistent\n",
    "        \"\"\"\n",
    "        # Any combination of M/F/U is consistent with parent-child\n",
    "        # Two males could be father-son\n",
    "        # Two females could be mother-daughter\n",
    "        # Male-female could be father-daughter or mother-son\n",
    "        return True\n",
    "    \n",
    "    def is_consistent_with_age(self, age1, age2, min_parent_age=15):\n",
    "        \"\"\"Check if the ages are consistent with a parent-child relationship.\n",
    "        \n",
    "        Args:\n",
    "            age1: Age of individual 1 (or None if unknown)\n",
    "            age2: Age of individual 2 (or None if unknown)\n",
    "            min_parent_age: Minimum age for a parent at child's birth\n",
    "            \n",
    "        Returns:\n",
    "            Boolean indicating whether ages are consistent\n",
    "        \"\"\"\n",
    "        if age1 is None or age2 is None:\n",
    "            # If ages are unknown, we can't constrain\n",
    "            return True\n",
    "        \n",
    "        # Check both possible directions (either could be parent)\n",
    "        age_diff = abs(age1 - age2)\n",
    "        \n",
    "        # Parent should be at least min_parent_age years older than child\n",
    "        return age_diff >= min_parent_age\n",
    "\n",
    "# Example parent-child features\n",
    "parent_child_features = {\n",
    "    'total_ibd': 3520,\n",
    "    'num_segments': 42,\n",
    "    'ibd1_fraction': 0.99,\n",
    "    'ibd2_fraction': 0.01\n",
    "}\n",
    "\n",
    "# Not parent-child features\n",
    "not_parent_child_features = {\n",
    "    'total_ibd': 2500,\n",
    "    'num_segments': 35,\n",
    "    'ibd1_fraction': 0.7,\n",
    "    'ibd2_fraction': 0.3\n",
    "}\n",
    "\n",
    "# Create model and calculate likelihoods\n",
    "pc_model = ParentChildModel()\n",
    "pc_log_likelihood = pc_model.calculate_log_likelihood(parent_child_features)\n",
    "non_pc_log_likelihood = pc_model.calculate_log_likelihood(not_parent_child_features)\n",
    "\n",
    "print(f\"Parent-child model log-likelihood for likely parent-child: {pc_log_likelihood:.2f}\")\n",
    "print(f\"Parent-child model log-likelihood for non-parent-child: {non_pc_log_likelihood:.2f}\")\n",
    "print(f\"Likelihood ratio: {np.exp(pc_log_likelihood - non_pc_log_likelihood):.2e}\")\n",
    "\n",
    "# Test age consistency\n",
    "age_pairs = [(40, 20), (20, 40), (25, 20), (20, 15)]\n",
    "print(\"\\nAge consistency for parent-child relationship:\")\n",
    "for age1, age2 in age_pairs:\n",
    "    is_consistent = pc_model.is_consistent_with_age(age1, age2)\n",
    "    print(f\"Ages {age1} and {age2}: {'Consistent' if is_consistent else 'Inconsistent'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Full Siblings Relationship Model\n",
    "\n",
    "Full siblings have a distinctive IBD sharing pattern that differs from parent-child:\n",
    "- They share on average 50% of their DNA (like parent-child)\n",
    "- But they have a mix of IBD0, IBD1, and IBD2 regions\n",
    "- The expected proportions are 25% IBD0, 50% IBD1, and 25% IBD2\n",
    "- However, there is significant variation in these proportions\n",
    "\n",
    "Let's implement a specialized likelihood model for full siblings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSiblingsModel:\n",
    "    \"\"\"Likelihood model for full sibling relationships.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize full siblings model parameters.\"\"\"\n",
    "        # Parameters for total IBD sharing\n",
    "        self.expected_total_ibd = 2550\n",
    "        self.total_ibd_sd = 200  # Higher variance than parent-child\n",
    "        \n",
    "        # Parameters for number of segments\n",
    "        self.expected_segments = 35\n",
    "        self.segments_sd = 5\n",
    "        \n",
    "        # Expected fraction of genome with IBD1 sharing\n",
    "        self.expected_ibd1_fraction = 0.5\n",
    "        self.ibd1_fraction_sd = 0.1\n",
    "        \n",
    "        # Expected fraction of genome with IBD2 sharing\n",
    "        self.expected_ibd2_fraction = 0.25\n",
    "        self.ibd2_fraction_sd = 0.1\n",
    "    \n",
    "    def calculate_log_likelihood(self, features):\n",
    "        \"\"\"Calculate log-likelihood of features under full siblings model.\n",
    "        \n",
    "        Args:\n",
    "            features: Dictionary with keys 'total_ibd', 'num_segments', 'ibd1_fraction', 'ibd2_fraction'\n",
    "        \n",
    "        Returns:\n",
    "            Log-likelihood value\n",
    "        \"\"\"\n",
    "        log_likelihood = 0.0\n",
    "        \n",
    "        # Component for total IBD\n",
    "        if 'total_ibd' in features:\n",
    "            log_likelihood += norm.logpdf(features['total_ibd'], \n",
    "                                         self.expected_total_ibd, \n",
    "                                         self.total_ibd_sd)\n",
    "        \n",
    "        # Component for number of segments\n",
    "        if 'num_segments' in features:\n",
    "            log_likelihood += norm.logpdf(features['num_segments'], \n",
    "                                         self.expected_segments, \n",
    "                                         self.segments_sd)\n",
    "        \n",
    "        # Component for IBD1 fraction\n",
    "        if 'ibd1_fraction' in features:\n",
    "            log_likelihood += norm.logpdf(features['ibd1_fraction'], \n",
    "                                         self.expected_ibd1_fraction, \n",
    "                                         self.ibd1_fraction_sd)\n",
    "        \n",
    "        # Component for IBD2 fraction\n",
    "        if 'ibd2_fraction' in features:\n",
    "            log_likelihood += norm.logpdf(features['ibd2_fraction'], \n",
    "                                         self.expected_ibd2_fraction, \n",
    "                                         self.ibd2_fraction_sd)\n",
    "        \n",
    "        # IBD0 fraction is redundant (1 - IBD1 - IBD2)\n",
    "        # but we could add a check for consistency\n",
    "        if 'ibd1_fraction' in features and 'ibd2_fraction' in features:\n",
    "            ibd0_fraction = 1 - features['ibd1_fraction'] - features['ibd2_fraction']\n",
    "            expected_ibd0 = 1 - self.expected_ibd1_fraction - self.expected_ibd2_fraction\n",
    "            \n",
    "            # Add a consistency check (should be close to 0.25 for siblings)\n",
    "            if ibd0_fraction < 0 or ibd0_fraction > 1:\n",
    "                # Invalid fractions, highly unlikely to be siblings\n",
    "                log_likelihood -= 100  # Large penalty\n",
    "            else:\n",
    "                # Check if IBD0 fraction is consistent with siblings\n",
    "                log_likelihood += norm.logpdf(ibd0_fraction, expected_ibd0, 0.1)\n",
    "        \n",
    "        return log_likelihood\n",
    "    \n",
    "    def is_consistent_with_sex(self, sex1, sex2):\n",
    "        \"\"\"Check if the sexes are consistent with a full sibling relationship.\n",
    "        \n",
    "        Args:\n",
    "            sex1: Sex of individual 1 ('M', 'F', or 'U' for unknown)\n",
    "            sex2: Sex of individual 2 ('M', 'F', or 'U' for unknown)\n",
    "            \n",
    "        Returns:\n",
    "            Boolean indicating whether sexes are consistent\n",
    "        \"\"\"\n",
    "        # Any combination of M/F/U is consistent with full siblings\n",
    "        return True\n",
    "    \n",
    "    def is_consistent_with_age(self, age1, age2, max_sibling_age_diff=30):\n",
    "        \"\"\"Check if the ages are consistent with a full sibling relationship.\n",
    "        \n",
    "        Args:\n",
    "            age1: Age of individual 1 (or None if unknown)\n",
    "            age2: Age of individual 2 (or None if unknown)\n",
    "            max_sibling_age_diff: Maximum plausible age difference between siblings\n",
    "            \n",
    "        Returns:\n",
    "            Boolean indicating whether ages are consistent\n",
    "        \"\"\"\n",
    "        if age1 is None or age2 is None:\n",
    "            # If ages are unknown, we can't constrain\n",
    "            return True\n",
    "        \n",
    "        # Siblings should be within a reasonable age range of each other\n",
    "        age_diff = abs(age1 - age2)\n",
    "        \n",
    "        return age_diff <= max_sibling_age_diff\n",
    "\n",
    "# Example full siblings features\n",
    "full_siblings_features = {\n",
    "    'total_ibd': 2600,\n",
    "    'num_segments': 36,\n",
    "    'ibd1_fraction': 0.48,\n",
    "    'ibd2_fraction': 0.27\n",
    "}\n",
    "\n",
    "# Not full siblings features (more like parent-child)\n",
    "not_full_siblings_features = {\n",
    "    'total_ibd': 3520,\n",
    "    'num_segments': 42,\n",
    "    'ibd1_fraction': 0.99,\n",
    "    'ibd2_fraction': 0.01\n",
    "}\n",
    "\n",
    "# Create model and calculate likelihoods\n",
    "fs_model = FullSiblingsModel()\n",
    "fs_log_likelihood = fs_model.calculate_log_likelihood(full_siblings_features)\n",
    "non_fs_log_likelihood = fs_model.calculate_log_likelihood(not_full_siblings_features)\n",
    "\n",
    "print(f\"Full siblings model log-likelihood for likely full siblings: {fs_log_likelihood:.2f}\")\n",
    "print(f\"Full siblings model log-likelihood for non-full siblings: {non_fs_log_likelihood:.2f}\")\n",
    "print(f\"Likelihood ratio: {np.exp(fs_log_likelihood - non_fs_log_likelihood):.2e}\")\n",
    "\n",
    "# Test age consistency\n",
    "age_pairs = [(40, 35), (20, 10), (25, 65), (5, 5)]\n",
    "print(\"\\nAge consistency for full sibling relationship:\")\n",
    "for age1, age2 in age_pairs:\n",
    "    is_consistent = fs_model.is_consistent_with_age(age1, age2)\n",
    "    print(f\"Ages {age1} and {age2}: {'Consistent' if is_consistent else 'Inconsistent'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 2.3 Half Siblings, Grandparent-Grandchild, and Avuncular Relationships\n\nHalf siblings, grandparent-grandchild, and avuncular (aunt/uncle-niece/nephew) relationships all share approximately 25% of their DNA (coefficient of relatedness r = 0.25). However, there are subtle differences in their IBD patterns that can sometimes help distinguish them:\n\n- All have approximately 1700 cM of shared DNA\n- Half siblings have only IBD1 regions (no IBD2)\n- Grandparent-grandchild and avuncular relationships also have only IBD1 regions\n- The length distribution of segments differs slightly between these relationships\n\nLet's implement a model for these relationships:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class HalfSiblingGrandparentAvuncularModel:\n    \"\"\"Likelihood model for r=0.25 relationships (half siblings, grandparent-grandchild, avuncular).\"\"\"\n    \n    def __init__(self, relationship_type='half-siblings'):\n        \"\"\"Initialize model parameters.\n        \n        Args:\n            relationship_type: One of 'half-siblings', 'grandparent-grandchild', or 'avuncular'\n        \"\"\"\n        self.relationship_type = relationship_type\n        \n        # Common parameters for all r=0.25 relationships\n        self.expected_total_ibd = 1700\n        self.total_ibd_sd = 300\n        \n        # Parameters specific to each relationship type\n        if relationship_type == 'half-siblings':\n            self.expected_segments = 25\n            self.segments_sd = 5\n            self.expected_segment_mean_length = 68  # Expected mean length of segments\n            self.segment_mean_length_sd = 15\n        elif relationship_type == 'grandparent-grandchild':\n            self.expected_segments = 30\n            self.segments_sd = 5\n            self.expected_segment_mean_length = 57  # Slightly shorter segments on average\n            self.segment_mean_length_sd = 12\n        elif relationship_type == 'avuncular':\n            self.expected_segments = 28\n            self.segments_sd = 5\n            self.expected_segment_mean_length = 61  # Intermediate\n            self.segment_mean_length_sd = 13\n        else:\n            raise ValueError(f\"Unknown relationship type: {relationship_type}\")\n        \n        # Common to all r=0.25 relationships\n        self.expected_ibd1_fraction = 0.25\n        self.ibd1_fraction_sd = 0.05\n        self.expected_ibd2_fraction = 0.0\n        self.ibd2_fraction_sd = 0.01  # Small to allow for measurement error\n    \n    def calculate_log_likelihood(self, features):\n        \"\"\"Calculate log-likelihood of features under this model.\n        \n        Args:\n            features: Dictionary with keys 'total_ibd', 'num_segments', 'ibd1_fraction', \n                     'ibd2_fraction', and optionally 'mean_segment_length'\n        \n        Returns:\n            Log-likelihood value\n        \"\"\"\n        log_likelihood = 0.0\n        \n        # Component for total IBD\n        if 'total_ibd' in features:\n            log_likelihood += norm.logpdf(features['total_ibd'], \n                                         self.expected_total_ibd, \n                                         self.total_ibd_sd)\n        \n        # Component for number of segments\n        if 'num_segments' in features:\n            log_likelihood += norm.logpdf(features['num_segments'], \n                                         self.expected_segments, \n                                         self.segments_sd)\n        \n        # Component for IBD1 fraction\n        if 'ibd1_fraction' in features:\n            log_likelihood += norm.logpdf(features['ibd1_fraction'], \n                                         self.expected_ibd1_fraction, \n                                         self.ibd1_fraction_sd)\n        \n        # Component for IBD2 fraction (should be close to 0)\n        if 'ibd2_fraction' in features:\n            log_likelihood += norm.logpdf(features['ibd2_fraction'], \n                                         self.expected_ibd2_fraction, \n                                         self.ibd2_fraction_sd)\n        \n        # Component for mean segment length (helpful for distinguishing between r=0.25 relationships)\n        if 'mean_segment_length' in features:\n            log_likelihood += norm.logpdf(features['mean_segment_length'], \n                                         self.expected_segment_mean_length, \n                                         self.segment_mean_length_sd)\n        \n        return log_likelihood\n    \n    def is_consistent_with_sex(self, sex1, sex2):\n        \"\"\"Check if the sexes are consistent with this relationship.\n        \n        Args:\n            sex1: Sex of individual 1 ('M', 'F', or 'U' for unknown)\n            sex2: Sex of individual 2 ('M', 'F', or 'U' for unknown)\n            \n        Returns:\n            Boolean indicating whether sexes are consistent\n        \"\"\"\n        # For half-siblings, any combination is valid\n        if self.relationship_type == 'half-siblings':\n            return True\n        \n        # For grandparent-grandchild, any combination is valid\n        elif self.relationship_type == 'grandparent-grandchild':\n            return True\n        \n        # For avuncular, any combination is valid\n        elif self.relationship_type == 'avuncular':\n            return True\n        \n        return False  # Should not reach here\n    \n    def is_consistent_with_age(self, age1, age2):\n        \"\"\"Check if the ages are consistent with this relationship.\n        \n        Args:\n            age1: Age of individual 1 (or None if unknown)\n            age2: Age of individual 2 (or None if unknown)\n            \n        Returns:\n            Boolean indicating whether ages are consistent\n        \"\"\"\n        if age1 is None or age2 is None:\n            return True\n        \n        # For half-siblings, similar constraints as full siblings\n        if self.relationship_type == 'half-siblings':\n            return abs(age1 - age2) <= 30  # Arbitrary threshold\n        \n        # For grandparent-grandchild, should be at least 30 years apart typically\n        elif self.relationship_type == 'grandparent-grandchild':\n            return abs(age1 - age2) >= 30\n        \n        # For avuncular, should be at least 15 years apart typically\n        elif self.relationship_type == 'avuncular':\n            return abs(age1 - age2) >= 12  # Can be closer in age than grandparent-grandchild\n        \n        return False  # Should not reach here\n\n# Example half-sibling features\nhalf_sibling_features = {\n    'total_ibd': 1750,\n    'num_segments': 26,\n    'ibd1_fraction': 0.26,\n    'ibd2_fraction': 0.01,\n    'mean_segment_length': 67\n}\n\n# Example grandparent-grandchild features\ngrandparent_features = {\n    'total_ibd': 1680,\n    'num_segments': 31,\n    'ibd1_fraction': 0.25,\n    'ibd2_fraction': 0.0,\n    'mean_segment_length': 54\n}\n\n# Example avuncular features\navuncular_features = {\n    'total_ibd': 1720,\n    'num_segments': 29,\n    'ibd1_fraction': 0.25,\n    'ibd2_fraction': 0.005,\n    'mean_segment_length': 59\n}\n\n# Create models\nhalf_sibling_model = HalfSiblingGrandparentAvuncularModel('half-siblings')\ngrandparent_model = HalfSiblingGrandparentAvuncularModel('grandparent-grandchild')\navuncular_model = HalfSiblingGrandparentAvuncularModel('avuncular')\n\n# Compare all models on all examples\nmodels = [half_sibling_model, grandparent_model, avuncular_model]\nexamples = [\n    ('Half-sibling', half_sibling_features),\n    ('Grandparent-Grandchild', grandparent_features),\n    ('Avuncular', avuncular_features)\n]\n\nprint(\"Log-likelihoods for r=0.25 relationships:\")\nprint(\"-\" * 80)\nprint(f\"{'Example Data':<25} {'Half-Sibling Model':<20} {'Grandparent Model':<20} {'Avuncular Model':<20}\")\nprint(\"-\" * 80)\n\nfor example_name, features in examples:\n    likelihoods = []\n    for model in models:\n        log_likelihood = model.calculate_log_likelihood(features)\n        likelihoods.append(log_likelihood)\n    \n    print(f\"{example_name:<25} {likelihoods[0]:<20.2f} {likelihoods[1]:<20.2f} {likelihoods[2]:<20.2f}\")\n\nprint(\"\\nMost likely relationship for each example:\")\nfor example_name, features in examples:\n    best_model_idx = np.argmax([model.calculate_log_likelihood(features) for model in models])\n    best_model = models[best_model_idx]\n    print(f\"{example_name}: Most likely {best_model.relationship_type}\")\n\n# Analyze age consistency\nage_pairs = [(40, 35), (60, 25), (30, 10), (25, 15)]\nprint(\"\\nAge consistency by relationship type:\")\nfor age1, age2 in age_pairs:\n    hs_consistent = half_sibling_model.is_consistent_with_age(age1, age2)\n    gp_consistent = grandparent_model.is_consistent_with_age(age1, age2)\n    av_consistent = avuncular_model.is_consistent_with_age(age1, age2)\n    \n    print(f\"Ages {age1} and {age2}:\")\n    print(f\"  Half-sibling: {'Consistent' if hs_consistent else 'Inconsistent'}\")\n    print(f\"  Grandparent-Grandchild: {'Consistent' if gp_consistent else 'Inconsistent'}\")\n    print(f\"  Avuncular: {'Consistent' if av_consistent else 'Inconsistent'}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 2.4 Distant Relationship Models\n\nFor more distant relationships (first cousins, second cousins, etc.), the amount of IBD sharing decreases and becomes more variable. The length distribution of IBD segments also becomes more important for accurately identifying these relationships.\n\nLet's implement models for distant relationships that incorporate both the total amount of sharing and the segment length distribution:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class DistantRelationshipModel:\n    \"\"\"Likelihood model for distant relationships.\"\"\"\n    \n    def __init__(self, relationship_type):\n        \"\"\"Initialize distant relationship model parameters.\n        \n        Args:\n            relationship_type: One of 'first-cousins', 'first-cousins-once-removed', \n                              'second-cousins', 'second-cousins-once-removed', or 'third-cousins'\n        \"\"\"\n        self.relationship_type = relationship_type\n        \n        # Set parameters based on relationship type\n        if relationship_type == 'first-cousins':\n            self.coef_relatedness = 0.125  # r = 1/8\n            self.expected_total_ibd = 850\n            self.total_ibd_sd = 200\n            self.expected_segments = 15\n            self.segments_sd = 5\n            self.expected_longest_segment = 75\n            self.longest_segment_sd = 20\n        elif relationship_type == 'first-cousins-once-removed':\n            self.coef_relatedness = 0.0625  # r = 1/16\n            self.expected_total_ibd = 425\n            self.total_ibd_sd = 150\n            self.expected_segments = 10\n            self.segments_sd = 4\n            self.expected_longest_segment = 55\n            self.longest_segment_sd = 15\n        elif relationship_type == 'second-cousins':\n            self.coef_relatedness = 0.03125  # r = 1/32\n            self.expected_total_ibd = 212\n            self.total_ibd_sd = 100\n            self.expected_segments = 5\n            self.segments_sd = 3\n            self.expected_longest_segment = 45\n            self.longest_segment_sd = 15\n        elif relationship_type == 'second-cousins-once-removed':\n            self.coef_relatedness = 0.015625  # r = 1/64\n            self.expected_total_ibd = 106\n            self.total_ibd_sd = 70\n            self.expected_segments = 3\n            self.segments_sd = 2\n            self.expected_longest_segment = 35\n            self.longest_segment_sd = 12\n        elif relationship_type == 'third-cousins':\n            self.coef_relatedness = 0.0078125  # r = 1/128\n            self.expected_total_ibd = 53\n            self.total_ibd_sd = 50\n            self.expected_segments = 2\n            self.segments_sd = 1.5\n            self.expected_longest_segment = 28\n            self.longest_segment_sd = 10\n        else:\n            raise ValueError(f\"Unknown relationship type: {relationship_type}\")\n        \n        # Expected segment length\n        # For distant relationships, segments get shorter as relationship distance increases\n        # This is due to more recombination events between the common ancestor and the relatives\n        self.expected_mean_segment_length = self.expected_total_ibd / max(1, self.expected_segments)\n        self.mean_segment_length_sd = self.expected_mean_segment_length * 0.3  # 30% variation\n        \n        # All distant relationships should have only IBD1 sharing (no IBD2)\n        self.expected_ibd1_fraction = self.coef_relatedness\n        self.ibd1_fraction_sd = self.coef_relatedness * 0.4  # 40% variation\n        self.expected_ibd2_fraction = 0.0\n        self.ibd2_fraction_sd = 0.005  # Very small, just for measurement error\n    \n    def calculate_log_likelihood(self, features):\n        \"\"\"Calculate log-likelihood of features under this model.\n        \n        Args:\n            features: Dictionary with keys 'total_ibd', 'num_segments', 'mean_segment_length',\n                     'longest_segment', 'ibd1_fraction', 'ibd2_fraction'\n        \n        Returns:\n            Log-likelihood value\n        \"\"\"\n        log_likelihood = 0.0\n        \n        # Component for total IBD\n        if 'total_ibd' in features:\n            log_likelihood += norm.logpdf(features['total_ibd'], \n                                         self.expected_total_ibd, \n                                         self.total_ibd_sd)\n        \n        # Component for number of segments\n        if 'num_segments' in features:\n            # For very distant relationships, use Poisson distribution\n            if self.expected_segments < 5:\n                log_likelihood += poisson.logpmf(features['num_segments'], self.expected_segments)\n            else:\n                log_likelihood += norm.logpdf(features['num_segments'], \n                                             self.expected_segments, \n                                             self.segments_sd)\n        \n        # Component for IBD1 fraction\n        if 'ibd1_fraction' in features:\n            log_likelihood += norm.logpdf(features['ibd1_fraction'], \n                                         self.expected_ibd1_fraction, \n                                         self.ibd1_fraction_sd)\n        \n        # Component for IBD2 fraction (should be close to 0)\n        if 'ibd2_fraction' in features:\n            log_likelihood += norm.logpdf(features['ibd2_fraction'], \n                                         self.expected_ibd2_fraction, \n                                         self.ibd2_fraction_sd)\n        \n        # Component for mean segment length\n        if 'mean_segment_length' in features:\n            log_likelihood += norm.logpdf(features['mean_segment_length'], \n                                         self.expected_mean_segment_length, \n                                         self.mean_segment_length_sd)\n        \n        # Component for longest segment (very informative for distant relationships)\n        if 'longest_segment' in features:\n            log_likelihood += norm.logpdf(features['longest_segment'], \n                                         self.expected_longest_segment, \n                                         self.longest_segment_sd)\n        \n        return log_likelihood\n    \n    def is_consistent_with_age(self, age1, age2):\n        \"\"\"Check if the ages are consistent with this relationship.\n        \n        Args:\n            age1: Age of individual 1 (or None if unknown)\n            age2: Age of individual 2 (or None if unknown)\n            \n        Returns:\n            Boolean indicating whether ages are consistent\n        \"\"\"\n        # For distant relationships, almost any age difference is plausible\n        # We'll just apply some very loose constraints\n        if age1 is None or age2 is None:\n            return True\n        \n        # Calculate minimum plausible age difference based on relationship\n        if self.relationship_type == 'first-cousins':\n            min_plausible_age_diff = 0  # Can be the same age\n        elif self.relationship_type == 'first-cousins-once-removed':\n            min_plausible_age_diff = 15  # Should be generational difference\n        elif self.relationship_type == 'second-cousins':\n            min_plausible_age_diff = 0  # Can be the same age\n        elif self.relationship_type == 'second-cousins-once-removed':\n            min_plausible_age_diff = 15  # Should be generational difference\n        elif self.relationship_type == 'third-cousins':\n            min_plausible_age_diff = 0  # Can be the same age\n        else:\n            return True  # Unknown relationship, be conservative\n        \n        if 'once-removed' in self.relationship_type and abs(age1 - age2) < min_plausible_age_diff:\n            return False  # Age difference too small for once-removed relationship\n        \n        return True  # Most distant relationships have compatible ages\n\n# Create example data for distant relationships\ndistant_relationship_examples = [\n    ('First Cousins', {\n        'total_ibd': 870,\n        'num_segments': 16,\n        'mean_segment_length': 54,\n        'longest_segment': 80,\n        'ibd1_fraction': 0.13,\n        'ibd2_fraction': 0.0\n    }),\n    ('First Cousins Once Removed', {\n        'total_ibd': 410,\n        'num_segments': 9,\n        'mean_segment_length': 45,\n        'longest_segment': 60,\n        'ibd1_fraction': 0.06,\n        'ibd2_fraction': 0.0\n    }),\n    ('Second Cousins', {\n        'total_ibd': 220,\n        'num_segments': 6,\n        'mean_segment_length': 37,\n        'longest_segment': 48,\n        'ibd1_fraction': 0.03,\n        'ibd2_fraction': 0.0\n    }),\n    ('Second Cousins Once Removed', {\n        'total_ibd': 105,\n        'num_segments': 3,\n        'mean_segment_length': 35,\n        'longest_segment': 40,\n        'ibd1_fraction': 0.015,\n        'ibd2_fraction': 0.0\n    }),\n    ('Third Cousins', {\n        'total_ibd': 60,\n        'num_segments': 2,\n        'mean_segment_length': 30,\n        'longest_segment': 35,\n        'ibd1_fraction': 0.009,\n        'ibd2_fraction': 0.0\n    })\n]\n\n# Create models for distant relationships\ndistant_models = [\n    DistantRelationshipModel('first-cousins'),\n    DistantRelationshipModel('first-cousins-once-removed'),\n    DistantRelationshipModel('second-cousins'),\n    DistantRelationshipModel('second-cousins-once-removed'),\n    DistantRelationshipModel('third-cousins')\n]\n\n# Calculate log-likelihoods for each example using each model\nprint(\"Log-likelihoods for distant relationships:\")\nprint(\"-\" * 100)\nheader = f\"{'Example Data':<25}\"\nfor model in distant_models:\n    header += f\"{model.relationship_type:<20}\"\nprint(header)\nprint(\"-\" * 100)\n\nfor example_name, features in distant_relationship_examples:\n    line = f\"{example_name:<25}\"\n    for model in distant_models:\n        log_likelihood = model.calculate_log_likelihood(features)\n        line += f\"{log_likelihood:<20.2f}\"\n    print(line)\n\nprint(\"\\nMost likely relationship for each example:\")\nfor example_name, features in distant_relationship_examples:\n    log_likelihoods = [model.calculate_log_likelihood(features) for model in distant_models]\n    best_model_idx = np.argmax(log_likelihoods)\n    best_model = distant_models[best_model_idx]\n    print(f\"{example_name}: Most likely {best_model.relationship_type}\")\n\n# Visualize the expected total IBD for different relationships\nplt.figure(figsize=(12, 6))\nrelationships = [\n    'Parent-Child', 'Full Siblings', 'Half Siblings/\\nGrandparent/\\nAvuncular', \n    'First Cousins', '1C1R', '2C', '2C1R', '3C'\n]\nexpected_ibd = [3540, 2550, 1700, 850, 425, 212, 106, 53]\nstd_dev = [60, 200, 300, 200, 150, 100, 70, 50]\n\nplt.errorbar(range(len(relationships)), expected_ibd, yerr=std_dev, fmt='o', capsize=5)\nplt.xticks(range(len(relationships)), relationships, rotation=45)\nplt.ylim(0, 4000)\nplt.grid(True, alpha=0.3)\nplt.title('Expected Total IBD Sharing by Relationship Type')\nplt.ylabel('Expected Total IBD (cM)')\nplt.tight_layout()\nplt.show()\n\n# Visualize segment length distribution for different relationships\nplt.figure(figsize=(10, 6))\n\n# Parameters for normal distribution of segment lengths\nrelationships = [\n    'First Cousins', 'First Cousins Once Removed', \n    'Second Cousins', 'Second Cousins Once Removed', 'Third Cousins'\n]\nsegment_means = [54, 45, 37, 35, 30]\nsegment_sds = [20, 15, 12, 10, 8]\n\nx = np.linspace(0, 100, 1000)\n\nfor i, rel in enumerate(relationships):\n    y = norm.pdf(x, segment_means[i], segment_sds[i])\n    plt.plot(x, y, label=rel)\n\nplt.xlabel('Segment Length (cM)')\nplt.ylabel('Probability Density')\nplt.title('Segment Length Distributions by Relationship Type')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Advanced Likelihood Calculation Techniques\n\nSo far, we've implemented relationship models using normal distributions for each feature independently. However, this approach ignores dependencies between features and may not capture the full complexity of IBD sharing patterns. Let's explore more advanced techniques for likelihood calculation.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 3.1 Multivariate Probability Distributions\n\nInstead of modeling each feature independently, we can use multivariate probability distributions to capture the dependencies between features. The multivariate normal distribution is a common choice:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class MultivariateRelationshipModel:\n    \"\"\"Relationship model using multivariate normal distribution.\"\"\"\n    \n    def __init__(self, relationship_type):\n        \"\"\"Initialize multivariate relationship model.\n        \n        Args:\n            relationship_type: Type of relationship to model\n        \"\"\"\n        self.relationship_type = relationship_type\n        \n        # Define mean vectors and covariance matrices for different relationships\n        if relationship_type == 'parent-child':\n            # Features: [total_ibd, num_segments, ibd1_fraction, ibd2_fraction]\n            self.mean = np.array([3540, 40, 1.0, 0.0])\n            \n            # Covariance matrix - positive correlation between total_ibd and num_segments\n            self.cov = np.array([\n                [3600, 100, 0.01, 0],     # total_ibd variance and covariances\n                [100, 25, 0.01, 0],       # num_segments variance and covariances\n                [0.01, 0.01, 0.0004, 0],  # ibd1_fraction variance and covariances\n                [0, 0, 0, 0.0001]         # ibd2_fraction variance and covariances\n            ])\n            \n        elif relationship_type == 'full-siblings':\n            # Features: [total_ibd, num_segments, ibd1_fraction, ibd2_fraction]\n            self.mean = np.array([2550, 35, 0.5, 0.25])\n            \n            # Covariance matrix - more complex correlations for siblings\n            self.cov = np.array([\n                [40000, 500, 0.2, 0.1],   # total_ibd variance and covariances\n                [500, 25, 0.05, 0.02],    # num_segments variance and covariances\n                [0.2, 0.05, 0.01, -0.005], # ibd1_fraction variance and covariances (negative correlation with ibd2)\n                [0.1, 0.02, -0.005, 0.01]  # ibd2_fraction variance and covariances\n            ])\n            \n        elif relationship_type == 'half-siblings':\n            # Features: [total_ibd, num_segments, ibd1_fraction, ibd2_fraction]\n            self.mean = np.array([1700, 25, 0.25, 0.0])\n            \n            # Covariance matrix\n            self.cov = np.array([\n                [90000, 400, 0.15, 0],    # total_ibd variance and covariances\n                [400, 25, 0.04, 0],       # num_segments variance and covariances\n                [0.15, 0.04, 0.0025, 0],  # ibd1_fraction variance and covariances\n                [0, 0, 0, 0.0001]         # ibd2_fraction variance and covariances\n            ])\n            \n        elif relationship_type == 'first-cousins':\n            # Features: [total_ibd, num_segments, ibd1_fraction, ibd2_fraction]\n            self.mean = np.array([850, 15, 0.125, 0.0])\n            \n            # Covariance matrix\n            self.cov = np.array([\n                [40000, 300, 0.1, 0],     # total_ibd variance and covariances\n                [300, 25, 0.03, 0],       # num_segments variance and covariances\n                [0.1, 0.03, 0.0016, 0],   # ibd1_fraction variance and covariances\n                [0, 0, 0, 0.0001]         # ibd2_fraction variance and covariances\n            ])\n            \n        elif relationship_type == 'second-cousins':\n            # Features: [total_ibd, num_segments, ibd1_fraction, ibd2_fraction]\n            self.mean = np.array([212, 5, 0.03125, 0.0])\n            \n            # Covariance matrix\n            self.cov = np.array([\n                [10000, 150, 0.05, 0],    # total_ibd variance and covariances\n                [150, 9, 0.01, 0],        # num_segments variance and covariances\n                [0.05, 0.01, 0.0004, 0],  # ibd1_fraction variance and covariances\n                [0, 0, 0, 0.0001]         # ibd2_fraction variance and covariances\n            ])\n            \n        elif relationship_type == 'unrelated':\n            # Features: [total_ibd, num_segments, ibd1_fraction, ibd2_fraction]\n            self.mean = np.array([30, 1, 0.004, 0.0])\n            \n            # Covariance matrix\n            self.cov = np.array([\n                [2500, 50, 0.01, 0],      # total_ibd variance and covariances\n                [50, 1, 0.005, 0],        # num_segments variance and covariances\n                [0.01, 0.005, 0.0001, 0], # ibd1_fraction variance and covariances\n                [0, 0, 0, 0.0001]         # ibd2_fraction variance and covariances\n            ])\n            \n        else:\n            raise ValueError(f\"Unknown relationship type: {relationship_type}\")\n    \n    def calculate_log_likelihood(self, features):\n        \"\"\"Calculate log-likelihood of features using multivariate normal distribution.\n        \n        Args:\n            features: Dictionary with keys 'total_ibd', 'num_segments', 'ibd1_fraction', 'ibd2_fraction'\n            \n        Returns:\n            Log-likelihood value\n        \"\"\"\n        # Extract features as vector in the correct order\n        feature_vector = np.array([\n            features.get('total_ibd', self.mean[0]),\n            features.get('num_segments', self.mean[1]),\n            features.get('ibd1_fraction', self.mean[2]),\n            features.get('ibd2_fraction', self.mean[3])\n        ])\n        \n        # Calculate log-likelihood using multivariate normal distribution\n        log_likelihood = multivariate_normal.logpdf(feature_vector, mean=self.mean, cov=self.cov)\n        \n        return log_likelihood\n\n# Create multivariate models for different relationships\nmv_models = {\n    'parent-child': MultivariateRelationshipModel('parent-child'),\n    'full-siblings': MultivariateRelationshipModel('full-siblings'),\n    'half-siblings': MultivariateRelationshipModel('half-siblings'),\n    'first-cousins': MultivariateRelationshipModel('first-cousins'),\n    'second-cousins': MultivariateRelationshipModel('second-cousins'),\n    'unrelated': MultivariateRelationshipModel('unrelated')\n}\n\n# Test with some example data\ntest_examples = [\n    ('Likely Parent-Child', {\n        'total_ibd': 3520,\n        'num_segments': 42,\n        'ibd1_fraction': 0.99,\n        'ibd2_fraction': 0.01\n    }),\n    ('Likely Full Siblings', {\n        'total_ibd': 2600,\n        'num_segments': 36,\n        'ibd1_fraction': 0.48,\n        'ibd2_fraction': 0.27\n    }),\n    ('Likely Half Siblings', {\n        'total_ibd': 1750,\n        'num_segments': 26,\n        'ibd1_fraction': 0.26,\n        'ibd2_fraction': 0.01\n    }),\n    ('Likely First Cousins', {\n        'total_ibd': 870,\n        'num_segments': 16,\n        'ibd1_fraction': 0.13,\n        'ibd2_fraction': 0.0\n    }),\n    ('Likely Second Cousins', {\n        'total_ibd': 220,\n        'num_segments': 6,\n        'ibd1_fraction': 0.03,\n        'ibd2_fraction': 0.0\n    }),\n    ('Likely Unrelated', {\n        'total_ibd': 35,\n        'num_segments': 1,\n        'ibd1_fraction': 0.005,\n        'ibd2_fraction': 0.0\n    })\n]\n\n# Calculate log-likelihoods for each example using each model\nprint(\"Multivariate model log-likelihoods:\")\nprint(\"-\" * 100)\nheader = f\"{'Example Data':<25}\"\nfor model_name in mv_models.keys():\n    header += f\"{model_name:<20}\"\nprint(header)\nprint(\"-\" * 100)\n\nfor example_name, features in test_examples:\n    line = f\"{example_name:<25}\"\n    for model_name, model in mv_models.items():\n        log_likelihood = model.calculate_log_likelihood(features)\n        line += f\"{log_likelihood:<20.2f}\"\n    print(line)\n\nprint(\"\\nMost likely relationship for each example:\")\nfor example_name, features in test_examples:\n    log_likelihoods = {model_name: model.calculate_log_likelihood(features) \n                      for model_name, model in mv_models.items()}\n    best_relationship = max(log_likelihoods.items(), key=lambda x: x[1])[0]\n    max_log_likelihood = log_likelihoods[best_relationship]\n    print(f\"{example_name}: Most likely {best_relationship} (log-likelihood: {max_log_likelihood:.2f})\")\n\n# Visualize feature correlations for full siblings\nfull_sib_model = mv_models['full-siblings']\n\n# Generate random samples from full sibling model\nnp.random.seed(42)\nfull_sib_samples = np.random.multivariate_normal(full_sib_model.mean, full_sib_model.cov, 1000)\n\n# Create a pandas DataFrame for plotting\nfull_sib_df = pd.DataFrame(full_sib_samples, columns=['total_ibd', 'num_segments', 'ibd1_fraction', 'ibd2_fraction'])\n\n# Scatterplot matrix\nplt.figure(figsize=(12, 10))\npd.plotting.scatter_matrix(full_sib_df, alpha=0.3, figsize=(12, 10), diagonal='kde')\nplt.suptitle('Feature Correlations for Full Siblings Model', fontsize=16)\nplt.tight_layout()\nplt.subplots_adjust(top=0.95)\nplt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 3.2 Segment-Based Likelihood Models\n\nAnother advanced approach is to model the likelihood based on the properties of individual IBD segments rather than summary statistics. This can provide more detailed information about the relationship, especially for distant relationships where the number of segments is small.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class SegmentBasedModel:\n    \"\"\"Likelihood model based on individual IBD segments.\"\"\"\n    \n    def __init__(self, relationship_type):\n        \"\"\"Initialize segment-based relationship model.\n        \n        Args:\n            relationship_type: Type of relationship to model\n        \"\"\"\n        self.relationship_type = relationship_type\n        \n        # Number of meioses (recombination events) between relatives\n        # This affects the length distribution of segments\n        if relationship_type == 'parent-child':\n            self.meioses = 1\n        elif relationship_type == 'full-siblings':\n            self.meioses = 2  # Complex, but effectively 2 for IBD1 regions\n        elif relationship_type == 'half-siblings':\n            self.meioses = 2\n        elif relationship_type == 'grandparent':\n            self.meioses = 2\n        elif relationship_type == 'avuncular':\n            self.meioses = 3\n        elif relationship_type == 'first-cousins':\n            self.meioses = 4\n        elif relationship_type == 'first-cousins-once-removed':\n            self.meioses = 5\n        elif relationship_type == 'second-cousins':\n            self.meioses = 6\n        elif relationship_type == 'second-cousins-once-removed':\n            self.meioses = 7\n        elif relationship_type == 'third-cousins':\n            self.meioses = 8\n        else:\n            raise ValueError(f\"Unknown relationship type: {relationship_type}\")\n        \n        # Expected number of segments\n        # This follows from population genetics theory\n        genome_length = 3500  # cM\n        if relationship_type == 'parent-child':\n            self.expected_segments = 23  # One per chromosome (simplified)\n        else:\n            # Expected number of segments is proportional to the genetic distance\n            # and the number of meioses\n            self.expected_segments = (0.01 * genome_length * self.meioses) / 2\n    \n    def segment_length_pdf(self, length):\n        \"\"\"Calculate probability density of observing an IBD segment of given length.\n        \n        Args:\n            length: Length of IBD segment in centiMorgans\n            \n        Returns:\n            Probability density value\n        \"\"\"\n        # For parent-child, all chromosomes are shared entirely\n        if self.relationship_type == 'parent-child':\n            # Use a normal distribution centered on chromosome lengths\n            # This is a simplification\n            mean_chrom_length = 150  # Average chromosome length in cM\n            sd = 50  # Standard deviation\n            return norm.pdf(length, mean_chrom_length, sd)\n        \n        # For other relationships, segment lengths follow an exponential distribution\n        # The rate parameter depends on the number of meioses\n        rate = self.meioses / 100  # Rate in cM^-1\n        return expon.pdf(length, scale=1/rate)\n    \n    def calculate_log_likelihood_segments(self, segments):\n        \"\"\"Calculate log-likelihood for a list of IBD segments.\n        \n        Args:\n            segments: List of segment lengths in centiMorgans\n            \n        Returns:\n            Log-likelihood value\n        \"\"\"\n        # If no segments, return very low likelihood\n        if not segments:\n            return -1000\n        \n        # Component for number of segments\n        # Use Poisson distribution for the count\n        num_segments = len(segments)\n        log_likelihood = poisson.logpmf(num_segments, self.expected_segments)\n        \n        # Component for segment lengths\n        # Assumes independence of segment lengths given the relationship\n        for length in segments:\n            log_likelihood += np.log(self.segment_length_pdf(length))\n        \n        return log_likelihood\n    \n    def calculate_log_likelihood(self, features):\n        \"\"\"Calculate log-likelihood based on features.\n        \n        Args:\n            features: Dictionary with segment information\n            \n        Returns:\n            Log-likelihood value\n        \"\"\"\n        # If we have individual segments, use those\n        if 'segments' in features:\n            segments = features['segments']\n            return self.calculate_log_likelihood_segments(segments)\n        \n        # If we only have summary statistics, make an approximation\n        elif 'total_ibd' in features and 'num_segments' in features:\n            # Estimate average segment length\n            num_segments = features['num_segments']\n            total_ibd = features['total_ibd']\n            \n            if num_segments > 0:\n                avg_segment_length = total_ibd / num_segments\n            else:\n                avg_segment_length = 0\n            \n            # Create approximate segment list (all segments same length)\n            segments = [avg_segment_length] * num_segments\n            \n            # Calculate likelihood using this approximation\n            return self.calculate_log_likelihood_segments(segments)\n        \n        else:\n            raise ValueError(\"Missing required features: 'segments' or 'total_ibd' and 'num_segments'\")\n\n# Sample data with individual segments\nindividual_segment_data = [\n    ('Parent-Child', {\n        'segments': [156, 85, 143, 201, 78, 198, 134, 99, 149, 177, 168, 129, 95, 103, 114, 67, 81, 92, 156, 75, 69, 52]\n    }),\n    ('Full Siblings', {\n        'segments': [142, 65, 98, 128, 73, 42, 89, 57, 32, 78, 115, 98, 67, 54, 49, 83, 72, 94, 61, 58, 55, 48, 51]\n    }),\n    ('Half Siblings', {\n        'segments': [97, 78, 63, 54, 87, 92, 65, 71, 59, 48, 55, 41, 38, 44]\n    }),\n    ('First Cousins', {\n        'segments': [85, 67, 54, 48, 42, 39, 35, 33, 29, 27]\n    }),\n    ('Second Cousins', {\n        'segments': [63, 42, 36, 29, 25]\n    }),\n    ('Third Cousins', {\n        'segments': [38, 24]\n    })\n]\n\n# Create segment-based models\nsegment_models = [\n    SegmentBasedModel('parent-child'),\n    SegmentBasedModel('full-siblings'),\n    SegmentBasedModel('half-siblings'),\n    SegmentBasedModel('first-cousins'),\n    SegmentBasedModel('second-cousins'),\n    SegmentBasedModel('third-cousins')\n]\n\n# Calculate log-likelihoods for each example using each model\nprint(\"Segment-based model log-likelihoods:\")\nprint(\"-\" * 100)\nheader = f\"{'Example Data':<25}\"\nfor model in segment_models:\n    header += f\"{model.relationship_type:<20}\"\nprint(header)\nprint(\"-\" * 100)\n\nfor example_name, features in individual_segment_data:\n    line = f\"{example_name:<25}\"\n    for model in segment_models:\n        log_likelihood = model.calculate_log_likelihood(features)\n        line += f\"{log_likelihood:<20.2f}\"\n    print(line)\n\nprint(\"\\nMost likely relationship for each example:\")\nfor example_name, features in individual_segment_data:\n    log_likelihoods = [model.calculate_log_likelihood(features) for model in segment_models]\n    best_model_idx = np.argmax(log_likelihoods)\n    best_model = segment_models[best_model_idx]\n    print(f\"{example_name}: Most likely {best_model.relationship_type}\")\n\n# Visualize the segment length distributions for different relationship types\nplt.figure(figsize=(12, 6))\nx = np.linspace(1, 200, 1000)\n\nfor model in segment_models:\n    y = [model.segment_length_pdf(length) for length in x]\n    plt.plot(x, y, label=model.relationship_type)\n\nplt.xlabel('Segment Length (cM)')\nplt.ylabel('Probability Density')\nplt.title('Theoretical IBD Segment Length Distributions by Relationship Type')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# Compare segment length histograms from example data\nplt.figure(figsize=(15, 10))\n\nfor i, (example_name, features) in enumerate(individual_segment_data):\n    plt.subplot(2, 3, i+1)\n    segments = features['segments']\n    plt.hist(segments, bins=15, alpha=0.7, density=True)\n    \n    # Overlay theoretical distribution for this relationship\n    x = np.linspace(1, max(segments) + 10, 1000)\n    y = [segment_models[i].segment_length_pdf(length) for length in x]\n    plt.plot(x, y, 'r-', linewidth=2)\n    \n    plt.title(f\"{example_name}\\n{len(segments)} segments, total {sum(segments):.0f} cM\")\n    plt.xlabel('Segment Length (cM)')\n    plt.ylabel('Density')\n    plt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 3.3 Bayesian Integration of Prior Knowledge\n\nWe introduced a simple Bayesian approach earlier, but now let's explore a more sophisticated implementation that integrates prior knowledge from multiple sources:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class BayesianRelationshipInference:\n    \"\"\"Bayesian relationship inference incorporating multiple sources of prior knowledge.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize Bayesian relationship inference model.\"\"\"\n        # Define relationship types\n        self.relationship_types = [\n            'parent-child', 'full-siblings', 'half-siblings', 'grandparent',\n            'avuncular', 'first-cousins', 'second-cousins', 'third-cousins', 'unrelated'\n        ]\n        \n        # Base prior probabilities (uniform by default)\n        self.base_priors = {rel: 1.0 / len(self.relationship_types) for rel in self.relationship_types}\n        \n        # Likelihood models for different features\n        self.likelihood_models = {\n            # Create models for IBD features\n            'genetic': {rel: MultivariateRelationshipModel(rel) if rel in mv_models else None \n                      for rel in self.relationship_types}\n        }\n    \n    def calculate_prior(self, relationship, demographic_info=None):\n        \"\"\"Calculate prior probability for a relationship given demographic information.\n        \n        Args:\n            relationship: Relationship type\n            demographic_info: Dictionary with demographic information (ages, populations, etc.)\n            \n        Returns:\n            Prior probability\n        \"\"\"\n        # Start with base prior\n        prior = self.base_priors[relationship]\n        \n        # If demographic information is provided, adjust the prior\n        if demographic_info:\n            # Age constraints\n            if 'age1' in demographic_info and 'age2' in demographic_info:\n                age1 = demographic_info['age1']\n                age2 = demographic_info['age2']\n                age_diff = abs(age1 - age2)\n                \n                # Apply age-based adjustments\n                if relationship == 'parent-child' and age_diff < 15:\n                    prior *= 0.01  # Very unlikely to be parent-child if age difference < 15\n                elif relationship == 'grandparent' and age_diff < 30:\n                    prior *= 0.1  # Unlikely to be grandparent if age difference < 30\n                elif relationship in ['full-siblings', 'half-siblings'] and age_diff > 25:\n                    prior *= 0.5  # Less likely to be siblings if age difference > 25\n                \n            # Population information (e.g., endogamy)\n            if 'population' in demographic_info:\n                population = demographic_info['population']\n                \n                if population == 'general':\n                    # Standard priors, no adjustment\n                    pass\n                elif population == 'endogamous':\n                    # In endogamous populations, distant cousins are more common\n                    if relationship in ['first-cousins', 'second-cousins', 'third-cousins']:\n                        prior *= 2.0  # Double the prior for cousin relationships\n                    elif relationship == 'unrelated':\n                        prior *= 0.5  # Reduce prior for truly unrelated individuals\n            \n            # Known family structure\n            if 'family_structure' in demographic_info:\n                family_structure = demographic_info['family_structure']\n                \n                if 'siblings_known' in family_structure and family_structure['siblings_known']:\n                    # If all siblings are already known, reduce prior for sibling relationships\n                    if relationship in ['full-siblings', 'half-siblings']:\n                        prior *= 0.1\n        \n        return prior\n    \n    def calculate_likelihood(self, relationship, features):\n        \"\"\"Calculate likelihood of observing features given relationship.\n        \n        Args:\n            relationship: Relationship type\n            features: Dictionary with observed features\n            \n        Returns:\n            Log-likelihood value\n        \"\"\"\n        log_likelihood = 0.0\n        \n        # Genetic features (IBD patterns)\n        if 'genetic' in features and relationship in self.likelihood_models['genetic']:\n            model = self.likelihood_models['genetic'][relationship]\n            if model:\n                log_likelihood += model.calculate_log_likelihood(features['genetic'])\n            else:\n                # If no model for this relationship, use a default value\n                log_likelihood += -100  # Very low likelihood\n        \n        return log_likelihood\n    \n    def infer_relationship(self, features, demographic_info=None):\n        \"\"\"Infer most likely relationship using Bayesian inference.\n        \n        Args:\n            features: Dictionary with observed features\n            demographic_info: Optional dictionary with demographic information\n            \n        Returns:\n            Dictionary mapping relationships to posterior probabilities\n        \"\"\"\n        # Calculate prior and likelihood for each relationship type\n        log_posteriors = {}\n        \n        for relationship in self.relationship_types:\n            # Calculate prior\n            prior = self.calculate_prior(relationship, demographic_info)\n            log_prior = np.log(prior) if prior > 0 else -1000\n            \n            # Calculate likelihood\n            log_likelihood = self.calculate_likelihood(relationship, features)\n            \n            # Calculate unnormalized log posterior\n            log_posteriors[relationship] = log_prior + log_likelihood\n        \n        # Normalize posteriors\n        # First convert log-posteriors to posteriors\n        max_log_posterior = max(log_posteriors.values())\n        posteriors = {r: np.exp(lp - max_log_posterior) for r, lp in log_posteriors.items()}\n        \n        # Normalize\n        sum_posteriors = sum(posteriors.values())\n        posteriors = {r: p / sum_posteriors for r, p in posteriors.items()}\n        \n        return posteriors\n\n# Example data with genetic features\ngenetic_features = [\n    ('Parent-Child Example', {\n        'genetic': {\n            'total_ibd': 3520,\n            'num_segments': 42,\n            'ibd1_fraction': 0.99,\n            'ibd2_fraction': 0.01\n        }\n    }),\n    ('Full Siblings Example', {\n        'genetic': {\n            'total_ibd': 2600,\n            'num_segments': 36,\n            'ibd1_fraction': 0.48,\n            'ibd2_fraction': 0.27\n        }\n    }),\n    ('Half Siblings Example', {\n        'genetic': {\n            'total_ibd': 1750,\n            'num_segments': 26,\n            'ibd1_fraction': 0.26,\n            'ibd2_fraction': 0.01\n        }\n    })\n]\n\n# Example demographic information\ndemographic_examples = [\n    ('No Demographic Info', None),\n    ('Parent-Child Demographics', {\n        'age1': 45,\n        'age2': 20,\n        'population': 'general'\n    }),\n    ('Sibling Demographics', {\n        'age1': 25,\n        'age2': 22,\n        'population': 'general'\n    }),\n    ('Endogamous Population', {\n        'age1': 35,\n        'age2': 40,\n        'population': 'endogamous'\n    })\n]\n\n# Create Bayesian inference model\nbayes_model = BayesianRelationshipInference()\n\n# Test with different combinations of features and demographic info\nprint(\"Bayesian relationship inference with multiple sources of prior knowledge:\")\nprint(\"=\" * 100)\n\nfor genetic_name, genetic_data in genetic_features:\n    print(f\"\\nGenetic data: {genetic_name}\")\n    print(\"-\" * 80)\n    \n    for demo_name, demographic_info in demographic_examples:\n        print(f\"\\nWith demographic info: {demo_name}\")\n        \n        # Infer relationship\n        posteriors = bayes_model.infer_relationship(genetic_data, demographic_info)\n        \n        # Sort by probability (descending)\n        sorted_posteriors = {k: v for k, v in sorted(posteriors.items(), key=lambda item: item[1], reverse=True)}\n        \n        # Print top 3 most likely relationships\n        top_3 = list(sorted_posteriors.items())[:3]\n        for rel, prob in top_3:\n            print(f\"  {rel}: {prob:.4f}\")\n\n# Show how demographic information affects the results for ambiguous cases\nambiguous_case = {\n    'genetic': {\n        'total_ibd': 1680,\n        'num_segments': 28,\n        'ibd1_fraction': 0.24,\n        'ibd2_fraction': 0.0\n    }\n}\n\nprint(\"\\n\\nAnalysis of ambiguous case (could be half-sibling, grandparent, or avuncular):\")\nprint(\"=\" * 100)\n\ndemographic_scenarios = [\n    ('No demographic info', None),\n    ('Ages consistent with half-siblings', {'age1': 35, 'age2': 32, 'population': 'general'}),\n    ('Ages consistent with grandparent', {'age1': 70, 'age2': 25, 'population': 'general'}),\n    ('Ages consistent with avuncular', {'age1': 45, 'age2': 20, 'population': 'general'})\n]\n\nfor scenario_name, demographic_info in demographic_scenarios:\n    print(f\"\\nScenario: {scenario_name}\")\n    \n    # Infer relationship\n    posteriors = bayes_model.infer_relationship(ambiguous_case, demographic_info)\n    \n    # Sort by probability (descending)\n    sorted_posteriors = {k: v for k, v in sorted(posteriors.items(), key=lambda item: item[1], reverse=True)}\n    \n    # Print top 5 most likely relationships\n    top_5 = list(sorted_posteriors.items())[:5]\n    for rel, prob in top_5:\n        print(f\"  {rel}: {prob:.4f}\")\n\n# Visualize how demographic information affects posteriors for the ambiguous case\nplt.figure(figsize=(12, 6))\n\n# Relationships of interest for the ambiguous case\nrel_focus = ['half-siblings', 'grandparent', 'avuncular', 'first-cousins']\n\n# Get posteriors for each scenario\nscenarios = []\nposteriors_list = []\n\nfor scenario_name, demographic_info in demographic_scenarios:\n    scenarios.append(scenario_name)\n    posteriors = bayes_model.infer_relationship(ambiguous_case, demographic_info)\n    posteriors_list.append([posteriors.get(rel, 0) for rel in rel_focus])\n\n# Create grouped bar chart\nx = np.arange(len(scenarios))\nwidth = 0.2\nmultiplier = 0\n\nfor i, relationship in enumerate(rel_focus):\n    offset = width * multiplier\n    plt.bar(x + offset, [posteriors[i] for posteriors in posteriors_list], width, label=relationship)\n    multiplier += 1\n\nplt.ylabel('Posterior Probability')\nplt.title('Effect of Demographic Information on Relationship Inference')\nplt.xticks(x + width, scenarios, rotation=45, ha='right')\nplt.legend(loc='upper left')\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Pedigree-Level Likelihood Calculations\n\nSo far, we've focused on pairwise relationship inference. However, Bonsai's power comes from its ability to reason about entire pedigrees, considering consistency among all relationships simultaneously. Let's explore how pedigree-level likelihoods are calculated.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 4.1 From Pairwise to Global Likelihood\n\nBonsai computes the likelihood of an entire pedigree by combining the likelihoods of all pairwise relationships implied by the pedigree. Let's implement a simple version of this approach:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class PedigreeLikelihood:\n    \"\"\"Calculator for pedigree-level likelihoods.\"\"\"\n    \n    def __init__(self, relationship_model=None):\n        \"\"\"Initialize pedigree likelihood calculator.\n        \n        Args:\n            relationship_model: Model for calculating pairwise relationship likelihoods\n        \"\"\"\n        self.relationship_model = relationship_model or MultivariateRelationshipModel('parent-child')\n        \n        # Cache for inferred relationships to avoid redundant computation\n        self.inferred_relationship_cache = {}\n    \n    def infer_relationship_from_pedigree(self, pedigree, id1, id2):\n        \"\"\"Infer relationship between two individuals based on pedigree structure.\n        \n        Args:\n            pedigree: Dictionary representing pedigree structure\n            id1: ID of first individual\n            id2: ID of second individual\n            \n        Returns:\n            Inferred relationship type\n        \"\"\"\n        # Check if result is in cache\n        cache_key = (min(id1, id2), max(id1, id2))\n        if cache_key in self.inferred_relationship_cache:\n            return self.inferred_relationship_cache[cache_key]\n        \n        # Helper function to get parents\n        def get_parents(indiv_id):\n            if indiv_id not in pedigree:\n                return (None, None)  # Individual not in pedigree\n            \n            father = pedigree[indiv_id].get('father')\n            mother = pedigree[indiv_id].get('mother')\n            return (father, mother)\n        \n        # Check if one is a direct ancestor of the other\n        def is_ancestor(ancestor_id, descendant_id, depth=0):\n            if depth > 10:  # Prevent excessive recursion\n                return False\n            \n            if descendant_id not in pedigree:\n                return False\n            \n            father, mother = get_parents(descendant_id)\n            \n            if father == ancestor_id or mother == ancestor_id:\n                return True\n            \n            # Recursively check parents\n            return (father and is_ancestor(ancestor_id, father, depth+1)) or \\\n                   (mother and is_ancestor(ancestor_id, mother, depth+1))\n        \n        # Identify parent-child\n        if is_ancestor(id1, id2):\n            result = 'parent-child'\n        elif is_ancestor(id2, id1):\n            result = 'parent-child'\n        \n        # Identify siblings\n        else:\n            father1, mother1 = get_parents(id1)\n            father2, mother2 = get_parents(id2)\n            \n            if father1 and father2 and mother1 and mother2:\n                # Both have known parents\n                if father1 == father2 and mother1 == mother2:\n                    result = 'full-siblings'\n                elif father1 == father2 or mother1 == mother2:\n                    result = 'half-siblings'\n                else:\n                    # Check for more distant relationships\n                    result = self._infer_distant_relationship(pedigree, id1, id2)\n            else:\n                # Can't determine sibling status with missing parents\n                result = self._infer_distant_relationship(pedigree, id1, id2)\n        \n        # Store result in cache\n        self.inferred_relationship_cache[cache_key] = result\n        return result\n    \n    def _infer_distant_relationship(self, pedigree, id1, id2):\n        \"\"\"Infer distant relationship between individuals.\n        \n        Simplified version - in a real implementation, would trace through\n        the pedigree to determine exact relationship.\n        \"\"\"\n        # For demonstration, we'll return a default value\n        return 'unrelated'\n    \n    def calculate_pedigree_likelihood(self, pedigree, ibd_segments):\n        \"\"\"Calculate the likelihood of a pedigree given observed IBD segments.\n        \n        Args:\n            pedigree: Dictionary representing pedigree structure\n            ibd_segments: Dictionary mapping pairs to IBD segments\n            \n        Returns:\n            Log-likelihood value\n        \"\"\"\n        total_log_likelihood = 0.0\n        \n        # Identify all pairs of individuals with IBD segments\n        pairs = list(ibd_segments.keys())\n        \n        # Calculate likelihood for each pair\n        for pair in pairs:\n            id1, id2 = pair\n            segments = ibd_segments[pair]\n            \n            # Infer relationship from pedigree\n            relationship = self.infer_relationship_from_pedigree(pedigree, id1, id2)\n            \n            # Calculate likelihood of observed segments given inferred relationship\n            if hasattr(self.relationship_model, 'calculate_log_likelihood_segments'):\n                # If model supports segment-based calculation\n                pair_likelihood = self.relationship_model.calculate_log_likelihood_segments(segments)\n            else:\n                # Create features from segments\n                features = {\n                    'total_ibd': sum(segments),\n                    'num_segments': len(segments),\n                    'mean_segment_length': sum(segments) / max(1, len(segments))\n                }\n                pair_likelihood = self.relationship_model.calculate_log_likelihood(features)\n            \n            # Add to total likelihood\n            total_log_likelihood += pair_likelihood\n        \n        return total_log_likelihood\n\n# Example pedigree structure\n\"\"\"\n        A1(-1)     A2(-2)   A3(-3)     A4(-4)\n          |  \\______/         |  \\______/\n          |         |         |         |\n        P1(1)     P2(2)     P3(3)     P4(4)\n          |         |         |         |\n          |         |         |         |\n        C1(5) -- C2(6)      C3(7) -- C4(8)\n                  |                    |\n                  |                    |\n                GC1(9)              GC2(10)\n\"\"\"\nexample_pedigree = {\n    # First generation (grandparents)\n    -1: {'father': None, 'mother': None, 'sex': 'M'},  # A1\n    -2: {'father': None, 'mother': None, 'sex': 'F'},  # A2\n    -3: {'father': None, 'mother': None, 'sex': 'M'},  # A3\n    -4: {'father': None, 'mother': None, 'sex': 'F'},  # A4\n    \n    # Second generation (parents)\n    1: {'father': -1, 'mother': -2, 'sex': 'M'},  # P1\n    2: {'father': -1, 'mother': -2, 'sex': 'F'},  # P2\n    3: {'father': -3, 'mother': -4, 'sex': 'M'},  # P3\n    4: {'father': -3, 'mother': -4, 'sex': 'F'},  # P4\n    \n    # Third generation (children)\n    5: {'father': 1, 'mother': None, 'sex': 'M'},  # C1\n    6: {'father': None, 'mother': 2, 'sex': 'F'},  # C2\n    7: {'father': 3, 'mother': None, 'sex': 'M'},  # C3\n    8: {'father': None, 'mother': 4, 'sex': 'F'},  # C4\n    \n    # Fourth generation (grandchildren)\n    9: {'father': None, 'mother': 6, 'sex': 'M'},   # GC1\n    10: {'father': None, 'mother': 8, 'sex': 'F'},  # GC2\n}\n\n# Visualize the pedigree\ndef visualize_pedigree(pedigree):\n    \"\"\"Create a visualization of a pedigree.\"\"\"\n    G = nx.DiGraph()\n    \n    # Add nodes\n    for id, info in pedigree.items():\n        # Label for the node\n        if id < 0:\n            label = f\"A{abs(id)}\"\n        else:\n            if id <= 4:\n                label = f\"P{id}\"\n            elif id <= 8:\n                label = f\"C{id-4}\"\n            else:\n                label = f\"GC{id-8}\"\n        \n        # Node color based on sex\n        if info.get('sex') == 'M':\n            color = 'lightblue'\n            shape = 's'  # square\n        elif info.get('sex') == 'F':\n            color = 'pink'\n            shape = 'o'  # circle\n        else:\n            color = 'lightgray'\n            shape = 'd'  # diamond\n        \n        G.add_node(id, label=label, color=color, shape=shape)\n    \n    # Add edges (directed from parent to child)\n    for child_id, info in pedigree.items():\n        if 'father' in info and info['father'] is not None:\n            G.add_edge(info['father'], child_id)\n        if 'mother' in info and info['mother'] is not None:\n            G.add_edge(info['mother'], child_id)\n    \n    # Create layout\n    pos = nx.nx_agraph.graphviz_layout(G, prog=\"dot\")\n    \n    # Draw the graph\n    plt.figure(figsize=(12, 8))\n    \n    # Draw nodes by shape and color\n    for shape in ['s', 'o', 'd']:\n        node_list = [n for n, d in G.nodes(data=True) if d.get('shape') == shape]\n        node_colors = [G.nodes[n].get('color', 'lightgray') for n in node_list]\n        if shape == 's':\n            nx.draw_networkx_nodes(G, pos, nodelist=node_list, node_shape=shape, \n                                  node_color=node_colors, node_size=500)\n        elif shape == 'o':\n            nx.draw_networkx_nodes(G, pos, nodelist=node_list, node_shape=shape, \n                                  node_color=node_colors, node_size=500)\n        else:\n            nx.draw_networkx_nodes(G, pos, nodelist=node_list, node_shape=shape, \n                                  node_color=node_colors, node_size=500)\n    \n    # Draw edges\n    nx.draw_networkx_edges(G, pos, arrows=True)\n    \n    # Draw labels\n    labels = {n: d.get('label', str(n)) for n, d in G.nodes(data=True)}\n    nx.draw_networkx_labels(G, pos, labels=labels)\n    \n    plt.title(\"Example Pedigree Structure\")\n    plt.axis('off')\n    plt.show()\n\n# Visualize the example pedigree\nvisualize_pedigree(example_pedigree)\n\n# Create example IBD segments\nexample_ibd_data = {\n    # Full siblings\n    (1, 2): [120, 105, 98, 87, 76, 65, 58, 52, 49, 45, 40, 38, 35, 33, 32, 30, 29, 28, 27, 26],\n    \n    # Parent-child\n    (2, 6): [175, 163, 155, 142, 130, 125, 112, 105, 98, 95, 88, 85, 82, 78, 75, 72, 68, 65, 55, 50, 45, 42],\n    \n    # Cousins\n    (5, 6): [75, 62, 58, 52, 45, 38, 35, 30, 28, 25],\n    \n    # Unrelated (some small segments due to background IBD or false positives)\n    (5, 10): [15, 10]\n}\n\n# Create a pedigree likelihood calculator\npedigree_calculator = PedigreeLikelihood(relationship_model=SegmentBasedModel('parent-child'))\n\n# Calculate the likelihood of the example pedigree\nexample_likelihood = pedigree_calculator.calculate_pedigree_likelihood(example_pedigree, example_ibd_data)\nprint(f\"Log-likelihood of example pedigree: {example_likelihood:.2f}\")\n\n# Let's also demonstrate how the likelihood changes with different pedigrees\nprint(\"\\nDemonstrating how likelihood changes with incorrect pedigrees:\")\n\n# Create a modified pedigree with an error (swapping parents)\nincorrect_pedigree_1 = example_pedigree.copy()\nincorrect_pedigree_1[6] = {'father': 1, 'mother': None, 'sex': 'F'}  # Changed father from None to 1\n\n# Calculate likelihood\nincorrect_likelihood_1 = pedigree_calculator.calculate_pedigree_likelihood(incorrect_pedigree_1, example_ibd_data)\nprint(f\"Log-likelihood of pedigree with incorrect parent: {incorrect_likelihood_1:.2f}\")\n\n# Create another modified pedigree with a different error (breaking sibling relationship)\nincorrect_pedigree_2 = example_pedigree.copy()\nincorrect_pedigree_2[2] = {'father': -3, 'mother': -4, 'sex': 'F'}  # Changed parents to be different from sibling\n\n# Calculate likelihood\nincorrect_likelihood_2 = pedigree_calculator.calculate_pedigree_likelihood(incorrect_pedigree_2, example_ibd_data)\nprint(f\"Log-likelihood of pedigree with incorrect sibling relationship: {incorrect_likelihood_2:.2f}\")\n\n# Compare likelihoods\nprint(f\"\\nLikelihood ratio (correct vs incorrect parent): {np.exp(example_likelihood - incorrect_likelihood_1):.2e}\")\nprint(f\"Likelihood ratio (correct vs incorrect sibling): {np.exp(example_likelihood - incorrect_likelihood_2):.2e}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 4.2 Relationship Consistency Constraints\n\nOne of the key advantages of pedigree-level likelihood calculations is the ability to enforce consistency constraints among relationships. For example, if A is a parent of B, and B is a parent of C, then A must be a grandparent of C (not some other relationship).\n\nLet's implement a function to check consistency constraints in a pedigree:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def check_pedigree_consistency(pedigree, ibd_data, tolerance=0.3):\n    \"\"\"Check if a pedigree is consistent with observed IBD data.\n    \n    Args:\n        pedigree: Dictionary representing pedigree structure\n        ibd_data: Dictionary mapping pairs to IBD segments\n        tolerance: Tolerance for deviations from expected IBD sharing\n        \n    Returns:\n        Tuple of (is_consistent, list_of_inconsistencies)\n    \"\"\"\n    inconsistencies = []\n    \n    # Get all pairs with IBD data\n    pairs = list(ibd_data.keys())\n    \n    # Helper function to calculate expected IBD sharing\n    def calculate_expected_ibd(relationship_type):\n        \"\"\"Calculate expected total IBD sharing for a relationship type.\"\"\"\n        if relationship_type == 'parent-child':\n            return 3540\n        elif relationship_type == 'full-siblings':\n            return 2550\n        elif relationship_type in ['half-siblings', 'grandparent', 'avuncular']:\n            return 1700\n        elif relationship_type == 'first-cousins':\n            return 850\n        elif relationship_type == 'second-cousins':\n            return 212\n        elif relationship_type == 'third-cousins':\n            return 53\n        else:\n            return 0  # Unknown or more distant\n    \n    # Create a relationship calculator\n    calculator = PedigreeLikelihood()\n    \n    # Check each pair\n    for pair in pairs:\n        id1, id2 = pair\n        segments = ibd_data[pair]\n        total_ibd = sum(segments)\n        \n        # Infer relationship from pedigree\n        inferred_relationship = calculator.infer_relationship_from_pedigree(pedigree, id1, id2)\n        \n        # Calculate expected IBD for this relationship\n        expected_ibd = calculate_expected_ibd(inferred_relationship)\n        \n        # Check if observed IBD is consistent with expected IBD\n        if expected_ibd > 0:  # Skip if relationship is unknown or very distant\n            # Calculate deviation from expected\n            deviation = abs(total_ibd - expected_ibd) / expected_ibd\n            \n            if deviation > tolerance:\n                inconsistency = {\n                    'pair': pair,\n                    'inferred_relationship': inferred_relationship,\n                    'expected_ibd': expected_ibd,\n                    'observed_ibd': total_ibd,\n                    'deviation': deviation\n                }\n                inconsistencies.append(inconsistency)\n    \n    # Return results\n    is_consistent = len(inconsistencies) == 0\n    return is_consistent, inconsistencies\n\n# Check consistency of our example pedigree\nis_consistent, inconsistencies = check_pedigree_consistency(example_pedigree, example_ibd_data)\n\nprint(f\"Is pedigree consistent with IBD data? {is_consistent}\")\nif not is_consistent:\n    print(\"\\nInconsistencies found:\")\n    for i, inconsistency in enumerate(inconsistencies):\n        print(f\"Inconsistency {i+1}:\")\n        print(f\"  Pair: {inconsistency['pair']}\")\n        print(f\"  Inferred relationship: {inconsistency['inferred_relationship']}\")\n        print(f\"  Expected IBD: {inconsistency['expected_ibd']:.2f} cM\")\n        print(f\"  Observed IBD: {inconsistency['observed_ibd']:.2f} cM\")\n        print(f\"  Deviation: {inconsistency['deviation']*100:.2f}%\")\n\n# Check consistency of an incorrect pedigree\nis_consistent_2, inconsistencies_2 = check_pedigree_consistency(incorrect_pedigree_1, example_ibd_data)\n\nprint(f\"\\nIs incorrect pedigree consistent with IBD data? {is_consistent_2}\")\nif not is_consistent_2:\n    print(\"\\nInconsistencies found in incorrect pedigree:\")\n    for i, inconsistency in enumerate(inconsistencies_2):\n        print(f\"Inconsistency {i+1}:\")\n        print(f\"  Pair: {inconsistency['pair']}\")\n        print(f\"  Inferred relationship: {inconsistency['inferred_relationship']}\")\n        print(f\"  Expected IBD: {inconsistency['expected_ibd']:.2f} cM\")\n        print(f\"  Observed IBD: {inconsistency['observed_ibd']:.2f} cM\")\n        print(f\"  Deviation: {inconsistency['deviation']*100:.2f}%\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Specialized Models for Complex Scenarios\n\nStandard relationship models work well for most cases, but some scenarios require specialized models. Let's explore models for several complex scenarios that are common in genetic genealogy.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 5.1 Models for Endogamous Populations\n\nEndogamous populations (those with a history of intermarriage within a small group) present unique challenges. In these populations, individuals share more IBD segments due to multiple distant relationships, making standard models unreliable.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class EndogamousPopulationModel:\n    \"\"\"Specialized model for relationship inference in endogamous populations.\"\"\"\n    \n    def __init__(self, endogamy_factor=2.0, background_ibd=50):\n        \"\"\"Initialize model for endogamous populations.\n        \n        Args:\n            endogamy_factor: Factor by which to increase expected IBD for distant relationships\n            background_ibd: Expected background IBD sharing in cM between 'unrelated' individuals\n        \"\"\"\n        self.endogamy_factor = endogamy_factor\n        self.background_ibd = background_ibd\n        \n        # Define relationship models with adjusted parameters\n        self.relationship_models = {}\n        \n        # Create models for each relationship type\n        # Close relationships are less affected by endogamy\n        self.relationship_models['parent-child'] = {\n            'expected_total_ibd': 3540,\n            'total_ibd_sd': 100,\n            'expected_segments': 40,\n            'segments_sd': 5\n        }\n        \n        self.relationship_models['full-siblings'] = {\n            'expected_total_ibd': 2550,\n            'total_ibd_sd': 250,  # Increased variance due to endogamy\n            'expected_segments': 35,\n            'segments_sd': 6  # Increased variance\n        }\n        \n        # More distant relationships are increasingly affected by endogamy\n        self.relationship_models['half-siblings'] = {\n            'expected_total_ibd': 1700 * 1.1,  # Slight increase\n            'total_ibd_sd': 350,  # Increased variance\n            'expected_segments': 25 * 1.2,  # More segments due to endogamy\n            'segments_sd': 7\n        }\n        \n        self.relationship_models['first-cousins'] = {\n            'expected_total_ibd': 850 * endogamy_factor * 0.9,  # Significantly increased\n            'total_ibd_sd': 300,\n            'expected_segments': 15 * endogamy_factor * 0.8,\n            'segments_sd': 8\n        }\n        \n        self.relationship_models['second-cousins'] = {\n            'expected_total_ibd': 212 * endogamy_factor,\n            'total_ibd_sd': 150,\n            'expected_segments': 5 * endogamy_factor,\n            'segments_sd': 4\n        }\n        \n        self.relationship_models['third-cousins'] = {\n            'expected_total_ibd': 53 * endogamy_factor * 1.2,\n            'total_ibd_sd': 100,\n            'expected_segments': 2 * endogamy_factor * 1.3,\n            'segments_sd': 3\n        }\n        \n        self.relationship_models['unrelated'] = {\n            'expected_total_ibd': background_ibd,\n            'total_ibd_sd': background_ibd * 0.8,\n            'expected_segments': background_ibd / 25,  # Rough estimate\n            'segments_sd': 2\n        }\n    \n    def calculate_relationship_likelihood(self, relationship, features):\n        \"\"\"Calculate log-likelihood of features under a specific relationship model.\n        \n        Args:\n            relationship: Type of relationship\n            features: Dictionary with observed features\n            \n        Returns:\n            Log-likelihood value\n        \"\"\"\n        if relationship not in self.relationship_models:\n            return float('-inf')  # Unknown relationship\n        \n        model = self.relationship_models[relationship]\n        log_likelihood = 0.0\n        \n        # Component for total IBD\n        if 'total_ibd' in features:\n            log_likelihood += norm.logpdf(features['total_ibd'], \n                                         model['expected_total_ibd'], \n                                         model['total_ibd_sd'])\n        \n        # Component for number of segments\n        if 'num_segments' in features:\n            log_likelihood += norm.logpdf(features['num_segments'], \n                                         model['expected_segments'], \n                                         model['segments_sd'])\n        \n        return log_likelihood\n    \n    def infer_relationship(self, features):\n        \"\"\"Infer most likely relationship type for an endogamous population.\n        \n        Args:\n            features: Dictionary with observed features\n            \n        Returns:\n            Tuple of (most_likely_relationship, log_likelihood, all_likelihoods)\n        \"\"\"\n        all_likelihoods = {}\n        \n        # Calculate likelihood for each relationship type\n        for relationship in self.relationship_models.keys():\n            log_likelihood = self.calculate_relationship_likelihood(relationship, features)\n            all_likelihoods[relationship] = log_likelihood\n        \n        # Find most likely relationship\n        most_likely = max(all_likelihoods.items(), key=lambda x: x[1])\n        most_likely_relationship = most_likely[0]\n        max_log_likelihood = most_likely[1]\n        \n        return most_likely_relationship, max_log_likelihood, all_likelihoods\n\n# Example data for endogamous population\nendogamous_examples = [\n    ('Parent-Child Example', {\n        'total_ibd': 3520,\n        'num_segments': 42\n    }),\n    ('Full Siblings Example', {\n        'total_ibd': 2600,\n        'num_segments': 37\n    }),\n    ('Half Siblings Example', {\n        'total_ibd': 1900,  # Higher than expected in non-endogamous\n        'num_segments': 30  # More segments than expected in non-endogamous\n    }),\n    ('First Cousins Example', {\n        'total_ibd': 1450,  # Much higher than expected in non-endogamous\n        'num_segments': 25  # Many more segments than expected in non-endogamous\n    }),\n    ('Second Cousins Example', {\n        'total_ibd': 650,  # Much higher than expected in non-endogamous\n        'num_segments': 16  # Many more segments than expected in non-endogamous\n    }),\n    ('Third Cousins Example', {\n        'total_ibd': 250,  # Much higher than expected in non-endogamous\n        'num_segments': 8  # Many more segments than expected in non-endogamous\n    }),\n    ('Unrelated Example', {\n        'total_ibd': 95,  # Background IBD in endogamous population\n        'num_segments': 4\n    })\n]\n\n# Create models with different endogamy factors\nstandard_model = EndogamousPopulationModel(endogamy_factor=1.0, background_ibd=10)  # No endogamy\nmoderate_endogamy_model = EndogamousPopulationModel(endogamy_factor=2.0, background_ibd=50)\nhigh_endogamy_model = EndogamousPopulationModel(endogamy_factor=3.5, background_ibd=100)\n\n# Compare results using different models\nprint(\"Relationship inference in endogamous populations:\")\nprint(\"=\" * 100)\n\nfor example_name, features in endogamous_examples:\n    print(f\"\\n{example_name}:\")\n    print(f\"  Total IBD: {features['total_ibd']} cM, Segments: {features['num_segments']}\")\n    \n    # Standard model\n    rel_std, ll_std, _ = standard_model.infer_relationship(features)\n    print(f\"  Standard model (no endogamy): {rel_std} (log-likelihood: {ll_std:.2f})\")\n    \n    # Moderate endogamy model\n    rel_mod, ll_mod, _ = moderate_endogamy_model.infer_relationship(features)\n    print(f\"  Moderate endogamy model: {rel_mod} (log-likelihood: {ll_mod:.2f})\")\n    \n    # High endogamy model\n    rel_high, ll_high, _ = high_endogamy_model.infer_relationship(features)\n    print(f\"  High endogamy model: {rel_high} (log-likelihood: {ll_high:.2f})\")\n\n# Visualize how the expected IBD changes with endogamy\nplt.figure(figsize=(12, 6))\n\n# Define relationships to show\nrelationships = ['first-cousins', 'second-cousins', 'third-cousins', 'unrelated']\nendogamy_factors = [1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n\nfor relationship in relationships:\n    expected_ibd = []\n    for factor in endogamy_factors:\n        model = EndogamousPopulationModel(endogamy_factor=factor, background_ibd=25*factor)\n        expected_ibd.append(model.relationship_models[relationship]['expected_total_ibd'])\n    \n    plt.plot(endogamy_factors, expected_ibd, marker='o', label=relationship)\n\nplt.xlabel('Endogamy Factor')\nplt.ylabel('Expected Total IBD (cM)')\nplt.title('Effect of Endogamy on Expected IBD Sharing')\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Exercises\n\nNow that we've explored advanced likelihood calculations in Bonsai, let's complete some exercises to deepen our understanding.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 1: Implement a Custom Relationship Model\n\nCreate a custom relationship model for a specific scenario that we haven't covered yet. For example, you could implement a model for:\n- Double first cousins (share both sets of grandparents)\n- Complex relationships (e.g., half-sibling and also first cousin)\n- Populations with unusual recombination rates",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Exercise 1: Your solution here\n# Hint: Start by defining expected IBD sharing for your chosen relationship type",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 2: Create a More Sophisticated Bayesian Model\n\nEnhance the Bayesian relationship inference model to incorporate additional types of prior knowledge, such as:\n- Known or suspected family structures\n- Historical demographic information\n- Geographical proximity information\n- Shared surnames or other metadata",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Exercise 2: Your solution here\n# Hint: Modify the calculate_prior method of the BayesianRelationshipInference class",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 3: Implement a Segment-Based Model for Endogamous Populations\n\nCombine the segment-based model and the endogamous population model to create a more accurate model for endogamous populations that considers the distribution of segment lengths.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Exercise 3: Your solution here\n# Hint: Modify the segment_length_pdf method to account for endogamy",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 4: Improve the Pedigree Consistency Check\n\nEnhance the pedigree consistency checking function to handle more complex pedigrees and provide more detailed diagnostic information.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Exercise 4: Your solution here\n# Hint: Add checks for specific relationships like parent-child, siblings, etc.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 5: Evaluate Model Performance\n\nDesign and implement a simulation to evaluate the performance of different relationship inference models. Compare their accuracy on simulated data with known true relationships.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Exercise 5: Your solution here\n# Hint: Generate simulated data with varying noise levels and test each model",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Conclusion\n\nIn this lab, we've explored advanced likelihood calculations in Bonsai, from the statistical foundations to specialized models for complex scenarios. We've implemented and tested various models for relationship inference, and seen how these models can be combined to infer entire pedigrees.\n\nKey takeaways:\n- Likelihood functions provide a principled way to evaluate genetic relationship hypotheses\n- Advanced likelihood models incorporate multiple features and their correlations\n- Bayesian approaches allow us to integrate prior knowledge with genetic evidence\n- Pedigree-level analysis considers consistency among all relationships\n- Specialized models are needed for complex scenarios like endogamous populations\n\nIn the next lab, we'll explore optimization techniques used in Bonsai to efficiently search the space of possible pedigrees.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}